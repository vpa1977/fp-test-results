#####
baseline-baseline-py-id - Run 1
2024-02-23 10:15:54
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.00it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 48.96it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.99it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.99it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.02it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.02it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.01it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.03it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.04it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.05it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.07it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.11it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.12it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.12it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.10it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.12it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.13it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.11it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.11it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.11it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.07it/s]
STAGE:2024-02-23 10:14:54 178476:178476 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:14:54 178476:178476 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:14:54 178476:178476 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.29it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.53it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.62it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.65it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.67it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.69it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.72it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.74it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.77it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.78it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.78it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.79it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.78it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.76it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 37.75it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.74it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.74it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.74it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.66it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.30it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.01it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 36.84it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 36.74it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 36.67it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 36.89it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 37.15it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.33it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.47it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.56it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.64it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.68it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.74it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 37.77it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 37.77it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 37.78it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.83it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.84it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.84it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.86it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.83it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.82it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 37.80it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 37.79it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 37.79it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.79it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.78it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 37.76it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.78it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.78it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.79it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.78it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 37.79it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 37.78it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.80it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.81it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.81it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.82it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 37.80it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.78it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.79it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 37.81it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 37.81it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 37.82it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.80it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.81it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:19, 37.79it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.77it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.75it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.77it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.77it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 37.79it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 37.79it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.81it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.81it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 37.79it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.78it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.62it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.45it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.54it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.62it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 37.67it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.75it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.78it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.80it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.83it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.86it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.85it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.85it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 37.85it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 37.84it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.83it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.84it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 37.83it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.82it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.66it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.51it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.51it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.52it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 37.52it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.54it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.54it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 37.56it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 37.54it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.54it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.52it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.57it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.60it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 37.64it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.65it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.67it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.68it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 37.69it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.69it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.70it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.71it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.72it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.74it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.75it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.76it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 37.79it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 37.77it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.77it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.78it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.78it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.78it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 37.79it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.80it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.81it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 37.82it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 37.82it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.85it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.85it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.85it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.85it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 37.84it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.83it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.81it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.80it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 37.80it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 37.81it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.83it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.81it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.81it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.81it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 37.81it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.81it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 37.81it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 37.81it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.82it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.82it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.81it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.80it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 37.79it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.77it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.77it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 37.78it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 37.77it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.76it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.73it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.76it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.76it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.77it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.76it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.75it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.76it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 37.77it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.78it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.77it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.76it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.77it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.77it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 37.75it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.75it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 37.76it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 37.77it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.77it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.80it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.78it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.77it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 37.78it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.79it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.80it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.78it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 37.79it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.80it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.81it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.82it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.82it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.81it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.80it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.80it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.78it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 37.77it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 37.77it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.78it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.77it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.77it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.77it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 37.78it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.78it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.79it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 37.79it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 37.79it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.79it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.77it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.76it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.78it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.79it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.80it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.79it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.77it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 37.78it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 37.79it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.82it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.83it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.82it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.82it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.81it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.81it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.80it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 37.79it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 37.78it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.76it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.76it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.74it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.72it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.73it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.73it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 37.73it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.75it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.75it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.75it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.75it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.75it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.76it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 37.76it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 37.76it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.77it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.77it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.77it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.78it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.78it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.73it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.23it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.33it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.38it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.40it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.38it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 37.42it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.43it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.44it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.44it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.44it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 37.45it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 37.45it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 37.47it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 37.48it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 37.47it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 37.48it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 37.50it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 37.49it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 37.49it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 37.52it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 37.51it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.46it/s]
STAGE:2024-02-23 10:15:24 178476:178476 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:15:24 178476:178476 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:15:24 178476:178476 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:27, 36.74it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 36.98it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.07it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.13it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:26, 37.15it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:26, 37.18it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:26, 37.19it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:26, 37.23it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.26it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.25it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.25it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.23it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.24it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:25, 37.24it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:25, 37.23it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:25, 37.24it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:25, 37.25it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.26it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.23it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.23it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.23it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.22it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:24, 37.23it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:24, 37.22it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:24, 37.22it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:24, 37.24it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 37.23it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:03<00:23, 37.23it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 37.23it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.23it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.21it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:23, 37.22it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:23, 37.21it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:23, 37.19it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:23, 37.20it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:23, 37.21it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 37.21it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:22, 37.22it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 37.21it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.22it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.22it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 37.23it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:22, 37.23it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 37.23it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 37.23it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 37.23it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:21, 37.24it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 37.24it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 37.24it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 37.25it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 37.25it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:20, 37.24it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:20, 37.25it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 37.26it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 37.25it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 37.25it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 37.26it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 37.27it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:20, 37.28it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 37.28it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 37.26it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 37.25it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 37.24it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 37.22it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 37.21it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 37.23it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:18, 37.22it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:18, 37.20it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 37.21it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 37.21it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 37.24it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 37.22it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 37.23it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 37.22it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 37.23it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:17, 37.24it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:17, 37.22it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 37.22it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 37.24it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 37.26it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 37.24it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 37.24it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 37.26it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 37.25it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 37.26it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:16, 37.27it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:16, 37.27it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 37.28it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 37.26it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 37.27it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 37.26it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 37.26it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 37.25it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 37.25it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:15, 37.25it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:15, 37.26it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 37.28it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 37.29it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 37.30it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 37.30it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 37.29it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:15, 37.27it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 37.27it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:14, 37.27it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:14, 37.27it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 37.27it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 37.26it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 37.27it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 37.26it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 37.27it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:14, 37.25it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 37.23it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 37.21it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:13, 37.20it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 37.22it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 37.23it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 37.23it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 37.24it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 37.24it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 37.25it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 37.26it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 37.26it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:12, 37.25it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 37.26it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 37.26it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 37.26it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 37.25it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 37.27it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 37.24it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:12, 37.23it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 37.24it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:11, 37.25it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:11, 37.24it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 37.23it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 37.24it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 37.26it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 37.25it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 37.26it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:11, 37.25it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 37.25it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:10, 37.24it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:10, 37.25it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 37.24it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 37.25it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 37.26it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 37.23it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 37.22it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:10, 37.24it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 37.23it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 37.23it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:09, 37.24it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:09, 37.23it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 37.21it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 37.23it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 37.23it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 37.23it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:09, 37.24it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:09, 37.25it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 37.25it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:08, 37.25it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:08, 37.26it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 37.25it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 37.25it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 37.25it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 37.22it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:08, 37.22it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:08, 37.21it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 37.22it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:07, 37.23it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:07, 37.23it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 37.23it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 37.24it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 37.26it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 37.26it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 37.25it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:07, 37.25it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 37.25it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 37.25it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:06, 37.26it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 37.25it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 37.26it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 37.25it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 37.25it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 37.24it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:06, 37.23it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:06, 37.22it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 37.22it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:05, 37.23it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 37.24it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 37.23it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 37.25it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 37.26it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 37.26it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 37.24it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:05, 37.24it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 37.25it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 37.25it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 37.25it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 37.27it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 37.27it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 37.30it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 37.30it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 37.29it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 37.28it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 37.28it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 37.28it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 37.27it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 37.25it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:03, 37.23it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 37.24it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 37.23it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 37.24it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 37.25it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 37.25it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 37.25it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 37.25it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 37.27it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 37.26it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:24<00:01, 37.28it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 37.29it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 37.28it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 37.26it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:25<00:01, 37.25it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 37.25it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 37.23it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 37.23it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 37.23it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 37.21it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 37.23it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 37.23it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 37.24it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:26<00:00, 37.24it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 37.26it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 37.25it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 37.25it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 37.27it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.26it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.24it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 27.45 GB
    total: 31.28 GB
    used: 3.36 GB
  system:
    node: baseline
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.379 us +/- 6.325 us [92.268 us, 234.127 us]
        batches_per_second: 10.41 K +/- 507.43 [4.27 K, 10.84 K]
      metrics:
        batches_per_second_max: 10837.994832041344
        batches_per_second_mean: 10406.780842233904
        batches_per_second_min: 4271.185336048879
        batches_per_second_std: 507.4346854968104
        seconds_per_batch_max: 0.00023412704467773438
        seconds_per_batch_mean: 9.637880325317383e-05
        seconds_per_batch_min: 9.226799011230469e-05
        seconds_per_batch_std: 6.325211364910243e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.513 us +/- 0.771 us [23.127 us, 33.379 us]
        batches_per_second: 40.83 K +/- 1.12 K [29.96 K, 43.24 K]
      metrics:
        batches_per_second_max: 43240.24742268041
        batches_per_second_mean: 40829.72254903667
        batches_per_second_min: 29959.314285714285
        batches_per_second_std: 1120.4272233646914
        seconds_per_batch_max: 3.337860107421875e-05
        seconds_per_batch_mean: 2.4513006210327148e-05
        seconds_per_batch_min: 2.3126602172851562e-05
        seconds_per_batch_std: 7.712675207793416e-07
    on_device_inference:
      human_readable:
        batch_latency: -26351896.137 us +/- 169.302 ms [-27448095.322 us, -26168415.070
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03643240043731
        batches_per_second_mean: -0.03794945373041223
        batches_per_second_min: -0.03821400712809952
        batches_per_second_std: 0.0002366528288662807
        seconds_per_batch_max: -26.168415069580078
        seconds_per_batch_mean: -26.35189613723755
        seconds_per_batch_min: -27.448095321655273
        seconds_per_batch_std: 0.169302114372479
    total:
      human_readable:
        batch_latency: 26.484 ms +/- 171.332 us [26.297 ms, 27.719 ms]
        batches_per_second: 37.76 +/- 0.24 [36.08, 38.03]
      metrics:
        batches_per_second_max: 38.027017715643076
        batches_per_second_mean: 37.76002720273699
        batches_per_second_min: 36.076620706857845
        batches_per_second_std: 0.23704518721029033
        seconds_per_batch_max: 0.027718782424926758
        seconds_per_batch_mean: 0.02648410725593567
        seconds_per_batch_min: 0.02629709243774414
        seconds_per_batch_std: 0.00017133155924046453
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.605 us +/- 6.493 us [144.005 us, 293.255 us]
        batches_per_second: 6.74 K +/- 227.58 [3.41 K, 6.94 K]
      metrics:
        batches_per_second_max: 6944.211920529801
        batches_per_second_mean: 6738.736744258814
        batches_per_second_min: 3410.0032520325203
        batches_per_second_std: 227.58486426276
        seconds_per_batch_max: 0.0002932548522949219
        seconds_per_batch_mean: 0.0001486051082611084
        seconds_per_batch_min: 0.00014400482177734375
        seconds_per_batch_std: 6.492737977177144e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.994 us +/- 1.131 us [23.365 us, 49.829 us]
        batches_per_second: 40.07 K +/- 1.31 K [20.07 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40066.56855616348
        batches_per_second_min: 20068.44019138756
        batches_per_second_std: 1305.651661765127
        seconds_per_batch_max: 4.982948303222656e-05
        seconds_per_batch_mean: 2.4993896484375e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 1.1307621902633598e-06
    on_device_inference:
      human_readable:
        batch_latency: -26647264.980 us +/- 57.267 ms [-27810112.000 us, -26425439.835
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03595814357085501
        batches_per_second_mean: -0.037527473864877335
        batches_per_second_min: -0.03784232187843682
        batches_per_second_std: 7.929825369217458e-05
        seconds_per_batch_max: -26.425439834594727
        seconds_per_batch_mean: -26.647264980316162
        seconds_per_batch_min: -27.81011199951172
        seconds_per_batch_std: 0.057266580644893386
    total:
      human_readable:
        batch_latency: 26.833 ms +/- 61.105 us [26.606 ms, 28.154 ms]
        batches_per_second: 37.27 +/- 0.08 [35.52, 37.59]
      metrics:
        batches_per_second_max: 37.5850530937766
        batches_per_second_mean: 37.26822194064138
        batches_per_second_min: 35.518460808888285
        batches_per_second_std: 0.0830537168520779
        seconds_per_batch_max: 0.028154373168945312
        seconds_per_batch_mean: 0.026832647800445558
        seconds_per_batch_min: 0.026606321334838867
        seconds_per_batch_std: 6.110468201261666e-05


#####
baseline-baseline-py-id - Run 2
2024-02-23 10:17:00
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.02it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.01it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.75it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.76it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.80it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.78it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.76it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.75it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.77it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.77it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.78it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.77it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.78it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.79it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.79it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.80it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.79it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.83it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.82it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.79it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.79it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.79it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.78it/s]
STAGE:2024-02-23 10:16:02 178522:178522 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:16:02 178522:178522 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:16:02 178522:178522 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.80it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 38.07it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.19it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.25it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.29it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.30it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.31it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.32it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.31it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 38.29it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.31it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.31it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.33it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.28it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.25it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:24, 38.25it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 38.25it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 38.26it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.26it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.27it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.27it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.27it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.25it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.27it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.29it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 38.28it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.29it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.30it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.29it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.29it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.31it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.30it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.32it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.32it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.33it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 38.33it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.33it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.33it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.33it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.31it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 38.29it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 38.28it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.28it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.27it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.26it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.28it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.30it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.32it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.31it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.32it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:19, 38.32it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.32it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.31it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.31it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.35it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.36it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.36it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:19, 38.37it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:18, 38.35it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 38.33it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.32it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.32it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.33it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.34it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.35it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.33it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.34it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 38.35it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:17, 38.34it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.34it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.34it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.33it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.31it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.31it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.29it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.28it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 38.28it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 38.27it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:16, 38.27it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.29it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.31it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.31it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.32it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.32it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.31it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.31it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 38.30it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:15, 38.30it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.31it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.32it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.32it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.32it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.33it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.34it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.34it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 38.34it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 38.35it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.33it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 38.34it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.31it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.31it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.33it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.35it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 38.35it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 38.34it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 38.33it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.32it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.31it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.30it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.31it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.32it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.31it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.31it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:12, 38.30it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 38.29it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.31it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.29it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.31it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.32it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.32it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.30it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.28it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 38.29it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 38.30it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 38.30it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.29it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.30it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.30it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.29it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.28it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.29it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.31it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:10, 38.30it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 38.30it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.30it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.30it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.32it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.32it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 38.34it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.30it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 38.32it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.34it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.34it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.34it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.36it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 38.37it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 38.37it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:06, 38.36it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.33it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.34it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.34it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.33it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.33it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.33it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.32it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:06, 38.33it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 38.34it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.34it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.33it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.31it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.32it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.32it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.31it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.32it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 38.33it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:05, 38.32it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 38.34it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.37it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.38it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.38it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.37it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.37it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.37it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.36it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 38.35it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 38.35it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.33it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.33it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.37it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 38.36it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 38.37it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 38.35it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.32it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 38.33it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.36it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 38.37it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 38.37it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 38.37it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.37it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.36it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.37it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.36it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.34it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.32it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.78it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.92it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.95it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.97it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.98it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 37.97it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.97it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.99it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 38.01it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 38.01it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 38.02it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 38.04it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 38.07it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 38.08it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 38.07it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 38.07it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 38.07it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 38.07it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 38.07it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 38.07it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 38.06it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 38.06it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 38.07it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 38.09it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.07it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.04it/s]
STAGE:2024-02-23 10:16:31 178522:178522 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:16:31 178522:178522 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:16:31 178522:178522 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.36it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.59it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.68it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.73it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 37.77it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 37.79it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.79it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.79it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.79it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.80it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.81it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.83it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.83it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 37.82it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 37.80it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 37.80it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 37.80it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.80it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.81it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.82it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.84it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.85it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 37.86it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 37.86it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 37.85it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 37.85it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 37.85it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 37.86it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 37.86it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.87it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.86it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:23, 37.86it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 37.88it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 37.86it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 37.86it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 37.86it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 37.85it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:22, 37.86it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 37.86it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.87it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.86it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 37.87it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 37.87it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 37.87it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 37.86it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 37.86it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:21, 37.87it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 37.85it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 37.87it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 37.89it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:21, 37.87it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 37.87it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 37.85it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 37.86it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 37.85it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:20, 37.86it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:20, 37.87it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 37.87it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 37.86it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 37.86it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 37.86it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 37.86it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 37.88it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 37.87it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 37.88it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 37.89it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 37.89it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 37.89it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 37.89it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:18, 37.90it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 37.90it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 37.88it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 37.85it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 37.85it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 37.85it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:18, 37.84it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 37.84it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 37.85it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 37.85it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:17, 37.85it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 37.85it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 37.85it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 37.86it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 37.86it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:17, 37.85it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 37.85it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 37.86it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 37.85it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 37.84it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:16, 37.84it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 37.82it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 37.84it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 37.86it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:16, 37.86it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:16, 37.85it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 37.84it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 37.85it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 37.81it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:15, 37.82it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 37.80it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 37.81it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 37.82it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 37.85it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:15, 37.84it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 37.83it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 37.82it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 37.82it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 37.73it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 37.33it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:15, 37.08it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:15, 36.89it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:15, 36.78it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:14, 36.68it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 36.62it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 36.56it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 36.53it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 36.50it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 36.51it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:14, 36.50it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:14, 36.50it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:14, 36.50it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 36.88it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 37.18it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 37.38it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 37.50it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 37.60it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 37.65it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 37.71it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 37.75it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 37.78it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 37.81it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 37.80it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 37.79it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 37.80it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 37.79it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 37.77it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:11, 37.78it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 37.76it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 37.78it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 37.78it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 37.78it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 37.78it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 37.78it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 37.78it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 37.81it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 37.82it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 37.80it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 37.79it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 37.80it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 37.80it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 37.80it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:09, 37.81it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 37.82it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 37.81it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 37.82it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 37.82it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 37.83it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 37.84it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 37.86it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 37.86it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:08, 37.88it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 37.88it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 37.88it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 37.88it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 37.87it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 37.87it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 37.87it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 37.88it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 37.89it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:08, 37.89it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:07, 37.89it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 37.89it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 37.88it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 37.85it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 37.87it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 37.88it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 37.89it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 37.90it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 37.89it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:06, 37.88it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 37.87it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 37.88it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 37.89it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 37.89it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 37.90it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 37.90it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 37.90it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 37.91it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:06, 37.91it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 37.89it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 37.89it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 37.87it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 37.88it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 37.87it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 37.87it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 37.87it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 37.87it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 37.88it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:04, 37.88it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 37.88it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 37.89it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 37.89it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 37.87it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 37.88it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 37.88it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 37.87it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 37.89it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 37.89it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 37.88it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 37.87it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 37.87it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 37.86it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 37.86it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 37.87it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 37.87it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 37.88it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 37.87it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:02, 37.88it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 37.86it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 37.84it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 37.84it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 37.83it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 37.83it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 37.83it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 37.83it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 37.83it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 37.83it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:24<00:01, 37.81it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 37.81it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 37.81it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 37.82it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 37.82it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 37.82it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 37.83it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 37.84it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 37.83it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 37.84it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 37.86it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 37.85it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 37.85it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 37.84it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 37.82it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 37.83it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 37.82it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 37.82it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.83it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.77it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 27.45 GB
    total: 31.28 GB
    used: 3.36 GB
  system:
    node: baseline
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.448 us +/- 5.792 us [91.553 us, 224.829 us]
        batches_per_second: 10.50 K +/- 472.35 [4.45 K, 10.92 K]
      metrics:
        batches_per_second_max: 10922.666666666666
        batches_per_second_mean: 10503.62654254495
        batches_per_second_min: 4447.83032873807
        batches_per_second_std: 472.354451993577
        seconds_per_batch_max: 0.00022482872009277344
        seconds_per_batch_mean: 9.544825553894043e-05
        seconds_per_batch_min: 9.1552734375e-05
        seconds_per_batch_std: 5.791579790151486e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.373 us +/- 0.775 us [23.365 us, 34.094 us]
        batches_per_second: 41.06 K +/- 1.08 K [29.33 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 41062.639351657876
        batches_per_second_min: 29330.797202797203
        batches_per_second_std: 1081.0988336839748
        seconds_per_batch_max: 3.409385681152344e-05
        seconds_per_batch_mean: 2.4373292922973633e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 7.747891833533015e-07
    on_device_inference:
      human_readable:
        batch_latency: -25947160.196 us +/- 52.462 ms [-27063135.147 us, -25840576.172
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03695063393670972
        batches_per_second_mean: -0.038540017603408284
        batches_per_second_min: -0.0386988275086685
        batches_per_second_std: 7.646707244011914e-05
        seconds_per_batch_max: -25.840576171875
        seconds_per_batch_mean: -25.94716019630432
        seconds_per_batch_min: -27.063135147094727
        seconds_per_batch_std: 0.05246158966195683
    total:
      human_readable:
        batch_latency: 26.079 ms +/- 56.751 us [25.969 ms, 27.341 ms]
        batches_per_second: 38.35 +/- 0.08 [36.57, 38.51]
      metrics:
        batches_per_second_max: 38.50776250677096
        batches_per_second_mean: 38.34591236189525
        batches_per_second_min: 36.57461762500218
        batches_per_second_std: 0.08154367625942649
        seconds_per_batch_max: 0.027341365814208984
        seconds_per_batch_mean: 0.026078519582748413
        seconds_per_batch_min: 0.02596879005432129
        seconds_per_batch_std: 5.675137785338814e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.194 us +/- 6.147 us [144.005 us, 288.486 us]
        batches_per_second: 6.76 K +/- 214.59 [3.47 K, 6.94 K]
      metrics:
        batches_per_second_max: 6944.211920529801
        batches_per_second_mean: 6756.398634461308
        batches_per_second_min: 3466.3669421487602
        batches_per_second_std: 214.5850168767208
        seconds_per_batch_max: 0.0002884864807128906
        seconds_per_batch_mean: 0.0001481943130493164
        seconds_per_batch_min: 0.00014400482177734375
        seconds_per_batch_std: 6.147329902464376e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.052 us +/- 0.706 us [23.603 us, 34.332 us]
        batches_per_second: 39.94 K +/- 983.89 [29.13 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 39943.938218538045
        batches_per_second_min: 29127.11111111111
        batches_per_second_std: 983.8886899521597
        seconds_per_batch_max: 3.4332275390625e-05
        seconds_per_batch_mean: 2.5052309036254882e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 7.056976891858709e-07
    on_device_inference:
      human_readable:
        batch_latency: -26272470.438 us +/- 227.498 ms [-27359584.808 us, -26097215.652
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.0365502622574455
        batches_per_second_mean: -0.03806542057400538
        batches_per_second_min: -0.0383182640369343
        batches_per_second_std: 0.00031929298399193285
        seconds_per_batch_max: -26.09721565246582
        seconds_per_batch_mean: -26.27247043800354
        seconds_per_batch_min: -27.35958480834961
        seconds_per_batch_std: 0.22749825182479086
    total:
      human_readable:
        batch_latency: 26.458 ms +/- 229.118 us [26.280 ms, 27.699 ms]
        batches_per_second: 37.80 +/- 0.32 [36.10, 38.05]
      metrics:
        batches_per_second_max: 38.05220231344976
        batches_per_second_mean: 37.79883693907137
        batches_per_second_min: 36.103016113482994
        batches_per_second_std: 0.3170537151834809
        seconds_per_batch_max: 0.027698516845703125
        seconds_per_batch_mean: 0.026457762241363526
        seconds_per_batch_min: 0.026279687881469727
        seconds_per_batch_std: 0.00022911799654954526


#####
baseline-baseline-py-id - Run 3
2024-02-23 10:18:05
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.74it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 50.27it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 50.26it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 50.28it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 50.30it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 50.27it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 50.26it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 50.26it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 50.25it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 50.26it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 50.25it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 50.26it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 50.28it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 50.27it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 50.26it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 50.25it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 50.25it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 50.26it/s]
STAGE:2024-02-23 10:17:08 178571:178571 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:17:09 178571:178571 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:17:09 178571:178571 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 38.13it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 38.34it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.40it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.48it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.51it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.54it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.55it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.56it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 38.57it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 38.58it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 38.59it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.59it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.59it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.60it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.61it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.61it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.61it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.61it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 38.58it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 38.58it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 38.58it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.56it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.55it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.53it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.54it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.51it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.52it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.53it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 38.54it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.54it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:21, 38.54it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 38.54it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.52it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.53it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.54it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.56it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.56it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.56it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.55it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:20, 38.55it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:20, 38.55it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.55it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.55it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.56it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.56it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.55it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.56it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.56it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.57it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:19, 38.58it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:19, 38.57it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.55it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.55it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.56it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.56it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.56it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.54it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.53it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:18, 38.53it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:18, 38.53it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 38.53it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.51it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.52it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.52it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.53it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.54it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.54it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.55it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:07<00:17, 38.55it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:17, 38.55it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.55it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.55it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.56it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.53it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.53it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.52it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.53it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 38.53it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:16, 38.53it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:16, 38.55it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.55it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.57it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.57it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.56it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.55it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.55it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.56it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:09<00:15, 38.55it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:15, 38.55it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.53it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.55it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.54it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.55it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.53it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.53it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.52it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 38.52it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:10<00:14, 38.52it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:14, 38.52it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.52it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.52it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.51it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.52it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.52it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.51it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.50it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:11<00:14, 38.52it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:13, 38.53it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.54it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.53it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.54it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.54it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.53it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.51it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.52it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 38.53it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:12<00:12, 38.54it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 38.53it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.53it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.53it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.52it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.53it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.54it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.54it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.54it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:12, 38.54it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:11, 38.55it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.54it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.54it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.52it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.52it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.51it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.50it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.50it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 38.51it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:14<00:11, 38.51it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 38.51it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.51it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.51it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.50it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.50it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.50it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.49it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.49it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:10, 38.51it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:15<00:09, 38.52it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.51it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.50it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.52it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.51it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.52it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.52it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.51it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 38.51it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:16<00:09, 38.53it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 38.54it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.53it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.51it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.53it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.52it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.53it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.52it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.52it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:08, 38.51it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:17<00:07, 38.53it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.52it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.52it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.53it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.54it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.52it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.53it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.52it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 38.54it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:07, 38.53it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:18<00:06, 38.53it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.52it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.52it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.50it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.51it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.52it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.52it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.52it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:06, 38.50it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:19<00:06, 38.50it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.51it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.51it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.51it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.50it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.49it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.50it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.51it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 38.51it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:05, 38.52it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:20<00:04, 38.51it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.49it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.50it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.50it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.51it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.50it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.51it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.52it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 38.51it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:21<00:04, 38.51it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.50it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.51it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.52it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.51it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.50it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.50it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.50it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 38.50it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 38.49it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:22<00:03, 38.49it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.49it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.50it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.51it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.51it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.51it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.51it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.50it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 38.50it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:23<00:02, 38.50it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:23<00:01, 38.51it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.52it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.52it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.51it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.50it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.50it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.51it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 38.51it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 38.52it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:24<00:01, 38.52it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.52it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.52it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.51it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.53it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.53it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.53it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.52it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 38.50it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 38.51it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 38.52it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 38.53it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.93it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 38.09it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 38.16it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 38.19it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.19it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.19it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 38.19it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 38.18it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 38.15it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 38.15it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 38.15it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 38.15it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 38.16it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 38.19it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 38.20it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 38.23it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 38.25it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 38.27it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 38.27it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 38.28it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 38.29it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 38.28it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 38.27it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 38.26it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.26it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.21it/s]
STAGE:2024-02-23 10:17:38 178571:178571 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:17:38 178571:178571 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:17:38 178571:178571 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.62it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.85it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.93it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 37.96it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 37.98it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 37.99it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 38.00it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 38.01it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 38.00it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 38.01it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 38.01it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 38.02it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 38.02it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 38.03it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 38.02it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 38.01it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 38.01it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 38.03it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 38.04it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 38.04it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 38.05it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 38.05it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 38.04it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 38.04it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 38.06it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 38.06it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 38.05it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 38.03it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:22, 38.02it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 38.03it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 38.03it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:21, 38.03it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 38.02it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 38.02it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 38.01it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 38.02it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 38.02it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:21, 38.00it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 38.00it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 38.01it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 38.00it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:20, 38.01it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 38.01it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 38.02it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 38.04it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 38.04it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:20, 38.04it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:20, 38.04it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 38.03it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 38.03it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 38.05it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 38.02it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 38.01it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 38.01it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:18, 38.01it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 38.02it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 38.02it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 38.02it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 38.03it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 38.04it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:07<00:18, 38.05it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 38.04it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 38.02it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:17, 38.04it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 38.05it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 38.05it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 38.05it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:16, 38.03it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 38.02it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 38.03it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 38.03it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:16, 38.03it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 38.05it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 38.06it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:15, 38.07it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:15, 38.08it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 38.07it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 38.07it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 38.07it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 38.09it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:15, 38.10it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 38.08it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 38.06it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 38.08it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:14, 38.09it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:14, 38.07it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 38.06it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 38.06it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 38.06it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 38.05it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 38.04it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:13, 38.04it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:13, 38.05it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 38.06it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 38.07it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 38.07it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 38.07it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:12<00:13, 38.07it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 38.07it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 38.06it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 38.05it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 38.06it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 38.05it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 38.06it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:11, 38.04it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:11, 38.05it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 38.06it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 38.06it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 38.07it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 38.08it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:14<00:11, 38.08it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 38.08it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 38.07it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 38.08it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:10, 38.08it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 38.07it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 38.06it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 38.07it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 38.07it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:15<00:10, 38.07it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:15<00:10, 38.07it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 38.07it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 38.07it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:09, 38.06it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:09, 38.06it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 38.05it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 38.05it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 38.04it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 38.05it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:16<00:09, 38.06it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 38.07it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 38.07it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 38.06it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 38.07it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 38.07it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:17<00:08, 38.05it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 38.05it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 38.04it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:07, 38.04it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:07, 38.05it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 38.04it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 38.05it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 38.05it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 38.05it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:18<00:07, 38.05it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 38.05it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 38.04it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 38.03it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:06, 38.03it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:19<00:06, 38.03it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:19<00:06, 38.02it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 38.02it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 38.02it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 38.02it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 38.04it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 38.04it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 38.03it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 38.03it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 38.02it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 38.04it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:21<00:04, 38.05it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:21<00:04, 38.05it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 38.04it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 38.04it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 38.03it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 38.03it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 38.03it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 38.03it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 38.03it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 38.05it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:02, 38.06it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 38.06it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 38.07it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 38.06it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 38.07it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:23<00:02, 38.08it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:23<00:02, 38.06it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 38.07it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 38.08it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:01, 38.07it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:24<00:01, 38.07it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 38.08it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 38.09it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 38.08it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 38.08it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:24<00:01, 38.08it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 38.07it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 38.07it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 38.06it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 38.09it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 38.11it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 38.11it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 38.12it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 38.12it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:25<00:00, 38.11it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:25<00:00, 38.10it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 38.10it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 38.09it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 38.06it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 38.04it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 27.45 GB
    total: 31.28 GB
    used: 3.36 GB
  system:
    node: baseline
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.555 us +/- 5.886 us [91.791 us, 227.690 us]
        batches_per_second: 10.49 K +/- 476.40 [4.39 K, 10.89 K]
      metrics:
        batches_per_second_max: 10894.296103896104
        batches_per_second_mean: 10492.548799284341
        batches_per_second_min: 4391.941361256545
        batches_per_second_std: 476.4002077601143
        seconds_per_batch_max: 0.0002276897430419922
        seconds_per_batch_mean: 9.555459022521973e-05
        seconds_per_batch_min: 9.179115295410156e-05
        seconds_per_batch_std: 5.886036504158445e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.695 us +/- 0.713 us [23.603 us, 33.617 us]
        batches_per_second: 40.52 K +/- 987.44 [29.75 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40522.43751067212
        batches_per_second_min: 29746.836879432623
        batches_per_second_std: 987.4425745656843
        seconds_per_batch_max: 3.361701965332031e-05
        seconds_per_batch_mean: 2.469491958618164e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 7.129439505361981e-07
    on_device_inference:
      human_readable:
        batch_latency: -25805569.590 us +/- 51.410 ms [-26900831.223 us, -25685951.233
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03717357250887936
        batches_per_second_mean: -0.03875147538899084
        batches_per_second_min: -0.03893178768940232
        batches_per_second_std: 7.577588510071597e-05
        seconds_per_batch_max: -25.685951232910156
        seconds_per_batch_mean: -25.80556958961487
        seconds_per_batch_min: -26.90083122253418
        seconds_per_batch_std: 0.05141039243533399
    total:
      human_readable:
        batch_latency: 25.937 ms +/- 55.932 us [25.815 ms, 27.181 ms]
        batches_per_second: 38.55 +/- 0.08 [36.79, 38.74]
      metrics:
        batches_per_second_max: 38.737153201078726
        batches_per_second_mean: 38.55449518733569
        batches_per_second_min: 36.79052673128371
        batches_per_second_std: 0.08126392276224215
        seconds_per_batch_max: 0.027180910110473633
        seconds_per_batch_mean: 0.02593743062019348
        seconds_per_batch_min: 0.02581501007080078
        seconds_per_batch_std: 5.5931825372966795e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 147.384 us +/- 6.016 us [143.290 us, 287.294 us]
        batches_per_second: 6.79 K +/- 210.27 [3.48 K, 6.98 K]
      metrics:
        batches_per_second_max: 6978.875207986689
        batches_per_second_mean: 6793.185267451028
        batches_per_second_min: 3480.7502074688796
        batches_per_second_std: 210.27017728350728
        seconds_per_batch_max: 0.0002872943878173828
        seconds_per_batch_mean: 0.0001473839282989502
        seconds_per_batch_min: 0.00014328956604003906
        seconds_per_batch_std: 6.015566147374897e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.740 us +/- 0.620 us [23.603 us, 34.809 us]
        batches_per_second: 40.44 K +/- 877.08 [28.73 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40442.974123134
        batches_per_second_min: 28728.109589041094
        batches_per_second_std: 877.0759771753837
        seconds_per_batch_max: 3.4809112548828125e-05
        seconds_per_batch_mean: 2.4739503860473633e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 6.204279513014772e-07
    on_device_inference:
      human_readable:
        batch_latency: -26082303.062 us +/- 48.981 ms [-27078847.885 us, -25963136.673
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03692919300857956
        batches_per_second_mean: -0.038340305705393235
        batches_per_second_min: -0.03851614743610511
        batches_per_second_std: 7.091534629018146e-05
        seconds_per_batch_max: -25.963136672973633
        seconds_per_batch_mean: -26.082303062438964
        seconds_per_batch_min: -27.078847885131836
        seconds_per_batch_std: 0.048980985244766816
    total:
      human_readable:
        batch_latency: 26.266 ms +/- 53.026 us [26.145 ms, 27.416 ms]
        batches_per_second: 38.07 +/- 0.08 [36.47, 38.25]
      metrics:
        batches_per_second_max: 38.24860704547734
        batches_per_second_mean: 38.07165802504464
        batches_per_second_min: 36.474746069291776
        batches_per_second_std: 0.07536085066851074
        seconds_per_batch_max: 0.027416229248046875
        seconds_per_batch_mean: 0.026266363143920897
        seconds_per_batch_min: 0.026144742965698242
        seconds_per_batch_std: 5.302605622601807e-05


