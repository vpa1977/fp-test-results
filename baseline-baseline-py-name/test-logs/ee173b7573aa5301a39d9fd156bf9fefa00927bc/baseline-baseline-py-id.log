#####
baseline-baseline-py-id - Run 1
2024-02-23 10:32:53
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.98it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.27it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.26it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.31it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.35it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.35it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.34it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.34it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.37it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.38it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.38it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.39it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.38it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.37it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.36it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.35it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.35it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.37it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.38it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.37it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.37it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.36it/s]
STAGE:2024-02-23 10:31:54 179179:179179 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:31:54 179179:179179 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:31:54 179179:179179 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.21it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.44it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.53it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.60it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.64it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.66it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.68it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.69it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.69it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.69it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.70it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.71it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.72it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.72it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 37.74it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.78it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.81it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.83it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.85it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.84it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.84it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.85it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.80it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 37.77it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 37.76it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.74it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.72it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.71it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.70it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.69it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.67it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.69it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.70it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 37.70it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 37.70it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.75it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.79it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.80it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.83it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.83it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.82it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 37.79it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 37.78it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 37.75it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.73it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.71it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 37.69it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.69it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.70it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.69it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.70it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 37.70it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 37.70it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.69it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.69it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.69it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.68it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 37.69it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.70it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.70it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 37.70it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 37.68it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 37.68it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.68it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.68it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.69it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.70it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 37.70it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 37.70it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.69it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.70it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 37.70it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.70it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.70it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.69it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.69it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.66it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 37.63it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.63it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.62it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.62it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.63it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.63it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.64it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.66it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.67it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 37.70it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 37.70it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.72it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.74it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 37.76it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.76it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.77it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.78it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.79it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 37.80it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 37.79it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.78it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.77it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 37.76it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 37.76it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.74it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.75it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.75it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.76it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 37.77it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.76it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.75it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.76it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 37.74it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.74it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.74it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.74it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.73it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.73it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 37.73it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.73it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.73it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.73it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.73it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 37.73it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.73it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.78it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 37.81it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 37.83it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.84it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.86it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.86it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.82it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 37.79it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.78it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.79it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.80it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 37.80it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 37.79it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.80it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.78it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.79it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.80it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.81it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.83it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 37.84it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 37.86it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.86it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.85it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.85it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.83it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 37.81it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.85it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.88it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 37.88it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 37.88it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.88it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.88it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.88it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.88it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 37.84it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.82it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.83it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.86it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 37.86it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.87it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.87it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.86it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.86it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.84it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 37.82it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.80it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.83it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 37.86it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 37.87it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.88it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.89it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.88it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.86it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 37.83it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.81it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.84it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.87it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 37.88it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.89it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.90it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.90it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.91it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.85it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.81it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.78it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.77it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 37.77it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 37.76it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.77it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.76it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.76it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 37.76it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.75it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.77it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 37.81it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 37.82it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.83it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.83it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.84it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.85it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.81it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.80it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.78it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.77it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 37.77it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 37.77it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.77it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.75it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.74it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.74it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.72it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.73it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.74it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 37.76it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 37.79it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.80it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.81it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.81it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.82it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.78it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.76it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.76it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 37.76it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 37.75it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 37.75it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.75it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.73it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.71it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.74it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.78it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.79it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.79it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 37.81it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 37.82it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.85it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.86it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.87it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.86it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.83it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.77it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.28it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.42it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.45it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.43it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.44it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.45it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.47it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.48it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.47it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.49it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.51it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.51it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.50it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.50it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.51it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.51it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.52it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.53it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.52it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.51it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.49it/s]
STAGE:2024-02-23 10:32:24 179179:179179 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:32:24 179179:179179 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:32:24 179179:179179 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 37.00it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.25it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.30it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.33it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.35it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 37.37it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:26, 37.36it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:25, 37.34it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.31it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.29it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.28it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.28it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.28it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.27it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 37.25it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:25, 37.26it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:25, 37.28it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.27it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.29it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.30it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.29it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.27it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.28it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.27it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:24, 37.27it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:24, 37.27it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.27it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:03<00:23, 37.27it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.28it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.28it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.28it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.27it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.27it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 37.27it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:23, 37.30it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.36it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.38it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 37.38it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:21, 37.35it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.32it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.31it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.29it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.30it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:21, 37.30it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:21, 37.31it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:20, 37.34it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 37.38it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:06<00:20, 37.39it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.40it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.40it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.41it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.41it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.41it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:20, 37.39it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:20, 37.37it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 37.32it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 37.32it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.32it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.31it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.31it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.31it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.31it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:19, 37.29it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:19, 37.28it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 37.32it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 37.34it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.38it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.39it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.39it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.40it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.41it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:18, 37.41it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 37.40it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 37.38it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:09<00:17, 37.37it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.35it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.33it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:17, 37.33it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:17, 37.33it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 37.38it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 37.41it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.44it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.45it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 37.45it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:16, 37.42it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:15, 37.39it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:15, 37.37it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:15, 37.34it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 37.33it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.32it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.31it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.29it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 37.29it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:15, 37.31it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:14, 37.33it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 37.37it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:11<00:14, 37.40it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:14, 37.41it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.41it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.41it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.43it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.43it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 37.43it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:14, 37.42it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:13, 37.39it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:12<00:13, 37.35it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:13, 37.34it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 37.33it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.33it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.31it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:13, 37.30it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:12, 37.28it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:13<00:12, 37.28it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:12, 37.34it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.35it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.37it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.37it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.39it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:12, 37.40it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:11, 37.38it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:14<00:11, 37.35it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:14<00:11, 37.34it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.31it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.31it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 37.29it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:11, 37.30it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:10, 37.32it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:15<00:10, 37.34it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:10, 37.34it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 37.37it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.39it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.42it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:09, 37.37it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:16<00:09, 37.34it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:09, 37.33it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:09, 37.36it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.39it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.40it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.40it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 37.41it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:08, 37.42it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:08, 37.41it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.44it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 37.41it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:18<00:07, 37.41it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:07, 37.43it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:07, 37.43it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 37.42it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.40it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.40it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:07, 37.40it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:06, 37.40it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:19<00:06, 37.39it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:06, 37.40it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:06, 37.39it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 37.41it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.42it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.41it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.42it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.43it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:05, 37.41it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:20<00:05, 37.38it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:20<00:05, 37.36it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:05, 37.39it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 37.41it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 37.41it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.42it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.41it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.39it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:05, 37.39it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:21<00:04, 37.40it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:21<00:04, 37.42it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 37.43it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:22<00:04, 37.44it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 37.44it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 37.43it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 37.44it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 37.43it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 37.43it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:22<00:03, 37.38it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:22<00:03, 37.36it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 37.35it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:23<00:03, 37.34it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 37.33it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 37.33it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 37.36it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 37.39it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 37.42it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:02, 37.41it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:23<00:02, 37.42it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:23<00:02, 37.42it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:24<00:02, 37.41it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 37.43it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 37.44it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 37.45it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 37.45it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 37.44it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 37.44it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:24<00:01, 37.43it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:24<00:01, 37.40it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:25<00:01, 37.37it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 37.35it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 37.33it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 37.32it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 37.32it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 37.32it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 37.31it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:25<00:00, 37.33it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:25<00:00, 37.37it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:26<00:00, 37.37it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 37.40it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 37.41it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.41it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.36it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 27.45 GB
    total: 31.28 GB
    used: 3.37 GB
  system:
    node: baseline
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.007 us +/- 6.001 us [91.791 us, 222.683 us]
        batches_per_second: 10.45 K +/- 497.94 [4.49 K, 10.89 K]
      metrics:
        batches_per_second_max: 10894.296103896104
        batches_per_second_mean: 10445.238944403403
        batches_per_second_min: 4490.689507494647
        batches_per_second_std: 497.93578686519703
        seconds_per_batch_max: 0.00022268295288085938
        seconds_per_batch_mean: 9.600663185119629e-05
        seconds_per_batch_min: 9.179115295410156e-05
        seconds_per_batch_std: 6.001385594460045e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.519 us +/- 0.815 us [23.365 us, 33.379 us]
        batches_per_second: 40.82 K +/- 1.16 K [29.96 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40822.25139248097
        batches_per_second_min: 29959.314285714285
        batches_per_second_std: 1160.2298284284166
        seconds_per_batch_max: 3.337860107421875e-05
        seconds_per_batch_mean: 2.451944351196289e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 8.147162993341512e-07
    on_device_inference:
      human_readable:
        batch_latency: -26329212.191 us +/- 73.468 ms [-27478111.267 us, -26158399.582
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03639260319895735
        batches_per_second_mean: -0.03798092033018439
        batches_per_second_min: -0.03822863844818654
        batches_per_second_std: 0.00010496883037242155
        seconds_per_batch_max: -26.15839958190918
        seconds_per_batch_mean: -26.329212190628052
        seconds_per_batch_min: -27.478111267089844
        seconds_per_batch_std: 0.07346838872261414
    total:
      human_readable:
        batch_latency: 26.461 ms +/- 76.599 us [26.287 ms, 27.753 ms]
        batches_per_second: 37.79 +/- 0.11 [36.03, 38.04]
      metrics:
        batches_per_second_max: 38.04184844224752
        batches_per_second_mean: 37.7914947174486
        batches_per_second_min: 36.032610843363145
        batches_per_second_std: 0.10802781540197583
        seconds_per_batch_max: 0.02775263786315918
        seconds_per_batch_mean: 0.026461199283599853
        seconds_per_batch_min: 0.026286840438842773
        seconds_per_batch_std: 7.659948954188454e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.595 us +/- 6.093 us [144.005 us, 283.718 us]
        batches_per_second: 6.74 K +/- 215.62 [3.52 K, 6.94 K]
      metrics:
        batches_per_second_max: 6944.211920529801
        batches_per_second_mean: 6738.163507746593
        batches_per_second_min: 3524.625210084034
        batches_per_second_std: 215.62091771458964
        seconds_per_batch_max: 0.0002837181091308594
        seconds_per_batch_mean: 0.00014859533309936524
        seconds_per_batch_min: 0.00014400482177734375
        seconds_per_batch_std: 6.092634989378067e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.089 us +/- 0.897 us [23.842 us, 33.617 us]
        batches_per_second: 39.90 K +/- 1.24 K [29.75 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 39902.92150075328
        batches_per_second_min: 29746.836879432623
        batches_per_second_std: 1239.7326539426972
        seconds_per_batch_max: 3.361701965332031e-05
        seconds_per_batch_mean: 2.508854866027832e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 8.971181080005369e-07
    on_device_inference:
      human_readable:
        batch_latency: -26558988.424 us +/- 70.487 ms [-27594911.575 us, -26405183.792
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03623856511627537
        batches_per_second_mean: -0.03765229945611846
        batches_per_second_min: -0.037871351620686076
        batches_per_second_std: 9.911428339459575e-05
        seconds_per_batch_max: -26.405183792114258
        seconds_per_batch_mean: -26.55898842430115
        seconds_per_batch_min: -27.594911575317383
        seconds_per_batch_std: 0.07048684274826464
    total:
      human_readable:
        batch_latency: 26.745 ms +/- 73.274 us [26.588 ms, 27.928 ms]
        batches_per_second: 37.39 +/- 0.10 [35.81, 37.61]
      metrics:
        batches_per_second_max: 37.61100450151545
        batches_per_second_mean: 37.39094005270023
        batches_per_second_min: 35.80651880687736
        batches_per_second_std: 0.10131426442490588
        seconds_per_batch_max: 0.027927875518798828
        seconds_per_batch_mean: 0.02674464511871338
        seconds_per_batch_min: 0.026587963104248047
        seconds_per_batch_std: 7.327374338566634e-05


#####
baseline-baseline-py-id - Run 2
2024-02-23 10:34:00
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.81it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.83it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.88it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.89it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.90it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.89it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.90it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.91it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.90it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.89it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.88it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.91it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.93it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.93it/s]Warming up with batch_size=1:  76%|███████▌  | 76/100 [00:01<00:00, 49.96it/s]Warming up with batch_size=1:  81%|████████  | 81/100 [00:01<00:00, 49.94it/s]Warming up with batch_size=1:  86%|████████▌ | 86/100 [00:01<00:00, 49.92it/s]Warming up with batch_size=1:  91%|█████████ | 91/100 [00:01<00:00, 49.92it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 49.92it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.91it/s]
STAGE:2024-02-23 10:33:01 179225:179225 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:33:01 179225:179225 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:33:01 179225:179225 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.80it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 38.04it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.11it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.14it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.18it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.18it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.20it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.21it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.21it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 38.20it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 38.21it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.21it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.23it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.24it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.27it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.32it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.31it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:24, 38.15it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.62it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.55it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.77it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 37.91it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.02it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.10it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.15it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.19it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.23it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.23it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 38.23it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.24it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.23it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.23it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.24it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.24it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.23it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.22it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.23it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.25it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 38.28it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.31it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.31it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.33it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.34it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.35it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.36it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 38.35it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:20, 38.34it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.33it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.32it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.30it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.28it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.27it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.28it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:19, 38.31it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.31it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.34it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.35it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.34it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 38.32it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 38.29it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 38.26it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.25it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.25it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.25it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.26it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.27it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.27it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.27it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 38.27it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:17, 38.29it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.32it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.34it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.36it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.36it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.37it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.37it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.36it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 38.36it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 38.34it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:16, 38.32it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.30it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.28it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.27it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.27it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.27it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.28it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.29it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 38.27it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:15, 38.30it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.32it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.33it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.35it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.36it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.36it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.37it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.38it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 38.36it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 38.35it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.33it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.36it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.36it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.38it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.37it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.38it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.38it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 38.37it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:13, 38.39it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.38it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.37it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.37it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.35it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.37it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.37it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.37it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 38.37it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 38.35it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 38.34it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.34it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.32it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.33it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.37it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.37it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.37it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.39it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 38.37it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.38it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.38it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.38it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.38it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 38.35it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 38.34it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.32it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.34it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.30it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.31it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.29it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:10, 38.26it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 38.24it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.27it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.30it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.36it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.36it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.37it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.36it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 38.36it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 38.34it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 38.35it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.33it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.30it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 38.29it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.32it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.32it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.31it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.31it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.32it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.31it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.32it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 38.33it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:06, 38.31it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.31it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.32it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.31it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.31it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.32it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.32it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.32it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:06, 38.30it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 38.27it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.30it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.33it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.33it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.36it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.37it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.37it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.37it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 38.37it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:05, 38.36it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 38.32it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.32it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.33it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.30it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.31it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.31it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.31it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.32it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 38.32it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 38.31it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.31it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.33it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 38.35it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 38.35it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 38.34it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.33it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.36it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.33it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.33it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 38.35it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.36it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.35it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.31it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 38.33it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.34it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.30it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.76it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.89it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.98it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 38.01it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 38.01it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:01, 38.01it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 38.00it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 38.00it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.99it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.98it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.96it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.96it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.96it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.97it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.97it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.99it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.97it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.96it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.98it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.98it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.99it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.99it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.99it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.99it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.99it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.98it/s]
STAGE:2024-02-23 10:33:31 179225:179225 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:33:31 179225:179225 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:33:31 179225:179225 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 37.22it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.44it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.52it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.58it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.60it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:25, 37.60it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:25, 37.63it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:25, 37.59it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.63it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.67it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.65it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.67it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.67it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.66it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:24, 37.67it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:24, 37.68it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 37.68it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.66it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.66it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.65it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.65it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.63it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.65it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.63it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:23, 37.64it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:23, 37.65it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.63it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:02<00:23, 37.66it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.67it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.70it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.70it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.70it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.70it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:22, 37.72it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:22, 37.73it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.72it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.71it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.70it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.70it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.68it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.69it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.70it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:21, 37.69it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:21, 37.70it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 37.69it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:21, 37.69it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:04<00:21, 37.73it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.74it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.75it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.75it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.75it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:20, 37.76it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:20, 37.77it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:20, 37.77it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 37.72it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:05<00:20, 37.72it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.72it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.72it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.71it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.70it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.71it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:19, 37.68it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 37.68it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.73it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.72it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.74it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.76it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.77it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:18, 37.78it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:18, 37.80it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 37.80it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 37.77it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:07<00:18, 37.75it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.75it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.73it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.73it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.74it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.72it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:17, 37.71it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.75it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.74it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.77it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.74it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.75it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:16, 37.77it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:16, 37.77it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 37.78it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 37.73it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:09<00:16, 37.73it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.72it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.72it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.70it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.70it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 37.70it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:15, 37.69it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:15, 37.71it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:15, 37.70it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:10<00:15, 37.72it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 37.75it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.75it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.77it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.79it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 37.80it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:14, 37.81it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:14, 37.81it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 37.79it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:11<00:14, 37.77it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:11<00:14, 37.79it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.78it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.79it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.78it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.78it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:13, 37.78it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:13, 37.78it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:13, 37.78it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:12<00:13, 37.76it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:12<00:13, 37.74it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 37.76it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.74it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.76it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.78it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 37.80it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:12, 37.81it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:12, 37.80it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:13<00:12, 37.79it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:13<00:12, 37.80it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:13<00:12, 37.80it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.79it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.80it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.80it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.78it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:11, 37.79it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:11, 37.77it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:14<00:11, 37.74it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:14<00:11, 37.74it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:14<00:11, 37.75it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 37.78it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.80it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.81it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.82it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 37.80it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:10, 37.79it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:10, 37.80it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:15<00:10, 37.77it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:15<00:10, 37.74it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 37.74it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.73it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.73it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.74it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.72it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:09, 37.73it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:09, 37.72it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:16<00:09, 37.72it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:16<00:09, 37.71it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:16<00:09, 37.72it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 37.74it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.74it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.74it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.75it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 37.75it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:08, 37.75it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:17<00:08, 37.75it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:17<00:08, 37.75it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:17<00:08, 37.73it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 37.73it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.74it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.74it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.75it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.75it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 37.75it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:18<00:07, 37.76it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:18<00:07, 37.75it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:18<00:07, 37.75it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 37.76it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.79it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.81it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.82it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:06, 37.83it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:06, 37.83it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:19<00:06, 37.83it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:19<00:06, 37.81it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:19<00:06, 37.79it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 37.76it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.75it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.74it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.75it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.75it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:05, 37.71it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:20<00:05, 37.72it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:20<00:05, 37.71it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:20<00:05, 37.72it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:20<00:05, 37.75it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 37.76it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.78it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.81it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.81it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:04, 37.79it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:21<00:04, 37.78it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:21<00:04, 37.77it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:21<00:04, 37.56it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:21<00:04, 37.14it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 36.86it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 36.65it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 36.51it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 36.42it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 36.36it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:22<00:04, 36.30it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:22<00:03, 36.27it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:22<00:03, 36.23it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:22<00:03, 36.23it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 36.24it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 36.22it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 36.19it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 36.18it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 36.17it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:03, 36.14it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:23<00:02, 36.11it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:23<00:02, 36.07it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:23<00:02, 36.05it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 36.06it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 36.05it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 36.08it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 36.11it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 36.10it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 36.08it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:24<00:01, 36.06it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:24<00:01, 36.05it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:24<00:01, 36.08it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 36.14it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 36.14it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 36.15it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 36.15it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 36.17it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 36.18it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:25<00:00, 36.19it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:25<00:00, 36.18it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:25<00:00, 36.15it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 36.16it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 36.14it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 36.14it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 36.14it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 36.12it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 36.10it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 36.10it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.44it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 27.45 GB
    total: 31.28 GB
    used: 3.37 GB
  system:
    node: baseline
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.475 us +/- 5.961 us [91.791 us, 227.213 us]
        batches_per_second: 10.50 K +/- 485.20 [4.40 K, 10.89 K]
      metrics:
        batches_per_second_max: 10894.296103896104
        batches_per_second_mean: 10502.207394799963
        batches_per_second_min: 4401.158447009444
        batches_per_second_std: 485.1955467693823
        seconds_per_batch_max: 0.00022721290588378906
        seconds_per_batch_mean: 9.54751968383789e-05
        seconds_per_batch_min: 9.179115295410156e-05
        seconds_per_batch_std: 5.960787268481254e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.658 us +/- 0.688 us [23.603 us, 34.094 us]
        batches_per_second: 40.58 K +/- 998.10 [29.33 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40582.13107646452
        batches_per_second_min: 29330.797202797203
        batches_per_second_std: 998.1046633433828
        seconds_per_batch_max: 3.409385681152344e-05
        seconds_per_batch_mean: 2.4658203125e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 6.880441302697335e-07
    on_device_inference:
      human_readable:
        batch_latency: -25957672.514 us +/- 125.675 ms [-27343200.684 us, -25830528.259
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03657216328006589
        batches_per_second_mean: -0.038525122422470075
        batches_per_second_min: -0.038713881108522745
        batches_per_second_std: 0.00017915324824077566
        seconds_per_batch_max: -25.830528259277344
        seconds_per_batch_mean: -25.957672513961793
        seconds_per_batch_min: -27.34320068359375
        seconds_per_batch_std: 0.12567455691492269
    total:
      human_readable:
        batch_latency: 26.089 ms +/- 128.000 us [25.959 ms, 27.476 ms]
        batches_per_second: 38.33 +/- 0.18 [36.40, 38.52]
      metrics:
        batches_per_second_max: 38.521909240363335
        batches_per_second_mean: 38.33059480454611
        batches_per_second_min: 36.39561965255723
        batches_per_second_std: 0.18056540363026935
        seconds_per_batch_max: 0.027475833892822266
        seconds_per_batch_mean: 0.026089423179626463
        seconds_per_batch_min: 0.025959253311157227
        seconds_per_batch_std: 0.00012799998824591027
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 147.616 us +/- 6.473 us [142.813 us, 290.394 us]
        batches_per_second: 6.78 K +/- 230.81 [3.44 K, 7.00 K]
      metrics:
        batches_per_second_max: 7002.176961602671
        batches_per_second_mean: 6783.989177442565
        batches_per_second_min: 3443.59934318555
        batches_per_second_std: 230.80614045979857
        seconds_per_batch_max: 0.0002903938293457031
        seconds_per_batch_mean: 0.00014761638641357422
        seconds_per_batch_min: 0.00014281272888183594
        seconds_per_batch_std: 6.472983614450544e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.582 us +/- 0.789 us [24.319 us, 35.048 us]
        batches_per_second: 39.12 K +/- 1.09 K [28.53 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 39123.68285265061
        batches_per_second_min: 28532.680272108842
        batches_per_second_std: 1092.0384093185703
        seconds_per_batch_max: 3.504753112792969e-05
        seconds_per_batch_mean: 2.5581836700439454e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 7.891329386929989e-07
    on_device_inference:
      human_readable:
        batch_latency: -26505390.802 us +/- 451.174 ms [-27703968.048 us, -26120639.801
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.036095912262963256
        batches_per_second_mean: -0.03773881188149058
        batches_per_second_min: -0.03828390145178389
        batches_per_second_std: 0.0006249524978022986
        seconds_per_batch_max: -26.12063980102539
        seconds_per_batch_mean: -26.505390802383424
        seconds_per_batch_min: -27.703968048095703
        seconds_per_batch_std: 0.45117404737602074
    total:
      human_readable:
        batch_latency: 26.690 ms +/- 453.229 us [26.302 ms, 27.889 ms]
        batches_per_second: 37.48 +/- 0.62 [35.86, 38.02]
      metrics:
        batches_per_second_max: 38.0201236425606
        batches_per_second_mean: 37.4771747839934
        batches_per_second_min: 35.856107235672276
        batches_per_second_std: 0.6191698576827348
        seconds_per_batch_max: 0.027889251708984375
        seconds_per_batch_mean: 0.02669039559364319
        seconds_per_batch_min: 0.026301860809326172
        seconds_per_batch_std: 0.00045322899878113215


#####
baseline-baseline-py-id - Run 3
2024-02-23 10:35:05
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.97it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.30it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.34it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.37it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.40it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.43it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.44it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.45it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.47it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.46it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.48it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.49it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.48it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.49it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.47it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.45it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.44it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.46it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.46it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.48it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.44it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.45it/s]
STAGE:2024-02-23 10:34:08 179271:179271 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:34:08 179271:179271 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:34:08 179271:179271 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.52it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.74it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.78it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.76it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 37.78it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.80it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.80it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.80it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.78it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.79it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.78it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.77it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.74it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 37.81it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 37.85it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.87it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.88it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.90it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.92it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.93it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.91it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.89it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 37.91it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 37.90it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 37.87it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.86it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.84it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.83it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.83it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.81it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.82it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.84it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 37.85it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 37.88it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 37.89it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.91it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.94it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.95it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.96it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.94it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.91it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 37.89it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 37.86it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 37.85it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.86it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.85it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 37.85it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.85it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.85it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.83it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.81it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 37.87it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 37.92it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.94it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.96it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.98it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.98it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.00it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.97it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.95it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 37.94it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 37.92it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 37.92it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.90it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.89it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 37.87it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.86it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.84it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.81it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.82it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 37.84it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 37.86it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.87it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.88it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 37.90it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.90it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.89it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.90it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.90it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 37.91it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 37.92it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.91it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.91it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.91it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 37.92it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.93it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.93it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.92it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 37.91it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 37.92it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 37.93it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.94it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.93it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 37.94it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.94it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.92it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.89it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.88it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 37.88it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 37.87it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.87it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.86it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 37.85it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 37.84it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.85it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.85it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.86it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.86it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 37.86it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.86it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.87it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.87it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 37.85it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.85it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.85it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.84it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.83it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 37.84it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.85it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.85it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.86it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 37.86it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 37.87it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.89it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.88it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.87it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 37.85it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 37.86it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.86it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.87it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 37.88it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 37.89it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.90it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.91it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.92it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.91it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 37.90it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.88it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.87it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.86it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 37.87it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 37.89it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.89it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.88it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.87it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 37.87it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 37.89it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.92it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.95it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 37.96it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 37.98it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.96it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.95it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.91it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.89it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 37.88it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.86it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.85it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 37.88it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 37.94it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.96it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.97it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.97it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.94it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 37.94it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.98it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.01it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.02it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.02it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 38.02it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 38.02it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.99it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.97it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 37.95it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.93it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.92it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 37.91it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 37.89it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.90it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.91it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.91it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.91it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 37.91it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.95it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.97it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.98it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 37.98it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 37.97it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.96it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.95it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.90it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.88it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.87it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.86it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.85it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 37.85it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 37.84it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.83it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.84it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.84it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.84it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 37.84it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.91it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.95it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 37.96it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 37.98it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.00it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 38.00it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 38.00it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.95it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.93it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.92it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.90it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.90it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 37.90it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 37.90it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.90it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.89it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.87it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.87it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.90it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.94it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.97it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 37.98it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 37.98it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 37.99it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.99it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.98it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.94it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.91it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.89it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.89it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 37.89it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 37.88it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 37.88it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.89it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.89it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.89it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.88it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.88it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.92it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.95it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 37.98it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.00it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.02it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 38.02it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 38.03it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.99it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.97it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.90it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.35it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.47it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.49it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.53it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.57it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.58it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.56it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.54it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.55it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.58it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.61it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.63it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.64it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.68it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.70it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.70it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.70it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.68it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.67it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.65it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.65it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.65it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.65it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.64it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.65it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.62it/s]
STAGE:2024-02-23 10:34:38 179271:179271 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-23 10:34:38 179271:179271 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-23 10:34:38 179271:179271 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 37.07it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.27it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.35it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.41it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 37.42it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:26, 37.38it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:25, 37.36it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.36it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.34it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.35it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.33it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.31it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.31it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 37.30it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:25, 37.30it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 37.31it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.34it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.39it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.41it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.43it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.44it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.45it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.45it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:24, 37.43it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:23, 37.42it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.41it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.39it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.39it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.37it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.35it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 37.34it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:23, 37.32it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.31it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.34it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.44it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.45it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 37.45it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 37.38it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:21, 37.35it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:21, 37.33it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:21, 37.31it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:21, 37.32it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 37.35it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:05<00:20, 37.38it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.38it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.41it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.43it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.45it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.46it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:20, 37.46it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:19, 37.43it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 37.40it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 37.38it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.38it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.38it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.40it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.43it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.45it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:19, 37.47it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:19, 37.43it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 37.39it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 37.35it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:08<00:18, 37.38it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.40it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.42it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.45it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.47it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 37.46it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 37.45it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:08<00:17, 37.43it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.45it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.47it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.49it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.48it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.51it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:17, 37.52it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:16, 37.49it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 37.44it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 37.42it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:16, 37.42it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.44it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.46it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.47it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.48it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 37.48it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:16, 37.48it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:15, 37.45it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:15, 37.43it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:15, 37.39it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 37.37it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.35it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.34it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.34it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 37.33it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:15, 37.33it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:15, 37.33it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 37.31it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:11<00:14, 37.32it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:14, 37.35it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.39it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.42it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.42it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.41it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 37.41it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:14, 37.38it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:13, 37.35it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:12<00:13, 37.35it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:13, 37.34it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 37.35it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.35it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.33it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:12, 37.31it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:13<00:12, 37.32it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:12, 37.35it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:12, 37.36it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.40it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.42it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.44it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.45it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:12, 37.46it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:11, 37.42it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:14<00:11, 37.39it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:14<00:11, 37.37it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:11, 37.35it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 37.33it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.31it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.31it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:11, 37.31it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:10, 37.30it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:15<00:10, 37.29it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:10, 37.35it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 37.38it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.39it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.42it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.44it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:10, 37.44it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:09, 37.41it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:16<00:09, 37.39it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 37.36it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.34it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.33it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.33it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 37.31it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:09, 37.31it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:17<00:08, 37.35it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:17<00:08, 37.39it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 37.44it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.45it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.45it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.46it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 37.37it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:18<00:07, 37.35it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:07, 37.35it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:07, 37.35it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 37.35it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.34it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.35it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.36it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:07, 37.36it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:06, 37.33it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:19<00:06, 37.34it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:06, 37.37it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:06, 37.42it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 37.44it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.44it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.45it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.45it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.45it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:05, 37.43it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:20<00:05, 37.41it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:20<00:05, 37.40it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:05, 37.37it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 37.35it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 37.33it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.32it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.33it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.34it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:05, 37.33it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:21<00:04, 37.34it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:21<00:04, 37.33it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 37.36it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:22<00:04, 37.39it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 37.40it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 37.42it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 37.42it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:22<00:03, 37.37it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:22<00:03, 37.33it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 37.33it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:23<00:03, 37.33it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 37.34it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 37.35it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 37.35it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 37.34it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 37.35it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:02, 37.35it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:23<00:02, 37.35it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:23<00:02, 37.37it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 37.45it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 37.46it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 37.47it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 37.47it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 37.47it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 37.43it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:24<00:01, 37.40it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:24<00:01, 37.39it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:25<00:01, 37.38it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 37.35it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 37.36it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 37.37it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 37.38it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 37.38it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 37.39it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:25<00:00, 37.38it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:25<00:00, 37.37it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:25<00:00, 37.38it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 37.46it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 37.49it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 37.50it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 37.52it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 37.53it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.49it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.39it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 27.44 GB
    total: 31.28 GB
    used: 3.37 GB
  system:
    node: baseline
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.850 us +/- 5.969 us [92.030 us, 225.782 us]
        batches_per_second: 10.46 K +/- 488.43 [4.43 K, 10.87 K]
      metrics:
        batches_per_second_max: 10866.072538860104
        batches_per_second_mean: 10461.436551341443
        batches_per_second_min: 4429.043294614572
        batches_per_second_std: 488.43263296277536
        seconds_per_batch_max: 0.0002257823944091797
        seconds_per_batch_mean: 9.584999084472656e-05
        seconds_per_batch_min: 9.202957153320312e-05
        seconds_per_batch_std: 5.968619604170251e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.947 us +/- 0.775 us [24.080 us, 37.909 us]
        batches_per_second: 40.12 K +/- 1.03 K [26.38 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 40116.450355578585
        batches_per_second_min: 26379.270440251574
        batches_per_second_std: 1033.0473196690084
        seconds_per_batch_max: 3.790855407714844e-05
        seconds_per_batch_mean: 2.4947166442871093e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 7.754838342683835e-07
    on_device_inference:
      human_readable:
        batch_latency: -26235924.917 us +/- 68.176 ms [-27293344.498 us, -26044384.003
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03663896889166434
        batches_per_second_mean: -0.0381159305676552
        batches_per_second_min: -0.03839599354305657
        batches_per_second_std: 9.818008980663566e-05
        seconds_per_batch_max: -26.044384002685547
        seconds_per_batch_mean: -26.23592491722107
        seconds_per_batch_min: -27.293344497680664
        seconds_per_batch_std: 0.06817574160663543
    total:
      human_readable:
        batch_latency: 26.368 ms +/- 71.518 us [26.173 ms, 27.575 ms]
        batches_per_second: 37.92 +/- 0.10 [36.26, 38.21]
      metrics:
        batches_per_second_max: 38.20714532966532
        batches_per_second_mean: 37.92474171800015
        batches_per_second_min: 36.26408438526716
        batches_per_second_std: 0.10163752383204552
        seconds_per_batch_max: 0.02757549285888672
        seconds_per_batch_mean: 0.026368202447891235
        seconds_per_batch_min: 0.026173114776611328
        seconds_per_batch_std: 7.151794430692682e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.568 us +/- 6.284 us [144.482 us, 287.056 us]
        batches_per_second: 6.74 K +/- 222.35 [3.48 K, 6.92 K]
      metrics:
        batches_per_second_max: 6921.293729372937
        batches_per_second_mean: 6739.9158677704445
        batches_per_second_min: 3483.641196013289
        batches_per_second_std: 222.3465019222919
        seconds_per_batch_max: 0.00028705596923828125
        seconds_per_batch_mean: 0.00014856839179992675
        seconds_per_batch_min: 0.00014448165893554688
        seconds_per_batch_std: 6.283788941310236e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.814 us +/- 0.709 us [23.365 us, 34.571 us]
        batches_per_second: 40.33 K +/- 1.02 K [28.93 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40328.56683258415
        batches_per_second_min: 28926.23448275862
        batches_per_second_std: 1019.3699658067864
        seconds_per_batch_max: 3.457069396972656e-05
        seconds_per_batch_mean: 2.4814128875732423e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 7.09427132090682e-07
    on_device_inference:
      human_readable:
        batch_latency: -26542244.001 us +/- 72.404 ms [-27474943.161 us, -26340511.322
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03639679959080258
        batches_per_second_mean: -0.03767606851951028
        batches_per_second_min: -0.03796433515563417
        batches_per_second_std: 0.00010226331357288803
        seconds_per_batch_max: -26.340511322021484
        seconds_per_batch_mean: -26.54224400138855
        seconds_per_batch_min: -27.474943161010742
        seconds_per_batch_std: 0.07240423193574916
    total:
      human_readable:
        batch_latency: 26.728 ms +/- 75.036 us [26.523 ms, 27.812 ms]
        batches_per_second: 37.41 +/- 0.10 [35.96, 37.70]
      metrics:
        batches_per_second_max: 37.703642443637406
        batches_per_second_mean: 37.41484508781851
        batches_per_second_min: 35.955080837348056
        batches_per_second_std: 0.10425578344270697
        seconds_per_batch_max: 0.027812480926513672
        seconds_per_batch_mean: 0.02672756814956665
        seconds_per_batch_min: 0.02652263641357422
        seconds_per_batch_std: 7.503604120307638e-05


