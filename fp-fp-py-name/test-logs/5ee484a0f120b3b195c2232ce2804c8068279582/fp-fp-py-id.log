#####
fp-fp-py-id - Run 1
2024-02-25 23:14:23
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 51.68it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 51.71it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 51.71it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 51.72it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 51.74it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 51.74it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 51.76it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 51.77it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 51.77it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 51.78it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 51.78it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 51.79it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 51.78it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 51.77it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 51.77it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 51.77it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 51.76it/s]
STAGE:2024-02-25 23:13:26 7315:7315 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:13:26 7315:7315 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:13:26 7315:7315 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 39.20it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 39.46it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.52it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:24, 39.54it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:24, 39.57it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.59it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.58it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:24, 39.58it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 39.58it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 39.57it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 39.58it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 39.57it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:23, 39.58it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:23, 39.60it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:23, 39.62it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:23, 39.62it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:23, 39.63it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:23, 39.64it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 39.67it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 39.69it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 39.68it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:22, 39.66it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:22, 39.64it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:22, 39.62it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:22, 39.63it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:22, 39.65it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:22, 39.64it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:22, 39.64it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:02<00:22, 39.66it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 39.66it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 39.68it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:21, 39.69it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:21, 39.70it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:21, 39.71it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:21, 39.70it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:21, 39.70it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:21, 39.70it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:21, 39.71it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:03<00:21, 39.71it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 39.73it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 39.74it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:20, 39.76it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:20, 39.76it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:20, 39.76it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:20, 39.77it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:20, 39.77it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:20, 39.75it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:20, 39.73it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:04<00:20, 39.72it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 39.75it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 39.74it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:19, 39.75it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:19, 39.76it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:19, 39.75it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:19, 39.76it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:19, 39.78it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:19, 39.76it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:05<00:19, 39.77it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:05<00:19, 39.77it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 39.78it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 39.78it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:18, 39.79it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:18, 39.80it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:18, 39.80it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:18, 39.79it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:18, 39.80it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:18, 39.79it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:06<00:18, 39.80it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:06<00:18, 39.80it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 39.77it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 39.77it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:17, 39.76it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:17, 39.76it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:17, 39.77it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:17, 39.75it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:17, 39.77it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:07<00:17, 39.76it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:07<00:17, 39.74it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:07<00:17, 39.75it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 39.74it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 39.75it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:16, 39.76it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:16, 39.76it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:16, 39.76it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:16, 39.77it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:16, 39.77it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:08<00:16, 39.75it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:08<00:16, 39.75it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:08<00:16, 39.75it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 39.72it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 39.70it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:15, 39.70it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:15, 39.72it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:15, 39.73it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:15, 39.75it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:09<00:15, 39.77it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:09<00:15, 39.75it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:09<00:15, 39.76it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:09<00:15, 39.77it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 39.76it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:14, 39.77it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:14, 39.78it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:14, 39.77it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:14, 39.78it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:14, 39.78it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:10<00:14, 39.78it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:10<00:14, 39.74it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:10<00:14, 39.70it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:10<00:14, 39.71it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 39.72it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:13, 39.74it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:13, 39.75it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:13, 39.76it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:13, 39.72it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:11<00:13, 39.72it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:11<00:13, 39.74it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:11<00:13, 39.70it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:11<00:13, 39.70it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:11<00:13, 39.73it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 39.74it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:12, 39.75it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:12, 39.76it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:12, 39.74it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:12, 39.74it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:12<00:12, 39.75it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:12<00:12, 39.74it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:12<00:12, 39.73it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:12<00:12, 39.74it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:12<00:12, 39.75it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 39.75it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:11, 39.76it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:11, 39.75it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:11, 39.75it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:11, 39.77it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:13<00:11, 39.76it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:13<00:11, 39.77it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:13<00:11, 39.76it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:13<00:11, 39.75it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:13<00:11, 39.79it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 39.80it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:10, 39.80it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:10, 39.75it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:10, 39.77it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:14<00:10, 39.74it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:14<00:10, 39.76it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:14<00:10, 39.79it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:14<00:10, 39.76it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:14<00:10, 39.72it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 39.75it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 39.76it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:09, 39.77it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:09, 39.81it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:09, 39.82it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:15<00:09, 39.81it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:15<00:09, 39.81it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:15<00:09, 39.81it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:15<00:09, 39.82it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:15<00:09, 39.84it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 39.85it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 39.84it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:08, 39.85it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:08, 39.85it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:16<00:08, 39.86it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:16<00:08, 39.85it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:16<00:08, 39.86it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:16<00:08, 39.86it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:16<00:08, 39.85it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:16<00:08, 39.85it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 39.85it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 39.87it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:07, 39.85it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:07, 39.84it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:17<00:07, 39.85it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:17<00:07, 39.85it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:17<00:07, 39.86it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:17<00:07, 39.86it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:17<00:07, 39.84it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:17<00:07, 39.85it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 39.86it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 39.86it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:06, 39.86it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:06, 39.86it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:18<00:06, 39.85it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:18<00:06, 39.85it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:18<00:06, 39.83it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:18<00:06, 39.84it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:18<00:06, 39.83it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:18<00:06, 39.83it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 39.83it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 39.83it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:05, 39.81it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:19<00:05, 39.84it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:19<00:05, 39.85it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:19<00:05, 39.85it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:19<00:05, 39.86it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:19<00:05, 39.88it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:19<00:05, 39.87it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:19<00:05, 39.85it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 39.84it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 39.85it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:04, 39.85it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:20<00:04, 39.84it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:20<00:04, 39.84it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:20<00:04, 39.83it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:20<00:04, 39.83it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:20<00:04, 39.83it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:20<00:04, 39.81it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:20<00:04, 39.85it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 39.86it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 39.86it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:21<00:03, 39.83it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:21<00:03, 39.83it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:21<00:03, 39.81it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:21<00:03, 39.82it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:21<00:03, 39.83it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:21<00:03, 39.83it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:21<00:03, 39.82it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:21<00:03, 39.82it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 39.84it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 39.85it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:22<00:02, 39.86it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:22<00:02, 39.84it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:22<00:02, 39.84it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:22<00:02, 39.84it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:22<00:02, 39.84it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:22<00:02, 39.83it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:22<00:02, 39.81it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:22<00:02, 39.81it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 39.82it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:23<00:02, 39.83it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:23<00:01, 39.84it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:23<00:01, 39.86it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:23<00:01, 39.85it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:23<00:01, 39.84it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:23<00:01, 39.85it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:23<00:01, 39.82it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:23<00:01, 39.81it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:23<00:01, 39.82it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 39.82it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:24<00:01, 39.80it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:24<00:00, 39.81it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:24<00:00, 39.82it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:24<00:00, 39.81it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:24<00:00, 39.82it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:24<00:00, 39.85it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:24<00:00, 39.83it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:24<00:00, 39.83it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:24<00:00, 39.83it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 39.82it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 39.81it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 39.77it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 39.23it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 39.38it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 39.46it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 39.52it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 39.52it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 39.53it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 39.54it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 39.55it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 39.56it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 39.56it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 39.56it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 39.56it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 39.56it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 39.57it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 39.52it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 39.54it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 39.55it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 39.55it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 39.54it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 39.53it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 39.53it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 39.54it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 39.54it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 39.53it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.51it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.53it/s]
STAGE:2024-02-25 23:13:54 7315:7315 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:13:54 7315:7315 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:13:54 7315:7315 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:25, 38.74it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:25, 38.96it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:25, 39.04it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 39.10it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 39.13it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:24, 39.12it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:24, 39.15it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:24, 39.15it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:24, 39.16it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:24, 39.18it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:24, 39.18it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 39.20it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 39.19it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 39.19it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:23, 39.17it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:23, 39.17it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:23, 39.17it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:23, 39.19it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:23, 39.20it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:23, 39.20it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:23, 39.21it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 39.22it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 39.21it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 39.19it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:22, 39.21it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:22, 39.21it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:22, 39.20it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:22, 39.23it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:02<00:22, 39.22it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:22, 39.21it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:22, 39.23it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 39.23it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 39.22it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 39.23it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:21, 39.24it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:21, 39.23it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:21, 39.23it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:21, 39.22it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:03<00:21, 39.22it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:21, 39.21it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:21, 39.20it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 39.19it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 39.20it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 39.21it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:20, 39.19it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:20, 39.20it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:20, 39.20it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:04<00:20, 39.20it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:20, 39.19it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:20, 39.19it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:20, 39.19it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 39.20it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 39.20it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:19, 39.20it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:19, 39.19it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:19, 39.20it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:19, 39.20it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:05<00:19, 39.21it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:19, 39.21it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:19, 39.20it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 39.22it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 39.23it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 39.24it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:18, 39.24it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:18, 39.24it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:18, 39.23it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:06<00:18, 39.23it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:06<00:18, 39.21it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:18, 39.20it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:18, 39.20it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 39.19it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 39.18it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 39.18it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:17, 39.19it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:17, 39.19it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:07<00:17, 39.21it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:07<00:17, 39.23it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:07<00:17, 39.24it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:17, 39.25it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:17, 39.24it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 39.21it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 39.20it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 39.19it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:16, 39.19it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:16, 39.17it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:08<00:16, 39.17it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:08<00:16, 39.17it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:08<00:16, 39.18it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:16, 39.15it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:16, 39.13it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 39.14it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 39.14it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 39.15it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:15, 39.15it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:09<00:15, 39.16it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:09<00:15, 39.16it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:09<00:15, 39.14it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:15, 39.14it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:15, 39.13it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 39.12it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 39.12it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 39.13it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 39.12it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:14, 39.12it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:10<00:14, 39.12it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:10<00:14, 39.13it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:10<00:14, 39.15it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:14, 39.16it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:14, 39.16it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 39.14it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 39.15it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 39.16it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:13, 39.17it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:11<00:13, 39.17it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:11<00:13, 39.18it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:11<00:13, 39.20it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:11<00:13, 39.21it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:13, 39.22it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 39.22it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 39.22it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 39.23it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 39.24it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:12<00:12, 39.24it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:12<00:12, 39.23it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:12<00:12, 39.24it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:12<00:12, 39.23it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:12<00:12, 39.22it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 39.22it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 39.22it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 39.22it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 39.21it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:13<00:12, 39.19it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:13<00:11, 39.18it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:13<00:11, 39.16it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:13<00:11, 39.16it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:13<00:11, 39.17it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:13<00:11, 39.18it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 39.17it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 39.17it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 39.17it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:14<00:11, 39.13it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:14<00:10, 39.14it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:14<00:10, 39.15it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:14<00:10, 39.17it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:14<00:10, 39.17it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 39.17it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 39.17it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 39.18it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 39.18it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:15<00:10, 39.19it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:15<00:10, 39.19it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:15<00:09, 39.19it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:15<00:09, 39.20it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:15<00:09, 39.20it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:15<00:09, 39.19it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 39.16it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 39.18it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 39.17it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 39.17it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:16<00:09, 39.18it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:16<00:08, 39.18it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:16<00:08, 39.19it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:16<00:08, 39.20it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:16<00:08, 39.21it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:16<00:08, 39.22it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 39.20it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 39.20it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 39.20it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:17<00:08, 39.20it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:17<00:08, 39.19it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:17<00:07, 39.19it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:17<00:07, 39.19it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:17<00:07, 39.18it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:17<00:07, 39.20it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:17<00:07, 39.21it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 39.21it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 39.22it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 39.24it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:18<00:07, 39.24it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:18<00:07, 39.22it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:18<00:06, 39.21it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:18<00:06, 39.21it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:18<00:06, 39.19it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:18<00:06, 39.19it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:18<00:06, 39.18it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 39.18it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 39.19it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:19<00:06, 39.17it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:19<00:06, 39.17it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:19<00:06, 39.19it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:19<00:05, 39.19it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:19<00:05, 39.20it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:19<00:05, 39.22it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:19<00:05, 39.23it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 39.24it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 39.22it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 39.21it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:20<00:05, 39.19it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:20<00:05, 39.17it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:20<00:05, 39.17it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:20<00:04, 39.17it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:20<00:04, 39.17it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:20<00:04, 39.16it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:20<00:04, 39.18it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 39.16it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 39.18it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:21<00:04, 39.21it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:21<00:04, 39.22it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:21<00:04, 39.21it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:21<00:03, 39.20it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:21<00:03, 39.20it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:21<00:03, 39.19it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:21<00:03, 39.19it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:21<00:03, 39.20it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 39.18it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 39.19it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:22<00:03, 39.18it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:22<00:03, 39.16it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:22<00:03, 39.15it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:22<00:02, 39.16it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:22<00:02, 39.17it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:22<00:02, 39.18it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:22<00:02, 39.17it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:22<00:02, 39.18it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 39.17it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:23<00:02, 39.18it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:23<00:02, 39.18it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:23<00:02, 39.18it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:23<00:02, 39.18it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:23<00:01, 39.19it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:23<00:01, 39.20it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:23<00:01, 39.19it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:23<00:01, 39.20it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:23<00:01, 39.19it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 39.18it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:24<00:01, 39.17it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:24<00:01, 39.16it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:24<00:01, 39.17it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:24<00:01, 39.18it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:24<00:00, 39.17it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:24<00:00, 39.20it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:24<00:00, 39.20it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:24<00:00, 39.21it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 39.21it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:25<00:00, 39.20it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:25<00:00, 39.20it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:25<00:00, 39.21it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:25<00:00, 39.20it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:25<00:00, 39.21it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:25<00:00, 39.19it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1013.33 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.680 us +/- 5.856 us [90.837 us, 223.875 us]
        batches_per_second: 10.59 K +/- 486.83 [4.47 K, 11.01 K]
      metrics:
        batches_per_second_max: 11008.671916010499
        batches_per_second_mean: 10589.988944588731
        batches_per_second_min: 4466.777422790203
        batches_per_second_std: 486.8294774469858
        seconds_per_batch_max: 0.0002238750457763672
        seconds_per_batch_mean: 9.46803092956543e-05
        seconds_per_batch_min: 9.083747863769531e-05
        seconds_per_batch_std: 5.8558926620036846e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.650 us +/- 0.702 us [22.650 us, 32.425 us]
        batches_per_second: 42.31 K +/- 1.06 K [30.84 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42313.79677245396
        batches_per_second_min: 30840.470588235294
        batches_per_second_std: 1061.9504606681828
        seconds_per_batch_max: 3.24249267578125e-05
        seconds_per_batch_mean: 2.3650407791137696e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 7.016230215917946e-07
    on_device_inference:
      human_readable:
        batch_latency: -24998822.905 us +/- 72.242 ms [-26116191.864 us, -24856416.702
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03829042171259017
        batches_per_second_mean: -0.0400022137474468
        batches_per_second_min: -0.04023106033254806
        batches_per_second_std: 0.0001143185060688889
        seconds_per_batch_max: -24.856416702270508
        seconds_per_batch_mean: -24.998822904586792
        seconds_per_batch_min: -26.116191864013672
        seconds_per_batch_std: 0.07224207420052875
    total:
      human_readable:
        batch_latency: 25.128 ms +/- 75.445 us [24.981 ms, 26.390 ms]
        batches_per_second: 39.80 +/- 0.12 [37.89, 40.03]
      metrics:
        batches_per_second_max: 40.03038805856191
        batches_per_second_mean: 39.79719985404485
        batches_per_second_min: 37.893032668401275
        batches_per_second_std: 0.11780519644680376
        seconds_per_batch_max: 0.02639007568359375
        seconds_per_batch_mean: 0.02512761926651001
        seconds_per_batch_min: 0.024981021881103516
        seconds_per_batch_std: 7.544507290037945e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 146.013 us +/- 5.954 us [141.859 us, 282.288 us]
        batches_per_second: 6.86 K +/- 213.77 [3.54 K, 7.05 K]
      metrics:
        batches_per_second_max: 7049.250420168068
        batches_per_second_mean: 6857.037536702608
        batches_per_second_min: 3542.4864864864867
        batches_per_second_std: 213.76867696767044
        seconds_per_batch_max: 0.00028228759765625
        seconds_per_batch_mean: 0.0001460130214691162
        seconds_per_batch_min: 0.0001418590545654297
        seconds_per_batch_std: 5.954386812112485e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.344 us +/- 0.951 us [23.127 us, 41.246 us]
        batches_per_second: 41.13 K +/- 1.28 K [24.24 K, 43.24 K]
      metrics:
        batches_per_second_max: 43240.24742268041
        batches_per_second_mean: 41127.0239335444
        batches_per_second_min: 24244.531791907513
        batches_per_second_std: 1281.9560861472767
        seconds_per_batch_max: 4.124641418457031e-05
        seconds_per_batch_mean: 2.434396743774414e-05
        seconds_per_batch_min: 2.3126602172851562e-05
        seconds_per_batch_std: 9.508318263154114e-07
    on_device_inference:
      human_readable:
        batch_latency: -25319894.659 us +/- 62.335 ms [-26443712.234 us, -25152704.239
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03781617312774463
        batches_per_second_mean: -0.039494871067402945
        batches_per_second_min: -0.039757156546761305
        batches_per_second_std: 9.58727136145161e-05
        seconds_per_batch_max: -25.1527042388916
        seconds_per_batch_mean: -25.319894659042358
        seconds_per_batch_min: -26.44371223449707
        seconds_per_batch_std: 0.062334709700052435
    total:
      human_readable:
        batch_latency: 25.501 ms +/- 65.786 us [25.331 ms, 26.776 ms]
        batches_per_second: 39.21 +/- 0.10 [37.35, 39.48]
      metrics:
        batches_per_second_max: 39.478031700613684
        batches_per_second_mean: 39.214566111412836
        batches_per_second_min: 37.34710523035279
        batches_per_second_std: 0.09934597043891721
        seconds_per_batch_max: 0.026775836944580078
        seconds_per_batch_mean: 0.025500895023345946
        seconds_per_batch_min: 0.025330543518066406
        seconds_per_batch_std: 6.578588420394301e-05


#####
fp-fp-py-id - Run 2
2024-02-25 23:15:32
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.20it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.07it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.07it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.07it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.11it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.12it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.15it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.17it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.19it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.19it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.20it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.20it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.20it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.19it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.19it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.18it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.18it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.17it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.17it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.16it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.17it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.16it/s]
STAGE:2024-02-25 23:14:31 7362:7362 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:14:31 7362:7362 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:14:31 7362:7362 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.28it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.54it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.60it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.65it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.67it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 37.15it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:26, 36.66it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:26, 36.33it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:26, 36.11it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:26, 35.95it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:26, 35.85it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:26, 35.78it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:26, 35.74it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:26, 35.71it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:26, 35.68it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:26, 35.66it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:26, 35.65it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:26, 35.63it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:25, 35.62it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:25, 35.60it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:25, 35.60it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:25, 35.59it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:25, 35.59it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:25, 35.61it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:25, 35.61it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:25, 35.59it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:03<00:25, 35.56it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:03<00:24, 35.55it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:24, 35.52it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:24, 35.51it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:24, 35.51it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:24, 35.53it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:24, 35.52it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:24, 35.53it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:24, 35.53it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:04<00:24, 35.54it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:04<00:23, 35.52it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 35.49it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:23, 35.52it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:23, 35.55it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:23, 35.56it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:23, 35.54it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:23, 35.56it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:23, 35.59it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:05<00:23, 35.58it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:05<00:22, 35.58it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 35.58it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:22, 35.58it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:22, 35.57it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:22, 35.56it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:22, 35.53it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:22, 35.53it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:22, 35.55it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:06<00:22, 35.54it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:06<00:21, 35.50it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:06<00:21, 35.49it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:21, 35.52it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 35.48it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:21, 35.46it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:21, 35.46it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:21, 35.48it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:21, 35.49it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:07<00:21, 35.50it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:07<00:20, 35.51it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 35.55it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:20, 35.56it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:20, 35.56it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:20, 35.55it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:20, 35.57it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:08<00:20, 35.57it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:08<00:19, 35.58it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:08<00:19, 35.57it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 35.59it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 35.59it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:19, 35.57it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:19, 35.59it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:19, 35.59it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:19, 35.58it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:09<00:18, 35.58it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:09<00:18, 35.57it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:09<00:18, 35.56it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 35.55it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 35.57it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:18, 35.60it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:18, 35.61it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:18, 35.60it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:18, 35.58it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:10<00:17, 35.58it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:10<00:17, 35.57it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:10<00:17, 35.56it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 35.55it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 35.57it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 35.56it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:17, 35.58it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:17, 35.57it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:17, 35.57it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:11<00:16, 35.57it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:11<00:16, 35.57it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:11<00:16, 35.58it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:11<00:16, 35.58it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 35.58it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 35.57it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:16, 35.57it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:16, 35.56it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:12<00:16, 35.56it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:12<00:15, 35.57it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:12<00:15, 35.58it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:12<00:15, 35.58it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:12<00:15, 35.58it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 35.59it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 35.59it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:15, 35.59it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:15, 35.58it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:13<00:15, 35.57it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:13<00:14, 35.57it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:13<00:14, 35.58it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:13<00:14, 35.57it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:13<00:14, 35.56it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 35.56it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 35.57it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:14, 35.57it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:14, 35.58it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:14<00:14, 35.58it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:14<00:13, 35.59it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:14<00:13, 35.60it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:14<00:13, 35.60it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:14<00:13, 35.60it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 35.60it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 35.60it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:13, 35.61it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:13, 35.58it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:15<00:13, 35.58it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:15<00:12, 35.61it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:15<00:12, 35.62it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:15<00:12, 35.58it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:15<00:12, 35.55it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 35.56it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 35.57it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:12, 35.56it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:12, 35.58it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:16<00:12, 35.59it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:16<00:11, 35.60it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:16<00:11, 35.60it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:16<00:11, 35.62it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:16<00:11, 35.60it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 35.60it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 36.14it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:10, 36.61it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 36.96it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:17<00:10, 37.21it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:17<00:10, 37.37it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:17<00:10, 37.50it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:17<00:10, 37.58it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:17<00:09, 37.64it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:09, 37.68it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:09, 37.69it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:09, 37.70it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 37.72it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.74it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:18<00:09, 37.74it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:18<00:09, 37.74it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:18<00:09, 37.74it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:18<00:09, 37.75it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:08, 37.75it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:08, 37.75it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:08, 37.75it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 37.75it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.73it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:19<00:08, 37.72it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:19<00:08, 37.73it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:19<00:08, 37.74it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:19<00:08, 37.73it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:07, 37.74it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:07, 37.72it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:07, 37.73it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 37.71it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 37.70it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:20<00:07, 37.71it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:20<00:07, 37.71it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:20<00:07, 37.70it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:20<00:07, 37.71it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:06, 37.72it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:06, 37.72it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:06, 37.72it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 37.73it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 37.73it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.74it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:21<00:06, 37.72it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:21<00:06, 37.74it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:21<00:06, 37.74it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 37.76it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:05, 37.77it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:05, 37.76it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:22<00:05, 37.76it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:22<00:05, 37.75it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:22<00:05, 37.75it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 37.76it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:04, 37.77it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:04, 37.77it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:04, 37.70it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 37.04it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 36.58it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 36.28it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:23<00:04, 36.05it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:23<00:04, 35.91it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 35.83it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 35.76it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 35.71it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:04, 35.69it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 35.67it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 35.62it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:24<00:03, 35.63it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:24<00:03, 35.62it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:24<00:03, 35.60it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:24<00:03, 35.60it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 35.59it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 35.57it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:03, 35.56it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 35.57it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 35.56it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:25<00:02, 35.56it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:25<00:02, 35.56it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:25<00:02, 35.56it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:25<00:02, 35.56it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 35.57it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 35.57it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:02, 35.57it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 35.57it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 35.59it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:26<00:01, 35.57it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:26<00:01, 35.53it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:26<00:01, 35.51it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:26<00:01, 35.52it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 35.54it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 35.56it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:01, 35.58it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 35.60it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 35.59it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:27<00:00, 35.59it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:27<00:00, 35.58it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:27<00:00, 35.55it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:27<00:00, 35.56it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 35.58it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 35.58it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 35.57it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.08it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.16it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.33it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.38it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.42it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.46it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 37.49it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.51it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.50it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.51it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.52it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 37.53it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 37.53it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 37.51it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 37.52it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 37.53it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 37.54it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 37.53it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 37.52it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 37.53it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 37.54it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 37.55it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 37.55it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.56it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.51it/s]
STAGE:2024-02-25 23:15:02 7362:7362 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:15:02 7362:7362 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:15:02 7362:7362 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 36.95it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.22it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.32it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.37it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:26, 37.39it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:26, 37.41it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.43it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.44it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.43it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:25, 37.41it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:25, 37.40it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:25, 37.39it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 37.39it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.39it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.38it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.38it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.37it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.37it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:24, 37.37it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:24, 37.38it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.39it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:23, 37.39it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:23, 37.38it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:23, 37.39it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 37.38it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 37.39it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.37it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.37it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 37.37it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 37.39it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 37.39it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:22, 36.85it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 36.37it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 36.04it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:22, 35.82it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:22, 35.65it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:22, 35.54it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:22, 35.46it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:22, 35.39it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:22, 35.35it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:21, 35.31it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:21, 35.30it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:21, 35.27it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:21, 35.26it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:21, 35.25it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:21, 35.27it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:21, 35.26it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:21, 35.25it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:21, 35.25it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:07<00:21, 35.23it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:20, 35.24it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:20, 35.23it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:20, 35.23it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:20, 35.22it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:20, 35.23it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:20, 35.22it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:20, 35.22it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:20, 35.23it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:08<00:19, 35.23it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:19, 35.24it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:19, 35.24it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:19, 35.24it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:19, 35.24it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:19, 35.25it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:19, 35.26it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:19, 35.26it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:09<00:19, 35.22it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:09<00:18, 35.21it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 35.20it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 35.19it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 35.18it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:18, 35.19it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:18, 35.19it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:18, 35.46it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 36.00it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:10<00:17, 36.40it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:10<00:17, 36.67it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 36.86it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:16, 37.01it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:16, 37.12it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 37.19it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 37.24it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 37.29it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 37.31it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 37.33it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:11<00:15, 37.35it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:15, 37.37it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 37.37it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 37.35it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 37.35it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 37.35it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:12<00:14, 37.36it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:14, 37.35it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 37.34it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 37.35it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 37.35it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 37.36it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:13<00:14, 37.36it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:13<00:13, 37.37it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:13, 37.33it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:13, 37.31it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 37.31it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 37.31it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:14<00:12, 37.30it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 37.33it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 37.34it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 37.29it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:15<00:12, 36.79it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 36.46it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 36.24it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:12, 36.08it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:12, 35.96it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 35.88it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 35.83it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 35.78it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 35.74it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:16<00:11, 35.74it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 35.72it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 35.70it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:11, 35.69it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:11, 35.67it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 35.67it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 35.67it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 35.68it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 35.66it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:17<00:10, 35.66it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 35.67it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 35.65it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 35.66it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:10, 35.66it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 35.67it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 35.67it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 35.67it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 35.66it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:18<00:09, 35.66it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:09, 35.66it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:09, 35.67it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:09, 35.68it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:09, 35.68it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 35.66it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 35.66it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 35.66it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 35.66it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:19<00:08, 35.66it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:19<00:08, 35.66it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:08, 35.67it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:08, 35.66it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:08, 35.67it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 35.68it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 35.64it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 35.61it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 35.57it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:20<00:07, 35.54it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:20<00:07, 35.57it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:07, 35.61it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:07, 35.61it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:07, 35.63it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 35.64it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 35.64it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 35.66it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 35.63it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:21<00:06, 35.63it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:21<00:06, 35.64it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:21<00:06, 35.66it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:21<00:06, 35.67it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:06, 35.67it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 35.66it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 35.67it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 35.67it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:22<00:05, 35.66it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:22<00:05, 35.68it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:22<00:05, 35.67it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:22<00:05, 35.67it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:22<00:05, 35.65it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:05, 35.67it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 35.64it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 35.64it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 35.63it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:23<00:04, 35.63it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:23<00:04, 35.61it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:23<00:04, 35.64it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:23<00:04, 35.62it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:23<00:04, 35.59it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:04, 35.60it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 35.61it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 35.58it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 35.61it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:24<00:03, 35.61it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:24<00:03, 35.61it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:24<00:03, 35.63it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:24<00:03, 35.63it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:24<00:03, 35.63it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:03, 35.62it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 35.61it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 35.61it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 35.57it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:25<00:02, 35.57it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:25<00:02, 35.58it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:25<00:02, 35.61it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:25<00:02, 35.63it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:25<00:02, 35.65it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:02, 35.65it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 35.64it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 35.64it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 35.63it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:26<00:01, 35.63it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:26<00:01, 35.64it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:26<00:01, 35.62it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:26<00:01, 35.64it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:26<00:01, 35.64it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:26<00:01, 35.63it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 35.65it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 35.65it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 35.66it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:27<00:00, 35.66it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:27<00:00, 35.66it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:27<00:00, 35.66it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:27<00:00, 35.66it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:27<00:00, 35.67it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 35.68it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.20it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1008.05 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 98.299 us +/- 5.977 us [92.983 us, 222.683 us]
        batches_per_second: 10.20 K +/- 480.33 [4.49 K, 10.75 K]
      metrics:
        batches_per_second_max: 10754.625641025641
        batches_per_second_mean: 10200.646024515927
        batches_per_second_min: 4490.689507494647
        batches_per_second_std: 480.3255528407115
        seconds_per_batch_max: 0.00022268295288085938
        seconds_per_batch_mean: 9.829878807067871e-05
        seconds_per_batch_min: 9.298324584960938e-05
        seconds_per_batch_std: 5.97653118975848e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.178 us +/- 0.914 us [23.603 us, 35.286 us]
        batches_per_second: 39.76 K +/- 1.24 K [28.34 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 39761.12942195904
        batches_per_second_min: 28339.891891891893
        batches_per_second_std: 1241.8371518810889
        seconds_per_batch_max: 3.528594970703125e-05
        seconds_per_batch_mean: 2.5178432464599608e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 9.137612185902606e-07
    on_device_inference:
      human_readable:
        batch_latency: -27559618.923 us +/- 697.121 ms [-28226240.158 us, -26259775.162
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035428027055658146
        batches_per_second_mean: -0.03630890304504734
        batches_per_second_min: -0.038081057200248264
        batches_per_second_std: 0.0009460914819528356
        seconds_per_batch_max: -26.259775161743164
        seconds_per_batch_mean: -27.559618923187255
        seconds_per_batch_min: -28.226240158081055
        seconds_per_batch_std: 0.6971205102800888
    total:
      human_readable:
        batch_latency: 27.695 ms +/- 698.870 us [26.389 ms, 28.370 ms]
        batches_per_second: 36.13 +/- 0.94 [35.25, 37.89]
      metrics:
        batches_per_second_max: 37.89474445036726
        batches_per_second_mean: 36.1315463075953
        batches_per_second_min: 35.24862175608444
        batches_per_second_std: 0.9391587121006901
        seconds_per_batch_max: 0.028369903564453125
        seconds_per_batch_mean: 0.02769481086730957
        seconds_per_batch_min: 0.026388883590698242
        seconds_per_batch_std: 0.0006988699950043342
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 149.484 us +/- 6.301 us [144.005 us, 288.725 us]
        batches_per_second: 6.70 K +/- 220.51 [3.46 K, 6.94 K]
      metrics:
        batches_per_second_max: 6944.211920529801
        batches_per_second_mean: 6698.593264885294
        batches_per_second_min: 3463.5045417010733
        batches_per_second_std: 220.511620774763
        seconds_per_batch_max: 0.0002887248992919922
        seconds_per_batch_mean: 0.00014948368072509766
        seconds_per_batch_min: 0.00014400482177734375
        seconds_per_batch_std: 6.301198722219992e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.355 us +/- 0.924 us [23.842 us, 34.332 us]
        batches_per_second: 39.49 K +/- 1.31 K [29.13 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 39487.001119159824
        batches_per_second_min: 29127.11111111111
        batches_per_second_std: 1314.3721725378982
        seconds_per_batch_max: 3.4332275390625e-05
        seconds_per_batch_mean: 2.535533905029297e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 9.243416669074503e-07
    on_device_inference:
      human_readable:
        batch_latency: -27415738.131 us +/- 678.457 ms [-28297760.010 us, -26436576.843
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03533848614359927
        batches_per_second_mean: -0.03649797844807934
        batches_per_second_min: -0.03782637994052111
        batches_per_second_std: 0.0009124373022391867
        seconds_per_batch_max: -26.43657684326172
        seconds_per_batch_mean: -27.41573813056946
        seconds_per_batch_min: -28.297760009765625
        seconds_per_batch_std: 0.6784568081084403
    total:
      human_readable:
        batch_latency: 27.602 ms +/- 680.522 us [26.618 ms, 28.483 ms]
        batches_per_second: 36.25 +/- 0.90 [35.11, 37.57]
      metrics:
        batches_per_second_max: 37.56923021801831
        batches_per_second_mean: 36.25099671005806
        batches_per_second_min: 35.10847346966108
        batches_per_second_std: 0.9028563730908491
        seconds_per_batch_max: 0.028483152389526367
        seconds_per_batch_mean: 0.027602396488189698
        seconds_per_batch_min: 0.02661752700805664
        seconds_per_batch_std: 0.0006805220278900528


#####
fp-fp-py-id - Run 3
2024-02-25 23:16:38
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.50it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 50.91it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 50.86it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 50.90it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 50.94it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 50.91it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 50.92it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 50.92it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 50.48it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 49.49it/s]Warming up with batch_size=1:  59%|█████▉    | 59/100 [00:01<00:00, 48.90it/s]Warming up with batch_size=1:  64%|██████▍   | 64/100 [00:01<00:00, 48.48it/s]Warming up with batch_size=1:  69%|██████▉   | 69/100 [00:01<00:00, 48.14it/s]Warming up with batch_size=1:  74%|███████▍  | 74/100 [00:01<00:00, 47.93it/s]Warming up with batch_size=1:  79%|███████▉  | 79/100 [00:01<00:00, 47.77it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 47.65it/s]Warming up with batch_size=1:  89%|████████▉ | 89/100 [00:01<00:00, 47.57it/s]Warming up with batch_size=1:  94%|█████████▍| 94/100 [00:01<00:00, 47.49it/s]Warming up with batch_size=1:  99%|█████████▉| 99/100 [00:02<00:00, 47.45it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.93it/s]
STAGE:2024-02-25 23:15:40 7408:7408 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:15:40 7408:7408 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:15:40 7408:7408 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 38.69it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 39.01it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.08it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 39.13it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 39.14it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.15it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.17it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:24, 39.18it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 39.17it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 39.19it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 39.21it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 39.22it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 39.23it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 39.23it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:23, 39.24it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:23, 39.24it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:23, 39.22it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:23, 39.22it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 39.20it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 39.20it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 39.20it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 39.19it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 39.00it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.36it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 37.95it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.67it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.46it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.32it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:02<00:23, 37.22it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.15it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.12it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 37.07it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 37.05it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 37.06it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:23, 37.04it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 37.00it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 36.97it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 36.94it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 36.91it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 36.92it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 36.91it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 36.88it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 36.88it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:22, 36.89it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:22, 36.86it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 36.85it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 36.83it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 36.83it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 36.87it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 36.87it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 36.85it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 36.86it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:21, 36.88it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:21, 36.93it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 36.94it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 36.95it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 36.96it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 36.98it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 36.97it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 36.99it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 37.00it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:20, 37.02it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.01it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:19, 37.00it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.00it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.00it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 36.98it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 36.93it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 36.90it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:19, 36.87it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:19, 36.85it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 36.85it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 36.85it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 36.87it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 36.92it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 36.97it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 36.98it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 37.01it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 37.02it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:18, 37.03it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.01it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.00it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.02it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.02it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.03it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.02it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.02it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 36.99it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:17, 37.02it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.00it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:16, 37.02it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.00it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.00it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.00it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 36.96it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 36.90it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 36.92it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:16, 36.92it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 36.93it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 36.97it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 36.97it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 36.98it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:15, 37.00it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:15, 37.00it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.00it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:14, 37.00it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 36.99it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.98it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 36.99it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 36.99it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.39it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.91it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.29it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.55it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:13, 38.73it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 38.87it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:12, 38.96it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:12, 39.02it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 39.07it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 39.12it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 39.14it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 39.15it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 39.16it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 39.17it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 39.17it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 39.16it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 39.17it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 39.18it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 39.18it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 39.18it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:10, 39.18it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:10, 39.17it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 39.17it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 39.18it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 39.16it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 39.16it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 39.16it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 39.17it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 39.17it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 39.17it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:09, 39.16it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:09, 39.15it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 39.15it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 39.15it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 39.16it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 39.16it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 39.17it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 39.17it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 39.18it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:08, 39.19it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:08, 39.21it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 39.20it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 39.21it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 39.21it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 39.22it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 39.22it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 39.21it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 39.22it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 39.21it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:07, 39.21it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:07, 39.22it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 39.22it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 39.22it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 39.21it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 39.20it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 39.21it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 39.21it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 39.21it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 39.20it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:06, 39.21it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:06, 39.20it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 39.20it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 39.21it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 39.22it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 39.21it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 39.21it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 39.22it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 39.23it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 39.23it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 39.22it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 39.23it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:04, 39.22it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:04, 39.22it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 39.20it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 39.19it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 39.21it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 39.22it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 39.23it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 39.22it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 39.22it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 39.22it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:03, 39.21it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 39.21it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 39.19it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 39.20it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 39.19it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 39.20it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 39.20it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 39.20it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 39.19it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 39.19it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:02, 39.19it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 39.21it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 39.20it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 39.20it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 39.21it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 39.21it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 39.22it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 39.22it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 39.21it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 39.21it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 39.20it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 39.20it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 39.19it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 39.19it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 39.19it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 39.21it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 39.20it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 39.19it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 39.17it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 39.17it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 39.16it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 39.17it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 39.18it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 39.19it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 39.20it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 39.20it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 39.19it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 39.19it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 39.18it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 39.17it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.32it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 38.71it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 38.83it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 38.86it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 38.90it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.93it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.94it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 38.95it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 38.96it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 38.96it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 38.97it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 38.96it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 38.96it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 38.96it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 38.97it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 38.97it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 38.98it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 38.96it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 38.97it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 38.98it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 38.99it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 38.99it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 39.00it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 39.00it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 39.01it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.01it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.96it/s]
STAGE:2024-02-25 23:16:09 7408:7408 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:16:09 7408:7408 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:16:09 7408:7408 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:25, 38.35it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:25, 38.56it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:25, 38.61it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 38.64it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 38.64it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 38.66it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 38.66it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 38.66it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:24, 38.66it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:24, 38.66it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:24, 38.66it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 38.67it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 38.65it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 38.65it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 38.66it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 38.66it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 38.65it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 38.66it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:23, 38.65it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:23, 38.66it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:23, 38.66it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 38.65it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 38.66it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 38.67it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 38.66it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 38.67it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 38.66it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:22, 38.67it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:22, 38.68it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:22, 38.69it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:22, 38.70it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 38.70it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 38.69it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 38.68it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 38.68it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 38.67it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 38.64it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:21, 38.62it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:21, 38.62it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:21, 38.63it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:21, 38.64it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 38.63it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 38.63it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 38.62it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 38.64it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 38.65it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:21, 38.65it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:04<00:20, 38.66it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:20, 38.67it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:20, 38.68it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:20, 38.68it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 38.66it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 38.66it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 38.66it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 38.66it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:20, 38.66it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:19, 38.66it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:19, 38.66it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:19, 38.67it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:19, 38.68it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 38.69it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 38.70it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 38.70it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 38.72it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 38.72it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 38.71it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:06<00:18, 38.70it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:18, 38.69it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:18, 38.69it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:18, 38.70it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 38.70it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 38.70it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 38.71it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 38.71it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 38.72it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:07<00:17, 38.70it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:07<00:17, 38.69it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:17, 38.67it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:17, 38.68it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:17, 38.69it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 38.70it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 38.70it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 38.71it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 38.72it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:17, 38.72it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:08<00:16, 38.71it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:08<00:16, 38.70it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:16, 38.68it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:16, 38.68it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:16, 38.68it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 38.69it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 38.69it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 38.69it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:16, 38.70it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:09<00:16, 38.70it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:09<00:15, 38.69it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:15, 38.70it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:15, 38.68it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:15, 38.69it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 38.71it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 38.73it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 38.73it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 38.73it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:15, 38.72it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:10<00:14, 38.72it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:10<00:14, 38.72it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:14, 38.72it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:14, 38.72it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:14, 38.72it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 38.72it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 38.73it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 38.74it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:14, 38.73it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:11<00:14, 38.73it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:11<00:13, 38.71it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:11<00:13, 38.71it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:13, 38.70it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:13, 38.71it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 38.70it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 38.69it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 38.70it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 38.71it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:12<00:13, 38.72it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:12<00:13, 38.72it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:12<00:12, 38.71it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:12, 38.71it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:12, 38.71it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 38.71it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 38.69it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 38.71it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 38.71it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:13<00:12, 38.73it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:13<00:12, 38.73it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:13<00:11, 38.72it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:13<00:11, 38.72it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:11, 38.72it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:11, 38.73it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 38.74it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 38.74it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 38.74it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 38.75it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:14<00:11, 38.76it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:14<00:11, 38.75it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:14<00:10, 38.76it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:14<00:10, 38.76it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:10, 38.76it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 38.75it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 38.74it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 38.73it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 38.72it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:15<00:10, 38.71it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:15<00:10, 38.72it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:15<00:10, 38.70it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:15<00:09, 38.70it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:09, 38.70it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:09, 38.71it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 38.70it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 38.70it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 38.70it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 38.70it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:16<00:09, 38.70it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:16<00:09, 38.71it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:16<00:08, 38.71it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:16<00:08, 38.71it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:08, 38.72it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 38.72it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 38.72it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 38.70it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 38.71it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:17<00:08, 38.71it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:17<00:08, 38.71it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:17<00:08, 38.71it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:17<00:07, 38.70it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:17<00:07, 38.69it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:07, 38.68it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 38.69it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 38.70it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 38.70it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 38.71it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:18<00:07, 38.71it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:18<00:07, 38.72it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:18<00:07, 38.72it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:18<00:06, 38.73it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:06, 38.72it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 38.72it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 38.73it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 38.72it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 38.71it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:19<00:06, 38.72it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:19<00:06, 38.72it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:19<00:06, 38.73it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:19<00:05, 38.75it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:19<00:05, 38.75it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 38.76it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 38.76it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 38.77it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 38.77it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:20<00:05, 38.77it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:20<00:04, 38.78it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:20<00:04, 38.78it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 38.77it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 38.77it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 38.77it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 38.76it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:21<00:04, 38.77it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:21<00:04, 38.78it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:21<00:04, 38.79it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:21<00:04, 38.78it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:21<00:03, 38.78it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 38.78it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 38.77it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 38.78it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 38.76it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 38.75it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:22<00:03, 38.73it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:22<00:03, 38.73it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:22<00:03, 38.72it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:22<00:02, 38.70it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:22<00:02, 38.71it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 38.72it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 38.72it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 38.73it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 38.74it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:23<00:02, 38.75it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:23<00:02, 38.74it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:23<00:02, 38.73it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:23<00:02, 38.71it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:23<00:01, 38.70it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:23<00:01, 38.69it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 38.68it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 38.68it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 38.69it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 38.70it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:24<00:01, 38.70it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:24<00:01, 38.71it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:24<00:01, 38.71it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:24<00:01, 38.70it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:24<00:00, 38.69it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 38.69it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 38.69it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 38.68it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 38.67it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:25<00:00, 38.68it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:25<00:00, 38.68it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:25<00:00, 38.69it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:25<00:00, 38.69it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:25<00:00, 38.68it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:25<00:00, 38.70it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1010.73 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.744 us +/- 6.040 us [91.314 us, 228.405 us]
        batches_per_second: 10.47 K +/- 493.77 [4.38 K, 10.95 K]
      metrics:
        batches_per_second_max: 10951.185378590078
        batches_per_second_mean: 10473.536874043972
        batches_per_second_min: 4378.187891440501
        batches_per_second_std: 493.7707167755572
        seconds_per_batch_max: 0.00022840499877929688
        seconds_per_batch_mean: 9.574437141418457e-05
        seconds_per_batch_min: 9.131431579589844e-05
        seconds_per_batch_std: 6.039851041122966e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.944 us +/- 1.062 us [23.365 us, 34.571 us]
        batches_per_second: 40.16 K +/- 1.55 K [28.93 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40155.60242695837
        batches_per_second_min: 28926.23448275862
        batches_per_second_std: 1550.3797829791192
        seconds_per_batch_max: 3.457069396972656e-05
        seconds_per_batch_mean: 2.4943828582763672e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 1.0619966419221296e-06
    on_device_inference:
      human_readable:
        batch_latency: -25949970.873 us +/- 748.064 ms [-27213920.593 us, -25284160.614
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03674589982626775
        batches_per_second_mean: -0.038567277745834225
        batches_per_second_min: -0.03955045276234138
        batches_per_second_std: 0.001095818092011583
        seconds_per_batch_max: -25.284160614013672
        seconds_per_batch_mean: -25.949970872879028
        seconds_per_batch_min: -27.21392059326172
        seconds_per_batch_std: 0.748064465147134
    total:
      human_readable:
        batch_latency: 26.082 ms +/- 750.254 us [25.410 ms, 27.346 ms]
        batches_per_second: 38.37 +/- 1.09 [36.57, 39.35]
      metrics:
        batches_per_second_max: 39.35394402274369
        batches_per_second_mean: 38.372450016942224
        batches_per_second_min: 36.56887772895306
        batches_per_second_std: 1.0880167937696565
        seconds_per_batch_max: 0.027345657348632812
        seconds_per_batch_mean: 0.02608163619041443
        seconds_per_batch_min: 0.02541041374206543
        seconds_per_batch_std: 0.0007502543899817302
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 147.763 us +/- 5.921 us [143.290 us, 280.380 us]
        batches_per_second: 6.78 K +/- 211.64 [3.57 K, 6.98 K]
      metrics:
        batches_per_second_max: 6978.875207986689
        batches_per_second_mean: 6775.71437955063
        batches_per_second_min: 3566.5850340136053
        batches_per_second_std: 211.6385507889385
        seconds_per_batch_max: 0.0002803802490234375
        seconds_per_batch_mean: 0.00014776325225830078
        seconds_per_batch_min: 0.00014328956604003906
        seconds_per_batch_std: 5.921408987464445e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.951 us +/- 0.631 us [23.842 us, 33.379 us]
        batches_per_second: 40.10 K +/- 919.85 [29.96 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 40100.9587723501
        batches_per_second_min: 29959.314285714285
        batches_per_second_std: 919.8451215056721
        seconds_per_batch_max: 3.337860107421875e-05
        seconds_per_batch_mean: 2.495145797729492e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 6.312594630936003e-07
    on_device_inference:
      human_readable:
        batch_latency: -25636134.304 us +/- 55.410 ms [-26657056.808 us, -25485792.160
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.037513518734828874
        batches_per_second_mean: -0.039007620970896766
        batches_per_second_min: -0.03923754826691873
        batches_per_second_std: 8.321350430137947e-05
        seconds_per_batch_max: -25.48579216003418
        seconds_per_batch_mean: -25.63613430404663
        seconds_per_batch_min: -26.65705680847168
        seconds_per_batch_std: 0.05541004105801087
    total:
      human_readable:
        batch_latency: 25.820 ms +/- 58.868 us [25.666 ms, 26.987 ms]
        batches_per_second: 38.73 +/- 0.09 [37.05, 38.96]
      metrics:
        batches_per_second_max: 38.96132945668026
        batches_per_second_mean: 38.72925013697311
        batches_per_second_min: 37.054774188988624
        batches_per_second_std: 0.0868042260088436
        seconds_per_batch_max: 0.026987075805664062
        seconds_per_batch_mean: 0.025820409774780274
        seconds_per_batch_min: 0.025666475296020508
        seconds_per_batch_std: 5.8867801972254316e-05


#####
fp-fp-py-id - Run 4
2024-02-25 23:17:45
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 51.07it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 51.10it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 51.11it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 51.12it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 51.12it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 51.13it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 51.13it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 51.12it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 51.11it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 51.12it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 51.08it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 51.08it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 51.06it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 51.04it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 51.01it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 51.02it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 51.07it/s]
STAGE:2024-02-25 23:16:46 7454:7454 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:16:46 7454:7454 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:16:46 7454:7454 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 38.61it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 38.96it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.07it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 39.12it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 39.16it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.17it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.07it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.52it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.17it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.90it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.70it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.57it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.47it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.41it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 37.40it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:25, 37.41it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.38it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.38it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.36it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.36it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.34it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.35it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.33it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 37.31it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 37.30it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 37.31it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.32it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.29it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.30it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.29it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.31it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.33it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 37.36it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 37.38it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.40it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.40it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.42it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.39it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.35it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:21, 37.31it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.29it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.27it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.25it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 37.21it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 37.23it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.21it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.22it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.22it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 37.23it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.24it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.24it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 37.26it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 37.30it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 37.33it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.33it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.32it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:19, 37.32it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.30it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.27it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.26it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.24it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 37.28it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.32it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.34it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:18, 37.34it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 37.33it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 37.32it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.31it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.33it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.34it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.32it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.27it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.28it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.30it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.31it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 37.33it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.34it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.36it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:16, 37.35it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.34it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.35it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.32it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.34it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.35it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 37.35it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.35it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.35it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:15, 37.31it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 37.29it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.28it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.32it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.34it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.34it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.36it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.37it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.37it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.38it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.38it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.38it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:14, 37.34it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.34it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.35it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:13, 37.36it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 37.35it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.33it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:13, 37.36it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.35it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.36it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:12, 37.38it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 37.37it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.32it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.29it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.21it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.23it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 37.27it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:12, 37.31it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.32it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.35it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:11, 37.36it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 37.37it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.35it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.36it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.37it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.36it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:11, 37.40it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.42it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.41it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:10, 37.39it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 37.38it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.39it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.36it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.34it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.33it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 37.31it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.32it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.33it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:09, 37.33it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 37.35it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.36it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.37it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.36it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.32it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.34it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.37it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.38it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 37.37it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.39it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.34it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.31it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.34it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.35it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:08, 37.36it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.37it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.33it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 37.33it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 37.34it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.35it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.34it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.34it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.24it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:07, 37.23it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.24it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.25it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 37.24it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 37.27it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.30it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.33it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.37it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.35it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.34it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:06, 37.32it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.34it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.35it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 37.33it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 37.33it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.33it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.35it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.36it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.35it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:05, 37.36it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.36it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.36it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 37.37it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 37.37it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.36it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.36it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.35it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.35it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.32it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.31it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.32it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 37.31it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 37.29it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 37.26it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.30it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.31it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.33it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.33it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:03, 37.32it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.31it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.32it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 37.33it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 37.33it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.33it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.33it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.32it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.34it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.31it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.32it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.35it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 37.32it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 37.28it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 37.27it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.32it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.33it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.34it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.35it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.35it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.33it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 37.32it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 37.29it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 37.28it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.27it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.32it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.33it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.34it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.34it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.37it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 38.70it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 38.93it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 39.01it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 39.04it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 39.06it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 39.07it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 39.09it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 39.11it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 39.10it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 39.11it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 39.13it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 39.12it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 39.12it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 39.13it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 39.13it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 39.14it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 39.16it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 39.16it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 39.15it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 39.16it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 39.17it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 39.16it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 39.15it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 39.13it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.13it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.11it/s]
STAGE:2024-02-25 23:17:16 7454:7454 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:17:16 7454:7454 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:17:16 7454:7454 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:25, 38.35it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:25, 38.60it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:25, 38.67it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 38.73it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 38.76it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 38.79it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 38.80it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:24, 38.79it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:24, 38.79it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:24, 38.78it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:24, 38.77it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 38.78it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 38.78it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 38.79it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 38.78it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 38.79it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 38.79it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:23, 38.79it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:23, 38.80it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:23, 38.81it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:23, 38.82it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 38.85it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 38.85it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 38.85it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 38.86it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:22, 38.87it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:22, 38.86it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:02<00:23, 38.42it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.98it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.67it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:23, 37.45it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:23, 37.31it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:23, 37.22it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:23, 37.16it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:23, 37.11it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 37.06it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:22, 37.03it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 37.04it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.04it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.01it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 36.95it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:22, 36.92it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 36.92it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 36.90it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:22, 36.89it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:22, 36.87it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 36.88it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 36.91it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 36.95it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:21, 36.97it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 36.99it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 36.99it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 36.98it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:20, 36.99it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:20, 37.00it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 36.98it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 36.94it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 36.92it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 36.92it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 36.91it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:20, 36.89it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:20, 36.91it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:20, 36.93it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 36.93it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 36.93it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 36.92it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 36.92it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 36.92it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 36.93it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 36.96it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:19, 36.95it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 36.94it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:18, 36.93it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 36.93it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 36.90it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 36.86it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 36.86it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 36.91it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:18, 36.93it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 36.92it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:17, 36.90it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 36.92it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 36.89it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 36.91it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 36.92it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 36.93it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 36.93it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:17, 36.93it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 36.95it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 36.94it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 36.94it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:16, 36.92it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:15, 36.90it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:15, 36.91it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 36.92it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 36.92it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 36.93it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:15, 36.93it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:15, 36.91it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 36.88it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:14, 36.87it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 36.84it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 36.83it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 36.81it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 36.80it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 36.79it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:14, 36.79it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:14, 36.78it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:14, 36.80it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:13, 36.83it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 36.87it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 36.90it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 36.91it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 36.91it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 36.90it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 36.89it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:13, 36.89it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:13, 36.87it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:12, 36.87it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 36.87it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 36.88it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 36.88it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 36.88it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 36.91it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 36.93it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:12, 36.94it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:12, 36.93it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:11, 36.92it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:11, 36.88it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 36.83it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 36.81it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 36.85it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 36.87it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 36.88it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:11, 36.85it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:11, 36.83it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 36.80it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:10, 36.79it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 36.79it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 36.77it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:10, 36.76it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:10, 36.77it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:10, 36.74it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:09, 36.78it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:09, 36.82it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 36.83it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 36.86it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 36.88it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 36.87it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:09, 36.86it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:09, 36.88it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:09, 36.87it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:08, 36.83it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:08, 36.81it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 36.81it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 36.80it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 36.83it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 36.85it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:08, 36.89it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:08, 36.89it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:08, 36.89it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:07, 36.91it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:07, 36.91it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 36.91it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 36.91it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 36.91it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 36.92it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 36.92it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:07, 36.92it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:07, 36.93it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:06, 36.93it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:06, 36.93it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 36.94it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 36.93it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 36.88it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 36.88it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 36.90it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:06, 36.89it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:06, 36.88it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 36.87it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:05, 36.84it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 36.81it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 36.78it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 36.76it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 36.75it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 36.79it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 36.81it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:05, 36.82it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 36.87it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:04, 36.89it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 36.91it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 36.87it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 36.84it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 36.86it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 36.87it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 36.88it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 36.84it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:04, 36.81it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:03, 36.83it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 36.85it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 36.88it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 36.90it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 36.93it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 36.93it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 36.93it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 36.93it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:03, 36.93it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:02, 36.94it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 36.93it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 36.93it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 36.93it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 36.95it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 36.94it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 36.91it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 36.86it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 36.84it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:01, 36.82it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 36.81it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 36.79it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 36.81it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:25<00:01, 36.84it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 36.86it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 36.85it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 36.87it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 36.88it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 36.90it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 36.92it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 36.91it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 36.93it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:26<00:00, 36.93it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 36.92it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 36.93it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 36.94it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 36.93it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 36.91it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.10it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1006.04 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 97.858 us +/- 5.913 us [92.745 us, 227.928 us]
        batches_per_second: 10.25 K +/- 462.22 [4.39 K, 10.78 K]
      metrics:
        batches_per_second_max: 10782.272493573264
        batches_per_second_mean: 10245.075199097737
        batches_per_second_min: 4387.347280334728
        batches_per_second_std: 462.22223111596116
        seconds_per_batch_max: 0.00022792816162109375
        seconds_per_batch_mean: 9.785771369934082e-05
        seconds_per_batch_min: 9.274482727050781e-05
        seconds_per_batch_std: 5.913237272413282e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.557 us +/- 1.011 us [23.603 us, 34.809 us]
        batches_per_second: 39.18 K +/- 1.33 K [28.73 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 39180.6641536818
        batches_per_second_min: 28728.109589041094
        batches_per_second_std: 1328.4472004348543
        seconds_per_batch_max: 3.4809112548828125e-05
        seconds_per_batch_mean: 2.555680274963379e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 1.0111239180333914e-06
    on_device_inference:
      human_readable:
        batch_latency: -26603242.348 us +/- 215.105 ms [-27170688.629 us, -25292064.667
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.0368043671490585
        batches_per_second_mean: -0.03759196356693023
        batches_per_second_min: -0.03953809280405323
        batches_per_second_std: 0.00031670879584813486
        seconds_per_batch_max: -25.292064666748047
        seconds_per_batch_mean: -26.603242347717284
        seconds_per_batch_min: -27.17068862915039
        seconds_per_batch_std: 0.21510509987429563
    total:
      human_readable:
        batch_latency: 26.738 ms +/- 215.787 us [25.420 ms, 27.304 ms]
        batches_per_second: 37.40 +/- 0.31 [36.63, 39.34]
      metrics:
        batches_per_second_max: 39.33881072969424
        batches_per_second_mean: 37.40246697222038
        batches_per_second_min: 36.62507858889277
        batches_per_second_std: 0.31444841980535365
        seconds_per_batch_max: 0.027303695678710938
        seconds_per_batch_mean: 0.02673801827430725
        seconds_per_batch_min: 0.025420188903808594
        seconds_per_batch_std: 0.00021578749487173815
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 149.121 us +/- 6.218 us [143.290 us, 293.255 us]
        batches_per_second: 6.71 K +/- 212.48 [3.41 K, 6.98 K]
      metrics:
        batches_per_second_max: 6978.875207986689
        batches_per_second_mean: 6714.422516625345
        batches_per_second_min: 3410.0032520325203
        batches_per_second_std: 212.47592878656454
        seconds_per_batch_max: 0.0002932548522949219
        seconds_per_batch_mean: 0.00014912056922912598
        seconds_per_batch_min: 0.00014328956604003906
        seconds_per_batch_std: 6.218311925507415e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.741 us +/- 0.986 us [23.603 us, 34.809 us]
        batches_per_second: 38.90 K +/- 1.33 K [28.73 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 38899.66511308146
        batches_per_second_min: 28728.109589041094
        batches_per_second_std: 1331.6567180680677
        seconds_per_batch_max: 3.4809112548828125e-05
        seconds_per_batch_mean: 2.5740623474121093e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 9.85701644989907e-07
    on_device_inference:
      human_readable:
        batch_latency: -26750642.071 us +/- 427.912 ms [-27166912.079 us, -25456384.659
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03680948342959623
        batches_per_second_mean: -0.03739221988438533
        batches_per_second_min: -0.039282875922987015
        batches_per_second_std: 0.0006213899375742228
        seconds_per_batch_max: -25.456384658813477
        seconds_per_batch_mean: -26.750642070770265
        seconds_per_batch_min: -27.166912078857422
        seconds_per_batch_std: 0.42791183617334877
    total:
      human_readable:
        batch_latency: 26.937 ms +/- 429.416 us [25.636 ms, 27.356 ms]
        batches_per_second: 37.13 +/- 0.61 [36.56, 39.01]
      metrics:
        batches_per_second_max: 39.00807261634612
        batches_per_second_mean: 37.132788161216055
        batches_per_second_min: 36.555491641827466
        batches_per_second_std: 0.6148594151524482
        seconds_per_batch_max: 0.027355670928955078
        seconds_per_batch_mean: 0.026937487602233887
        seconds_per_batch_min: 0.025635719299316406
        seconds_per_batch_std: 0.000429415950216987


#####
fp-fp-py-id - Run 5
2024-02-25 23:18:53
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.56it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.55it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 51.13it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 51.20it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 51.19it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 51.18it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 51.17it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 51.14it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 51.12it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 51.16it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 51.18it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 51.20it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 51.18it/s]
STAGE:2024-02-25 23:17:53 7505:7505 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:17:53 7505:7505 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:17:53 7505:7505 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 38.77it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 39.03it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.12it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 39.16it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 39.19it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.21it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.20it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:24, 39.25it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 39.29it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 39.29it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 39.29it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 39.26it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 39.26it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 39.25it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:23, 39.24it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:23, 39.24it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:23, 39.22it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:23, 39.27it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 39.29it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 39.28it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 39.27it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 39.25it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 39.23it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 39.22it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:22, 39.19it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:22, 39.21it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:22, 39.20it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:22, 39.22it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:02<00:22, 39.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 39.25it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 39.24it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 39.23it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 39.23it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 39.23it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:21, 39.23it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:21, 39.23it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:21, 39.24it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:21, 39.29it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:03<00:21, 39.29it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 39.26it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 39.27it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 39.31it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 39.29it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:20, 39.33it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:20, 39.34it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:20, 39.32it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:20, 39.36it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:20, 39.38it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:04<00:20, 39.37it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 39.33it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.98it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.43it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.07it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.82it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.64it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.53it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 37.50it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:05<00:20, 37.48it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.40it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.30it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 37.24it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 37.19it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 37.18it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.21it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.24it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 37.27it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:19, 37.29it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.27it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.26it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.24it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 37.22it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:19, 37.23it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.23it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 37.25it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 37.31it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:07<00:18, 37.33it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.31it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.29it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.29it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 37.28it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 37.27it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.28it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.29it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 37.31it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 37.34it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.30it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.28it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.26it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.24it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 37.24it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.24it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.24it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 37.27it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 37.30it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.29it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.26it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.25it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.24it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 37.21it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:16, 37.21it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.29it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 37.30it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 37.29it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 37.28it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.26it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.25it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.24it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 37.23it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:15, 37.21it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.21it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.23it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 37.27it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 37.29it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.27it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.26it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.24it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.21it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:14, 37.17it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.15it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.15it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 37.20it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 37.23it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.22it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.21it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.21it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.20it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:13, 37.20it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:13, 37.21it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.21it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 37.25it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 37.28it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.28it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.28it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.28it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.28it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 37.27it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:12, 37.28it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.27it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.28it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 37.31it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 37.32it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.31it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.28it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.27it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.25it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:11, 37.23it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.22it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.17it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 37.19it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 37.21it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.22it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.31it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.35it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.37it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 37.39it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.40it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.40it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 37.40it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 37.39it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.37it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.33it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.28it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.26it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.26it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:09, 37.25it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.23it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.24it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 37.30it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 37.31it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.28it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.26it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.25it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.24it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:08, 37.24it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.23it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.24it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 37.24it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 37.25it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.24it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.24it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.24it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.22it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:07, 37.22it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.22it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.22it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.26it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 37.30it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.27it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.25it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.23it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.21it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.22it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:06, 37.22it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.20it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.24it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 37.29it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 37.30it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.26it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.23it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.23it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.21it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:05, 37.21it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.20it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.22it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 37.27it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 37.30it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.27it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.26it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.24it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.25it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.28it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.26it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.26it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 37.22it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 37.23it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.22it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.23it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.24it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.23it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:03, 37.18it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.16it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.11it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 37.08it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 37.07it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.10it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.07it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.12it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.14it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.15it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.19it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.20it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 37.25it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 37.30it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 37.29it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.26it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.24it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.24it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.24it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.23it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.22it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.22it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 37.25it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 37.23it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.19it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.16it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.16it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.18it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.18it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.63it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 38.87it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 39.02it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 39.06it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 39.09it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 39.10it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 39.10it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 39.11it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 39.12it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 39.12it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 39.11it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 39.10it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 39.12it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 39.11it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 39.11it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 39.11it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 39.13it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 39.12it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 39.10it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 39.11it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 39.12it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 39.17it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 39.23it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 39.22it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 39.21it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.18it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.13it/s]
STAGE:2024-02-25 23:18:23 7505:7505 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:18:23 7505:7505 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:18:23 7505:7505 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:25, 38.33it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:25, 38.67it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:25, 38.76it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 38.84it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 38.86it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 38.88it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 38.88it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:24, 38.88it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:24, 38.88it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:24, 38.88it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:24, 38.87it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 38.88it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 38.88it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 38.88it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 38.87it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 38.86it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:23, 38.86it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:23, 38.86it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:23, 38.87it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:23, 38.87it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:23, 38.88it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 38.89it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 38.87it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 38.87it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 38.88it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 38.88it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:22, 38.88it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:22, 38.89it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:02<00:22, 38.88it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:22, 38.88it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:22, 38.89it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 38.89it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 38.89it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 38.88it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 38.55it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 37.68it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:22, 37.42it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 37.26it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.15it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 37.02it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:22, 36.97it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 36.96it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 36.94it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:22, 36.94it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:21, 36.93it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 36.92it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 36.90it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 36.90it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:21, 36.90it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 36.91it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 36.90it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 36.89it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:21, 36.85it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:21, 36.79it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:20, 36.80it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 36.80it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 36.81it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 36.83it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 36.86it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 36.86it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:20, 36.86it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:20, 36.86it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:20, 36.86it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 36.88it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 36.88it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 36.88it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 36.88it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 36.87it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 36.88it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 36.86it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:19, 36.82it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:19, 36.82it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:19, 36.81it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:18, 36.81it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 36.81it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 36.81it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 36.81it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 36.80it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 36.80it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 36.79it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:18, 36.81it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:18, 36.81it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:17, 36.81it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 36.81it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 36.79it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 36.80it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 36.79it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 36.79it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 36.78it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:17, 36.79it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:17, 36.80it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:16, 36.82it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:16, 36.83it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 36.83it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 36.84it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 36.84it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 36.84it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 36.86it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:16, 36.85it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:16, 36.85it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 36.86it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:15, 36.86it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 36.86it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 36.90it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 36.90it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 36.88it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 36.83it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:15, 36.78it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:15, 36.77it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:15, 36.77it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:14, 36.78it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 36.78it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 36.77it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 36.77it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 36.75it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 36.76it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:14, 36.77it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:14, 36.78it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:14, 36.78it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:13, 36.75it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 36.72it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 36.75it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 36.76it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 36.78it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 36.79it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 36.79it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:13, 36.80it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:13, 36.81it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:12, 36.80it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 36.80it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 36.79it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 36.81it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 36.78it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 36.77it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 36.78it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:12, 36.77it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:12, 36.77it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:11, 36.78it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:11, 36.78it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 36.76it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 36.78it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 36.79it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 36.80it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 36.78it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:11, 36.77it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:11, 36.77it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 36.78it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:10, 36.76it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 36.71it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 36.73it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 36.74it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 36.75it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:10, 36.79it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:10, 36.79it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:09, 36.78it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:09, 36.78it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 36.74it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 36.76it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 36.77it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 36.76it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:09, 36.76it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:09, 36.78it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:09, 36.78it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:08, 36.77it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:08, 36.75it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 36.72it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 36.76it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 36.75it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 36.80it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:08, 36.78it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:08, 36.80it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:08, 36.80it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:07, 36.80it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:07, 36.82it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 36.83it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 36.85it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 36.84it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 36.84it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 36.83it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:07, 36.83it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:07, 36.84it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:06, 36.83it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:06, 36.81it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 36.81it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 36.82it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 36.81it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 36.82it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 36.82it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:06, 36.76it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:06, 36.72it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 36.70it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:05, 36.69it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 36.69it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 36.71it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 36.73it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 36.75it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 36.78it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 36.79it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:05, 36.79it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:05, 36.79it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:04, 36.80it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 36.79it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 36.80it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 36.81it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 36.81it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 36.83it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 36.83it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 36.85it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:04, 36.86it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:03, 36.89it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 36.88it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 36.71it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 36.76it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 36.78it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 36.77it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 36.77it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 36.78it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:03, 36.80it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:02, 36.79it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 36.79it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 36.80it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 36.81it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 36.81it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 36.81it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 36.81it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 36.81it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 36.79it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:01, 36.78it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 36.80it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 36.81it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 36.81it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:25<00:01, 36.80it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 36.80it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 36.79it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 36.81it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 36.79it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 36.78it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 36.81it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 36.78it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 36.78it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.08it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1001.70 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 97.588 us +/- 5.907 us [91.553 us, 221.968 us]
        batches_per_second: 10.27 K +/- 482.13 [4.51 K, 10.92 K]
      metrics:
        batches_per_second_max: 10922.666666666666
        batches_per_second_mean: 10274.686842835608
        batches_per_second_min: 4505.160042964554
        batches_per_second_std: 482.12896076169267
        seconds_per_batch_max: 0.0002219676971435547
        seconds_per_batch_mean: 9.758758544921875e-05
        seconds_per_batch_min: 9.1552734375e-05
        seconds_per_batch_std: 5.906502867213553e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.870 us +/- 1.051 us [23.127 us, 34.332 us]
        batches_per_second: 40.27 K +/- 1.51 K [29.13 K, 43.24 K]
      metrics:
        batches_per_second_max: 43240.24742268041
        batches_per_second_mean: 40271.869992004606
        batches_per_second_min: 29127.11111111111
        batches_per_second_std: 1513.2315819284424
        seconds_per_batch_max: 3.4332275390625e-05
        seconds_per_batch_mean: 2.487039566040039e-05
        seconds_per_batch_min: 2.3126602172851562e-05
        seconds_per_batch_std: 1.05113676424086e-06
    on_device_inference:
      human_readable:
        batch_latency: -26419954.905 us +/- 557.545 ms [-27008192.062 us, -25157087.326
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03702580304858641
        batches_per_second_mean: -0.0378675700170123
        batches_per_second_min: -0.03975022970821086
        batches_per_second_std: 0.0008241573945698696
        seconds_per_batch_max: -25.157087326049805
        seconds_per_batch_mean: -26.419954904556274
        seconds_per_batch_min: -27.00819206237793
        seconds_per_batch_std: 0.5575452409593603
    total:
      human_readable:
        batch_latency: 26.554 ms +/- 559.550 us [25.284 ms, 27.148 ms]
        batches_per_second: 37.68 +/- 0.82 [36.84, 39.55]
      metrics:
        batches_per_second_max: 39.55062282529774
        batches_per_second_mean: 37.67664111912853
        batches_per_second_min: 36.83511465130371
        batches_per_second_std: 0.8187725084225388
        seconds_per_batch_max: 0.027148008346557617
        seconds_per_batch_mean: 0.026553803682327272
        seconds_per_batch_min: 0.0252840518951416
        seconds_per_batch_std: 0.0005595504551735728
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 150.304 us +/- 6.259 us [142.813 us, 284.433 us]
        batches_per_second: 6.66 K +/- 221.63 [3.52 K, 7.00 K]
      metrics:
        batches_per_second_max: 7002.176961602671
        batches_per_second_mean: 6662.057149641833
        batches_per_second_min: 3515.761944677284
        batches_per_second_std: 221.62646643164567
        seconds_per_batch_max: 0.00028443336486816406
        seconds_per_batch_mean: 0.00015030384063720702
        seconds_per_batch_min: 0.00014281272888183594
        seconds_per_batch_std: 6.259101201823119e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.359 us +/- 0.976 us [23.365 us, 35.286 us]
        batches_per_second: 39.49 K +/- 1.37 K [28.34 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 39486.579190857665
        batches_per_second_min: 28339.891891891893
        batches_per_second_std: 1372.1415635723997
        seconds_per_batch_max: 3.528594970703125e-05
        seconds_per_batch_mean: 2.535867691040039e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 9.757396791097734e-07
    on_device_inference:
      human_readable:
        batch_latency: -26765693.092 us +/- 503.398 ms [-28178207.397 us, -25360031.128
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03548841790731185
        batches_per_second_mean: -0.037374995291051635
        batches_per_second_min: -0.039432128255500166
        batches_per_second_std: 0.0007303839436548302
        seconds_per_batch_max: -25.360031127929688
        seconds_per_batch_mean: -26.76569309234619
        seconds_per_batch_min: -28.178207397460938
        seconds_per_batch_std: 0.5033979976386072
    total:
      human_readable:
        batch_latency: 26.953 ms +/- 505.176 us [25.548 ms, 28.372 ms]
        batches_per_second: 37.11 +/- 0.72 [35.25, 39.14]
      metrics:
        batches_per_second_max: 39.141670632809806
        batches_per_second_mean: 37.11495486642512
        batches_per_second_min: 35.24654829032177
        batches_per_second_std: 0.722700367455873
        seconds_per_batch_max: 0.028371572494506836
        seconds_per_batch_mean: 0.026953153371810912
        seconds_per_batch_min: 0.025548219680786133
        seconds_per_batch_std: 0.0005051764597723183


#####
fp-fp-py-id - Run 6
2024-02-25 23:20:02
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.96it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.93it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.68it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.02it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 47.63it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 47.42it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 47.29it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 47.22it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 47.16it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 47.12it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 47.08it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 47.08it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 47.09it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 47.08it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 47.10it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 47.10it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 47.10it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 47.08it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:02<00:00, 47.09it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 47.09it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 47.34it/s]
STAGE:2024-02-25 23:19:01 7551:7551 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:19:01 7551:7551 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:19:01 7551:7551 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.82it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 38.09it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.16it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.21it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.21it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.20it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.20it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.19it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.18it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 38.20it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 38.21it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.22it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.23it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.25it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.27it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.29it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.29it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:24, 38.29it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 38.28it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 38.28it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.28it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.26it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.25it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.27it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.28it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.26it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.28it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 38.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.28it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.29it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.28it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.30it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.30it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.29it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.30it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.31it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.31it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.31it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.33it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 38.33it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:20, 38.34it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.33it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.33it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.34it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.15it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.57it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:21, 37.14it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:21, 36.87it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:21, 36.67it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 36.52it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 36.42it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 36.34it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 36.26it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 36.18it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 36.17it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:20, 36.18it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:20, 36.19it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:20, 36.19it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 36.17it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:20, 36.19it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:20, 36.17it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 36.17it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 36.19it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 36.19it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:19, 36.20it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:19, 36.20it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:19, 36.20it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 36.19it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:19, 36.22it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 36.21it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 36.20it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 36.19it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 36.20it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 36.20it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:18, 36.21it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:18, 36.19it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 36.20it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:18, 36.18it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:18, 36.19it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 36.16it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 36.17it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 36.15it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 36.15it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:17, 36.16it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:17, 36.18it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 36.18it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 36.18it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:17, 36.20it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 36.22it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 36.21it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 36.20it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 36.21it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:16, 36.22it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:16, 36.23it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 36.23it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 36.21it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:16, 36.22it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 36.23it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 36.22it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 36.23it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 36.21it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:15, 36.20it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:15, 36.20it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 36.19it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 36.20it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:15, 36.21it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.21it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 36.16it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 36.12it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 36.11it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:14, 36.12it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:14, 36.16it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 36.17it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 36.19it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:14, 36.18it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 36.19it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 36.20it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 36.21it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 36.18it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:13, 36.19it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:13, 36.20it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 36.22it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 36.21it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:13, 36.21it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 36.22it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 36.22it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 36.22it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 36.21it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 36.21it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:12, 36.17it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 36.17it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 36.17it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:12, 36.16it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 36.17it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 36.19it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 36.18it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 36.20it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 36.20it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:11, 36.20it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 36.21it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 36.20it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:11, 36.19it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 36.18it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 36.19it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 36.19it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 36.20it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 36.20it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 36.22it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:10, 36.20it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 36.19it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:10, 36.15it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 36.14it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 36.16it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 36.18it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 36.17it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 36.18it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 36.21it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:09, 36.21it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 36.22it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:09, 36.21it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 36.22it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 36.20it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 36.21it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 36.18it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 36.20it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 36.22it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:08, 36.22it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 36.23it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:08, 36.24it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 36.21it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 36.20it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 36.20it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 36.21it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 36.21it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 36.19it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:07, 36.19it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 36.19it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:07, 36.20it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 36.20it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 36.20it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 36.20it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 36.20it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 36.21it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 36.22it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 36.20it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:06, 36.20it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:06, 36.20it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:05, 36.21it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 36.19it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 36.19it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 36.17it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 36.19it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 36.20it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 36.21it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:05, 36.21it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:05, 36.20it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:04, 36.20it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 36.21it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 36.20it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 36.20it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 36.18it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 36.18it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 36.19it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 36.20it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 36.21it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:03, 36.21it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 36.22it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 36.21it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 36.22it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 36.22it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 36.23it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 36.22it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 36.21it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 36.21it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:02, 36.20it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 36.21it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 36.17it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 36.18it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 36.18it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 36.19it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 36.20it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 36.20it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 36.19it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:01, 36.19it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 36.19it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 36.19it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 36.20it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 36.18it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 36.16it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 36.15it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 36.18it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 36.18it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:00, 36.20it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 36.20it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 36.21it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 36.22it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 36.22it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 36.19it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 36.19it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 36.18it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 36.19it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.19it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.61it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.78it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.93it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.98it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 38.03it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.04it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.03it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 38.01it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 38.01it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 38.01it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 38.02it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 38.03it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 38.00it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 38.00it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 38.00it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 38.01it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 38.02it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 38.03it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 38.03it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 38.04it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 38.03it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 38.02it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 37.49it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 37.09it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 36.80it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 36.59it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.71it/s]
STAGE:2024-02-25 23:19:31 7551:7551 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:19:31 7551:7551 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:19:31 7551:7551 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.34it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.59it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.71it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.76it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 37.79it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 37.82it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.83it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.85it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.86it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.86it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.86it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.85it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.85it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 37.85it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 37.84it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 37.85it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 37.84it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.86it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.86it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.86it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.87it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.87it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 37.88it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 37.88it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 37.88it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 37.89it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 37.89it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 37.90it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 37.90it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.90it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.35it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:23, 36.92it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:23, 36.61it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:23, 36.39it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:23, 36.25it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:23, 36.15it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:23, 36.09it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:23, 36.03it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:23, 35.98it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:23, 35.94it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:23, 35.92it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:23, 35.93it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:23, 35.89it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 35.86it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 35.87it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:22, 35.87it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:22, 35.87it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 35.87it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 35.87it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:22, 35.87it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:22, 35.90it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:22, 35.89it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 35.88it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 35.89it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:21, 35.87it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:21, 35.90it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:21, 35.92it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:21, 35.93it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:21, 35.93it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:21, 35.95it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:21, 35.93it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 35.93it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:20, 35.94it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:20, 35.93it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:07<00:20, 35.92it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:20, 35.92it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:20, 35.87it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:20, 35.85it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:20, 35.87it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:20, 35.87it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 35.88it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 35.90it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:19, 35.89it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:08<00:19, 35.89it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:19, 35.90it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:19, 35.88it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:19, 35.88it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:19, 35.87it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:19, 35.85it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 35.86it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 35.85it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 35.84it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:09<00:18, 35.83it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 35.85it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 35.89it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 35.89it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:18, 35.89it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:18, 35.88it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 35.87it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 35.85it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 35.85it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:10<00:17, 35.83it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 35.86it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:17, 35.86it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:17, 35.87it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:17, 35.88it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:17, 35.87it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 35.86it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 35.87it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 35.88it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:11<00:16, 35.88it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:16, 35.84it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:16, 35.83it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:16, 35.83it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:16, 35.80it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:16, 35.81it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 35.83it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 35.84it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 35.85it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:12<00:15, 35.84it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:15, 35.84it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:15, 35.85it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:15, 35.87it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:15, 35.82it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:15, 35.84it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 35.84it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 35.85it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 35.86it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:13<00:14, 35.87it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:13<00:14, 35.87it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:14, 35.89it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:14, 35.88it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:14, 35.86it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:14, 35.85it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 35.83it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 35.81it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 35.83it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:14<00:13, 35.82it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:14<00:13, 35.85it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:13, 35.87it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:13, 35.86it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:13, 35.84it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:13, 35.83it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 35.85it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 35.86it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 35.85it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:15<00:12, 35.85it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:15<00:12, 35.85it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 35.84it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 35.85it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:12, 35.87it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:12, 35.84it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 35.84it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 35.84it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 35.84it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:16<00:11, 35.81it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 35.82it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 35.84it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 35.84it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:17<00:10, 35.86it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:17<00:10, 35.88it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 35.87it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 35.87it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 35.87it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:10, 35.88it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 35.89it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 35.87it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:18<00:09, 35.86it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:18<00:09, 35.87it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:18<00:09, 35.88it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:09, 35.87it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:09, 35.87it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:09, 35.86it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:09, 35.87it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 35.88it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 35.87it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:19<00:08, 35.88it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:19<00:08, 35.88it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:19<00:08, 35.86it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:19<00:08, 35.87it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:08, 35.87it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:08, 35.87it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:08, 35.87it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 35.88it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 35.88it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:20<00:07, 35.85it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:20<00:07, 35.83it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:20<00:07, 35.83it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:20<00:07, 35.83it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:07, 35.82it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:07, 35.84it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:07, 35.84it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 35.85it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 35.84it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:21<00:06, 35.82it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:21<00:06, 35.83it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:21<00:06, 35.84it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:21<00:06, 35.85it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:21<00:06, 35.86it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:21<00:06, 35.85it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:06, 35.86it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 35.87it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 35.87it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:22<00:05, 35.87it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:22<00:05, 35.87it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:22<00:05, 35.86it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:22<00:05, 35.86it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:22<00:05, 35.85it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:22<00:05, 35.84it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:05, 35.85it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 35.85it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 35.84it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:23<00:04, 35.83it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:23<00:04, 35.84it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:23<00:04, 35.83it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:23<00:04, 35.84it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:23<00:04, 35.85it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:23<00:04, 35.85it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:04, 35.85it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 35.85it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 35.86it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:24<00:03, 35.85it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:24<00:03, 35.85it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:24<00:03, 35.84it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:24<00:03, 35.85it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:24<00:03, 35.87it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:24<00:03, 35.87it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:03, 35.86it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 35.84it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 35.83it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:25<00:02, 35.85it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:25<00:02, 35.86it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:25<00:02, 35.86it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:25<00:02, 35.88it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:25<00:02, 35.88it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:25<00:02, 35.88it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:02, 35.86it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 35.87it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 35.88it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:26<00:01, 35.88it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:26<00:01, 35.88it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:26<00:01, 35.88it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:26<00:01, 35.89it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:26<00:01, 35.87it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:26<00:01, 35.87it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:26<00:01, 35.87it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 35.88it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 35.87it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:27<00:00, 35.87it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:27<00:00, 35.88it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:27<00:00, 35.85it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:27<00:00, 35.86it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:27<00:00, 35.87it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:27<00:00, 35.87it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 35.89it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.09it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1004.45 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 98.653 us +/- 5.842 us [93.222 us, 225.306 us]
        batches_per_second: 10.16 K +/- 455.97 [4.44 K, 10.73 K]
      metrics:
        batches_per_second_max: 10727.120204603581
        batches_per_second_mean: 10161.901365940026
        batches_per_second_min: 4438.4169312169315
        batches_per_second_std: 455.97138274321924
        seconds_per_batch_max: 0.00022530555725097656
        seconds_per_batch_mean: 9.865307807922363e-05
        seconds_per_batch_min: 9.322166442871094e-05
        seconds_per_batch_std: 5.841698138316434e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.467 us +/- 0.985 us [24.080 us, 34.571 us]
        batches_per_second: 39.32 K +/- 1.31 K [28.93 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 39316.61336941546
        batches_per_second_min: 28926.23448275862
        batches_per_second_std: 1312.928323346003
        seconds_per_batch_max: 3.457069396972656e-05
        seconds_per_batch_mean: 2.54671573638916e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 9.854365384874974e-07
    on_device_inference:
      human_readable:
        batch_latency: -27158129.614 us +/- 614.766 ms [-27715967.178 us, -25882400.513
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.0360802851859822
        batches_per_second_mean: -0.03684088325574403
        batches_per_second_min: -0.038636292623224815
        batches_per_second_std: 0.0008612858682065326
        seconds_per_batch_max: -25.882400512695312
        seconds_per_batch_mean: -27.158129613876344
        seconds_per_batch_min: -27.715967178344727
        seconds_per_batch_std: 0.6147663798466875
    total:
      human_readable:
        batch_latency: 27.294 ms +/- 616.423 us [26.012 ms, 27.872 ms]
        batches_per_second: 36.66 +/- 0.85 [35.88, 38.44]
      metrics:
        batches_per_second_max: 38.443878205715755
        batches_per_second_mean: 36.65740567900591
        batches_per_second_min: 35.878190652159034
        batches_per_second_std: 0.854958832898916
        seconds_per_batch_max: 0.027872085571289062
        seconds_per_batch_mean: 0.027293993949890138
        seconds_per_batch_min: 0.026011943817138672
        seconds_per_batch_std: 0.0006164227121162512
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 149.862 us +/- 6.208 us [143.528 us, 289.202 us]
        batches_per_second: 6.68 K +/- 214.66 [3.46 K, 6.97 K]
      metrics:
        batches_per_second_max: 6967.282392026578
        batches_per_second_mean: 6681.320443953903
        batches_per_second_min: 3457.7938994229185
        batches_per_second_std: 214.66195538680094
        seconds_per_batch_max: 0.0002892017364501953
        seconds_per_batch_mean: 0.00014986181259155274
        seconds_per_batch_min: 0.00014352798461914062
        seconds_per_batch_std: 6.2079347217346016e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.603 us +/- 0.749 us [23.842 us, 34.571 us]
        batches_per_second: 39.09 K +/- 1.04 K [28.93 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 39088.06314114888
        batches_per_second_min: 28926.23448275862
        batches_per_second_std: 1042.185574868878
        seconds_per_batch_max: 3.457069396972656e-05
        seconds_per_batch_mean: 2.5603055953979492e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 7.488480873258794e-07
    on_device_inference:
      human_readable:
        batch_latency: -27501511.496 us +/- 479.056 ms [-27902912.140 us, -26129056.931
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03583855315841058
        batches_per_second_mean: -0.036373133181504355
        batches_per_second_min: -0.03827156880013951
        batches_per_second_std: 0.000659937315131964
        seconds_per_batch_max: -26.129056930541992
        seconds_per_batch_mean: -27.50151149559021
        seconds_per_batch_min: -27.902912139892578
        seconds_per_batch_std: 0.47905606859919403
    total:
      human_readable:
        batch_latency: 27.689 ms +/- 480.567 us [26.311 ms, 28.090 ms]
        batches_per_second: 36.13 +/- 0.65 [35.60, 38.01]
      metrics:
        batches_per_second_max: 38.00737619500702
        batches_per_second_mean: 36.12682858033735
        batches_per_second_min: 35.600159569501855
        batches_per_second_std: 0.6529864955813443
        seconds_per_batch_max: 0.02808976173400879
        seconds_per_batch_mean: 0.027688945770263672
        seconds_per_batch_min: 0.02631068229675293
        seconds_per_batch_std: 0.0004805674257176832


#####
fp-fp-py-id - Run 7
2024-02-25 23:21:12
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 48.77it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 48.81it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.81it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.83it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 48.82it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 48.84it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 48.86it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 48.87it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 48.87it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 48.86it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 48.86it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 48.85it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 48.85it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 48.86it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 48.86it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 48.86it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 48.86it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 48.87it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 48.87it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.90it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.86it/s]
STAGE:2024-02-25 23:20:10 7597:7597 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:20:10 7597:7597 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:20:10 7597:7597 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.13it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.45it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.53it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.57it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.59it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.61it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.62it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.62it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.63it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.63it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.64it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.65it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.63it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 37.62it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.64it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:25, 37.12it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:25, 36.78it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:25, 36.55it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:25, 36.38it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:25, 36.26it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:25, 36.15it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:25, 36.07it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:25, 36.01it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 36.00it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 36.00it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:24, 35.98it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:03<00:24, 36.00it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:24, 35.99it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:24, 35.97it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:24, 35.98it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:24, 35.98it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:24, 36.00it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 36.01it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 36.01it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 36.00it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:04<00:23, 36.02it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 36.01it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:23, 36.02it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:23, 36.03it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:23, 36.04it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:23, 36.04it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 36.03it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 36.01it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 35.99it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:05<00:22, 35.96it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 35.96it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:22, 35.96it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:22, 35.98it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:22, 36.00it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:22, 35.99it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:22, 35.99it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 35.94it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 35.93it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:06<00:21, 35.96it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:06<00:21, 35.97it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:21, 35.98it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 36.00it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:21, 36.00it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:21, 35.99it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:21, 36.00it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 35.98it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 35.95it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:07<00:20, 35.95it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:07<00:20, 35.93it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 35.94it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 35.95it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:20, 35.97it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:20, 35.97it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:20, 35.99it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 35.99it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 35.99it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:08<00:19, 35.97it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:08<00:19, 35.98it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 35.99it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 35.99it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:19, 35.99it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:19, 35.99it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:19, 35.99it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 35.99it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 35.96it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:09<00:18, 35.97it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:09<00:18, 35.98it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 35.97it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 35.93it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:18, 35.94it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:18, 35.97it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:18, 35.97it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 35.99it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 35.99it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:10<00:17, 35.98it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:10<00:17, 35.99it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 35.99it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 35.99it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 35.99it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:17, 36.00it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:17, 36.00it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 35.99it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 35.98it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:11<00:16, 35.97it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:11<00:16, 35.97it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:11<00:16, 35.96it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 35.98it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 36.00it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:16, 35.97it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:16, 35.96it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 35.96it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 35.96it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:12<00:15, 35.96it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:12<00:15, 35.97it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:12<00:15, 35.99it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 35.99it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 36.00it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:15, 36.01it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.00it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 35.98it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 35.97it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:13<00:14, 35.98it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:13<00:14, 36.00it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:13<00:14, 35.99it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 36.00it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 36.01it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:14, 36.00it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:14, 35.99it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 35.98it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 35.99it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:14<00:13, 35.99it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:14<00:13, 35.96it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:14<00:13, 35.97it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 35.97it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 35.98it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:13, 35.98it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:13, 36.00it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 36.00it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 36.02it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:15<00:12, 35.99it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:15<00:12, 35.96it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:15<00:12, 35.99it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 35.98it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 35.98it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:12, 35.97it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:12, 35.97it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 35.97it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 35.98it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:16<00:11, 36.00it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:16<00:11, 35.99it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:16<00:11, 35.98it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 35.97it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 35.98it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:11, 35.98it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:11, 35.95it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 35.93it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 35.95it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:17<00:10, 35.96it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:17<00:10, 35.95it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:17<00:10, 35.95it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:10, 35.94it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 35.93it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:10, 35.95it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:10, 35.96it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 35.98it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 35.98it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:18<00:09, 35.98it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:18<00:09, 36.00it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:18<00:09, 35.98it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:09, 35.95it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 35.96it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:09, 35.98it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:09, 35.99it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 36.02it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 35.99it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:19<00:08, 35.98it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:19<00:08, 35.99it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:19<00:08, 35.98it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:08, 35.97it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 35.98it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:08, 35.96it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:08, 35.92it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 35.89it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 35.92it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:20<00:07, 35.95it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:20<00:07, 35.96it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:20<00:07, 35.96it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:07, 35.96it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 35.99it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:07, 35.97it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:07, 35.97it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 35.97it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 35.98it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:21<00:06, 35.97it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:21<00:06, 35.99it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:21<00:06, 35.99it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 36.00it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:06, 35.98it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:06, 35.99it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:06, 35.99it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 35.99it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 36.01it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:22<00:05, 36.02it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:22<00:05, 36.02it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:22<00:05, 35.99it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 35.98it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:05, 35.98it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:05, 35.97it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:05, 35.98it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 35.97it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 35.96it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:23<00:04, 35.95it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:23<00:04, 35.95it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:23<00:04, 35.95it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 35.95it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 35.97it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 35.96it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:04, 35.94it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 35.93it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 35.95it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:24<00:03, 35.94it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:24<00:03, 35.94it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:24<00:03, 35.96it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:24<00:03, 35.96it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 35.97it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 35.97it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:03, 35.98it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 35.99it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 36.00it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:25<00:02, 35.97it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:25<00:02, 35.98it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:25<00:02, 36.00it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:25<00:02, 35.98it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 35.96it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 35.98it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:02, 35.97it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 35.98it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 35.97it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:26<00:01, 35.98it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:26<00:01, 35.99it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:26<00:01, 36.01it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:26<00:01, 36.00it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 35.99it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 36.00it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:01, 36.00it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 35.98it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 35.99it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:27<00:00, 36.00it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:27<00:00, 35.99it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:27<00:00, 35.98it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:27<00:00, 35.97it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 35.98it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 35.99it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.00it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.08it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.08it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.27it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.35it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.37it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.39it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 37.40it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.41it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.42it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.43it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.45it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 37.44it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 37.45it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 37.46it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 37.47it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 37.47it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 37.46it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 37.46it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 37.45it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 37.45it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 37.46it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 37.45it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 37.45it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 37.46it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 37.47it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.46it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.43it/s]
STAGE:2024-02-25 23:20:41 7597:7597 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:20:41 7597:7597 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:20:41 7597:7597 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:27, 36.78it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.01it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.10it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.15it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:26, 37.16it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:26, 37.17it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:26, 37.18it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:26, 37.20it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.21it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.21it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.21it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.20it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.20it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:25, 37.19it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:25, 36.69it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:25, 36.35it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:25, 36.08it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:25, 35.92it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:25, 35.81it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:25, 35.73it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:25, 35.68it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:25, 35.67it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:25, 35.65it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:25, 35.63it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:25, 35.61it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:25, 35.59it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:25, 35.58it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:03<00:24, 35.58it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:24, 35.58it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:24, 35.57it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:24, 35.58it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:24, 35.58it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:24, 35.58it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:24, 35.57it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:24, 35.59it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:24, 35.59it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:04<00:23, 35.59it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:23, 35.61it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:23, 35.61it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:23, 35.61it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:23, 35.58it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:23, 35.59it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:23, 35.58it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:23, 35.57it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:23, 35.58it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:05<00:22, 35.58it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:22, 35.58it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 35.57it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 35.57it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:22, 35.58it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:22, 35.59it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:22, 35.55it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:22, 35.56it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:06<00:22, 35.58it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:06<00:21, 35.59it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:21, 35.59it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:21, 35.58it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:21, 35.57it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:21, 35.56it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:21, 35.54it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:21, 35.51it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:21, 35.50it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:07<00:21, 35.51it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:20, 35.54it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:20, 35.51it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:20, 35.51it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:08<00:20, 35.52it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:08<00:19, 35.52it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:08<00:19, 35.52it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:19, 35.52it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:19, 35.51it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:19, 35.50it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:19, 35.51it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:19, 35.50it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:19, 35.50it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:09<00:19, 35.50it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:18, 35.49it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:18, 35.50it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:10<00:18, 35.51it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:10<00:17, 35.49it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:10<00:17, 35.50it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 35.51it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:17, 35.52it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:17, 35.51it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:17, 35.53it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:17, 35.54it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:17, 35.54it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:11<00:16, 35.55it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:11<00:16, 35.55it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:11<00:16, 35.53it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:16, 35.52it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:16, 35.52it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:16, 35.52it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:16, 35.50it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:16, 35.51it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:16, 35.50it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:12<00:15, 35.53it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:12<00:15, 35.52it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:12<00:15, 35.52it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:15, 35.43it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:15, 35.45it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:15, 35.45it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:15, 35.46it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:15, 35.49it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:15, 35.51it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:13<00:14, 35.53it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:13<00:14, 35.53it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:13<00:14, 35.54it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:13<00:14, 35.52it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:14, 35.55it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:14, 35.57it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:14, 35.54it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:14, 35.55it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:14<00:14, 35.55it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:14<00:13, 35.56it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:14<00:13, 35.54it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:14<00:13, 35.54it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:14<00:13, 35.55it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:13, 35.54it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:13, 35.54it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:13, 35.55it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:13, 35.55it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:15<00:13, 35.55it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:15<00:12, 35.54it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:15<00:12, 35.54it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:15<00:12, 35.55it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:15<00:12, 35.53it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 35.55it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 35.54it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:12, 35.53it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:12, 35.53it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:16<00:12, 35.53it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:16<00:11, 35.55it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:16<00:11, 35.54it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:16<00:11, 35.53it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:16<00:11, 35.52it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 35.49it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 35.51it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:11, 35.52it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:11, 35.51it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:17<00:11, 35.52it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:17<00:10, 35.51it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:17<00:10, 35.51it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:17<00:10, 35.52it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:17<00:10, 35.52it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 35.52it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 35.50it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 35.50it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:10, 35.51it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:18<00:10, 35.52it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:18<00:09, 35.52it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:18<00:09, 35.52it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:18<00:09, 35.52it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:18<00:09, 35.52it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:09, 35.51it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:09, 35.52it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:09, 35.52it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:09, 35.53it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:19<00:09, 35.52it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:19<00:08, 35.51it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:19<00:08, 35.52it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:19<00:08, 35.51it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:19<00:08, 35.50it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:19<00:08, 35.50it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:08, 35.50it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:08, 35.50it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:08, 35.50it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:20<00:08, 35.48it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:20<00:07, 35.50it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:20<00:07, 35.50it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:20<00:07, 35.51it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:20<00:07, 35.51it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:20<00:07, 35.50it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:07, 35.51it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:07, 35.52it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:07, 35.52it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:21<00:06, 35.52it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:21<00:06, 35.50it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:21<00:06, 35.50it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:21<00:06, 35.51it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:21<00:06, 35.51it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:21<00:06, 35.51it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:21<00:06, 35.49it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:21<00:06, 35.49it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:06, 35.51it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:22<00:05, 35.50it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:22<00:05, 35.50it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:22<00:05, 35.49it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:22<00:05, 35.49it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:22<00:05, 35.48it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:22<00:05, 35.50it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:22<00:05, 35.51it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:22<00:05, 35.52it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:23<00:05, 35.52it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:23<00:04, 35.53it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:23<00:04, 35.55it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:23<00:04, 35.55it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:23<00:04, 35.54it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:23<00:04, 35.54it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:23<00:04, 35.54it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:23<00:04, 35.52it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:23<00:04, 35.53it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:24<00:04, 35.52it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:24<00:03, 35.53it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:24<00:03, 35.54it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:24<00:03, 35.54it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:24<00:03, 35.51it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:24<00:03, 35.51it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:24<00:03, 35.50it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:24<00:03, 35.51it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:25<00:03, 35.48it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:25<00:02, 35.47it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:25<00:02, 35.47it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:25<00:02, 35.45it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:25<00:02, 35.48it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:25<00:02, 35.49it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:25<00:02, 35.50it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:25<00:02, 35.48it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:25<00:02, 35.49it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:26<00:02, 35.51it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:26<00:01, 35.51it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:26<00:01, 35.49it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:26<00:01, 35.48it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:26<00:01, 35.49it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:26<00:01, 35.49it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:26<00:01, 35.52it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:26<00:01, 35.52it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:26<00:01, 35.52it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:27<00:01, 35.53it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:27<00:00, 35.53it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:27<00:00, 35.53it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:27<00:00, 35.53it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:27<00:00, 35.52it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:27<00:00, 35.53it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:27<00:00, 35.54it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:27<00:00, 35.55it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:27<00:00, 35.55it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:28<00:00, 35.57it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:28<00:00, 35.61it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1004.66 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 99.371 us +/- 6.000 us [93.222 us, 232.697 us]
        batches_per_second: 10.09 K +/- 452.40 [4.30 K, 10.73 K]
      metrics:
        batches_per_second_max: 10727.120204603581
        batches_per_second_mean: 10088.782852699098
        batches_per_second_min: 4297.44262295082
        batches_per_second_std: 452.4011711018025
        seconds_per_batch_max: 0.000232696533203125
        seconds_per_batch_mean: 9.937143325805664e-05
        seconds_per_batch_min: 9.322166442871094e-05
        seconds_per_batch_std: 6.000439887519206e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.564 us +/- 0.686 us [24.080 us, 34.571 us]
        batches_per_second: 39.14 K +/- 943.69 [28.93 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 39141.96563005383
        batches_per_second_min: 28926.23448275862
        batches_per_second_std: 943.6941847973808
        seconds_per_batch_max: 3.457069396972656e-05
        seconds_per_batch_mean: 2.5564432144165038e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 6.858161298310198e-07
    on_device_inference:
      human_readable:
        batch_latency: -27564056.194 us +/- 300.001 ms [-27872768.402 us, -26330112.457
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035877311703442834
        batches_per_second_mean: -0.03628359348600897
        batches_per_second_min: -0.03797932886244417
        batches_per_second_std: 0.00041004580477464183
        seconds_per_batch_max: -26.33011245727539
        seconds_per_batch_mean: -27.56405619430542
        seconds_per_batch_min: -27.87276840209961
        seconds_per_batch_std: 0.3000011229363017
    total:
      human_readable:
        batch_latency: 27.701 ms +/- 301.073 us [26.460 ms, 28.013 ms]
        batches_per_second: 36.10 +/- 0.41 [35.70, 37.79]
      metrics:
        batches_per_second_max: 37.792651060532336
        batches_per_second_mean: 36.10464448828348
        batches_per_second_min: 35.697419486620824
        batches_per_second_std: 0.40740276757892363
        seconds_per_batch_max: 0.028013229370117188
        seconds_per_batch_mean: 0.027700664758682252
        seconds_per_batch_min: 0.02646017074584961
        seconds_per_batch_std: 0.0003010725235701799
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 150.464 us +/- 6.079 us [144.243 us, 286.579 us]
        batches_per_second: 6.65 K +/- 209.70 [3.49 K, 6.93 K]
      metrics:
        batches_per_second_max: 6932.7338842975205
        batches_per_second_mean: 6654.212451994852
        batches_per_second_min: 3489.4376039933445
        batches_per_second_std: 209.69693477887375
        seconds_per_batch_max: 0.0002865791320800781
        seconds_per_batch_mean: 0.00015046429634094237
        seconds_per_batch_min: 0.0001442432403564453
        seconds_per_batch_std: 6.0786187948922974e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 26.087 us +/- 0.758 us [23.842 us, 35.048 us]
        batches_per_second: 38.36 K +/- 1.00 K [28.53 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 38362.84444762802
        batches_per_second_min: 28532.680272108842
        batches_per_second_std: 1004.2131799402756
        seconds_per_batch_max: 3.504753112792969e-05
        seconds_per_batch_mean: 2.6086568832397462e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 7.57885187755521e-07
    on_device_inference:
      human_readable:
        batch_latency: -27870776.440 us +/- 293.688 ms [-28571807.861 us, -26599967.957
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.03]
      metrics:
        batches_per_second_max: -0.034999535376040995
        batches_per_second_mean: -0.03588401955875625
        batches_per_second_min: -0.037594030249725296
        batches_per_second_std: 0.0003932472970150238
        seconds_per_batch_max: -26.59996795654297
        seconds_per_batch_mean: -27.87077643966675
        seconds_per_batch_min: -28.571807861328125
        seconds_per_batch_std: 0.2936884681007557
    total:
      human_readable:
        batch_latency: 28.059 ms +/- 294.679 us [26.781 ms, 28.767 ms]
        batches_per_second: 35.64 +/- 0.39 [34.76, 37.34]
      metrics:
        batches_per_second_max: 37.33979061320419
        batches_per_second_mean: 35.642872950846154
        batches_per_second_min: 34.761922127003594
        batches_per_second_std: 0.3892280752988195
        seconds_per_batch_max: 0.028767108917236328
        seconds_per_batch_mean: 0.028059317588806153
        seconds_per_batch_min: 0.026781082153320312
        seconds_per_batch_std: 0.0002946786462240375


#####
fp-fp-py-id - Run 8
2024-02-25 23:22:20
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.67it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.75it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.77it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.77it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.78it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.80it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.81it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.82it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.81it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.81it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.80it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.77it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.74it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.73it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.73it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.67it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.68it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.71it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.72it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.73it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.75it/s]
STAGE:2024-02-25 23:21:20 7644:7644 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:21:20 7644:7644 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:21:20 7644:7644 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.79it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.22it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 36.90it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 36.79it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 36.71it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 36.63it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:26, 36.60it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:26, 36.56it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:26, 36.51it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:26, 36.49it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:26, 36.47it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:26, 36.43it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:26, 36.41it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 36.44it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 36.44it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:25, 36.45it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:25, 36.46it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:25, 36.43it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:25, 36.40it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:25, 36.38it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:25, 36.41it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:25, 36.43it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 36.44it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 36.44it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 36.44it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 36.44it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:24, 36.44it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:03<00:24, 36.43it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:24, 36.44it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:24, 36.44it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:24, 36.43it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 36.43it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 36.43it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 36.43it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 36.44it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 36.44it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:04<00:23, 36.44it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 36.43it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:23, 36.39it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:23, 36.40it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 36.40it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 36.37it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 36.35it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 36.36it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 36.38it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:05<00:22, 36.40it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 36.41it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:22, 36.42it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:22, 36.42it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 36.41it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 36.40it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 36.40it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 36.40it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 36.40it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:06<00:21, 36.40it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:06<00:21, 36.38it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:21, 36.39it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 36.41it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 36.41it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 36.41it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 36.41it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 36.40it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 36.40it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:07<00:20, 36.43it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:07<00:20, 36.43it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 36.43it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 36.43it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 36.44it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 36.44it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 36.44it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 36.44it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 36.44it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:08<00:19, 36.45it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:08<00:19, 36.46it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 36.46it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 36.47it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 36.46it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 36.42it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 36.41it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 36.43it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 36.44it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 36.45it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:09<00:18, 36.46it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 36.45it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 36.47it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 36.46it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 36.46it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 36.47it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 36.45it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 36.46it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 36.47it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:10<00:17, 36.49it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 36.48it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 36.47it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 36.47it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 36.48it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 36.46it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 36.47it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 36.43it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 36.44it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:11<00:16, 36.44it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:11<00:16, 36.45it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 36.45it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 36.45it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 36.44it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 36.41it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 36.35it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 36.37it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 36.37it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:12<00:15, 36.38it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:12<00:15, 36.38it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 36.42it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 36.41it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 36.40it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.41it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 36.41it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 36.42it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 36.43it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:13<00:14, 36.43it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:13<00:14, 36.42it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 36.42it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 36.42it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 36.41it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 36.41it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 36.41it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 36.42it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 36.41it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:14<00:13, 36.41it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:14<00:13, 36.40it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 36.42it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 36.42it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 36.41it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 36.40it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 36.41it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 36.38it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 36.40it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:15<00:12, 36.39it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:15<00:12, 36.41it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 36.44it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 36.43it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:11, 36.43it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 36.44it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 36.45it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 36.45it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 36.43it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:16<00:11, 36.39it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:16<00:11, 36.36it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 36.40it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 36.41it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:10, 36.42it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 36.42it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 36.43it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 36.43it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 36.41it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:17<00:10, 36.37it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:17<00:10, 36.38it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:10, 36.40it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 36.41it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:09, 36.43it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 36.43it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 36.43it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 36.44it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 36.44it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:18<00:09, 36.45it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:18<00:09, 36.46it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:09, 36.45it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 36.44it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:09, 36.44it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 36.45it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 36.45it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 36.43it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 36.42it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 36.44it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:19<00:08, 36.44it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:08, 36.45it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 36.46it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:08, 36.47it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 36.47it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 36.43it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 36.41it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 36.43it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 36.41it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:20<00:07, 36.39it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:07, 36.39it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 36.38it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:07, 36.38it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 36.42it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 36.43it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 36.43it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 36.43it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 36.45it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:21<00:06, 36.45it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 36.45it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:06, 36.45it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:06, 36.46it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:05, 36.46it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 36.41it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 36.38it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 36.40it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 36.42it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:22<00:05, 36.44it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 36.44it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:05, 36.44it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:05, 36.45it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:04, 36.46it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 36.45it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 36.44it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 36.41it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 36.41it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:23<00:04, 36.41it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 36.41it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 36.42it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 36.42it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:03, 36.43it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 36.44it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 36.42it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 36.42it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 36.42it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:24<00:03, 36.42it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:24<00:03, 36.42it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 36.44it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 36.44it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:02, 36.43it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 36.44it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 36.44it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 36.45it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 36.40it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:25<00:02, 36.39it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:25<00:02, 36.39it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 36.41it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 36.41it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:01, 36.41it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 36.43it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 36.40it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 36.42it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 36.44it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:26<00:01, 36.46it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:26<00:01, 36.46it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 36.46it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 36.47it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:00, 36.46it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 36.45it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 36.45it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 36.44it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 36.43it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:27<00:00, 36.45it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:27<00:00, 36.46it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 36.45it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 36.45it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.46it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.44it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.67it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.92it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.99it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 38.03it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.06it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.07it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 38.08it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 38.10it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 38.12it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 38.12it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 38.13it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 38.14it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 38.14it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 38.15it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 38.16it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 38.14it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 38.14it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 38.13it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 38.13it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 38.12it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 38.11it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 38.11it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 38.11it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 38.07it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.08it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.10it/s]
STAGE:2024-02-25 23:21:50 7644:7644 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:21:50 7644:7644 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:21:50 7644:7644 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.69it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.76it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.82it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 37.86it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 37.88it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.89it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.90it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.90it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.90it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.90it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.91it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.91it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 37.91it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 37.91it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 37.91it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 37.89it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.90it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.90it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.91it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.91it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.90it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 37.91it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 37.91it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 37.90it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 37.91it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 37.90it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 37.90it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 37.91it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.92it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.92it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 37.93it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 37.93it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 37.92it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 37.68it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 37.26it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:23, 36.95it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:23, 36.75it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:23, 36.60it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:23, 36.49it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 36.40it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 36.34it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:22, 36.26it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 36.20it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 36.20it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:22, 36.20it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:22, 36.20it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 36.20it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 36.18it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:22, 36.15it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:22, 36.16it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 36.17it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 36.18it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 36.19it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:21, 36.19it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:21, 36.18it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:21, 36.18it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:21, 36.17it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:21, 36.19it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:21, 36.17it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 36.17it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 36.16it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:20, 36.16it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:20, 36.18it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:07<00:20, 36.18it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:20, 36.18it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:20, 36.14it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:20, 36.15it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:20, 36.16it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 36.16it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 36.16it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 36.15it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:19, 36.15it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:08<00:19, 36.16it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:19, 36.16it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:19, 36.15it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:19, 36.15it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:19, 36.15it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 36.16it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 36.14it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 36.15it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 36.16it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:09<00:18, 36.15it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 36.15it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 36.16it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 36.16it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:18, 36.17it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 36.15it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 36.15it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 36.17it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 36.15it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:10<00:17, 36.15it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 36.12it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:17, 36.15it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:17, 36.17it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:17, 36.18it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 36.18it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 36.19it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 36.17it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 36.16it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:16, 36.16it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:16, 36.16it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:16, 36.16it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:16, 36.18it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:16, 36.18it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 36.18it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 36.18it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 36.19it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 36.19it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:15, 36.19it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:15, 36.18it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:15, 36.18it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:15, 36.15it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:15, 36.18it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 36.18it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 36.18it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 36.17it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 36.18it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:14, 36.19it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:13<00:14, 36.18it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:14, 36.18it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:14, 36.18it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:14, 36.18it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 36.18it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 36.18it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 36.19it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 36.19it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 36.19it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:14<00:13, 36.18it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:13, 36.20it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:13, 36.20it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:13, 36.21it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 36.20it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 36.20it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 36.20it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 36.19it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 36.18it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:15<00:12, 36.18it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 36.17it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 36.15it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:12, 36.18it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 36.18it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 36.18it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 36.19it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 36.19it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 36.19it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:16<00:11, 36.20it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 36.20it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 36.18it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:11, 36.19it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 36.21it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 36.18it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 36.18it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 36.18it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 36.17it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:17<00:10, 36.17it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 36.16it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 36.17it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 36.19it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:09, 36.20it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 36.20it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 36.19it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 36.19it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 36.19it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:18<00:09, 36.18it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:09, 36.17it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:09, 36.16it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:09, 36.17it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:08, 36.14it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 36.17it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 36.19it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 36.18it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 36.17it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:19<00:08, 36.17it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:19<00:08, 36.17it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:08, 36.18it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:08, 36.18it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:07, 36.18it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 36.19it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 36.20it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 36.19it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 36.20it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:20<00:07, 36.20it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:20<00:07, 36.20it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:07, 36.18it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:07, 36.18it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:06, 36.17it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 36.19it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 36.21it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 36.22it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 36.22it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:21<00:06, 36.21it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:21<00:06, 36.21it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:21<00:06, 36.21it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:21<00:06, 36.21it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:05, 36.21it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 36.20it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 36.21it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 36.20it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 36.21it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:22<00:05, 36.20it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:22<00:05, 36.20it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:22<00:05, 36.20it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:22<00:05, 36.19it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:04, 36.18it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 36.19it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 36.19it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 36.17it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 36.17it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:23<00:04, 36.18it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:23<00:04, 36.19it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:23<00:04, 36.18it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:23<00:04, 36.18it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:03, 36.19it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 36.21it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 36.21it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 36.16it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 36.13it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:24<00:03, 36.13it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:24<00:03, 36.15it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:24<00:03, 36.15it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:24<00:03, 36.15it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:02, 36.17it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 36.17it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 36.19it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 36.19it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 36.20it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:25<00:02, 36.21it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:25<00:02, 36.20it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:25<00:02, 36.22it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:25<00:02, 36.21it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:01, 36.21it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 36.21it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 36.19it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 36.18it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:25<00:01, 36.18it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:26<00:01, 36.20it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:26<00:01, 36.19it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:26<00:01, 36.18it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:26<00:01, 36.14it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:26<00:00, 36.14it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 36.16it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 36.17it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 36.18it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:26<00:00, 36.17it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:27<00:00, 36.14it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:27<00:00, 36.12it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:27<00:00, 36.14it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:27<00:00, 36.17it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.17it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.41it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1009.20 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 98.134 us +/- 6.184 us [93.699 us, 225.544 us]
        batches_per_second: 10.22 K +/- 493.12 [4.43 K, 10.67 K]
      metrics:
        batches_per_second_max: 10672.529262086515
        batches_per_second_mean: 10219.489868617047
        batches_per_second_min: 4433.725158562368
        batches_per_second_std: 493.12007626014537
        seconds_per_batch_max: 0.00022554397583007812
        seconds_per_batch_mean: 9.813404083251953e-05
        seconds_per_batch_min: 9.369850158691406e-05
        seconds_per_batch_std: 6.183601690577075e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.438 us +/- 0.864 us [24.319 us, 36.001 us]
        batches_per_second: 39.35 K +/- 1.12 K [27.78 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 39348.371002946245
        batches_per_second_min: 27776.847682119205
        batches_per_second_std: 1115.1263938136094
        seconds_per_batch_max: 3.600120544433594e-05
        seconds_per_batch_mean: 2.5438308715820312e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 8.638383853143141e-07
    on_device_inference:
      human_readable:
        batch_latency: -27292656.181 us +/- 98.592 ms [-27667327.881 us, -25932704.926
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03614371450348168
        batches_per_second_mean: -0.036640384196380084
        batches_per_second_min: -0.03856134571659182
        batches_per_second_std: 0.00013603796113555164
        seconds_per_batch_max: -25.93270492553711
        seconds_per_batch_mean: -27.29265618133545
        seconds_per_batch_min: -27.667327880859375
        seconds_per_batch_std: 0.09859166164117598
    total:
      human_readable:
        batch_latency: 27.428 ms +/- 99.489 us [26.066 ms, 27.812 ms]
        batches_per_second: 36.46 +/- 0.14 [35.96, 38.36]
      metrics:
        batches_per_second_max: 38.3637062105552
        batches_per_second_mean: 36.45980253645853
        batches_per_second_min: 35.95600552074136
        batches_per_second_std: 0.13581968855748633
        seconds_per_batch_max: 0.027811765670776367
        seconds_per_batch_mean: 0.027427836656570434
        seconds_per_batch_min: 0.026066303253173828
        seconds_per_batch_std: 9.948887803170467e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 150.028 us +/- 6.747 us [143.528 us, 286.341 us]
        batches_per_second: 6.68 K +/- 239.39 [3.49 K, 6.97 K]
      metrics:
        batches_per_second_max: 6967.282392026578
        batches_per_second_mean: 6675.808702346122
        batches_per_second_min: 3492.3430474604497
        batches_per_second_std: 239.38832557005625
        seconds_per_batch_max: 0.00028634071350097656
        seconds_per_batch_mean: 0.00015002799034118653
        seconds_per_batch_min: 0.00014352798461914062
        seconds_per_batch_std: 6.74680697881103e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.444 us +/- 0.747 us [23.603 us, 32.902 us]
        batches_per_second: 39.33 K +/- 1.08 K [30.39 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 39334.2363552016
        batches_per_second_min: 30393.507246376812
        batches_per_second_std: 1080.5447668814377
        seconds_per_batch_max: 3.2901763916015625e-05
        seconds_per_batch_mean: 2.5443553924560548e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 7.471475293946386e-07
    on_device_inference:
      human_readable:
        batch_latency: -27261631.584 us +/- 436.436 ms [-27710784.912 us, -26080223.083
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03608703265431534
        batches_per_second_mean: -0.036691307785826424
        batches_per_second_min: -0.038343230301308776
        batches_per_second_std: 0.0006070116658655675
        seconds_per_batch_max: -26.080223083496094
        seconds_per_batch_mean: -27.261631584167482
        seconds_per_batch_min: -27.710784912109375
        seconds_per_batch_std: 0.4364363982438321
    total:
      human_readable:
        batch_latency: 27.449 ms +/- 438.386 us [26.262 ms, 27.911 ms]
        batches_per_second: 36.44 +/- 0.60 [35.83, 38.08]
      metrics:
        batches_per_second_max: 38.078457362300156
        batches_per_second_mean: 36.44082741574457
        batches_per_second_min: 35.82792906686712
        batches_per_second_std: 0.6013285852065544
        seconds_per_batch_max: 0.02791118621826172
        seconds_per_batch_mean: 0.027448981761932372
        seconds_per_batch_min: 0.026261568069458008
        seconds_per_batch_std: 0.00043838634867181335


#####
fp-fp-py-id - Run 9
2024-02-25 23:23:27
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 50.05it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 50.08it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 50.08it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 50.08it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 50.13it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 50.13it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 50.13it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 50.15it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 50.12it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 50.11it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 50.11it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 50.11it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 50.12it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 50.13it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 50.12it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 50.11it/s]
STAGE:2024-02-25 23:22:28 7691:7691 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:22:29 7691:7691 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:22:29 7691:7691 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.96it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 38.22it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.33it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.37it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.39it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.42it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.44it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.46it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.47it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 38.47it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 38.49it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.50it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.49it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.49it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.49it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.49it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.49it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.50it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:24, 38.48it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 38.48it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 38.48it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.49it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.49it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.49it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.50it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.49it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.47it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.46it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:22, 38.46it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 38.48it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.46it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.47it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.47it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.47it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.46it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.43it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.41it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.43it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:21, 38.44it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 38.46it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.46it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.48it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.48it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.50it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.49it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.47it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.46it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:21, 38.46it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:20, 38.46it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.46it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.47it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.46it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.46it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.47it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.47it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.47it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.47it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:19, 38.45it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:19, 38.46it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.47it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.47it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.47it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.48it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.48it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.47it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.47it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:19, 38.48it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:18, 38.48it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 38.47it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.46it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.46it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.48it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.49it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.48it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.49it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.49it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:17, 38.49it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:17, 38.50it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.50it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.50it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.50it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.49it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.47it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.48it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.47it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 38.47it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:16, 38.45it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:16, 38.47it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.47it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.49it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.48it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.47it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.49it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.49it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.48it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:09<00:16, 38.47it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:15, 38.48it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.48it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.49it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.50it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.49it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.49it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.48it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.48it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 38.49it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:14, 38.50it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:14, 38.50it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.49it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:11<00:14, 38.47it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:13, 38.47it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.47it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.47it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.47it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.47it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.47it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.46it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.48it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 38.49it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:12<00:12, 38.49it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 38.51it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.51it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.50it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.49it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.49it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.47it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.47it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.48it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:12, 38.48it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:11, 38.47it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.48it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.44it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.46it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.47it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.47it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.47it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.46it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 38.45it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:14<00:11, 38.45it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 38.43it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.43it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.42it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.43it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.43it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.44it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.44it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.44it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:10, 38.44it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:09, 38.45it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.45it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.47it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.46it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.44it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.43it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.43it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.41it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 38.41it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:16<00:09, 38.41it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 38.42it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.44it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.45it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.44it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.44it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.44it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.45it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.46it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:08, 38.47it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:17<00:08, 38.44it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.45it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.45it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.47it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.49it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.48it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.48it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.48it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 38.47it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:07, 38.48it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:06, 38.48it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.48it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.48it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.48it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.46it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.47it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.47it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.48it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:06, 38.47it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:19<00:06, 38.49it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.49it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.49it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.49it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.48it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.47it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.48it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.47it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 38.46it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:05, 38.47it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:04, 38.47it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.46it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.47it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.48it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.46it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.48it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.48it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.47it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 38.47it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:21<00:04, 38.46it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.44it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.45it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.44it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.43it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.44it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.45it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.46it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 38.46it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 38.46it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:22<00:03, 38.45it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.45it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.46it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.45it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.47it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.48it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.48it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.49it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 38.47it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:23<00:02, 38.47it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.48it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.49it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.48it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.49it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.49it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.48it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.44it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 38.45it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 38.44it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:24<00:01, 38.44it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.44it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.45it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.47it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.47it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.48it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.48it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.48it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 38.48it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 38.49it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 38.48it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 38.47it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 38.01it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 38.18it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 38.24it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 38.27it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.30it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.32it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 38.30it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 38.31it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 38.31it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 38.33it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 38.31it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 38.29it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 38.28it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 38.28it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 38.28it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 38.27it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 38.26it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 38.24it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 38.24it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 38.25it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 38.26it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 38.26it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 38.26it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 38.26it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.25it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 38.27it/s]
STAGE:2024-02-25 23:22:58 7691:7691 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:22:58 7691:7691 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:22:58 7691:7691 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.56it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.84it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.93it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 37.97it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 37.99it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 38.01it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.97it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.98it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.98it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.99it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 38.01it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 38.00it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 38.00it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 38.02it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 38.02it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 38.02it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 38.02it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 38.02it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 38.01it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 38.03it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 38.03it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 38.03it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 38.04it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 38.05it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 38.05it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 38.06it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 38.06it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 38.06it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 38.06it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 38.07it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 38.07it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 38.06it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 38.05it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 38.05it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 38.05it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:22, 38.05it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 38.06it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 38.07it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:21, 38.06it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 38.06it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 38.06it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 38.07it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 38.07it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 38.05it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:21, 38.04it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 38.05it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 38.06it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 38.06it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:20, 38.05it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 38.06it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 38.06it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 38.05it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 38.05it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:20, 38.02it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:20, 38.03it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 38.03it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 38.04it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 38.05it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 38.05it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 38.05it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 38.05it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 38.05it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:18, 38.04it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 38.04it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 38.04it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 38.05it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 38.06it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 38.06it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:07<00:18, 38.07it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 38.06it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 38.05it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:17, 38.05it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:17, 38.05it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 38.04it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 38.04it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:17, 38.02it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 38.01it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 38.02it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 38.05it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:09<00:16, 38.06it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 38.06it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 38.05it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 38.03it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 38.02it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 38.02it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 38.01it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 38.02it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 38.02it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 38.02it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:11<00:14, 38.04it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 38.03it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 38.03it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:13, 38.03it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 38.02it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 38.02it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 38.03it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:12, 38.03it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 38.03it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 38.03it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 38.03it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 38.04it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 38.02it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:11, 38.03it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:11, 38.02it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 38.01it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 38.01it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 38.02it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 38.02it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:14<00:11, 38.02it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 38.03it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 38.03it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 38.03it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:10, 38.02it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 38.02it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 38.03it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 38.04it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 38.03it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:15<00:10, 38.02it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:15<00:10, 38.02it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 38.03it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 38.01it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:09, 38.01it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 38.04it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 38.04it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 38.04it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 38.03it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 38.03it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 38.04it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 38.04it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 38.04it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 38.02it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 38.02it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 38.03it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 38.04it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:18<00:07, 38.03it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 38.03it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 38.03it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 38.04it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 38.06it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 38.06it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:05, 38.07it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 38.06it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 38.04it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 38.05it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 38.05it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 38.02it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 38.02it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 38.03it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 38.04it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 38.04it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 38.02it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:02, 38.03it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 38.03it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 38.05it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 38.05it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 38.06it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:23<00:02, 38.06it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:23<00:02, 38.04it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 38.04it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 38.05it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 38.03it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 38.03it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 38.02it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 38.02it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 38.03it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 38.03it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 38.03it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 38.02it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:25<00:00, 38.02it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:25<00:00, 38.03it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 38.03it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 38.03it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 38.02it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 38.03it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1005.22 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.925 us +/- 6.124 us [92.268 us, 224.590 us]
        batches_per_second: 10.45 K +/- 489.93 [4.45 K, 10.84 K]
      metrics:
        batches_per_second_max: 10837.994832041344
        batches_per_second_mean: 10454.228589812123
        batches_per_second_min: 4452.552016985138
        batches_per_second_std: 489.9254019297308
        seconds_per_batch_max: 0.00022459030151367188
        seconds_per_batch_mean: 9.592533111572265e-05
        seconds_per_batch_min: 9.226799011230469e-05
        seconds_per_batch_std: 6.123879480900732e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.447 us +/- 0.995 us [23.365 us, 45.776 us]
        batches_per_second: 40.95 K +/- 1.17 K [21.85 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40951.48593552348
        batches_per_second_min: 21845.333333333332
        batches_per_second_std: 1165.5620864174941
        seconds_per_batch_max: 4.57763671875e-05
        seconds_per_batch_mean: 2.4446725845336916e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 9.954548436664049e-07
    on_device_inference:
      human_readable:
        batch_latency: -25848530.571 us +/- 54.493 ms [-27048543.930 us, -25753408.432
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03697056679228109
        batches_per_second_mean: -0.038687086746723276
        batches_per_second_min: -0.03882981169813548
        batches_per_second_std: 7.974467159197431e-05
        seconds_per_batch_max: -25.753408432006836
        seconds_per_batch_mean: -25.848530570983886
        seconds_per_batch_min: -27.04854393005371
        seconds_per_batch_std: 0.05449276579888626
    total:
      human_readable:
        batch_latency: 25.980 ms +/- 59.453 us [25.881 ms, 27.326 ms]
        batches_per_second: 38.49 +/- 0.09 [36.60, 38.64]
      metrics:
        batches_per_second_max: 38.637949776148275
        batches_per_second_mean: 38.49142205158592
        batches_per_second_min: 36.59567933549715
        batches_per_second_std: 0.08579227938347075
        seconds_per_batch_max: 0.02732563018798828
        seconds_per_batch_mean: 0.025979946851730346
        seconds_per_batch_min: 0.025881290435791016
        seconds_per_batch_std: 5.9453401834402593e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 147.752 us +/- 6.434 us [143.528 us, 286.818 us]
        batches_per_second: 6.78 K +/- 224.91 [3.49 K, 6.97 K]
      metrics:
        batches_per_second_max: 6967.282392026578
        batches_per_second_mean: 6777.507325684917
        batches_per_second_min: 3486.536990856193
        batches_per_second_std: 224.90678686481402
        seconds_per_batch_max: 0.0002868175506591797
        seconds_per_batch_mean: 0.000147752046585083
        seconds_per_batch_min: 0.00014352798461914062
        seconds_per_batch_std: 6.433931594435394e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.739 us +/- 0.615 us [23.603 us, 33.379 us]
        batches_per_second: 40.44 K +/- 886.40 [29.96 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40443.84175072675
        batches_per_second_min: 29959.314285714285
        batches_per_second_std: 886.4047339596035
        seconds_per_batch_max: 3.337860107421875e-05
        seconds_per_batch_mean: 2.473902702331543e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 6.153246350456438e-07
    on_device_inference:
      human_readable:
        batch_latency: -26091952.032 us +/- 50.989 ms [-27229087.830 us, -25968639.374
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03672543150392648
        batches_per_second_mean: -0.03832613739504435
        batches_per_second_min: -0.0385079859443736
        batches_per_second_std: 7.333604478251157e-05
        seconds_per_batch_max: -25.968639373779297
        seconds_per_batch_mean: -26.09195203208923
        seconds_per_batch_min: -27.229087829589844
        seconds_per_batch_std: 0.050988800535951145
    total:
      human_readable:
        batch_latency: 26.276 ms +/- 55.834 us [26.149 ms, 27.564 ms]
        batches_per_second: 38.06 +/- 0.08 [36.28, 38.24]
      metrics:
        batches_per_second_max: 38.242678434662096
        batches_per_second_mean: 38.05790383299952
        batches_per_second_min: 36.27882677553562
        batches_per_second_std: 0.07884003062690399
        seconds_per_batch_max: 0.027564287185668945
        seconds_per_batch_mean: 0.026275866508483885
        seconds_per_batch_min: 0.02614879608154297
        seconds_per_batch_std: 5.5833569826078804e-05


#####
fp-fp-py-id - Run 10
2024-02-25 23:24:35
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.24it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.23it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.97it/s]Warming up with batch_size=1:  11%|█         | 11/100 [00:00<00:01, 50.06it/s]Warming up with batch_size=1:  17%|█▋        | 17/100 [00:00<00:01, 50.09it/s]Warming up with batch_size=1:  23%|██▎       | 23/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 50.11it/s]Warming up with batch_size=1:  41%|████      | 41/100 [00:00<00:01, 50.12it/s]Warming up with batch_size=1:  47%|████▋     | 47/100 [00:00<00:01, 50.12it/s]Warming up with batch_size=1:  53%|█████▎    | 53/100 [00:01<00:00, 50.11it/s]Warming up with batch_size=1:  59%|█████▉    | 59/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1:  71%|███████   | 71/100 [00:01<00:00, 50.09it/s]Warming up with batch_size=1:  77%|███████▋  | 77/100 [00:01<00:00, 50.09it/s]Warming up with batch_size=1:  83%|████████▎ | 83/100 [00:01<00:00, 50.09it/s]Warming up with batch_size=1:  89%|████████▉ | 89/100 [00:01<00:00, 50.09it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 50.10it/s]
STAGE:2024-02-25 23:23:35 7737:7737 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:23:35 7737:7737 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:23:35 7737:7737 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 38.19it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 38.39it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.52it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.54it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.55it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.56it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.56it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.56it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.55it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 38.55it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 38.57it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.58it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.59it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.59it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.59it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.60it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.61it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.60it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 38.59it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 38.59it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 38.60it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.03it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.66it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 37.23it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 37.10it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:24, 37.00it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:24, 36.94it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 36.91it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 36.89it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 36.88it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 36.86it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 36.81it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 36.81it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 36.80it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 36.81it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:23, 36.80it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 36.78it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 36.78it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 36.77it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 36.73it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 36.71it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 36.74it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 36.72it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 36.71it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:22, 36.72it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 36.75it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 36.77it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 36.79it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 36.76it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 36.75it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 36.77it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 36.79it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 36.81it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:21, 36.81it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:21, 36.82it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 36.82it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 36.81it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 36.81it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 36.80it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 36.78it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 36.72it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 36.72it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:20, 36.73it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:20, 36.75it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 36.77it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 36.76it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 36.77it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 36.72it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 36.72it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 36.74it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 36.73it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:19, 36.75it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:19, 36.75it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 36.77it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 36.78it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 36.77it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 36.78it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 36.79it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 36.79it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 36.79it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 36.76it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:18, 36.76it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 36.77it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 36.78it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 36.77it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 36.76it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 36.78it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 36.78it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 36.78it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 36.79it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:17, 36.80it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 36.80it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:16, 36.80it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 36.81it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 36.83it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 36.83it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 36.81it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 36.76it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 36.78it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:16, 36.79it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:16, 36.75it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 36.74it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 36.70it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 36.71it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 36.72it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 36.74it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 36.74it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 36.74it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:15, 36.71it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:15, 36.68it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 36.71it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:14, 36.74it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 36.76it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.77it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 36.76it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 36.74it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 36.75it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:14, 36.76it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:14, 36.76it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 36.77it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:13, 36.75it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 36.76it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 36.77it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 36.79it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 36.78it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 36.79it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:13, 36.81it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:13, 36.83it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 36.83it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:12, 36.82it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 36.81it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 36.80it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 36.80it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 36.81it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 36.81it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 36.82it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:12, 36.80it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 36.81it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:11, 36.82it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:11, 36.81it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 36.77it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 36.78it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 36.79it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 36.74it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 36.73it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:11, 36.75it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:11, 36.79it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:10, 36.80it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:10, 36.81it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 36.80it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 36.80it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 36.79it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 36.78it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 36.80it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:10, 36.79it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 36.78it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:09, 36.79it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 36.79it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 36.79it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 36.78it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 36.73it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 36.74it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 36.75it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:09, 36.75it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 36.76it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:08, 36.75it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 36.76it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 36.76it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 36.76it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 36.74it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 36.75it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 36.74it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:08, 36.75it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 36.76it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:07, 36.76it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 36.76it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 36.77it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 36.76it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 36.73it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 36.74it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 36.77it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:07, 36.79it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 36.78it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:06, 36.78it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 36.79it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 36.80it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 36.80it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 36.80it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 36.79it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 36.80it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 36.78it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:06, 36.78it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:05, 36.81it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:05, 36.80it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 36.81it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 36.82it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 36.83it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 36.82it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 36.83it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 36.84it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:05, 36.83it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:04, 36.82it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:04, 36.83it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 36.83it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 36.82it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 36.80it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 36.80it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 36.79it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 36.80it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 36.80it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 36.80it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:03, 36.78it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 36.76it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 36.74it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 36.75it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 36.77it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 36.74it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 36.75it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 36.75it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 36.75it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:02, 36.74it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 36.72it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 36.73it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 36.75it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 36.73it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 36.71it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 36.72it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 36.74it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 36.74it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:01, 36.74it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 36.76it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 36.77it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 36.77it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 36.79it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 36.79it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 36.77it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 36.77it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 36.77it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:00, 36.79it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 36.82it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 36.81it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 36.81it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 36.80it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 36.78it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.77it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.92it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 38.02it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 38.19it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 38.26it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 38.29it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.30it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.33it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.77it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.41it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.16it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.01it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 36.91it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 36.83it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 36.77it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 36.73it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 36.71it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 36.69it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 36.68it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 36.67it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 36.66it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 36.65it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 36.64it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 36.61it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 36.61it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 36.61it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 36.62it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.02it/s]
STAGE:2024-02-25 23:24:05 7737:7737 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:24:05 7737:7737 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:24:05 7737:7737 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.67it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.88it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.98it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 38.02it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 38.03it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 38.05it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 38.07it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 38.10it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 38.10it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 38.11it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 38.11it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 38.10it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 38.09it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 38.06it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 38.07it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 38.08it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 38.10it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 38.09it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:24, 38.11it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 38.10it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 38.10it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 38.10it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 38.11it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 38.10it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 38.10it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 38.10it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 38.10it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 38.09it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 38.10it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 38.11it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:22, 38.10it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 38.11it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 38.11it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 38.11it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 38.11it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 38.12it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 38.10it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:22, 38.10it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 38.10it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.91it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.46it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 37.16it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:22, 36.94it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:22, 36.77it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 36.66it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:22, 36.57it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:22, 36.52it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 36.48it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 36.45it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 36.44it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:22, 36.13it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 36.16it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 36.22it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 36.26it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:21, 36.29it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:21, 36.31it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:21, 36.34it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:21, 36.38it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:21, 36.38it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 36.40it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 36.42it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 36.43it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:20, 36.44it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:20, 36.45it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:20, 36.42it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:20, 36.43it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:20, 36.42it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 36.42it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 36.43it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 36.43it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 36.42it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 36.42it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:19, 36.43it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:19, 36.40it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:19, 36.39it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:19, 36.39it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:19, 36.38it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 36.40it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 36.40it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 36.40it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 36.39it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 36.38it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:18, 36.37it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 36.38it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 36.37it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 36.37it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 36.36it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 36.35it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 36.36it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 36.38it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 36.40it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:17, 36.40it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 36.40it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:17, 36.36it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:17, 36.34it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 36.33it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 36.36it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 36.38it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 36.38it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 36.38it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:16, 36.37it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:16, 36.39it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:16, 36.40it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:16, 36.39it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 36.39it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 36.40it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 36.41it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 36.37it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 36.33it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:15, 36.35it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:15, 36.37it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:15, 36.38it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:15, 36.37it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 36.37it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 36.38it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 36.39it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 36.37it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 36.35it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:14, 36.35it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:14, 36.36it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:14, 36.38it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:14, 36.37it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 36.38it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 36.35it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 36.36it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 36.34it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 36.34it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 36.37it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:13, 36.35it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:13, 36.33it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:13, 36.34it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 36.36it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 36.38it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 36.39it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 36.40it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 36.41it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 36.39it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:12, 36.40it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 36.40it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 36.41it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:11, 36.40it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 36.41it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 36.40it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 36.39it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 36.41it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 36.39it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:11, 36.40it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 36.41it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 36.40it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:10, 36.37it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 36.33it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 36.30it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 36.28it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 36.28it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 36.30it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:10, 36.32it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 36.35it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 36.36it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 36.36it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:09, 36.35it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 36.35it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 36.71it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 37.11it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:09, 37.58it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:08, 37.72it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:08, 37.81it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:08, 37.53it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:08, 37.69it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 37.80it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 37.88it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 37.93it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 37.97it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:07, 38.01it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:07, 38.03it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:07, 38.07it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:07, 38.07it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:07, 38.09it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 38.08it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 38.09it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 38.10it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 38.09it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 38.09it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:06, 38.09it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:06, 38.09it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:06, 38.10it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:06, 38.08it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 38.08it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 38.09it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 38.09it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 38.10it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 38.12it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:05, 38.12it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 38.12it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:21<00:05, 38.11it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:05, 38.09it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 38.10it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 38.09it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 38.08it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 38.09it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 38.10it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 38.10it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:04, 38.10it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:22<00:04, 38.10it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:04, 38.10it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 37.96it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 37.46it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 37.14it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 36.91it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 36.74it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 36.63it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 36.56it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:23<00:04, 36.51it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:03, 36.44it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 36.37it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 36.38it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 36.36it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 36.37it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 36.38it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 36.39it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 36.39it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:24<00:03, 36.40it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:02, 36.40it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 36.42it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 36.40it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 36.38it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 36.36it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 36.36it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 36.34it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 36.35it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 36.36it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:01, 36.36it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 36.36it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 36.37it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 36.32it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:25<00:01, 36.34it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 36.34it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 36.32it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 36.35it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 36.35it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:26<00:00, 36.34it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 36.34it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 36.33it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 36.34it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:26<00:00, 36.35it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 36.33it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 36.33it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 36.35it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 36.34it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.34it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.92it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1005.34 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 99.855 us +/- 5.906 us [94.175 us, 227.451 us]
        batches_per_second: 10.04 K +/- 448.37 [4.40 K, 10.62 K]
      metrics:
        batches_per_second_max: 10618.491139240507
        batches_per_second_mean: 10039.493102270762
        batches_per_second_min: 4396.545073375262
        batches_per_second_std: 448.3732084879381
        seconds_per_batch_max: 0.00022745132446289062
        seconds_per_batch_mean: 9.985470771789551e-05
        seconds_per_batch_min: 9.417533874511719e-05
        seconds_per_batch_std: 5.905695864975542e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.704 us +/- 0.827 us [24.080 us, 34.809 us]
        batches_per_second: 38.94 K +/- 1.11 K [28.73 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 38940.14965693402
        batches_per_second_min: 28728.109589041094
        batches_per_second_std: 1113.982127310191
        seconds_per_batch_max: 3.4809112548828125e-05
        seconds_per_batch_mean: 2.5703907012939454e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 8.274842229646479e-07
    on_device_inference:
      human_readable:
        batch_latency: -26930355.204 us +/- 356.138 ms [-27301984.787 us, -25663679.123
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03662737371667649
        batches_per_second_mean: -0.03713957272013499
        batches_per_second_min: -0.03896557446849941
        batches_per_second_std: 0.0005107316832816313
        seconds_per_batch_max: -25.663679122924805
        seconds_per_batch_mean: -26.93035520362854
        seconds_per_batch_min: -27.301984786987305
        seconds_per_batch_std: 0.35613776369548567
    total:
      human_readable:
        batch_latency: 27.068 ms +/- 357.291 us [25.795 ms, 27.450 ms]
        batches_per_second: 36.95 +/- 0.51 [36.43, 38.77]
      metrics:
        batches_per_second_max: 38.767586952704015
        batches_per_second_mean: 36.95110723158863
        batches_per_second_min: 36.430392940277244
        batches_per_second_std: 0.5071405405450355
        seconds_per_batch_max: 0.027449607849121094
        seconds_per_batch_mean: 0.027067692041397095
        seconds_per_batch_min: 0.02579474449157715
        seconds_per_batch_std: 0.00035729071065252296
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 151.846 us +/- 6.336 us [146.627 us, 288.725 us]
        batches_per_second: 6.59 K +/- 217.78 [3.46 K, 6.82 K]
      metrics:
        batches_per_second_max: 6820.006504065041
        batches_per_second_mean: 6594.340539690983
        batches_per_second_min: 3463.5045417010733
        batches_per_second_std: 217.77953787815096
        seconds_per_batch_max: 0.0002887248992919922
        seconds_per_batch_mean: 0.00015184617042541504
        seconds_per_batch_min: 0.00014662742614746094
        seconds_per_batch_std: 6.335588194061213e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.710 us +/- 0.962 us [23.842 us, 34.809 us]
        batches_per_second: 38.94 K +/- 1.29 K [28.73 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 38943.37499620665
        batches_per_second_min: 28728.109589041094
        batches_per_second_std: 1289.4618855775357
        seconds_per_batch_max: 3.4809112548828125e-05
        seconds_per_batch_mean: 2.570986747741699e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 9.615032889090594e-07
    on_device_inference:
      human_readable:
        batch_latency: -26874796.228 us +/- 589.437 ms [-29118175.507 us, -25935775.757
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.03]
      metrics:
        batches_per_second_max: -0.03434281106567337
        batches_per_second_mean: -0.03722774067131145
        batches_per_second_min: -0.03855678000055303
        batches_per_second_std: 0.0008278739041196728
        seconds_per_batch_max: -25.935775756835938
        seconds_per_batch_mean: -26.87479622840881
        seconds_per_batch_min: -29.118175506591797
        seconds_per_batch_std: 0.5894367310888631
    total:
      human_readable:
        batch_latency: 27.064 ms +/- 591.664 us [26.120 ms, 29.307 ms]
        batches_per_second: 36.97 +/- 0.82 [34.12, 38.28]
      metrics:
        batches_per_second_max: 38.284566796889266
        batches_per_second_mean: 36.96681885323144
        batches_per_second_min: 34.12194824318058
        batches_per_second_std: 0.8193765664590438
        seconds_per_batch_max: 0.029306650161743164
        seconds_per_batch_mean: 0.027064399719238283
        seconds_per_batch_min: 0.02612018585205078
        seconds_per_batch_std: 0.0005916640720295764


#####
fp-fp-py-id - Run 11
2024-02-25 23:25:42
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.49it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.53it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.54it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.57it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.58it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.60it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.60it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.56it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.56it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.55it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.55it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.53it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.53it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.54it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.55it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.56it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.55it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.57it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.55it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.56it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.55it/s]
STAGE:2024-02-25 23:24:43 7783:7783 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:24:43 7783:7783 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:24:43 7783:7783 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.52it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.81it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.88it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 37.91it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 37.94it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.97it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.99it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.00it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.01it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 38.01it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 38.01it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 38.03it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.03it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.04it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 38.05it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 38.07it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 38.07it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.05it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.06it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.06it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.06it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.06it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.06it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.05it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.04it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 38.05it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 38.05it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.05it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.03it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.03it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.03it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.04it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.05it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 38.06it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.05it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.04it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.04it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.05it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.06it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.06it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.06it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 38.06it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 38.06it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 38.05it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.05it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.06it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.07it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.06it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.06it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.05it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.05it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.05it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 38.04it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.05it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.02it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.02it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 38.02it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 38.01it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 38.02it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.02it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.00it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.02it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.02it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.03it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.03it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.05it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 38.06it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 38.07it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.06it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.06it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.07it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.07it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.06it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.07it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.07it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 38.06it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 38.06it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 38.06it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 38.04it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 38.04it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.05it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.05it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.06it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.04it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.05it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 38.05it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 38.05it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 38.06it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.06it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.04it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.04it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.03it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 38.02it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 38.03it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.03it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.03it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.02it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.01it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.03it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.01it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.01it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 38.02it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 38.01it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 38.02it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.02it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 38.04it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 38.04it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.03it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.03it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.03it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.03it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.04it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.04it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.05it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 38.04it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 38.05it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 38.05it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.06it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.05it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.04it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.03it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.04it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.03it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.04it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 38.04it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 38.04it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.02it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.03it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.02it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 38.02it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 38.03it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 38.01it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.01it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.01it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.01it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.03it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.04it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 38.03it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 38.03it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.04it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.03it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.01it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.02it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 38.02it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 38.03it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 38.02it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.03it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.01it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 38.03it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 38.03it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.02it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.01it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.01it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.02it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.03it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.02it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 38.01it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 38.00it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 38.01it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.04it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 38.03it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 38.03it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.03it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.03it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 38.02it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 38.02it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 38.03it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.02it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.01it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.01it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.02it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.02it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.03it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.02it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 38.01it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 38.01it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.01it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.01it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.01it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.01it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.01it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.01it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.02it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 38.03it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 38.03it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 38.03it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.05it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 38.05it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 38.04it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.02it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.03it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.58it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.72it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.76it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.77it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.80it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 37.82it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.83it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.84it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.84it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.84it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 37.84it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 37.84it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 37.85it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 37.86it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 37.86it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 37.86it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 37.88it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 37.87it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 37.88it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 37.88it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 37.88it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 37.87it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 37.88it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 37.89it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.88it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.85it/s]
STAGE:2024-02-25 23:25:12 7783:7783 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:25:13 7783:7783 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:25:13 7783:7783 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.25it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.51it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.59it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.64it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:26, 37.65it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 37.66it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.66it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.67it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.67it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.67it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.67it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.66it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.66it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:25, 37.68it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 37.68it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 37.69it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 37.68it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.67it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.66it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.65it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.66it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.68it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:24, 37.69it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 37.71it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 37.71it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:23, 37.71it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:23, 37.67it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:23, 37.67it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:23, 37.69it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:23, 37.69it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:23, 37.68it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:23, 37.67it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:23, 37.68it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 37.67it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 37.67it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:22, 37.67it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:22, 37.68it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:22, 37.68it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:22, 37.68it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:22, 37.69it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:22, 37.69it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:22, 37.68it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 37.67it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 37.68it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 37.68it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:21, 37.68it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:21, 37.68it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:21, 37.68it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:21, 37.69it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 37.70it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:21, 37.69it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 37.69it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 37.69it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 37.68it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 37.68it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:20, 37.68it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:20, 37.66it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 37.67it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 37.68it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 37.69it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 37.69it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 37.70it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:19, 37.69it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 37.69it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 37.69it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 37.69it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 37.68it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 37.69it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 37.68it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 37.67it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 37.66it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 37.64it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:18, 37.63it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 37.63it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 37.64it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 37.63it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 37.61it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 37.63it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 37.64it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 37.64it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 37.64it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:17, 37.65it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:17, 37.65it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 37.65it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 37.66it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 37.64it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 37.64it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 37.64it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 37.64it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 37.63it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:16, 37.64it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:16, 37.63it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:16, 37.63it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 37.62it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 37.62it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 37.62it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 37.63it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 37.64it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 37.65it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 37.63it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:15, 37.63it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:15, 37.63it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 37.63it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 37.64it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 37.63it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:14, 37.64it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 37.64it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 37.64it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 37.64it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:14, 37.65it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:14, 37.64it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 37.62it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 37.62it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 37.63it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 37.62it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 37.62it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 37.62it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 37.62it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 37.62it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:13, 37.62it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:13, 37.62it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 37.62it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 37.62it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 37.62it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 37.62it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 37.61it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 37.62it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 37.62it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:12, 37.62it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:12, 37.62it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 37.63it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 37.63it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 37.62it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 37.63it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 37.62it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 37.63it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 37.64it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 37.63it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:11, 37.63it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 37.63it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 37.64it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 37.63it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 37.63it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 37.64it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 37.65it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 37.65it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 37.64it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:10, 37.63it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 37.63it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 37.63it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 37.63it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 37.62it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:09, 37.61it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 37.61it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 37.60it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 37.60it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 37.59it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 37.59it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 37.60it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 37.60it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 37.60it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:09, 37.61it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 37.63it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 37.63it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 37.63it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 37.65it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 37.64it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 37.66it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 37.65it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 37.65it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:08, 37.66it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:07, 37.66it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 37.66it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 37.65it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 37.64it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 37.64it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 37.65it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 37.65it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 37.65it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 37.66it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:07, 37.67it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 37.67it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 37.66it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 37.66it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 37.66it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 37.65it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 37.65it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 37.65it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 37.66it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:06, 37.66it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 37.66it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 37.67it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 37.67it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 37.67it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 37.67it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 37.67it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 37.67it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 37.67it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 37.67it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:04, 37.67it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 37.67it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 37.68it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 37.67it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 37.68it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 37.67it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 37.68it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 37.67it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 37.66it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 37.67it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 37.67it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 37.67it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 37.67it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 37.67it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 37.67it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 37.67it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 37.67it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 37.66it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 37.66it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:02, 37.64it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 37.65it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 37.67it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 37.67it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 37.66it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:24<00:02, 37.64it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 37.65it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 37.65it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 37.65it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 37.65it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:24<00:01, 37.65it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 37.65it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 37.65it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 37.64it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:25<00:01, 37.63it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 37.64it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 37.64it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 37.65it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 37.65it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 37.64it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 37.64it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 37.64it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 37.64it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:26<00:00, 37.63it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 37.63it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 37.63it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 37.64it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 37.64it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.64it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.65it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1010.38 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.851 us +/- 5.799 us [92.030 us, 224.113 us]
        batches_per_second: 10.46 K +/- 471.89 [4.46 K, 10.87 K]
      metrics:
        batches_per_second_max: 10866.072538860104
        batches_per_second_mean: 10459.590908893419
        batches_per_second_min: 4462.025531914894
        batches_per_second_std: 471.88993183439794
        seconds_per_batch_max: 0.00022411346435546875
        seconds_per_batch_mean: 9.585070610046386e-05
        seconds_per_batch_min: 9.202957153320312e-05
        seconds_per_batch_std: 5.798878373176353e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.178 us +/- 0.945 us [23.127 us, 41.723 us]
        batches_per_second: 41.41 K +/- 1.20 K [23.97 K, 43.24 K]
      metrics:
        batches_per_second_max: 43240.24742268041
        batches_per_second_mean: 41405.76009174733
        batches_per_second_min: 23967.45142857143
        batches_per_second_std: 1204.7170363517798
        seconds_per_batch_max: 4.172325134277344e-05
        seconds_per_batch_mean: 2.4178266525268555e-05
        seconds_per_batch_min: 2.3126602172851562e-05
        seconds_per_batch_std: 9.452350756739143e-07
    on_device_inference:
      human_readable:
        batch_latency: -26145638.941 us +/- 52.374 ms [-27413152.695 us, -26036575.317
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03647883959706902
        batches_per_second_mean: -0.03824744559456811
        batches_per_second_min: -0.03840750896806192
        batches_per_second_std: 7.453986287445403e-05
        seconds_per_batch_max: -26.036575317382812
        seconds_per_batch_mean: -26.145638940811157
        seconds_per_batch_min: -27.41315269470215
        seconds_per_batch_std: 0.05237414078768797
    total:
      human_readable:
        batch_latency: 26.277 ms +/- 57.238 us [26.165 ms, 27.689 ms]
        batches_per_second: 38.06 +/- 0.08 [36.12, 38.22]
      metrics:
        batches_per_second_max: 38.219678883198775
        batches_per_second_mean: 38.056803162650915
        batches_per_second_min: 36.11576182890602
        batches_per_second_std: 0.08032753459074958
        seconds_per_batch_max: 0.02768874168395996
        seconds_per_batch_mean: 0.026276631593704223
        seconds_per_batch_min: 0.026164531707763672
        seconds_per_batch_std: 5.7238270172517825e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 146.953 us +/- 6.190 us [143.051 us, 289.202 us]
        batches_per_second: 6.81 K +/- 218.47 [3.46 K, 6.99 K]
      metrics:
        batches_per_second_max: 6990.506666666667
        batches_per_second_mean: 6813.664764594121
        batches_per_second_min: 3457.7938994229185
        batches_per_second_std: 218.47093999283945
        seconds_per_batch_max: 0.0002892017364501953
        seconds_per_batch_mean: 0.00014695310592651367
        seconds_per_batch_min: 0.0001430511474609375
        seconds_per_batch_std: 6.190386065447488e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.418 us +/- 0.621 us [23.603 us, 33.379 us]
        batches_per_second: 40.98 K +/- 903.37 [29.96 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40976.836619431655
        batches_per_second_min: 29959.314285714285
        batches_per_second_std: 903.3677664692067
        seconds_per_batch_max: 3.337860107421875e-05
        seconds_per_batch_mean: 2.4417638778686525e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 6.213892134179875e-07
    on_device_inference:
      human_readable:
        batch_latency: -26359597.479 us +/- 48.888 ms [-27442592.621 us, -26266399.384
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03643970574559513
        batches_per_second_mean: -0.03793697432355451
        batches_per_second_min: -0.03807145339556775
        batches_per_second_std: 6.900307945822161e-05
        seconds_per_batch_max: -26.266399383544922
        seconds_per_batch_mean: -26.359597478866576
        seconds_per_batch_min: -27.44259262084961
        seconds_per_batch_std: 0.0488878119590102
    total:
      human_readable:
        batch_latency: 26.542 ms +/- 53.182 us [26.451 ms, 27.781 ms]
        batches_per_second: 37.68 +/- 0.07 [36.00, 37.81]
      metrics:
        batches_per_second_max: 37.80525485600973
        batches_per_second_mean: 37.675903722481515
        batches_per_second_min: 35.99612087091597
        batches_per_second_std: 0.07367541770031545
        seconds_per_batch_max: 0.027780771255493164
        seconds_per_batch_mean: 0.026542267560958864
        seconds_per_batch_min: 0.02645134925842285
        seconds_per_batch_std: 5.318198733603043e-05


#####
fp-fp-py-id - Run 12
2024-02-25 23:26:47
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.54it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 51.30it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 51.30it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 51.32it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 51.34it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 51.34it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 51.33it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 51.30it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 51.31it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 51.33it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 51.34it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 51.33it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 51.33it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 51.32it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 51.31it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 51.32it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 51.34it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 51.32it/s]
STAGE:2024-02-25 23:25:50 7830:7830 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:25:50 7830:7830 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:25:50 7830:7830 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 38.93it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 39.16it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.27it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 39.33it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:24, 39.37it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.37it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.33it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:24, 39.35it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 39.36it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 39.37it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 39.38it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 39.39it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 39.38it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:23, 39.39it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:23, 39.38it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:23, 39.37it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:23, 39.37it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:23, 39.37it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 39.36it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 39.37it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 39.37it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 39.37it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 39.36it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:22, 39.35it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:22, 39.36it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:22, 39.36it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:22, 39.36it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:22, 39.37it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:02<00:22, 39.39it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 39.38it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 39.37it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 39.39it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 39.38it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:21, 39.35it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:21, 39.38it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:21, 39.38it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:21, 39.38it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:21, 39.40it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:03<00:21, 39.40it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 39.41it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 39.40it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 39.40it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 39.41it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:20, 39.42it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:20, 39.42it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:20, 39.43it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:20, 39.41it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:20, 39.42it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:04<00:20, 39.41it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 39.41it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 39.40it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 39.40it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 39.39it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:19, 39.39it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:19, 39.38it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:19, 39.38it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:19, 39.38it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:05<00:19, 39.38it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:05<00:19, 39.39it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 39.37it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 39.37it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 39.39it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:18, 39.38it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:18, 39.38it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:18, 39.38it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:18, 39.37it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:18, 39.37it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:06<00:18, 39.38it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 39.38it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 39.37it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 39.36it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 39.34it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:17, 39.35it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:17, 39.35it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:17, 39.37it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:17, 39.36it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:07<00:17, 39.36it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:07<00:17, 39.34it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 39.35it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 39.37it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 39.38it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 39.37it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:16, 39.37it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:16, 39.36it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:16, 39.36it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:16, 39.35it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:08<00:16, 39.37it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:08<00:16, 39.38it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 39.37it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 39.36it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 39.36it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 39.37it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:15, 39.39it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:15, 39.38it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:15, 39.39it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:09<00:15, 39.39it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:09<00:15, 39.39it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:09<00:15, 39.40it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 39.39it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 39.40it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 39.40it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 39.40it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:14, 39.40it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:14, 39.41it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:14, 39.42it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:10<00:14, 39.42it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:10<00:14, 39.43it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:10<00:14, 39.43it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 39.43it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 39.43it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 39.43it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 39.42it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:13, 39.42it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:13, 39.43it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:11<00:13, 39.42it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:11<00:13, 39.43it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:11<00:13, 39.42it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:11<00:13, 39.42it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 39.42it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 39.42it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 39.40it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:12, 39.41it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:12, 39.39it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:12, 39.40it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:12<00:12, 39.38it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:12<00:12, 39.37it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:12<00:12, 39.38it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 39.39it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 39.36it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 39.36it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 39.38it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:11, 39.38it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:11, 39.39it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:11, 39.39it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:13<00:11, 39.38it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:13<00:11, 39.39it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:13<00:11, 39.40it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 39.41it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 39.40it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 39.40it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 39.39it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:10, 39.39it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:10, 39.39it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:14<00:10, 39.40it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:14<00:10, 39.38it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:14<00:10, 39.38it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:14<00:10, 39.39it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 39.39it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 39.37it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 39.39it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 39.39it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:09, 39.40it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:09, 39.39it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:15<00:09, 39.39it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:15<00:09, 39.38it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:15<00:09, 39.39it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:15<00:09, 39.40it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 39.39it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:08, 39.40it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:16<00:08, 39.38it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:16<00:08, 39.38it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:16<00:08, 39.37it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:16<00:08, 39.38it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:16<00:08, 39.39it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 39.39it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 39.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 39.38it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 39.39it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:07, 39.40it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:17<00:07, 39.40it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:17<00:07, 39.41it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:17<00:07, 39.41it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:17<00:07, 39.40it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:17<00:07, 39.40it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 39.39it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 39.39it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 39.39it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 39.40it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:06, 39.39it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:18<00:06, 39.40it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:18<00:06, 39.39it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:18<00:06, 39.40it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:18<00:06, 39.38it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:18<00:06, 39.38it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 39.40it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 39.41it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 39.39it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:05, 39.40it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:19<00:05, 39.40it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:19<00:05, 39.40it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:19<00:05, 39.40it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:19<00:05, 39.38it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:19<00:05, 39.39it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 39.38it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 39.38it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 39.40it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 39.39it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:04, 39.39it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:20<00:04, 39.38it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:20<00:04, 39.37it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:20<00:04, 39.38it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:20<00:04, 39.38it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:20<00:04, 39.38it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 39.38it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 39.39it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 39.39it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 39.40it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:21<00:03, 39.41it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:21<00:03, 39.39it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:21<00:03, 39.39it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:21<00:03, 39.40it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:21<00:03, 39.41it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:21<00:03, 39.41it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 39.41it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 39.40it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 39.41it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 39.40it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:22<00:02, 39.38it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:22<00:02, 39.39it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:22<00:02, 39.38it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:22<00:02, 39.40it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:22<00:02, 39.42it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:22<00:02, 39.43it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 39.43it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 39.43it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 39.44it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:23<00:02, 39.43it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:23<00:01, 39.44it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:23<00:01, 39.41it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:23<00:01, 39.40it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:23<00:01, 39.40it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:23<00:01, 39.39it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:23<00:01, 39.41it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 39.41it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 39.40it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 39.41it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:24<00:01, 39.42it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:24<00:00, 39.41it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:24<00:00, 39.41it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:24<00:00, 39.41it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:24<00:00, 39.40it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:24<00:00, 39.40it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:24<00:00, 39.41it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 39.41it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 39.41it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 39.40it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 39.39it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 39.39it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 38.98it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 39.12it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 39.18it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 39.23it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 39.25it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 39.27it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 39.28it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 39.29it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 39.28it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 39.28it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 39.29it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 39.28it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 39.29it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 39.28it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 39.28it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 39.27it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 39.27it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 39.28it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 39.28it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 39.28it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 39.30it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 39.31it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 39.32it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 39.32it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.31it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 39.28it/s]
STAGE:2024-02-25 23:26:18 7830:7830 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:26:18 7830:7830 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:26:18 7830:7830 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:25, 38.54it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:25, 38.80it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:25, 38.89it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 38.94it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 38.99it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 39.00it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:24, 39.03it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:24, 39.01it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:24, 39.01it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:24, 39.01it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:24, 38.99it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 38.99it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 39.00it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 39.01it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 39.00it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:23, 39.00it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:23, 39.01it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:23, 39.01it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:23, 39.03it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:23, 39.02it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:23, 39.03it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 39.03it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 39.04it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 39.04it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 39.05it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:22, 39.03it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:22, 39.04it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:22, 39.05it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:02<00:22, 39.07it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:22, 39.06it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:22, 39.06it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 39.06it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 39.05it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 39.05it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:22, 39.05it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:21, 39.06it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:21, 39.06it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:21, 39.04it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:03<00:21, 39.05it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:21, 39.05it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:21, 39.04it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 39.03it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 39.01it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 39.01it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:21, 39.02it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:20, 39.01it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:20, 38.98it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:04<00:20, 38.99it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:20, 39.00it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:20, 39.01it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:20, 39.01it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 39.00it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 39.01it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 39.02it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:19, 39.05it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:19, 39.05it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:19, 39.05it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:05<00:19, 39.05it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:19, 39.04it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:19, 39.03it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 39.02it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 39.02it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 39.02it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 39.04it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:18, 39.04it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:18, 39.04it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:06<00:18, 39.05it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:06<00:18, 39.04it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:18, 39.03it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:18, 39.02it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:18, 39.02it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 39.01it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 39.01it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 39.03it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:17, 39.04it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:07<00:17, 39.04it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:07<00:17, 39.03it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:07<00:17, 39.03it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:17, 39.03it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:17, 39.03it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:17, 39.02it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 39.03it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 39.04it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 39.03it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:16, 39.04it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:08<00:16, 39.02it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:08<00:16, 39.01it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:16, 39.00it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:16, 39.00it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:16, 39.02it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 39.04it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 39.05it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 39.05it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:15, 39.05it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:09<00:15, 39.05it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:09<00:15, 39.05it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:09<00:15, 39.05it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:15, 39.04it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:15, 39.04it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:15, 39.04it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 39.03it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 39.02it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 39.01it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:14, 39.01it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:10<00:14, 39.00it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:10<00:14, 39.00it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:10<00:14, 39.00it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:14, 39.01it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:14, 39.01it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 39.01it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 39.00it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 39.00it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:14, 39.01it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:11<00:13, 39.02it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:11<00:13, 39.01it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:11<00:13, 39.00it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:11<00:13, 39.01it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:13, 39.00it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 38.99it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 38.96it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 38.98it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 38.99it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:12<00:13, 38.99it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:12<00:12, 38.99it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:12<00:12, 39.00it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:12<00:12, 38.99it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:12, 38.99it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:12, 38.98it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 38.98it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 38.98it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 39.00it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:13<00:12, 39.00it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:13<00:11, 39.00it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:13<00:11, 39.00it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:13<00:11, 39.00it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:13<00:11, 39.00it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:11, 38.99it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 38.99it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 39.00it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 39.01it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 39.02it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:14<00:11, 39.02it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:14<00:10, 39.02it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:14<00:10, 39.02it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:14<00:10, 39.01it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:14<00:10, 39.00it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:10, 39.01it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 39.00it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 39.00it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 39.00it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:15<00:10, 39.01it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:15<00:10, 39.01it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:15<00:09, 39.00it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:15<00:09, 39.00it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:15<00:09, 38.99it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:15<00:09, 39.00it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 38.99it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 38.99it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 38.98it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 38.99it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:16<00:09, 38.98it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:16<00:09, 38.98it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:16<00:08, 38.99it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:16<00:08, 39.00it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:16<00:08, 39.00it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 39.00it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 39.00it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 39.01it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 39.00it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:17<00:08, 39.00it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:17<00:08, 38.99it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:17<00:08, 39.00it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:17<00:07, 38.99it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:17<00:07, 38.99it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:17<00:07, 38.99it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 38.99it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 39.00it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 39.00it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 39.00it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:18<00:07, 38.99it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:18<00:07, 38.99it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:18<00:06, 39.00it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:18<00:06, 39.00it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:18<00:06, 39.01it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:18<00:06, 39.00it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 39.00it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 38.99it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 39.00it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:19<00:06, 38.98it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:19<00:06, 38.99it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:19<00:06, 38.98it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:19<00:05, 38.99it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:19<00:05, 38.98it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:19<00:05, 38.98it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:19<00:05, 38.98it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 38.98it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 38.98it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 38.79it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:20<00:05, 38.23it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:20<00:05, 37.84it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:20<00:05, 37.57it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:20<00:05, 37.35it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:20<00:05, 37.19it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:20<00:04, 37.08it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 37.00it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 36.94it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 36.93it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:21<00:04, 36.90it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:21<00:04, 36.88it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:21<00:04, 36.84it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:21<00:04, 36.84it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:21<00:04, 36.88it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:21<00:04, 36.89it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 36.89it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 36.90it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 36.93it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 36.92it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:22<00:03, 36.93it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:22<00:03, 36.92it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:22<00:03, 36.89it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:22<00:03, 36.91it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:22<00:03, 36.93it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 36.94it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 36.95it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 36.95it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 36.96it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:23<00:02, 36.94it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:23<00:02, 36.90it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:23<00:02, 36.86it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:23<00:02, 36.85it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:23<00:02, 36.88it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:23<00:01, 36.90it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 36.87it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 36.86it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 36.83it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 36.84it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:24<00:01, 36.85it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:24<00:01, 36.87it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:24<00:01, 36.88it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:24<00:01, 36.89it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:24<00:00, 36.89it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 36.89it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 36.90it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 36.91it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 36.92it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:25<00:00, 36.92it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:25<00:00, 36.91it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:25<00:00, 36.92it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:25<00:00, 36.90it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:25<00:00, 36.90it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:25<00:00, 38.55it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1005.67 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.647 us +/- 5.612 us [91.314 us, 222.921 us]
        batches_per_second: 10.59 K +/- 457.65 [4.49 K, 10.95 K]
      metrics:
        batches_per_second_max: 10951.185378590078
        batches_per_second_mean: 10590.851474292904
        batches_per_second_min: 4485.886631016043
        batches_per_second_std: 457.64956824635254
        seconds_per_batch_max: 0.00022292137145996094
        seconds_per_batch_mean: 9.464693069458008e-05
        seconds_per_batch_min: 9.131431579589844e-05
        seconds_per_batch_std: 5.612190615515794e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.823 us +/- 0.809 us [22.888 us, 36.478 us]
        batches_per_second: 42.01 K +/- 1.10 K [27.41 K, 43.69 K]
      metrics:
        batches_per_second_max: 43690.666666666664
        batches_per_second_mean: 42013.18389863851
        batches_per_second_min: 27413.75163398693
        batches_per_second_std: 1103.6318860584463
        seconds_per_batch_max: 3.647804260253906e-05
        seconds_per_batch_mean: 2.3823022842407228e-05
        seconds_per_batch_min: 2.288818359375e-05
        seconds_per_batch_std: 8.093163882371005e-07
    on_device_inference:
      human_readable:
        batch_latency: -25242941.780 us +/- 53.836 ms [-26409568.787 us, -25144512.177
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03786506353358534
        batches_per_second_mean: -0.03961521039633153
        batches_per_second_min: -0.039770109397232765
        batches_per_second_std: 8.267186929212595e-05
        seconds_per_batch_max: -25.144512176513672
        seconds_per_batch_mean: -25.242941780090334
        seconds_per_batch_min: -26.409568786621094
        seconds_per_batch_std: 0.053835533208429806
    total:
      human_readable:
        batch_latency: 25.372 ms +/- 58.448 us [25.272 ms, 26.685 ms]
        batches_per_second: 39.41 +/- 0.09 [37.47, 39.57]
      metrics:
        batches_per_second_max: 39.569652257589766
        batches_per_second_mean: 39.41388718930709
        batches_per_second_min: 37.47390239979987
        batches_per_second_std: 0.08848085325165617
        seconds_per_batch_max: 0.026685237884521484
        seconds_per_batch_mean: 0.025371899127960205
        seconds_per_batch_min: 0.025271892547607422
        seconds_per_batch_std: 5.844808988082518e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 145.992 us +/- 6.022 us [141.621 us, 283.241 us]
        batches_per_second: 6.86 K +/- 217.23 [3.53 K, 7.06 K]
      metrics:
        batches_per_second_max: 7061.117845117845
        batches_per_second_mean: 6858.270809764554
        batches_per_second_min: 3530.5589225589224
        batches_per_second_std: 217.23232025130432
        seconds_per_batch_max: 0.00028324127197265625
        seconds_per_batch_mean: 0.00014599156379699706
        seconds_per_batch_min: 0.00014162063598632812
        seconds_per_batch_std: 6.022219750586531e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.321 us +/- 0.841 us [22.888 us, 31.948 us]
        batches_per_second: 41.16 K +/- 1.30 K [31.30 K, 43.69 K]
      metrics:
        batches_per_second_max: 43690.666666666664
        batches_per_second_mean: 41161.990660540614
        batches_per_second_min: 31300.776119402984
        batches_per_second_std: 1296.815126316531
        seconds_per_batch_max: 3.1948089599609375e-05
        seconds_per_batch_mean: 2.4320602416992186e-05
        seconds_per_batch_min: 2.288818359375e-05
        seconds_per_batch_std: 8.409769197114544e-07
    on_device_inference:
      human_readable:
        batch_latency: -25743749.895 us +/- 598.953 ms [-27072256.088 us, -25326528.549
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03693818486128207
        batches_per_second_mean: -0.03886474547526395
        batches_per_second_min: -0.039484290081745574
        batches_per_second_std: 0.0008753493988650229
        seconds_per_batch_max: -25.326528549194336
        seconds_per_batch_mean: -25.743749895095824
        seconds_per_batch_min: -27.072256088256836
        seconds_per_batch_std: 0.5989528101521842
    total:
      human_readable:
        batch_latency: 25.925 ms +/- 601.314 us [25.505 ms, 27.255 ms]
        batches_per_second: 38.59 +/- 0.87 [36.69, 39.21]
      metrics:
        batches_per_second_max: 39.208630134425185
        batches_per_second_mean: 38.59272761425639
        batches_per_second_min: 36.691078957957906
        batches_per_second_std: 0.8666561934763006
        seconds_per_batch_max: 0.027254581451416016
        seconds_per_batch_mean: 0.02592512083053589
        seconds_per_batch_min: 0.025504589080810547
        seconds_per_batch_std: 0.0006013137827754943


#####
fp-fp-py-id - Run 13
2024-02-25 23:27:53
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.34it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 51.51it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 51.53it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 51.53it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 51.57it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 51.58it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 51.57it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 51.57it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 51.56it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 51.57it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 51.57it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 51.56it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 51.56it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 51.55it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 51.55it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 51.57it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 51.57it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 51.52it/s]
STAGE:2024-02-25 23:26:55 7876:7876 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:26:55 7876:7876 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:26:55 7876:7876 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 38.88it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 39.14it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.23it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 39.28it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:24, 39.34it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.36it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.39it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:24, 39.41it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 39.42it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 39.44it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 39.45it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 39.45it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 39.43it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:23, 39.43it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:23, 39.43it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:23, 39.41it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:23, 39.42it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:23, 39.42it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 39.43it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 39.42it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 39.43it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 39.43it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 39.43it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:22, 39.42it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:22, 39.41it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:22, 39.41it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:22, 39.40it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:22, 39.41it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:02<00:22, 39.41it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 39.40it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 39.39it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 39.40it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 39.39it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:21, 39.38it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:21, 39.40it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:21, 39.39it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:21, 39.40it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:21, 39.40it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:03<00:21, 39.40it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 39.40it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 39.42it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 39.42it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 39.41it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:20, 39.45it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:20, 39.46it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:20, 39.45it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:20, 39.46it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:20, 39.47it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:04<00:20, 39.47it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 39.48it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 39.48it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 39.49it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:19, 39.50it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:19, 39.51it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:19, 39.51it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:19, 39.54it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:19, 39.53it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:05<00:19, 39.54it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:05<00:19, 39.56it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 39.57it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 39.57it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:18, 39.60it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:18, 39.61it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:18, 39.58it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:18, 39.57it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:18, 39.59it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:18, 39.61it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:06<00:18, 39.63it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:06<00:18, 39.61it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 39.60it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 39.61it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:17, 39.60it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:17, 39.56it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:17, 39.53it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:17, 39.13it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:17, 38.69it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:07<00:18, 38.41it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:07<00:18, 38.17it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.97it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 37.85it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 37.77it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.74it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.69it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 37.69it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 37.66it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:08<00:17, 37.64it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:08<00:17, 37.63it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.60it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.59it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 37.57it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.61it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.66it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 37.70it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 37.69it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:09<00:16, 37.72it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:09<00:16, 37.72it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.69it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.63it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 37.62it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.63it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.61it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 37.59it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 37.59it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 37.62it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:10<00:15, 37.64it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.64it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.65it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 37.65it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.66it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.65it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.64it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 37.62it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 37.62it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:11<00:14, 37.61it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:11<00:14, 37.62it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.59it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.56it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.53it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.52it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.50it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 37.52it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 37.54it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 37.54it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:12<00:13, 37.54it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.52it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.54it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 37.59it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.61it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.65it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 37.67it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 37.66it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 37.66it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:12, 37.64it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:13<00:12, 37.61it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.63it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 37.66it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.67it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.68it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.68it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 37.69it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 37.67it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 37.66it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:14<00:11, 37.66it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.64it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.62it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 37.62it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.63it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.57it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 37.51it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 37.48it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 37.47it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:10, 37.46it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.45it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.45it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 37.46it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.47it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.45it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 37.51it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 37.56it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 37.59it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 37.61it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:16<00:09, 37.61it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.60it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.62it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.63it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.63it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.64it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 37.65it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 37.66it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 37.66it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:08, 37.66it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.68it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.69it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 37.73it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.77it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 37.78it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 37.78it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 37.79it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 37.80it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:07, 37.80it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.79it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 37.77it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.76it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.74it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.73it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 37.74it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 37.76it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 37.77it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:06, 37.79it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.78it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.77it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.78it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.76it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.78it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 37.79it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 37.77it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 37.76it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 37.78it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:05, 37.78it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.79it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 37.78it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.78it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.75it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 37.73it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 37.74it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 37.72it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 37.75it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 37.76it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.71it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.74it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.76it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.77it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.77it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 37.79it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 37.78it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 37.80it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 37.80it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.75it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.74it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.73it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.75it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.74it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 37.73it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 37.72it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 37.75it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 37.75it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 37.75it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.75it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.76it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.75it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 37.73it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 37.74it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 37.74it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.74it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.73it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.75it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.72it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 37.70it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 37.71it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 37.73it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 37.73it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 37.73it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.70it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.67it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.19it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 39.04it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 39.17it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 39.23it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 39.28it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 38.91it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 38.46it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 38.22it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 38.07it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.95it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.90it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 37.83it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 37.78it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 37.75it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 37.75it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 37.73it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 37.72it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 37.73it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 37.73it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:01<00:00, 37.71it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 37.68it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 37.65it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 37.64it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 37.62it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 37.60it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.59it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 37.94it/s]
STAGE:2024-02-25 23:27:24 7876:7876 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:27:24 7876:7876 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:27:24 7876:7876 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:25, 38.42it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:25, 38.76it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:25, 38.93it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:25, 39.03it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:25, 39.08it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:24, 39.09it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:24, 39.10it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:24, 39.11it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:24, 39.12it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:24, 39.12it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:24, 39.10it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:24, 39.11it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:24, 39.10it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:24, 39.11it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:24, 39.12it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:23, 39.12it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:23, 39.12it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:23, 39.13it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:01<00:23, 39.11it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:23, 39.11it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:23, 39.10it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:23, 39.07it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:23, 39.06it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:23, 39.09it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:23, 39.10it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:22, 39.11it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:22, 39.14it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:02<00:22, 39.14it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:02<00:22, 39.13it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:22, 39.14it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:22, 39.13it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:22, 39.11it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:22, 39.13it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:22, 39.13it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:21, 39.14it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:21, 39.13it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:03<00:21, 39.15it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:03<00:21, 39.13it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:03<00:21, 39.12it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:21, 39.09it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:21, 39.08it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:21, 39.07it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:21, 39.10it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:21, 39.09it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:20, 39.11it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:04<00:20, 39.13it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:04<00:20, 39.13it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:04<00:20, 39.13it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:20, 39.14it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:20, 39.10it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:20, 39.09it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:20, 39.09it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:20, 39.09it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:20, 39.10it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:19, 39.08it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:05<00:19, 39.09it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:05<00:19, 39.10it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:05<00:19, 39.11it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:19, 39.12it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:19, 39.11it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:19, 39.06it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:19, 38.54it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 38.22it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 37.99it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:06<00:19, 37.83it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:06<00:19, 37.74it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:06<00:19, 37.66it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:06<00:19, 37.62it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 37.57it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 37.52it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 37.47it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:19, 37.45it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 37.42it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:07<00:18, 37.40it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:07<00:18, 37.40it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:07<00:18, 37.39it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:07<00:18, 37.38it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 37.38it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 37.37it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 37.37it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 37.39it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:17, 37.42it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:17, 37.44it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:08<00:17, 37.43it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:08<00:17, 37.43it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:08<00:17, 37.45it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:17, 37.46it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:17, 37.45it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 37.44it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 37.42it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:16, 37.44it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:09<00:16, 37.44it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:09<00:16, 37.46it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:09<00:16, 37.48it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:09<00:16, 37.44it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:09<00:16, 37.43it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 37.41it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:10<00:15, 37.42it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:10<00:15, 37.41it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:10<00:15, 37.42it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:10<00:15, 37.41it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:10<00:15, 37.40it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:15, 37.39it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 37.37it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:11<00:14, 37.34it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:11<00:14, 37.35it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:11<00:14, 37.39it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:11<00:14, 37.44it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:11<00:14, 37.45it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:14, 37.46it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 37.46it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 37.45it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 37.46it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:12<00:13, 37.44it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:12<00:13, 37.43it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:12<00:13, 37.43it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:12<00:13, 37.44it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:12<00:13, 37.45it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:12<00:13, 37.45it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 37.45it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 37.43it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 37.42it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:13<00:13, 37.44it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:13<00:12, 37.43it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:13<00:12, 37.43it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:13<00:12, 37.43it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:13<00:12, 37.41it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:13<00:12, 37.41it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 37.41it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 37.39it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 37.37it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:14<00:12, 37.40it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:14<00:11, 37.40it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:14<00:11, 37.42it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:14<00:11, 37.42it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:14<00:11, 37.44it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:14<00:11, 37.45it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 37.45it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 37.44it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:15<00:11, 37.40it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:15<00:10, 37.41it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:15<00:10, 37.41it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:15<00:10, 37.38it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:15<00:10, 37.35it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:15<00:10, 37.34it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 37.35it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 37.36it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:16<00:10, 37.38it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:16<00:09, 37.41it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:16<00:09, 37.42it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:16<00:09, 37.45it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:16<00:09, 37.45it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:16<00:09, 37.44it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 37.45it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 37.42it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:17<00:09, 37.42it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:17<00:09, 37.41it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:17<00:08, 37.42it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:18<00:08, 37.44it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:18<00:08, 37.41it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:18<00:07, 37.43it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:18<00:07, 37.44it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:18<00:07, 37.45it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:18<00:07, 37.46it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:18<00:07, 37.45it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 37.44it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:19<00:07, 37.40it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:19<00:07, 37.37it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:19<00:07, 37.35it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:19<00:06, 37.35it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:19<00:06, 37.36it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:19<00:06, 37.37it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:19<00:06, 37.38it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:19<00:06, 37.39it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 37.41it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:20<00:06, 37.40it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:20<00:06, 37.41it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:20<00:06, 37.42it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:20<00:05, 37.45it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:20<00:05, 37.45it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:20<00:05, 37.46it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:20<00:05, 37.47it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:20<00:05, 37.47it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:20<00:05, 37.47it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:21<00:05, 37.44it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:21<00:05, 37.46it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:21<00:05, 37.47it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:21<00:05, 37.48it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:21<00:04, 37.48it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:21<00:04, 37.49it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:21<00:04, 37.49it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:21<00:04, 37.50it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:21<00:04, 37.50it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:22<00:04, 37.48it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:22<00:04, 37.46it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:22<00:04, 37.43it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:22<00:03, 37.44it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:22<00:03, 37.46it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:22<00:03, 37.47it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:22<00:03, 37.48it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:22<00:03, 37.47it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:23<00:03, 37.48it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:23<00:03, 37.46it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:23<00:03, 37.46it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:23<00:03, 37.48it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:23<00:02, 37.50it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:23<00:02, 37.51it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:23<00:02, 37.49it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:23<00:02, 37.51it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:23<00:02, 37.51it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:23<00:02, 37.50it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:24<00:02, 37.47it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:24<00:02, 37.40it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:24<00:02, 37.35it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:24<00:02, 37.33it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:24<00:01, 37.35it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:24<00:01, 37.39it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:24<00:01, 37.41it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:24<00:01, 37.45it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:24<00:01, 37.45it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:25<00:01, 37.44it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:25<00:01, 37.46it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:25<00:01, 37.41it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:25<00:00, 37.42it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:25<00:00, 37.44it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:25<00:00, 37.45it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:25<00:00, 37.47it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:25<00:00, 37.47it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:26<00:00, 37.48it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:26<00:00, 37.45it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:26<00:00, 37.43it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.45it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:26<00:00, 37.82it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1010.47 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.447 us +/- 5.981 us [91.314 us, 222.683 us]
        batches_per_second: 10.40 K +/- 492.18 [4.49 K, 10.95 K]
      metrics:
        batches_per_second_max: 10951.185378590078
        batches_per_second_mean: 10397.11233088262
        batches_per_second_min: 4490.689507494647
        batches_per_second_std: 492.1787465616061
        seconds_per_batch_max: 0.00022268295288085938
        seconds_per_batch_mean: 9.644699096679688e-05
        seconds_per_batch_min: 9.131431579589844e-05
        seconds_per_batch_std: 5.981347769919906e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.751 us +/- 0.983 us [22.888 us, 33.617 us]
        batches_per_second: 40.46 K +/- 1.47 K [29.75 K, 43.69 K]
      metrics:
        batches_per_second_max: 43690.666666666664
        batches_per_second_mean: 40460.40053905962
        batches_per_second_min: 29746.836879432623
        batches_per_second_std: 1468.6633196501136
        seconds_per_batch_max: 3.361701965332031e-05
        seconds_per_batch_mean: 2.475094795227051e-05
        seconds_per_batch_min: 2.288818359375e-05
        seconds_per_batch_std: 9.829102243360162e-07
    on_device_inference:
      human_readable:
        batch_latency: -26037686.079 us +/- 554.651 ms [-26680576.324 us, -25027296.066
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.037480449741376834
        batches_per_second_mean: -0.03842362948357641
        batches_per_second_min: -0.039956373926752796
        batches_per_second_std: 0.0008337007287838105
        seconds_per_batch_max: -25.02729606628418
        seconds_per_batch_mean: -26.037686079025267
        seconds_per_batch_min: -26.68057632446289
        seconds_per_batch_std: 0.5546508942827321
    total:
      human_readable:
        batch_latency: 26.170 ms +/- 556.823 us [25.153 ms, 26.820 ms]
        batches_per_second: 38.23 +/- 0.83 [37.29, 39.76]
      metrics:
        batches_per_second_max: 39.75718970975753
        batches_per_second_mean: 38.22922142275373
        batches_per_second_min: 37.285353625146676
        batches_per_second_std: 0.8284971330815712
        seconds_per_batch_max: 0.02682018280029297
        seconds_per_batch_mean: 0.02617006778717041
        seconds_per_batch_min: 0.02515268325805664
        seconds_per_batch_std: 0.0005568233477237262
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 147.547 us +/- 6.224 us [141.621 us, 282.288 us]
        batches_per_second: 6.79 K +/- 225.76 [3.54 K, 7.06 K]
      metrics:
        batches_per_second_max: 7061.117845117845
        batches_per_second_mean: 6786.631124817197
        batches_per_second_min: 3542.4864864864867
        batches_per_second_std: 225.76264700086412
        seconds_per_batch_max: 0.00028228759765625
        seconds_per_batch_mean: 0.00014754724502563475
        seconds_per_batch_min: 0.00014162063598632812
        seconds_per_batch_std: 6.224331684871022e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.147 us +/- 0.899 us [23.365 us, 35.286 us]
        batches_per_second: 39.81 K +/- 1.27 K [28.34 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 39810.5191498501
        batches_per_second_min: 28339.891891891893
        batches_per_second_std: 1271.4244964684005
        seconds_per_batch_max: 3.528594970703125e-05
        seconds_per_batch_mean: 2.5147438049316406e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 8.991707557893936e-07
    on_device_inference:
      human_readable:
        batch_latency: -26236789.896 us +/- 493.745 ms [-26730720.520 us, -25226688.385
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03741014011392123
        batches_per_second_mean: -0.038128224212142174
        batches_per_second_min: -0.039640557838508096
        batches_per_second_std: 0.000733605546851564
        seconds_per_batch_max: -25.226688385009766
        seconds_per_batch_mean: -26.236789896011352
        seconds_per_batch_min: -26.73072052001953
        seconds_per_batch_std: 0.49374475114372374
    total:
      human_readable:
        batch_latency: 26.421 ms +/- 495.805 us [25.404 ms, 26.966 ms]
        batches_per_second: 37.86 +/- 0.73 [37.08, 39.36]
      metrics:
        batches_per_second_max: 39.36354677953695
        batches_per_second_mean: 37.86200172029044
        batches_per_second_min: 37.0836044702221
        batches_per_second_std: 0.726359348217531
        seconds_per_batch_max: 0.026966094970703125
        seconds_per_batch_mean: 0.026421216011047362
        seconds_per_batch_min: 0.02540421485900879
        seconds_per_batch_std: 0.0004958046151858533


#####
fp-fp-py-id - Run 14
2024-02-25 23:29:04
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 48.74it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 48.78it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.78it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.81it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 48.82it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 48.84it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 48.85it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 48.86it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 48.86it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 48.87it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 48.13it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 47.65it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 47.29it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 47.05it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 46.90it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 46.80it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 46.74it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 46.69it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 46.62it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 46.60it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 47.66it/s]
STAGE:2024-02-25 23:28:02 7922:7922 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:28:02 7922:7922 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:28:02 7922:7922 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.13it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.48it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.51it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.52it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 37.51it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.53it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.53it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.55it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.54it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.56it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 37.56it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.57it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.56it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.57it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.57it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.57it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.57it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.59it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.58it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 37.57it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 37.59it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.59it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.59it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.59it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.59it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.59it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.59it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.61it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.63it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 37.63it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 36.71it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:23, 36.45it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 36.29it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:23, 36.17it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:23, 36.07it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:23, 36.01it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:23, 35.96it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:23, 35.92it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 35.90it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 35.87it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:22, 35.86it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 35.85it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:22, 35.85it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:22, 35.86it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:22, 35.86it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:22, 35.85it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:22, 35.83it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 35.83it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 35.84it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:21, 35.84it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:06<00:21, 35.84it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:21, 35.85it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 35.84it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:21, 35.85it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:21, 35.85it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:21, 35.86it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 35.85it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 35.83it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:20, 35.84it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:07<00:20, 35.84it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 35.84it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 35.84it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:20, 35.85it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:20, 35.85it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:20, 35.83it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 35.86it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 35.86it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:19, 35.85it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:08<00:19, 35.84it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 35.84it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 35.82it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:19, 35.83it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:19, 35.83it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:19, 35.85it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 35.86it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 35.83it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 35.85it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:09<00:18, 35.86it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 35.85it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 35.83it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:18, 35.83it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:18, 35.84it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:18, 35.82it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 35.82it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 35.82it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 35.81it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:10<00:17, 35.83it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 35.81it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 35.81it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 35.81it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:17, 35.81it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:17, 35.81it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 35.82it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 35.81it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 35.80it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:11<00:16, 35.80it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:11<00:16, 35.76it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 35.78it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 35.79it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:16, 35.80it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:16, 35.81it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 35.82it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 35.81it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 35.80it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:12<00:15, 35.80it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:12<00:15, 35.79it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 35.79it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 35.77it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:15, 35.75it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:15, 35.78it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 35.80it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 35.76it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 35.78it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:13<00:14, 35.80it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:13<00:14, 35.79it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 35.80it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 35.81it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:14, 35.82it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:14, 35.80it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 35.80it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 35.78it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:14<00:13, 35.77it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:14<00:13, 35.77it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:14<00:13, 35.76it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 35.77it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 35.78it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:13, 35.78it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:13, 35.80it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 35.80it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 35.79it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:15<00:12, 35.79it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:15<00:12, 35.79it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:15<00:12, 35.80it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 35.80it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 35.79it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:12, 35.80it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:12, 35.80it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 35.81it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 35.83it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:16<00:11, 35.81it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:16<00:11, 35.79it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 35.81it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:11, 35.81it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:11, 35.80it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 35.80it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 35.78it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:17<00:10, 35.78it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:17<00:10, 35.80it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:17<00:10, 35.80it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:10, 35.78it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 35.80it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:10, 35.81it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:10, 35.80it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 35.80it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 35.79it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:18<00:09, 35.78it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:18<00:09, 35.79it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:18<00:09, 35.79it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:09, 35.80it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 35.81it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:09, 35.80it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:09, 35.80it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 35.82it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 35.81it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:19<00:08, 35.80it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:19<00:08, 35.78it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:19<00:08, 35.77it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:08, 35.78it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 35.80it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:08, 35.80it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:08, 35.79it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 35.81it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 35.81it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:20<00:07, 35.83it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:20<00:07, 35.82it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:20<00:07, 35.80it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:07, 35.79it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 35.79it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:07, 35.79it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:07, 35.80it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 35.79it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 35.77it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:21<00:06, 35.79it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:21<00:06, 35.78it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:21<00:06, 35.79it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 35.80it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:06, 35.81it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:06, 35.80it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:06, 35.82it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 35.83it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 35.82it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:22<00:05, 35.82it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:22<00:05, 35.81it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:22<00:05, 35.80it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 35.80it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:05, 35.79it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:05, 35.78it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:05, 35.78it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 35.76it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 35.75it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:23<00:04, 35.75it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:23<00:04, 35.76it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:23<00:04, 35.77it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 35.78it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 35.77it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 35.76it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:04, 35.78it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 35.80it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 35.79it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:24<00:03, 35.78it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:24<00:03, 35.78it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:24<00:03, 35.78it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:24<00:03, 35.80it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 35.81it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 35.80it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:03, 35.78it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 35.77it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 35.78it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:25<00:02, 35.77it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:25<00:02, 35.77it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:25<00:02, 35.75it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:25<00:02, 35.75it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 35.76it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 35.76it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:02, 35.75it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 35.76it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 35.76it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:26<00:01, 35.76it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:26<00:01, 35.78it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:26<00:01, 35.78it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:26<00:01, 35.78it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 35.78it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 35.77it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:01, 35.73it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 35.74it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 35.77it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:27<00:00, 35.77it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:27<00:00, 35.80it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:27<00:00, 35.80it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:27<00:00, 35.82it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 35.83it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 35.83it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 35.82it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.03it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.06it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.24it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.31it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.34it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.36it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 37.36it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 37.37it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 37.39it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 37.39it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 37.39it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 37.40it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 37.42it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 37.41it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 37.40it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 36.87it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 36.52it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 36.29it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 36.13it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 36.01it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 35.92it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 35.86it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 35.81it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 35.78it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 35.78it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 35.75it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 36.63it/s]
STAGE:2024-02-25 23:28:33 7922:7922 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:28:33 7922:7922 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:28:33 7922:7922 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:27, 36.68it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 36.92it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 36.76it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:27, 36.24it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:27, 35.96it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:27, 35.76it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:27, 35.65it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:27, 35.58it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:01<00:27, 35.54it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:27, 35.52it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:26, 35.48it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:26, 35.47it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:26, 35.46it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:26, 35.46it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:26, 35.44it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:26, 35.43it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:26, 35.42it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:02<00:26, 35.41it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:26, 35.42it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:25, 35.43it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:25, 35.43it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:25, 35.43it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:25, 35.43it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:25, 35.42it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:25, 35.42it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:25, 35.39it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:03<00:25, 35.39it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:03<00:25, 35.38it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:24, 35.39it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:24, 35.41it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:24, 35.41it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:24, 35.41it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:24, 35.40it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:24, 35.41it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:24, 35.42it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:04<00:24, 35.43it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:04<00:24, 35.44it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:23, 35.44it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:23, 35.45it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:23, 35.44it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:23, 35.45it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:23, 35.43it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:23, 35.44it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:23, 35.44it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:05<00:23, 35.43it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:05<00:23, 35.43it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:22, 35.42it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 35.41it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 35.39it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:22, 35.39it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:22, 35.37it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:22, 35.36it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:22, 35.36it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:06<00:22, 35.35it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:06<00:22, 35.34it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:21, 35.33it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:21, 35.32it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:21, 35.31it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:21, 35.32it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:21, 35.32it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:21, 35.34it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:21, 35.35it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:07<00:21, 35.35it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:07<00:21, 35.34it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:07<00:20, 35.35it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:20, 35.35it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:20, 35.36it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:20, 35.36it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:20, 35.35it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:20, 35.35it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:08<00:20, 35.35it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:08<00:20, 35.35it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:08<00:20, 35.34it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:08<00:19, 35.36it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:19, 35.35it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:19, 35.36it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:19, 35.35it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:19, 35.36it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:19, 35.36it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:09<00:19, 35.36it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:09<00:19, 35.36it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:09<00:19, 35.35it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:09<00:18, 35.35it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 35.35it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 35.34it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 35.33it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:18, 35.33it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:18, 35.32it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:10<00:18, 35.33it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:10<00:18, 35.34it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:10<00:17, 35.35it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:10<00:17, 35.34it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 35.34it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:17, 35.34it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:17, 35.33it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:17, 35.33it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:17, 35.34it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:11<00:17, 35.34it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:11<00:17, 35.35it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:11<00:16, 35.36it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:11<00:16, 35.38it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:16, 35.37it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:16, 35.36it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:16, 35.34it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:16, 35.34it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:16, 35.34it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:12<00:16, 35.33it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:12<00:16, 35.33it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:12<00:15, 35.33it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:12<00:15, 35.34it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:15, 35.35it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:15, 35.32it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:15, 35.34it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:15, 35.33it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:15, 35.34it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:13<00:15, 35.34it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:13<00:15, 35.35it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:13<00:14, 35.35it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:13<00:14, 35.34it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:13<00:14, 35.35it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:14, 35.37it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:14, 35.37it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:14, 35.34it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:14<00:14, 35.32it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:14<00:14, 35.32it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:14<00:14, 35.32it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:14<00:13, 35.33it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:14<00:13, 35.33it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:14<00:13, 35.32it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:13, 35.32it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:13, 35.32it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:13, 35.34it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:15<00:13, 35.35it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:15<00:13, 35.36it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:15<00:13, 35.37it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:15<00:12, 35.37it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:15<00:12, 35.37it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:15<00:12, 35.37it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 35.37it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 35.36it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:12, 35.36it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:16<00:12, 35.35it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:16<00:12, 35.35it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:16<00:11, 35.35it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:16<00:11, 35.35it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:16<00:11, 35.35it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:16<00:11, 35.35it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 35.34it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 35.35it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:11, 35.35it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:17<00:11, 35.35it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:17<00:11, 35.34it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:17<00:10, 35.34it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:17<00:10, 35.34it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:17<00:10, 35.33it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:17<00:10, 35.35it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 35.35it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 35.35it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 35.37it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:18<00:10, 35.38it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:18<00:10, 35.39it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:18<00:09, 35.40it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:18<00:09, 35.39it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:18<00:09, 35.39it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:18<00:09, 35.40it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:09, 35.40it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:09, 35.40it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:09, 35.39it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:19<00:09, 35.38it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:19<00:09, 35.37it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:19<00:08, 35.36it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:19<00:08, 35.36it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:19<00:08, 35.36it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:19<00:08, 35.38it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:19<00:08, 35.40it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:08, 35.41it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:20<00:08, 35.41it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:20<00:08, 35.41it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:20<00:08, 35.41it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:20<00:07, 35.39it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:20<00:07, 35.37it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:20<00:07, 35.37it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:20<00:07, 35.38it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:20<00:07, 35.39it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:07, 35.39it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:21<00:07, 35.39it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:21<00:07, 35.39it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:21<00:07, 35.39it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:21<00:06, 35.39it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:21<00:06, 35.39it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:21<00:06, 35.40it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:21<00:06, 35.42it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:21<00:06, 35.41it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:21<00:06, 35.41it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:22<00:06, 35.41it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:22<00:06, 35.41it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:22<00:05, 35.41it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:22<00:05, 35.41it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:22<00:05, 35.42it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:22<00:05, 35.42it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:22<00:05, 35.42it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:22<00:05, 35.44it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:22<00:05, 35.44it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:23<00:05, 35.46it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:23<00:05, 35.45it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:23<00:04, 35.44it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:23<00:04, 35.43it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:23<00:04, 35.43it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:23<00:04, 35.42it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:23<00:04, 35.42it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:23<00:04, 35.40it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:23<00:04, 35.36it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:24<00:04, 35.31it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:24<00:04, 35.32it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:24<00:03, 35.34it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:24<00:03, 35.34it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:24<00:03, 35.33it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:24<00:03, 35.35it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:24<00:03, 35.35it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:24<00:03, 35.37it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:24<00:03, 35.39it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:25<00:03, 35.36it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:25<00:03, 35.36it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:25<00:02, 35.37it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:25<00:02, 35.38it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:25<00:02, 35.37it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:25<00:02, 35.39it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:25<00:02, 35.41it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:25<00:02, 35.39it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:25<00:02, 35.39it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:26<00:02, 35.39it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:26<00:02, 35.37it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:26<00:01, 35.38it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:26<00:01, 35.38it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:26<00:01, 35.40it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:26<00:01, 35.39it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:26<00:01, 35.40it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:26<00:01, 35.41it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:27<00:01, 35.41it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:27<00:01, 35.41it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:27<00:01, 35.39it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:27<00:00, 35.39it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:27<00:00, 35.37it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:27<00:00, 35.38it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:27<00:00, 35.37it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:27<00:00, 35.37it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:27<00:00, 35.35it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:28<00:00, 35.35it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:28<00:00, 35.36it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:28<00:00, 35.36it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:28<00:00, 35.39it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 999.68 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 100.396 us +/- 5.948 us [94.891 us, 225.544 us]
        batches_per_second: 9.99 K +/- 457.03 [4.43 K, 10.54 K]
      metrics:
        batches_per_second_max: 10538.452261306533
        batches_per_second_mean: 9986.111164979118
        batches_per_second_min: 4433.725158562368
        batches_per_second_std: 457.03317827761015
        seconds_per_batch_max: 0.00022554397583007812
        seconds_per_batch_mean: 0.00010039615631103515
        seconds_per_batch_min: 9.489059448242188e-05
        seconds_per_batch_std: 5.948118469859576e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.880 us +/- 1.086 us [24.080 us, 41.246 us]
        batches_per_second: 38.69 K +/- 1.32 K [24.24 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 38694.25560350962
        batches_per_second_min: 24244.531791907513
        batches_per_second_std: 1317.764184156092
        seconds_per_batch_max: 4.124641418457031e-05
        seconds_per_batch_mean: 2.588009834289551e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 1.0864564610938517e-06
    on_device_inference:
      human_readable:
        batch_latency: -27595098.803 us +/- 452.855 ms [-28004991.531 us, -26354751.587
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035707920099878214
        batches_per_second_mean: -0.03624842457459121
        batches_per_second_min: -0.03794382188358514
        batches_per_second_std: 0.0006157895566322109
        seconds_per_batch_max: -26.354751586914062
        seconds_per_batch_mean: -27.59509880256653
        seconds_per_batch_min: -28.00499153137207
        seconds_per_batch_std: 0.45285493921437137
    total:
      human_readable:
        batch_latency: 27.733 ms +/- 454.335 us [26.486 ms, 28.158 ms]
        batches_per_second: 36.07 +/- 0.61 [35.51, 37.76]
      metrics:
        batches_per_second_max: 37.75522989954272
        batches_per_second_mean: 36.06788518513505
        batches_per_second_min: 35.51334829177427
        batches_per_second_std: 0.6116050840137915
        seconds_per_batch_max: 0.02815842628479004
        seconds_per_batch_mean: 0.02773319983482361
        seconds_per_batch_min: 0.02648639678955078
        seconds_per_batch_std: 0.00045433471517877387
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 153.821 us +/- 6.147 us [147.581 us, 287.294 us]
        batches_per_second: 6.51 K +/- 205.66 [3.48 K, 6.78 K]
      metrics:
        batches_per_second_max: 6775.9353796445885
        batches_per_second_mean: 6508.964307583745
        batches_per_second_min: 3480.7502074688796
        batches_per_second_std: 205.65927393532198
        seconds_per_batch_max: 0.0002872943878173828
        seconds_per_batch_mean: 0.00015382122993469238
        seconds_per_batch_min: 0.0001475811004638672
        seconds_per_batch_std: 6.1468224839123024e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 26.320 us +/- 0.771 us [24.796 us, 34.809 us]
        batches_per_second: 38.02 K +/- 985.27 [28.73 K, 40.33 K]
      metrics:
        batches_per_second_max: 40329.846153846156
        batches_per_second_mean: 38021.92139689732
        batches_per_second_min: 28728.109589041094
        batches_per_second_std: 985.2729308403248
        seconds_per_batch_max: 3.4809112548828125e-05
        seconds_per_batch_mean: 2.6320457458496094e-05
        seconds_per_batch_min: 2.47955322265625e-05
        seconds_per_batch_std: 7.713562888867556e-07
    on_device_inference:
      human_readable:
        batch_latency: -28043111.818 us +/- 139.300 ms [-28351455.688 us, -26707296.371
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035271557516760935
        batches_per_second_mean: -0.035660294879184845
        batches_per_second_min: -0.0374429513976796
        batches_per_second_std: 0.00018406804353516198
        seconds_per_batch_max: -26.70729637145996
        seconds_per_batch_mean: -28.043111818313598
        seconds_per_batch_min: -28.351455688476562
        seconds_per_batch_std: 0.13929953579335458
    total:
      human_readable:
        batch_latency: 28.236 ms +/- 139.888 us [26.894 ms, 28.543 ms]
        batches_per_second: 35.42 +/- 0.18 [35.04, 37.18]
      metrics:
        batches_per_second_max: 37.18321646084698
        batches_per_second_mean: 35.41701551851186
        batches_per_second_min: 35.03545056634034
        batches_per_second_std: 0.1822894906380784
        seconds_per_batch_max: 0.028542518615722656
        seconds_per_batch_mean: 0.02823573589324951
        seconds_per_batch_min: 0.02689385414123535
        seconds_per_batch_std: 0.0001398880634326496


#####
fp-fp-py-id - Run 15
2024-02-25 23:30:11
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.41it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.33it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.33it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.33it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.37it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.40it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.42it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.43it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.43it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.43it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.43it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.42it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.42it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.41it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.41it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.41it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.41it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.41it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.42it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.43it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.41it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.41it/s]
STAGE:2024-02-25 23:29:12 7968:7968 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:29:12 7968:7968 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:29:12 7968:7968 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.46it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.74it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.83it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 37.88it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 37.90it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.91it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.91it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.90it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.91it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.91it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.91it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.91it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.92it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 37.92it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 37.92it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.92it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.92it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.92it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.91it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.91it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.35it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.00it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 36.76it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 36.59it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 36.42it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 36.32it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:24, 36.28it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:24, 36.24it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:24, 36.22it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:24, 36.20it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:24, 36.18it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:24, 36.15it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:24, 36.14it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 36.13it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 36.14it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 36.14it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:23, 36.13it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 36.14it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:23, 36.15it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:23, 36.16it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:23, 36.16it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:23, 36.15it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 36.14it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 36.11it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 36.06it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:22, 36.06it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 36.09it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:22, 36.10it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:22, 36.12it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:22, 36.13it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:22, 36.15it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 36.15it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 36.15it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 36.15it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:21, 36.16it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:06<00:21, 36.18it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:21, 36.17it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 36.18it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:21, 36.19it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 36.20it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 36.20it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 36.17it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 36.17it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:20, 36.18it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:07<00:20, 36.16it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 36.14it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 36.14it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:20, 36.12it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:20, 36.13it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 36.12it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 36.12it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 36.12it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:19, 36.15it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:08<00:19, 36.16it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 36.15it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 36.15it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:19, 36.14it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:19, 36.14it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 36.13it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 36.16it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 36.16it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:18, 36.18it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:09<00:18, 36.18it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 36.16it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 36.15it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:18, 36.16it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:18, 36.16it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 36.16it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 36.13it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 36.12it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 36.10it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:10<00:17, 36.11it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 36.11it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 36.11it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 36.12it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:17, 36.11it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 36.09it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 36.06it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 36.08it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 36.09it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:11<00:16, 36.11it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:11<00:16, 36.13it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 36.14it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 36.14it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:16, 36.13it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 36.15it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 36.15it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 36.16it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 36.16it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:12<00:15, 36.16it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:12<00:15, 36.14it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 36.15it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 36.14it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:15, 36.14it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.14it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 36.16it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 36.15it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 36.14it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:13<00:14, 36.11it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:13<00:14, 36.10it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 36.10it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 36.11it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:14, 36.11it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 36.12it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 36.13it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 36.15it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 36.14it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:14<00:13, 36.13it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:14<00:13, 36.14it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 36.13it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 36.13it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:13, 36.12it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 36.12it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 36.11it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 36.11it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 36.11it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:15<00:12, 36.12it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:15<00:12, 36.14it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 36.14it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 36.15it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:12, 36.15it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 36.15it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 36.14it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 36.10it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 36.13it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:16<00:11, 36.14it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:16<00:11, 36.15it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 36.15it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 36.14it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:11, 36.16it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 36.14it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 36.13it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 36.11it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 36.12it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:17<00:10, 36.09it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:17<00:10, 36.08it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:10, 36.10it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 36.10it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:10, 36.10it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 36.07it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 36.05it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 36.04it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 36.08it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:18<00:09, 36.08it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:18<00:09, 36.08it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:09, 36.10it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 36.13it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:09, 36.14it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 36.12it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 36.11it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 36.11it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 36.12it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:19<00:08, 36.11it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:19<00:08, 36.13it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:08, 36.14it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 36.15it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:08, 36.17it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 36.14it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 36.14it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 36.13it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 36.13it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:20<00:07, 36.14it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:20<00:07, 36.11it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:07, 36.09it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 36.08it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:07, 36.09it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 36.10it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 36.11it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 36.12it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 36.11it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:21<00:06, 36.13it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:21<00:06, 36.13it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 36.14it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:06, 36.13it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:06, 36.13it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:05, 36.14it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 36.15it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 36.15it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 36.16it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:22<00:05, 36.16it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:22<00:05, 36.14it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 36.12it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:05, 36.13it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:05, 36.12it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:04, 36.11it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 36.13it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 36.11it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 36.09it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:23<00:04, 36.09it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:23<00:04, 36.11it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 36.14it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 36.15it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 36.16it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:03, 36.16it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 36.16it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 36.17it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 36.18it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:24<00:03, 36.17it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:24<00:03, 36.14it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:24<00:03, 36.13it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 36.12it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 36.11it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:02, 36.09it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 36.12it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 36.13it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 36.14it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:25<00:02, 36.14it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:25<00:02, 36.14it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:25<00:02, 36.13it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 36.10it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 36.08it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:01, 36.06it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 36.03it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 36.02it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 36.05it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:26<00:01, 36.07it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:26<00:01, 36.11it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:26<00:01, 36.12it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 36.13it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 36.15it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:00, 36.14it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 36.10it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 36.11it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 36.13it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:27<00:00, 36.10it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:27<00:00, 36.06it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:27<00:00, 36.05it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 36.02it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 36.01it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.00it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.26it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   4%|▍         | 4/100 [00:00<00:02, 37.36it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:02, 37.57it/s]Warming up with batch_size=32:  12%|█▏        | 12/100 [00:00<00:02, 37.63it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:02, 37.67it/s]Warming up with batch_size=32:  20%|██        | 20/100 [00:00<00:02, 37.04it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:02, 36.67it/s]Warming up with batch_size=32:  28%|██▊       | 28/100 [00:00<00:01, 36.42it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:01, 36.31it/s]Warming up with batch_size=32:  36%|███▌      | 36/100 [00:00<00:01, 36.21it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:01<00:01, 36.14it/s]Warming up with batch_size=32:  44%|████▍     | 44/100 [00:01<00:01, 36.09it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:01<00:01, 36.06it/s]Warming up with batch_size=32:  52%|█████▏    | 52/100 [00:01<00:01, 36.04it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:01<00:01, 36.03it/s]Warming up with batch_size=32:  60%|██████    | 60/100 [00:01<00:01, 36.03it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:01<00:00, 36.03it/s]Warming up with batch_size=32:  68%|██████▊   | 68/100 [00:01<00:00, 36.03it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:01<00:00, 36.04it/s]Warming up with batch_size=32:  76%|███████▌  | 76/100 [00:02<00:00, 36.03it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:02<00:00, 36.03it/s]Warming up with batch_size=32:  84%|████████▍ | 84/100 [00:02<00:00, 36.03it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:02<00:00, 36.03it/s]Warming up with batch_size=32:  92%|█████████▏| 92/100 [00:02<00:00, 36.02it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:02<00:00, 36.00it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 35.99it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:02<00:00, 36.25it/s]
STAGE:2024-02-25 23:29:43 7968:7968 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:29:43 7968:7968 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:29:43 7968:7968 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   0%|          | 4/1000 [00:00<00:26, 37.18it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:26, 37.42it/s]Measuring inference for batch_size=32:   1%|          | 12/1000 [00:00<00:26, 37.51it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:26, 37.55it/s]Measuring inference for batch_size=32:   2%|▏         | 20/1000 [00:00<00:26, 37.57it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:25, 37.57it/s]Measuring inference for batch_size=32:   3%|▎         | 28/1000 [00:00<00:25, 37.57it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:25, 37.58it/s]Measuring inference for batch_size=32:   4%|▎         | 36/1000 [00:00<00:25, 37.59it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:01<00:25, 37.57it/s]Measuring inference for batch_size=32:   4%|▍         | 44/1000 [00:01<00:25, 37.57it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:01<00:25, 37.58it/s]Measuring inference for batch_size=32:   5%|▌         | 52/1000 [00:01<00:25, 37.56it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:01<00:25, 37.56it/s]Measuring inference for batch_size=32:   6%|▌         | 60/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:01<00:24, 37.55it/s]Measuring inference for batch_size=32:   7%|▋         | 68/1000 [00:01<00:24, 37.55it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:24, 37.55it/s]Measuring inference for batch_size=32:   8%|▊         | 76/1000 [00:02<00:24, 37.54it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:02<00:24, 37.53it/s]Measuring inference for batch_size=32:   8%|▊         | 84/1000 [00:02<00:24, 37.54it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:02<00:24, 37.53it/s]Measuring inference for batch_size=32:   9%|▉         | 92/1000 [00:02<00:24, 37.48it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:02<00:24, 36.94it/s]Measuring inference for batch_size=32:  10%|█         | 100/1000 [00:02<00:24, 36.59it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:02<00:24, 36.34it/s]Measuring inference for batch_size=32:  11%|█         | 108/1000 [00:02<00:24, 36.15it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:03<00:24, 36.05it/s]Measuring inference for batch_size=32:  12%|█▏        | 116/1000 [00:03<00:24, 35.99it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:03<00:24, 35.96it/s]Measuring inference for batch_size=32:  12%|█▏        | 124/1000 [00:03<00:24, 35.92it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:03<00:24, 35.88it/s]Measuring inference for batch_size=32:  13%|█▎        | 132/1000 [00:03<00:24, 35.86it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:03<00:24, 35.84it/s]Measuring inference for batch_size=32:  14%|█▍        | 140/1000 [00:03<00:23, 35.85it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:03<00:23, 35.83it/s]Measuring inference for batch_size=32:  15%|█▍        | 148/1000 [00:04<00:23, 35.81it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:04<00:23, 35.81it/s]Measuring inference for batch_size=32:  16%|█▌        | 156/1000 [00:04<00:23, 35.80it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:04<00:23, 35.80it/s]Measuring inference for batch_size=32:  16%|█▋        | 164/1000 [00:04<00:23, 35.80it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:04<00:23, 35.80it/s]Measuring inference for batch_size=32:  17%|█▋        | 172/1000 [00:04<00:23, 35.81it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:04<00:23, 35.81it/s]Measuring inference for batch_size=32:  18%|█▊        | 180/1000 [00:04<00:22, 35.79it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:05<00:22, 35.74it/s]Measuring inference for batch_size=32:  19%|█▉        | 188/1000 [00:05<00:22, 35.72it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:05<00:22, 35.70it/s]Measuring inference for batch_size=32:  20%|█▉        | 196/1000 [00:05<00:22, 36.02it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:05<00:21, 36.48it/s]Measuring inference for batch_size=32:  20%|██        | 204/1000 [00:05<00:21, 36.81it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:05<00:21, 37.04it/s]Measuring inference for batch_size=32:  21%|██        | 212/1000 [00:05<00:21, 37.20it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:05<00:21, 37.30it/s]Measuring inference for batch_size=32:  22%|██▏       | 220/1000 [00:05<00:20, 37.38it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:06<00:20, 37.43it/s]Measuring inference for batch_size=32:  23%|██▎       | 228/1000 [00:06<00:20, 37.45it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:06<00:20, 37.46it/s]Measuring inference for batch_size=32:  24%|██▎       | 236/1000 [00:06<00:20, 37.47it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:06<00:20, 37.49it/s]Measuring inference for batch_size=32:  24%|██▍       | 244/1000 [00:06<00:20, 37.50it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:06<00:20, 37.50it/s]Measuring inference for batch_size=32:  25%|██▌       | 252/1000 [00:06<00:19, 37.51it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:06<00:19, 37.53it/s]Measuring inference for batch_size=32:  26%|██▌       | 260/1000 [00:07<00:19, 37.53it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:07<00:19, 37.52it/s]Measuring inference for batch_size=32:  27%|██▋       | 268/1000 [00:07<00:19, 37.51it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:07<00:19, 37.50it/s]Measuring inference for batch_size=32:  28%|██▊       | 276/1000 [00:07<00:19, 37.50it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:07<00:19, 37.51it/s]Measuring inference for batch_size=32:  28%|██▊       | 284/1000 [00:07<00:19, 37.50it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:07<00:18, 37.50it/s]Measuring inference for batch_size=32:  29%|██▉       | 292/1000 [00:07<00:18, 37.50it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=32:  30%|███       | 300/1000 [00:08<00:18, 37.50it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=32:  31%|███       | 308/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=32:  32%|███▏      | 316/1000 [00:08<00:18, 37.48it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:08<00:18, 37.41it/s]Measuring inference for batch_size=32:  32%|███▏      | 324/1000 [00:08<00:18, 36.91it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:08<00:18, 36.58it/s]Measuring inference for batch_size=32:  33%|███▎      | 332/1000 [00:08<00:18, 36.35it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:09<00:18, 36.19it/s]Measuring inference for batch_size=32:  34%|███▍      | 340/1000 [00:09<00:18, 36.07it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:09<00:18, 35.98it/s]Measuring inference for batch_size=32:  35%|███▍      | 348/1000 [00:09<00:18, 35.93it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:09<00:18, 35.87it/s]Measuring inference for batch_size=32:  36%|███▌      | 356/1000 [00:09<00:17, 35.85it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:09<00:17, 35.83it/s]Measuring inference for batch_size=32:  36%|███▋      | 364/1000 [00:09<00:17, 35.83it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:10<00:17, 35.82it/s]Measuring inference for batch_size=32:  37%|███▋      | 372/1000 [00:10<00:17, 35.82it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:10<00:17, 35.82it/s]Measuring inference for batch_size=32:  38%|███▊      | 380/1000 [00:10<00:17, 35.82it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:10<00:17, 35.82it/s]Measuring inference for batch_size=32:  39%|███▉      | 388/1000 [00:10<00:17, 35.82it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:10<00:16, 35.80it/s]Measuring inference for batch_size=32:  40%|███▉      | 396/1000 [00:10<00:16, 35.80it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:10<00:16, 35.82it/s]Measuring inference for batch_size=32:  40%|████      | 404/1000 [00:11<00:16, 35.80it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:11<00:16, 35.80it/s]Measuring inference for batch_size=32:  41%|████      | 412/1000 [00:11<00:16, 35.79it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:11<00:16, 35.79it/s]Measuring inference for batch_size=32:  42%|████▏     | 420/1000 [00:11<00:16, 35.77it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:11<00:16, 35.76it/s]Measuring inference for batch_size=32:  43%|████▎     | 428/1000 [00:11<00:15, 35.78it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:11<00:15, 35.76it/s]Measuring inference for batch_size=32:  44%|████▎     | 436/1000 [00:11<00:15, 35.75it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:12<00:15, 35.76it/s]Measuring inference for batch_size=32:  44%|████▍     | 444/1000 [00:12<00:15, 35.77it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:12<00:15, 35.79it/s]Measuring inference for batch_size=32:  45%|████▌     | 452/1000 [00:12<00:15, 35.80it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:12<00:15, 35.79it/s]Measuring inference for batch_size=32:  46%|████▌     | 460/1000 [00:12<00:15, 35.80it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:12<00:14, 35.77it/s]Measuring inference for batch_size=32:  47%|████▋     | 468/1000 [00:12<00:14, 35.77it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:12<00:14, 35.78it/s]Measuring inference for batch_size=32:  48%|████▊     | 476/1000 [00:13<00:14, 35.78it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:13<00:14, 35.79it/s]Measuring inference for batch_size=32:  48%|████▊     | 484/1000 [00:13<00:14, 35.80it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:13<00:14, 35.81it/s]Measuring inference for batch_size=32:  49%|████▉     | 492/1000 [00:13<00:14, 35.80it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:13<00:14, 35.78it/s]Measuring inference for batch_size=32:  50%|█████     | 500/1000 [00:13<00:13, 35.77it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:13<00:13, 35.76it/s]Measuring inference for batch_size=32:  51%|█████     | 508/1000 [00:13<00:13, 35.78it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:14<00:13, 35.78it/s]Measuring inference for batch_size=32:  52%|█████▏    | 516/1000 [00:14<00:13, 35.77it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:14<00:13, 35.78it/s]Measuring inference for batch_size=32:  52%|█████▏    | 524/1000 [00:14<00:13, 35.78it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:14<00:13, 35.79it/s]Measuring inference for batch_size=32:  53%|█████▎    | 532/1000 [00:14<00:13, 35.79it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:14<00:12, 35.79it/s]Measuring inference for batch_size=32:  54%|█████▍    | 540/1000 [00:14<00:12, 35.77it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:14<00:12, 35.76it/s]Measuring inference for batch_size=32:  55%|█████▍    | 548/1000 [00:15<00:12, 35.77it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:15<00:12, 35.78it/s]Measuring inference for batch_size=32:  56%|█████▌    | 556/1000 [00:15<00:12, 35.79it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:15<00:12, 35.80it/s]Measuring inference for batch_size=32:  56%|█████▋    | 564/1000 [00:15<00:12, 35.79it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:15<00:12, 35.78it/s]Measuring inference for batch_size=32:  57%|█████▋    | 572/1000 [00:15<00:11, 35.78it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:15<00:11, 35.77it/s]Measuring inference for batch_size=32:  58%|█████▊    | 580/1000 [00:15<00:11, 35.76it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:16<00:11, 35.78it/s]Measuring inference for batch_size=32:  59%|█████▉    | 588/1000 [00:16<00:11, 35.75it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:16<00:11, 35.74it/s]Measuring inference for batch_size=32:  60%|█████▉    | 596/1000 [00:16<00:11, 35.73it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:16<00:11, 35.69it/s]Measuring inference for batch_size=32:  60%|██████    | 604/1000 [00:16<00:11, 35.71it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:16<00:10, 35.73it/s]Measuring inference for batch_size=32:  61%|██████    | 612/1000 [00:16<00:10, 35.72it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:16<00:10, 35.72it/s]Measuring inference for batch_size=32:  62%|██████▏   | 620/1000 [00:17<00:10, 35.75it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:17<00:10, 35.74it/s]Measuring inference for batch_size=32:  63%|██████▎   | 628/1000 [00:17<00:10, 35.76it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:17<00:10, 35.75it/s]Measuring inference for batch_size=32:  64%|██████▎   | 636/1000 [00:17<00:10, 35.71it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:17<00:10, 35.72it/s]Measuring inference for batch_size=32:  64%|██████▍   | 644/1000 [00:17<00:09, 35.72it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:17<00:09, 35.72it/s]Measuring inference for batch_size=32:  65%|██████▌   | 652/1000 [00:17<00:09, 35.70it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:18<00:09, 35.70it/s]Measuring inference for batch_size=32:  66%|██████▌   | 660/1000 [00:18<00:09, 35.71it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:18<00:09, 35.71it/s]Measuring inference for batch_size=32:  67%|██████▋   | 668/1000 [00:18<00:09, 35.72it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:18<00:09, 35.74it/s]Measuring inference for batch_size=32:  68%|██████▊   | 676/1000 [00:18<00:09, 35.76it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:18<00:08, 35.74it/s]Measuring inference for batch_size=32:  68%|██████▊   | 684/1000 [00:18<00:08, 35.69it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:18<00:08, 35.66it/s]Measuring inference for batch_size=32:  69%|██████▉   | 692/1000 [00:19<00:08, 35.64it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:19<00:08, 35.66it/s]Measuring inference for batch_size=32:  70%|███████   | 700/1000 [00:19<00:08, 35.69it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:19<00:08, 35.72it/s]Measuring inference for batch_size=32:  71%|███████   | 708/1000 [00:19<00:08, 35.73it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:19<00:08, 35.76it/s]Measuring inference for batch_size=32:  72%|███████▏  | 716/1000 [00:19<00:07, 35.77it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:19<00:07, 35.76it/s]Measuring inference for batch_size=32:  72%|███████▏  | 724/1000 [00:19<00:07, 35.75it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:20<00:07, 35.76it/s]Measuring inference for batch_size=32:  73%|███████▎  | 732/1000 [00:20<00:07, 35.77it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:20<00:07, 35.77it/s]Measuring inference for batch_size=32:  74%|███████▍  | 740/1000 [00:20<00:07, 35.78it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:20<00:07, 35.78it/s]Measuring inference for batch_size=32:  75%|███████▍  | 748/1000 [00:20<00:07, 35.80it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:20<00:06, 35.78it/s]Measuring inference for batch_size=32:  76%|███████▌  | 756/1000 [00:20<00:06, 35.79it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:20<00:06, 35.79it/s]Measuring inference for batch_size=32:  76%|███████▋  | 764/1000 [00:21<00:06, 35.80it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:21<00:06, 35.81it/s]Measuring inference for batch_size=32:  77%|███████▋  | 772/1000 [00:21<00:06, 35.82it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:21<00:06, 35.78it/s]Measuring inference for batch_size=32:  78%|███████▊  | 780/1000 [00:21<00:06, 35.78it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:21<00:06, 35.80it/s]Measuring inference for batch_size=32:  79%|███████▉  | 788/1000 [00:21<00:05, 35.78it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:21<00:05, 35.79it/s]Measuring inference for batch_size=32:  80%|███████▉  | 796/1000 [00:21<00:05, 35.80it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:22<00:05, 35.79it/s]Measuring inference for batch_size=32:  80%|████████  | 804/1000 [00:22<00:05, 35.79it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:22<00:05, 35.77it/s]Measuring inference for batch_size=32:  81%|████████  | 812/1000 [00:22<00:05, 35.79it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:22<00:05, 35.80it/s]Measuring inference for batch_size=32:  82%|████████▏ | 820/1000 [00:22<00:05, 35.81it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:22<00:04, 35.83it/s]Measuring inference for batch_size=32:  83%|████████▎ | 828/1000 [00:22<00:04, 35.82it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:22<00:04, 35.83it/s]Measuring inference for batch_size=32:  84%|████████▎ | 836/1000 [00:23<00:04, 35.83it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:23<00:04, 35.82it/s]Measuring inference for batch_size=32:  84%|████████▍ | 844/1000 [00:23<00:04, 35.83it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:23<00:04, 35.84it/s]Measuring inference for batch_size=32:  85%|████████▌ | 852/1000 [00:23<00:04, 35.84it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:23<00:04, 35.84it/s]Measuring inference for batch_size=32:  86%|████████▌ | 860/1000 [00:23<00:03, 35.82it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:23<00:03, 35.80it/s]Measuring inference for batch_size=32:  87%|████████▋ | 868/1000 [00:23<00:03, 35.80it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:24<00:03, 35.78it/s]Measuring inference for batch_size=32:  88%|████████▊ | 876/1000 [00:24<00:03, 35.76it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:24<00:03, 35.76it/s]Measuring inference for batch_size=32:  88%|████████▊ | 884/1000 [00:24<00:03, 35.76it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:24<00:03, 35.76it/s]Measuring inference for batch_size=32:  89%|████████▉ | 892/1000 [00:24<00:03, 35.77it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:24<00:02, 35.77it/s]Measuring inference for batch_size=32:  90%|█████████ | 900/1000 [00:24<00:02, 35.76it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:24<00:02, 35.76it/s]Measuring inference for batch_size=32:  91%|█████████ | 908/1000 [00:25<00:02, 35.75it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:25<00:02, 35.75it/s]Measuring inference for batch_size=32:  92%|█████████▏| 916/1000 [00:25<00:02, 35.76it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:25<00:02, 35.75it/s]Measuring inference for batch_size=32:  92%|█████████▏| 924/1000 [00:25<00:02, 35.76it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:25<00:02, 35.77it/s]Measuring inference for batch_size=32:  93%|█████████▎| 932/1000 [00:25<00:01, 35.79it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:25<00:01, 35.80it/s]Measuring inference for batch_size=32:  94%|█████████▍| 940/1000 [00:25<00:01, 35.78it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:26<00:01, 35.77it/s]Measuring inference for batch_size=32:  95%|█████████▍| 948/1000 [00:26<00:01, 35.75it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:26<00:01, 35.75it/s]Measuring inference for batch_size=32:  96%|█████████▌| 956/1000 [00:26<00:01, 35.78it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:26<00:01, 35.79it/s]Measuring inference for batch_size=32:  96%|█████████▋| 964/1000 [00:26<00:01, 35.78it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:26<00:00, 35.78it/s]Measuring inference for batch_size=32:  97%|█████████▋| 972/1000 [00:26<00:00, 35.76it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:26<00:00, 35.77it/s]Measuring inference for batch_size=32:  98%|█████████▊| 980/1000 [00:27<00:00, 35.77it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:27<00:00, 35.76it/s]Measuring inference for batch_size=32:  99%|█████████▉| 988/1000 [00:27<00:00, 35.78it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:27<00:00, 35.79it/s]Measuring inference for batch_size=32: 100%|█████████▉| 996/1000 [00:27<00:00, 35.79it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 35.79it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:27<00:00, 36.14it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1001.51 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_32:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 98.578 us +/- 5.994 us [93.222 us, 222.921 us]
        batches_per_second: 10.17 K +/- 479.09 [4.49 K, 10.73 K]
      metrics:
        batches_per_second_max: 10727.120204603581
        batches_per_second_mean: 10171.759532939903
        batches_per_second_min: 4485.886631016043
        batches_per_second_std: 479.0919949162771
        seconds_per_batch_max: 0.00022292137145996094
        seconds_per_batch_mean: 9.857821464538574e-05
        seconds_per_batch_min: 9.322166442871094e-05
        seconds_per_batch_std: 5.99353632733778e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.103 us +/- 0.750 us [23.365 us, 35.048 us]
        batches_per_second: 39.87 K +/- 1.03 K [28.53 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 39866.08399219379
        batches_per_second_min: 28532.680272108842
        batches_per_second_std: 1025.6869048516241
        seconds_per_batch_max: 3.504753112792969e-05
        seconds_per_batch_mean: 2.5103092193603517e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 7.50314291517599e-07
    on_device_inference:
      human_readable:
        batch_latency: -27425305.498 us +/- 357.617 ms [-27751071.930 us, -26165439.606
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.036034644085997415
        batches_per_second_mean: -0.036469125747315125
        batches_per_second_min: -0.038218352722866646
        batches_per_second_std: 0.0004947210902790952
        seconds_per_batch_max: -26.16543960571289
        seconds_per_batch_mean: -27.42530549812317
        seconds_per_batch_min: -27.75107192993164
        seconds_per_batch_std: 0.35761727312112424
    total:
      human_readable:
        batch_latency: 27.561 ms +/- 358.705 us [26.295 ms, 27.902 ms]
        batches_per_second: 36.29 +/- 0.49 [35.84, 38.03]
      metrics:
        batches_per_second_max: 38.030465689830265
        batches_per_second_mean: 36.29015600549818
        batches_per_second_min: 35.83956250534051
        batches_per_second_std: 0.4912998139319182
        seconds_per_batch_max: 0.02790212631225586
        seconds_per_batch_mean: 0.027560538053512572
        seconds_per_batch_min: 0.026294708251953125
        seconds_per_batch_std: 0.00035870490711773374
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 150.150 us +/- 6.458 us [144.482 us, 292.301 us]
        batches_per_second: 6.67 K +/- 224.11 [3.42 K, 6.92 K]
      metrics:
        batches_per_second_max: 6921.293729372937
        batches_per_second_mean: 6669.216045138981
        batches_per_second_min: 3421.1288743882546
        batches_per_second_std: 224.1059109304903
        seconds_per_batch_max: 0.0002923011779785156
        seconds_per_batch_mean: 0.00015015029907226561
        seconds_per_batch_min: 0.00014448165893554688
        seconds_per_batch_std: 6.458133193317052e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.511 us +/- 0.809 us [23.842 us, 34.571 us]
        batches_per_second: 39.23 K +/- 1.12 K [28.93 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 39233.84593486628
        batches_per_second_min: 28926.23448275862
        batches_per_second_std: 1116.0184067998316
        seconds_per_batch_max: 3.457069396972656e-05
        seconds_per_batch_mean: 2.551102638244629e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 8.089032931465554e-07
    on_device_inference:
      human_readable:
        batch_latency: -27463255.106 us +/- 541.005 ms [-27995391.846 us, -26331392.288
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035720164429614336
        batches_per_second_mean: -0.03642681044421573
        batches_per_second_min: -0.03797748288638084
        batches_per_second_std: 0.0007371354517324983
        seconds_per_batch_max: -26.331392288208008
        seconds_per_batch_mean: -27.46325510597229
        seconds_per_batch_min: -27.995391845703125
        seconds_per_batch_std: 0.5410049516000051
    total:
      human_readable:
        batch_latency: 27.651 ms +/- 542.719 us [26.513 ms, 28.180 ms]
        batches_per_second: 36.18 +/- 0.73 [35.49, 37.72]
      metrics:
        batches_per_second_max: 37.71754359144987
        batches_per_second_mean: 36.17977037628779
        batches_per_second_min: 35.48630652734887
        batches_per_second_std: 0.7294115301550249
        seconds_per_batch_max: 0.02817988395690918
        seconds_per_batch_mean: 0.027650696754455566
        seconds_per_batch_min: 0.026512861251831055
        seconds_per_batch_std: 0.0005427185629144685


