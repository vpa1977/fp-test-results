#####
fp-fp-py-id - Run 1
2024-02-25 22:48:13
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.02it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 280.32it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 282.29it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 283.36it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 283.05it/s]
STAGE:2024-02-25 22:48:06 4674:4674 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:48:06 4674:4674 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:48:06 4674:4674 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 212.57it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 212.99it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 213.21it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 213.24it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 213.28it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:04, 213.41it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:03, 213.43it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:00<00:03, 213.24it/s]Measuring inference for batch_size=1:  20%|█▉        | 198/1000 [00:00<00:03, 213.16it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:01<00:03, 213.15it/s]Measuring inference for batch_size=1:  24%|██▍       | 242/1000 [00:01<00:03, 213.18it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:01<00:03, 213.29it/s]Measuring inference for batch_size=1:  29%|██▊       | 286/1000 [00:01<00:03, 213.31it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:01<00:03, 213.33it/s]Measuring inference for batch_size=1:  33%|███▎      | 330/1000 [00:01<00:03, 213.28it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:01<00:03, 211.72it/s]Measuring inference for batch_size=1:  37%|███▋      | 374/1000 [00:01<00:02, 209.18it/s]Measuring inference for batch_size=1:  40%|███▉      | 395/1000 [00:01<00:02, 207.49it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:01<00:02, 206.50it/s]Measuring inference for batch_size=1:  44%|████▎     | 437/1000 [00:02<00:02, 205.71it/s]Measuring inference for batch_size=1:  46%|████▌     | 458/1000 [00:02<00:02, 205.06it/s]Measuring inference for batch_size=1:  48%|████▊     | 479/1000 [00:02<00:02, 204.68it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:02<00:02, 204.36it/s]Measuring inference for batch_size=1:  52%|█████▏    | 521/1000 [00:02<00:02, 204.08it/s]Measuring inference for batch_size=1:  54%|█████▍    | 542/1000 [00:02<00:02, 204.00it/s]Measuring inference for batch_size=1:  56%|█████▋    | 563/1000 [00:02<00:02, 203.93it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:02<00:02, 203.85it/s]Measuring inference for batch_size=1:  60%|██████    | 605/1000 [00:02<00:01, 203.88it/s]Measuring inference for batch_size=1:  63%|██████▎   | 626/1000 [00:02<00:01, 203.86it/s]Measuring inference for batch_size=1:  65%|██████▍   | 647/1000 [00:03<00:01, 203.84it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:03<00:01, 203.67it/s]Measuring inference for batch_size=1:  69%|██████▉   | 689/1000 [00:03<00:01, 203.68it/s]Measuring inference for batch_size=1:  71%|███████   | 710/1000 [00:03<00:01, 203.66it/s]Measuring inference for batch_size=1:  73%|███████▎  | 731/1000 [00:03<00:01, 203.73it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:03<00:01, 203.75it/s]Measuring inference for batch_size=1:  77%|███████▋  | 773/1000 [00:03<00:01, 203.76it/s]Measuring inference for batch_size=1:  79%|███████▉  | 794/1000 [00:03<00:01, 203.77it/s]Measuring inference for batch_size=1:  82%|████████▏ | 815/1000 [00:03<00:00, 203.70it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:04<00:00, 203.52it/s]Measuring inference for batch_size=1:  86%|████████▌ | 857/1000 [00:04<00:00, 203.39it/s]Measuring inference for batch_size=1:  88%|████████▊ | 878/1000 [00:04<00:00, 203.45it/s]Measuring inference for batch_size=1:  90%|████████▉ | 899/1000 [00:04<00:00, 203.43it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:04<00:00, 203.42it/s]Measuring inference for batch_size=1:  94%|█████████▍| 941/1000 [00:04<00:00, 203.45it/s]Measuring inference for batch_size=1:  96%|█████████▌| 962/1000 [00:04<00:00, 203.44it/s]Measuring inference for batch_size=1:  98%|█████████▊| 983/1000 [00:04<00:00, 203.39it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 206.78it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.96 GB
    total: 31.28 GB
    used: 939.82 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.119 us +/- 2.630 us [92.745 us, 138.521 us]
        batches_per_second: 10.52 K +/- 255.82 [7.22 K, 10.78 K]
      metrics:
        batches_per_second_max: 10782.272493573264
        batches_per_second_mean: 10520.130022061288
        batches_per_second_min: 7219.111876075732
        batches_per_second_std: 255.82078306792542
        seconds_per_batch_max: 0.0001385211944580078
        seconds_per_batch_mean: 9.511923789978027e-05
        seconds_per_batch_min: 9.274482727050781e-05
        seconds_per_batch_std: 2.6295236754706056e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.469 us +/- 0.759 us [22.411 us, 31.471 us]
        batches_per_second: 42.65 K +/- 1.20 K [31.78 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 42647.28547020023
        batches_per_second_min: 31775.030303030304
        batches_per_second_std: 1204.9124799172873
        seconds_per_batch_max: 3.147125244140625e-05
        seconds_per_batch_mean: 2.346944808959961e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 7.586865801883438e-07
    on_device_inference:
      human_readable:
        batch_latency: -4706108.089 us +/- 104.737 ms [-4839647.770 us, -4537663.937
          us]
        batches_per_second: -0.21 +/- 0.00 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.206626607459675
        batches_per_second_mean: -0.21259665746689124
        batches_per_second_min: -0.22037771284269692
        batches_per_second_std: 0.004801175973317444
        seconds_per_batch_max: -4.53766393661499
        seconds_per_batch_mean: -4.706108089447022
        seconds_per_batch_min: -4.8396477699279785
        seconds_per_batch_std: 0.10473666255906801
    total:
      human_readable:
        batch_latency: 4.832 ms +/- 106.527 us [4.660 ms, 4.970 ms]
        batches_per_second: 207.04 +/- 4.63 [201.22, 214.58]
      metrics:
        batches_per_second_max: 214.57533125287767
        batches_per_second_mean: 207.0435004802174
        batches_per_second_min: 201.22356553444635
        batches_per_second_std: 4.630710128707032
        seconds_per_batch_max: 0.004969596862792969
        seconds_per_batch_mean: 0.004832285404205322
        seconds_per_batch_min: 0.004660367965698242
        seconds_per_batch_std: 0.00010652691432291431


#####
fp-fp-py-id - Run 2
2024-02-25 22:48:26
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 276.40it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 277.14it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:00<00:00, 278.34it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 278.33it/s]
STAGE:2024-02-25 22:48:19 4720:4720 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:48:19 4720:4720 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:48:19 4720:4720 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 21/1000 [00:00<00:04, 209.67it/s]Measuring inference for batch_size=1:   4%|▍         | 43/1000 [00:00<00:04, 210.28it/s]Measuring inference for batch_size=1:   6%|▋         | 65/1000 [00:00<00:04, 210.33it/s]Measuring inference for batch_size=1:   9%|▊         | 87/1000 [00:00<00:04, 210.39it/s]Measuring inference for batch_size=1:  11%|█         | 109/1000 [00:00<00:04, 210.50it/s]Measuring inference for batch_size=1:  13%|█▎        | 131/1000 [00:00<00:04, 210.54it/s]Measuring inference for batch_size=1:  15%|█▌        | 153/1000 [00:00<00:04, 210.65it/s]Measuring inference for batch_size=1:  18%|█▊        | 175/1000 [00:00<00:03, 210.66it/s]Measuring inference for batch_size=1:  20%|█▉        | 197/1000 [00:00<00:03, 210.66it/s]Measuring inference for batch_size=1:  22%|██▏       | 219/1000 [00:01<00:03, 210.71it/s]Measuring inference for batch_size=1:  24%|██▍       | 241/1000 [00:01<00:03, 210.76it/s]Measuring inference for batch_size=1:  26%|██▋       | 263/1000 [00:01<00:03, 210.70it/s]Measuring inference for batch_size=1:  28%|██▊       | 285/1000 [00:01<00:03, 210.74it/s]Measuring inference for batch_size=1:  31%|███       | 307/1000 [00:01<00:03, 210.77it/s]Measuring inference for batch_size=1:  33%|███▎      | 329/1000 [00:01<00:03, 210.68it/s]Measuring inference for batch_size=1:  35%|███▌      | 351/1000 [00:01<00:03, 210.65it/s]Measuring inference for batch_size=1:  37%|███▋      | 373/1000 [00:01<00:02, 210.60it/s]Measuring inference for batch_size=1:  40%|███▉      | 395/1000 [00:01<00:02, 210.62it/s]Measuring inference for batch_size=1:  42%|████▏     | 417/1000 [00:01<00:02, 210.55it/s]Measuring inference for batch_size=1:  44%|████▍     | 439/1000 [00:02<00:02, 210.54it/s]Measuring inference for batch_size=1:  46%|████▌     | 461/1000 [00:02<00:02, 210.46it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 210.49it/s]Measuring inference for batch_size=1:  50%|█████     | 505/1000 [00:02<00:02, 210.47it/s]Measuring inference for batch_size=1:  53%|█████▎    | 527/1000 [00:02<00:02, 210.40it/s]Measuring inference for batch_size=1:  55%|█████▍    | 549/1000 [00:02<00:02, 210.39it/s]Measuring inference for batch_size=1:  57%|█████▋    | 571/1000 [00:02<00:02, 210.38it/s]Measuring inference for batch_size=1:  59%|█████▉    | 593/1000 [00:02<00:01, 210.40it/s]Measuring inference for batch_size=1:  62%|██████▏   | 615/1000 [00:02<00:01, 210.37it/s]Measuring inference for batch_size=1:  64%|██████▎   | 637/1000 [00:03<00:01, 210.35it/s]Measuring inference for batch_size=1:  66%|██████▌   | 659/1000 [00:03<00:01, 210.24it/s]Measuring inference for batch_size=1:  68%|██████▊   | 681/1000 [00:03<00:01, 210.22it/s]Measuring inference for batch_size=1:  70%|███████   | 703/1000 [00:03<00:01, 210.20it/s]Measuring inference for batch_size=1:  72%|███████▎  | 725/1000 [00:03<00:01, 210.18it/s]Measuring inference for batch_size=1:  75%|███████▍  | 747/1000 [00:03<00:01, 210.20it/s]Measuring inference for batch_size=1:  77%|███████▋  | 769/1000 [00:03<00:01, 210.20it/s]Measuring inference for batch_size=1:  79%|███████▉  | 791/1000 [00:03<00:00, 210.20it/s]Measuring inference for batch_size=1:  81%|████████▏ | 813/1000 [00:03<00:00, 210.23it/s]Measuring inference for batch_size=1:  84%|████████▎ | 835/1000 [00:03<00:00, 210.23it/s]Measuring inference for batch_size=1:  86%|████████▌ | 857/1000 [00:04<00:00, 210.27it/s]Measuring inference for batch_size=1:  88%|████████▊ | 879/1000 [00:04<00:00, 210.34it/s]Measuring inference for batch_size=1:  90%|█████████ | 901/1000 [00:04<00:00, 209.83it/s]Measuring inference for batch_size=1:  92%|█████████▏| 922/1000 [00:04<00:00, 207.45it/s]Measuring inference for batch_size=1:  94%|█████████▍| 943/1000 [00:04<00:00, 205.74it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:04<00:00, 204.53it/s]Measuring inference for batch_size=1:  98%|█████████▊| 985/1000 [00:04<00:00, 203.73it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 209.51it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.97 GB
    total: 31.28 GB
    used: 932.23 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.618 us +/- 2.618 us [92.983 us, 141.144 us]
        batches_per_second: 10.58 K +/- 250.29 [7.08 K, 10.75 K]
      metrics:
        batches_per_second_max: 10754.625641025641
        batches_per_second_mean: 10575.658181921375
        batches_per_second_min: 7084.972972972973
        batches_per_second_std: 250.29457828020358
        seconds_per_batch_max: 0.000141143798828125
        seconds_per_batch_mean: 9.46180820465088e-05
        seconds_per_batch_min: 9.298324584960938e-05
        seconds_per_batch_std: 2.617881065338579e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.308 us +/- 0.678 us [22.411 us, 30.041 us]
        batches_per_second: 42.94 K +/- 1.08 K [33.29 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 42935.29586422186
        batches_per_second_min: 33288.12698412698
        batches_per_second_std: 1076.1646343400141
        seconds_per_batch_max: 3.0040740966796875e-05
        seconds_per_batch_mean: 2.330780029296875e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 6.784003659083962e-07
    on_device_inference:
      human_readable:
        batch_latency: -4644605.338 us +/- 62.327 ms [-4874623.775 us, -4595359.802
          us]
        batches_per_second: -0.22 +/- 0.00 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.20514403696746505
        batches_per_second_mean: -0.21534108190787157
        batches_per_second_min: -0.2176108167876704
        batches_per_second_std: 0.002797230264873276
        seconds_per_batch_max: -4.595359802246094
        seconds_per_batch_mean: -4.644605338096619
        seconds_per_batch_min: -4.874623775482178
        seconds_per_batch_std: 0.06232715548665064
    total:
      human_readable:
        batch_latency: 4.770 ms +/- 63.734 us [4.720 ms, 5.033 ms]
        batches_per_second: 209.70 +/- 2.71 [198.67, 211.88]
      metrics:
        batches_per_second_max: 211.87633865427358
        batches_per_second_mean: 209.69631860392283
        batches_per_second_min: 198.66919287608943
        batches_per_second_std: 2.7128088393213474
        seconds_per_batch_max: 0.0050334930419921875
        seconds_per_batch_mean: 0.004769625425338745
        seconds_per_batch_min: 0.004719734191894531
        seconds_per_batch_std: 6.373403294569848e-05


#####
fp-fp-py-id - Run 3
2024-02-25 22:48:38
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 288.99it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 289.41it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 289.00it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 287.92it/s]
STAGE:2024-02-25 22:48:31 4766:4766 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:48:31 4766:4766 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:48:31 4766:4766 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 23/1000 [00:00<00:04, 220.37it/s]Measuring inference for batch_size=1:   5%|▍         | 46/1000 [00:00<00:04, 220.90it/s]Measuring inference for batch_size=1:   7%|▋         | 69/1000 [00:00<00:04, 221.14it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:00<00:04, 221.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 115/1000 [00:00<00:03, 221.35it/s]Measuring inference for batch_size=1:  14%|█▍        | 138/1000 [00:00<00:03, 221.40it/s]Measuring inference for batch_size=1:  16%|█▌        | 161/1000 [00:00<00:03, 221.26it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:00<00:03, 221.21it/s]Measuring inference for batch_size=1:  21%|██        | 207/1000 [00:00<00:03, 221.25it/s]Measuring inference for batch_size=1:  23%|██▎       | 230/1000 [00:01<00:03, 221.35it/s]Measuring inference for batch_size=1:  25%|██▌       | 253/1000 [00:01<00:03, 221.35it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:01<00:03, 221.22it/s]Measuring inference for batch_size=1:  30%|██▉       | 299/1000 [00:01<00:03, 221.25it/s]Measuring inference for batch_size=1:  32%|███▏      | 322/1000 [00:01<00:03, 221.19it/s]Measuring inference for batch_size=1:  34%|███▍      | 345/1000 [00:01<00:02, 221.19it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:01<00:02, 221.15it/s]Measuring inference for batch_size=1:  39%|███▉      | 391/1000 [00:01<00:02, 221.17it/s]Measuring inference for batch_size=1:  41%|████▏     | 414/1000 [00:01<00:02, 221.14it/s]Measuring inference for batch_size=1:  44%|████▎     | 437/1000 [00:01<00:02, 221.27it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:02<00:02, 221.34it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 221.27it/s]Measuring inference for batch_size=1:  51%|█████     | 506/1000 [00:02<00:02, 221.23it/s]Measuring inference for batch_size=1:  53%|█████▎    | 529/1000 [00:02<00:02, 221.17it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:02<00:02, 220.98it/s]Measuring inference for batch_size=1:  57%|█████▊    | 575/1000 [00:02<00:01, 220.87it/s]Measuring inference for batch_size=1:  60%|█████▉    | 598/1000 [00:02<00:01, 220.71it/s]Measuring inference for batch_size=1:  62%|██████▏   | 621/1000 [00:02<00:01, 220.70it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:02<00:01, 220.77it/s]Measuring inference for batch_size=1:  67%|██████▋   | 667/1000 [00:03<00:01, 220.95it/s]Measuring inference for batch_size=1:  69%|██████▉   | 690/1000 [00:03<00:01, 220.96it/s]Measuring inference for batch_size=1:  71%|███████▏  | 713/1000 [00:03<00:01, 220.94it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:03<00:01, 220.96it/s]Measuring inference for batch_size=1:  76%|███████▌  | 759/1000 [00:03<00:01, 220.94it/s]Measuring inference for batch_size=1:  78%|███████▊  | 782/1000 [00:03<00:00, 220.91it/s]Measuring inference for batch_size=1:  80%|████████  | 805/1000 [00:03<00:00, 220.93it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:03<00:00, 221.03it/s]Measuring inference for batch_size=1:  85%|████████▌ | 851/1000 [00:03<00:00, 221.01it/s]Measuring inference for batch_size=1:  87%|████████▋ | 874/1000 [00:03<00:00, 221.03it/s]Measuring inference for batch_size=1:  90%|████████▉ | 897/1000 [00:04<00:00, 221.08it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:04<00:00, 221.10it/s]Measuring inference for batch_size=1:  94%|█████████▍| 943/1000 [00:04<00:00, 221.05it/s]Measuring inference for batch_size=1:  97%|█████████▋| 966/1000 [00:04<00:00, 221.09it/s]Measuring inference for batch_size=1:  99%|█████████▉| 989/1000 [00:04<00:00, 221.12it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 221.09it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.97 GB
    total: 31.28 GB
    used: 933.63 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 90.845 us +/- 2.384 us [89.169 us, 134.468 us]
        batches_per_second: 11.01 K +/- 247.36 [7.44 K, 11.21 K]
      metrics:
        batches_per_second_max: 11214.716577540106
        batches_per_second_mean: 11014.199886835262
        batches_per_second_min: 7436.709219858156
        batches_per_second_std: 247.36031671427438
        seconds_per_batch_max: 0.00013446807861328125
        seconds_per_batch_mean: 9.084486961364746e-05
        seconds_per_batch_min: 8.916854858398438e-05
        seconds_per_batch_std: 2.3835662871406317e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 22.362 us +/- 0.663 us [21.696 us, 29.802 us]
        batches_per_second: 44.75 K +/- 1.11 K [33.55 K, 46.09 K]
      metrics:
        batches_per_second_max: 46091.25274725275
        batches_per_second_mean: 44751.429472577256
        batches_per_second_min: 33554.432
        batches_per_second_std: 1107.8343268988451
        seconds_per_batch_max: 2.9802322387695312e-05
        seconds_per_batch_mean: 2.2361993789672853e-05
        seconds_per_batch_min: 2.1696090698242188e-05
        seconds_per_batch_std: 6.630502128992473e-07
    on_device_inference:
      human_readable:
        batch_latency: -4401020.479 us +/- 17.411 ms [-4623007.774 us, -4366176.128
          us]
        batches_per_second: -0.23 +/- 0.00 [-0.23, -0.22]
      metrics:
        batches_per_second_max: -0.21630939180930672
        batches_per_second_mean: -0.22722354368031805
        batches_per_second_min: -0.2290333625110372
        batches_per_second_std: 0.0008886197073195834
        seconds_per_batch_max: -4.366176128387451
        seconds_per_batch_mean: -4.4010204787254334
        seconds_per_batch_min: -4.623007774353027
        seconds_per_batch_std: 0.01741052818318075
    total:
      human_readable:
        batch_latency: 4.520 ms +/- 18.593 us [4.484 ms, 4.798 ms]
        batches_per_second: 221.25 +/- 0.90 [208.42, 223.01]
      metrics:
        batches_per_second_max: 223.00638026371757
        batches_per_second_mean: 221.24894699976028
        batches_per_second_min: 208.4229775392566
        batches_per_second_std: 0.895515193521077
        seconds_per_batch_max: 0.004797935485839844
        seconds_per_batch_mean: 0.0045198707580566405
        seconds_per_batch_min: 0.0044841766357421875
        seconds_per_batch_std: 1.859305581809095e-05


#####
fp-fp-py-id - Run 4
2024-02-25 22:48:50
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.20it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 285.20it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 278.86it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 282.97it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 283.48it/s]
STAGE:2024-02-25 22:48:43 4812:4812 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:48:43 4812:4812 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:48:43 4812:4812 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 219.28it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 219.69it/s]Measuring inference for batch_size=1:   7%|▋         | 67/1000 [00:00<00:04, 219.93it/s]Measuring inference for batch_size=1:   9%|▉         | 89/1000 [00:00<00:04, 219.85it/s]Measuring inference for batch_size=1:  11%|█         | 111/1000 [00:00<00:04, 219.88it/s]Measuring inference for batch_size=1:  13%|█▎        | 133/1000 [00:00<00:03, 219.91it/s]Measuring inference for batch_size=1:  16%|█▌        | 155/1000 [00:00<00:03, 219.91it/s]Measuring inference for batch_size=1:  18%|█▊        | 177/1000 [00:00<00:03, 219.92it/s]Measuring inference for batch_size=1:  20%|█▉        | 199/1000 [00:00<00:03, 219.86it/s]Measuring inference for batch_size=1:  22%|██▏       | 221/1000 [00:01<00:03, 219.81it/s]Measuring inference for batch_size=1:  24%|██▍       | 243/1000 [00:01<00:03, 219.82it/s]Measuring inference for batch_size=1:  26%|██▋       | 265/1000 [00:01<00:03, 219.79it/s]Measuring inference for batch_size=1:  29%|██▊       | 287/1000 [00:01<00:03, 219.80it/s]Measuring inference for batch_size=1:  31%|███       | 309/1000 [00:01<00:03, 219.82it/s]Measuring inference for batch_size=1:  33%|███▎      | 331/1000 [00:01<00:03, 219.77it/s]Measuring inference for batch_size=1:  35%|███▌      | 353/1000 [00:01<00:02, 219.71it/s]Measuring inference for batch_size=1:  38%|███▊      | 375/1000 [00:01<00:02, 219.62it/s]Measuring inference for batch_size=1:  40%|███▉      | 397/1000 [00:01<00:02, 219.61it/s]Measuring inference for batch_size=1:  42%|████▏     | 419/1000 [00:01<00:02, 219.62it/s]Measuring inference for batch_size=1:  44%|████▍     | 441/1000 [00:02<00:02, 219.58it/s]Measuring inference for batch_size=1:  46%|████▋     | 463/1000 [00:02<00:02, 219.55it/s]Measuring inference for batch_size=1:  48%|████▊     | 485/1000 [00:02<00:02, 219.50it/s]Measuring inference for batch_size=1:  51%|█████     | 507/1000 [00:02<00:02, 219.49it/s]Measuring inference for batch_size=1:  53%|█████▎    | 529/1000 [00:02<00:02, 219.48it/s]Measuring inference for batch_size=1:  55%|█████▌    | 551/1000 [00:02<00:02, 219.26it/s]Measuring inference for batch_size=1:  57%|█████▋    | 573/1000 [00:02<00:01, 219.35it/s]Measuring inference for batch_size=1:  60%|█████▉    | 595/1000 [00:02<00:01, 219.51it/s]Measuring inference for batch_size=1:  62%|██████▏   | 617/1000 [00:02<00:01, 219.64it/s]Measuring inference for batch_size=1:  64%|██████▍   | 639/1000 [00:02<00:01, 219.74it/s]Measuring inference for batch_size=1:  66%|██████▌   | 661/1000 [00:03<00:01, 219.74it/s]Measuring inference for batch_size=1:  68%|██████▊   | 683/1000 [00:03<00:01, 219.69it/s]Measuring inference for batch_size=1:  70%|███████   | 705/1000 [00:03<00:01, 219.74it/s]Measuring inference for batch_size=1:  73%|███████▎  | 727/1000 [00:03<00:01, 219.66it/s]Measuring inference for batch_size=1:  75%|███████▍  | 749/1000 [00:03<00:01, 219.69it/s]Measuring inference for batch_size=1:  77%|███████▋  | 771/1000 [00:03<00:01, 219.64it/s]Measuring inference for batch_size=1:  79%|███████▉  | 793/1000 [00:03<00:00, 219.66it/s]Measuring inference for batch_size=1:  82%|████████▏ | 815/1000 [00:03<00:00, 219.58it/s]Measuring inference for batch_size=1:  84%|████████▎ | 837/1000 [00:03<00:00, 219.45it/s]Measuring inference for batch_size=1:  86%|████████▌ | 859/1000 [00:03<00:00, 219.43it/s]Measuring inference for batch_size=1:  88%|████████▊ | 881/1000 [00:04<00:00, 219.51it/s]Measuring inference for batch_size=1:  90%|█████████ | 903/1000 [00:04<00:00, 219.56it/s]Measuring inference for batch_size=1:  92%|█████████▎| 925/1000 [00:04<00:00, 219.59it/s]Measuring inference for batch_size=1:  95%|█████████▍| 947/1000 [00:04<00:00, 219.54it/s]Measuring inference for batch_size=1:  97%|█████████▋| 969/1000 [00:04<00:00, 219.58it/s]Measuring inference for batch_size=1:  99%|█████████▉| 991/1000 [00:04<00:00, 217.98it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 219.53it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 925.66 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 91.405 us +/- 2.701 us [89.884 us, 142.574 us]
        batches_per_second: 10.95 K +/- 269.86 [7.01 K, 11.13 K]
      metrics:
        batches_per_second_max: 11125.474801061007
        batches_per_second_mean: 10948.195380633839
        batches_per_second_min: 7013.886287625418
        batches_per_second_std: 269.8566938700479
        seconds_per_batch_max: 0.00014257431030273438
        seconds_per_batch_mean: 9.140491485595703e-05
        seconds_per_batch_min: 8.988380432128906e-05
        seconds_per_batch_std: 2.7010162926024715e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 22.417 us +/- 0.470 us [21.696 us, 27.657 us]
        batches_per_second: 44.63 K +/- 838.14 [36.16 K, 46.09 K]
      metrics:
        batches_per_second_max: 46091.25274725275
        batches_per_second_mean: 44627.316348374945
        batches_per_second_min: 36157.793103448275
        batches_per_second_std: 838.1398266000494
        seconds_per_batch_max: 2.765655517578125e-05
        seconds_per_batch_mean: 2.241659164428711e-05
        seconds_per_batch_min: 2.1696090698242188e-05
        seconds_per_batch_std: 4.69842874417235e-07
    on_device_inference:
      human_readable:
        batch_latency: -4432280.672 us +/- 28.124 ms [-4681151.867 us, -4396224.022
          us]
        batches_per_second: -0.23 +/- 0.00 [-0.23, -0.21]
      metrics:
        batches_per_second_max: -0.2136226357166846
        batches_per_second_mean: -0.22562627979183347
        batches_per_second_min: -0.2274679349859809
        batches_per_second_std: 0.001386980916430098
        seconds_per_batch_max: -4.396224021911621
        seconds_per_batch_mean: -4.4322806720733645
        seconds_per_batch_min: -4.681151866912842
        seconds_per_batch_std: 0.0281238445905933
    total:
      human_readable:
        batch_latency: 4.552 ms +/- 29.299 us [4.515 ms, 4.846 ms]
        batches_per_second: 219.70 +/- 1.37 [206.35, 221.48]
      metrics:
        batches_per_second_max: 221.47555180061252
        batches_per_second_mean: 219.69967003646317
        batches_per_second_min: 206.35166781462166
        batches_per_second_std: 1.36780021681877
        seconds_per_batch_max: 0.004846096038818359
        seconds_per_batch_mean: 0.004551850557327271
        seconds_per_batch_min: 0.004515171051025391
        seconds_per_batch_std: 2.9298957377822615e-05


#####
fp-fp-py-id - Run 5
2024-02-25 22:49:03
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.04it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.03it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 277.63it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 277.95it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:00<00:00, 279.15it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 279.11it/s]
STAGE:2024-02-25 22:48:55 4858:4858 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:48:55 4858:4858 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:48:55 4858:4858 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 21/1000 [00:00<00:04, 209.89it/s]Measuring inference for batch_size=1:   4%|▍         | 43/1000 [00:00<00:04, 210.23it/s]Measuring inference for batch_size=1:   6%|▋         | 65/1000 [00:00<00:04, 210.41it/s]Measuring inference for batch_size=1:   9%|▊         | 87/1000 [00:00<00:04, 210.59it/s]Measuring inference for batch_size=1:  11%|█         | 109/1000 [00:00<00:04, 210.58it/s]Measuring inference for batch_size=1:  13%|█▎        | 131/1000 [00:00<00:04, 210.68it/s]Measuring inference for batch_size=1:  15%|█▌        | 153/1000 [00:00<00:04, 210.76it/s]Measuring inference for batch_size=1:  18%|█▊        | 175/1000 [00:00<00:03, 210.64it/s]Measuring inference for batch_size=1:  20%|█▉        | 197/1000 [00:00<00:03, 210.71it/s]Measuring inference for batch_size=1:  22%|██▏       | 219/1000 [00:01<00:03, 210.79it/s]Measuring inference for batch_size=1:  24%|██▍       | 241/1000 [00:01<00:03, 210.74it/s]Measuring inference for batch_size=1:  26%|██▋       | 263/1000 [00:01<00:03, 210.78it/s]Measuring inference for batch_size=1:  28%|██▊       | 285/1000 [00:01<00:03, 210.60it/s]Measuring inference for batch_size=1:  31%|███       | 307/1000 [00:01<00:03, 210.51it/s]Measuring inference for batch_size=1:  33%|███▎      | 329/1000 [00:01<00:03, 210.45it/s]Measuring inference for batch_size=1:  35%|███▌      | 351/1000 [00:01<00:03, 210.46it/s]Measuring inference for batch_size=1:  37%|███▋      | 373/1000 [00:01<00:02, 210.31it/s]Measuring inference for batch_size=1:  40%|███▉      | 395/1000 [00:01<00:02, 210.37it/s]Measuring inference for batch_size=1:  42%|████▏     | 417/1000 [00:01<00:02, 210.38it/s]Measuring inference for batch_size=1:  44%|████▍     | 439/1000 [00:02<00:02, 210.50it/s]Measuring inference for batch_size=1:  46%|████▌     | 461/1000 [00:02<00:02, 210.52it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 210.46it/s]Measuring inference for batch_size=1:  50%|█████     | 505/1000 [00:02<00:02, 210.46it/s]Measuring inference for batch_size=1:  53%|█████▎    | 527/1000 [00:02<00:02, 210.48it/s]Measuring inference for batch_size=1:  55%|█████▍    | 549/1000 [00:02<00:02, 210.57it/s]Measuring inference for batch_size=1:  57%|█████▋    | 571/1000 [00:02<00:02, 210.60it/s]Measuring inference for batch_size=1:  59%|█████▉    | 593/1000 [00:02<00:01, 210.65it/s]Measuring inference for batch_size=1:  62%|██████▏   | 615/1000 [00:02<00:01, 210.10it/s]Measuring inference for batch_size=1:  64%|██████▎   | 637/1000 [00:03<00:01, 207.73it/s]Measuring inference for batch_size=1:  66%|██████▌   | 658/1000 [00:03<00:01, 205.97it/s]Measuring inference for batch_size=1:  68%|██████▊   | 679/1000 [00:03<00:01, 204.70it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:03<00:01, 203.81it/s]Measuring inference for batch_size=1:  72%|███████▏  | 721/1000 [00:03<00:01, 203.19it/s]Measuring inference for batch_size=1:  74%|███████▍  | 742/1000 [00:03<00:01, 202.73it/s]Measuring inference for batch_size=1:  76%|███████▋  | 763/1000 [00:03<00:01, 202.58it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:03<00:01, 202.41it/s]Measuring inference for batch_size=1:  80%|████████  | 805/1000 [00:03<00:00, 202.28it/s]Measuring inference for batch_size=1:  83%|████████▎ | 826/1000 [00:03<00:00, 202.24it/s]Measuring inference for batch_size=1:  85%|████████▍ | 847/1000 [00:04<00:00, 202.21it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:04<00:00, 202.14it/s]Measuring inference for batch_size=1:  89%|████████▉ | 889/1000 [00:04<00:00, 201.94it/s]Measuring inference for batch_size=1:  91%|█████████ | 910/1000 [00:04<00:00, 201.78it/s]Measuring inference for batch_size=1:  93%|█████████▎| 931/1000 [00:04<00:00, 201.80it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:04<00:00, 201.87it/s]Measuring inference for batch_size=1:  97%|█████████▋| 973/1000 [00:04<00:00, 201.87it/s]Measuring inference for batch_size=1:  99%|█████████▉| 994/1000 [00:04<00:00, 201.85it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 207.08it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 926.01 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.399 us +/- 3.323 us [92.983 us, 142.574 us]
        batches_per_second: 10.49 K +/- 315.42 [7.01 K, 10.75 K]
      metrics:
        batches_per_second_max: 10754.625641025641
        batches_per_second_mean: 10493.222988923224
        batches_per_second_min: 7013.886287625418
        batches_per_second_std: 315.420675993545
        seconds_per_batch_max: 0.00014257431030273438
        seconds_per_batch_mean: 9.53986644744873e-05
        seconds_per_batch_min: 9.298324584960938e-05
        seconds_per_batch_std: 3.3234715194700573e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.407 us +/- 0.637 us [22.411 us, 30.994 us]
        batches_per_second: 42.75 K +/- 1.04 K [32.26 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 42750.09525526011
        batches_per_second_min: 32263.876923076925
        batches_per_second_std: 1044.2932518527418
        seconds_per_batch_max: 3.0994415283203125e-05
        seconds_per_batch_mean: 2.3407220840454103e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 6.37147546506369e-07
    on_device_inference:
      human_readable:
        batch_latency: -4699133.862 us +/- 99.322 ms [-4956352.234 us, -4581920.147
          us]
        batches_per_second: -0.21 +/- 0.00 [-0.22, -0.20]
      metrics:
        batches_per_second_max: -0.20176128588339062
        batches_per_second_mean: -0.21289940230680104
        batches_per_second_min: -0.21824911127431487
        batches_per_second_std: 0.0044582592858809205
        seconds_per_batch_max: -4.581920146942139
        seconds_per_batch_mean: -4.699133861541748
        seconds_per_batch_min: -4.956352233886719
        seconds_per_batch_std: 0.09932207325693014
    total:
      human_readable:
        batch_latency: 4.825 ms +/- 101.345 us [4.704 ms, 5.084 ms]
        batches_per_second: 207.33 +/- 4.31 [196.69, 212.56]
      metrics:
        batches_per_second_max: 212.56355159132374
        batches_per_second_mean: 207.329902882987
        batches_per_second_min: 196.6940536484712
        batches_per_second_std: 4.314399541806598
        seconds_per_batch_max: 0.005084037780761719
        seconds_per_batch_mean: 0.004825339794158935
        seconds_per_batch_min: 0.004704475402832031
        seconds_per_batch_std: 0.00010134536161692435


#####
fp-fp-py-id - Run 6
2024-02-25 22:49:15
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.01it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.00it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 274.21it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 267.74it/s]Warming up with batch_size=1:  83%|████████▎ | 83/100 [00:00<00:00, 265.61it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 266.19it/s]
STAGE:2024-02-25 22:49:08 4904:4904 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:49:08 4904:4904 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:49:08 4904:4904 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 210.03it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 210.39it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 210.53it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 210.66it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 210.61it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:04, 210.58it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:04, 210.02it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:00<00:03, 206.78it/s]Measuring inference for batch_size=1:  20%|█▉        | 197/1000 [00:00<00:03, 204.71it/s]Measuring inference for batch_size=1:  22%|██▏       | 218/1000 [00:01<00:03, 203.06it/s]Measuring inference for batch_size=1:  24%|██▍       | 239/1000 [00:01<00:03, 201.92it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:01<00:03, 201.39it/s]Measuring inference for batch_size=1:  28%|██▊       | 281/1000 [00:01<00:03, 200.87it/s]Measuring inference for batch_size=1:  30%|███       | 302/1000 [00:01<00:03, 200.57it/s]Measuring inference for batch_size=1:  32%|███▏      | 323/1000 [00:01<00:03, 200.33it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:01<00:03, 200.25it/s]Measuring inference for batch_size=1:  36%|███▋      | 365/1000 [00:01<00:03, 200.15it/s]Measuring inference for batch_size=1:  39%|███▊      | 386/1000 [00:01<00:03, 200.04it/s]Measuring inference for batch_size=1:  41%|████      | 407/1000 [00:01<00:02, 200.03it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:02<00:02, 199.96it/s]Measuring inference for batch_size=1:  45%|████▍     | 449/1000 [00:02<00:02, 199.97it/s]Measuring inference for batch_size=1:  47%|████▋     | 469/1000 [00:02<00:02, 199.93it/s]Measuring inference for batch_size=1:  49%|████▉     | 489/1000 [00:02<00:02, 199.92it/s]Measuring inference for batch_size=1:  51%|█████     | 509/1000 [00:02<00:02, 199.88it/s]Measuring inference for batch_size=1:  53%|█████▎    | 529/1000 [00:02<00:02, 199.88it/s]Measuring inference for batch_size=1:  55%|█████▌    | 550/1000 [00:02<00:02, 199.92it/s]Measuring inference for batch_size=1:  57%|█████▋    | 570/1000 [00:02<00:02, 199.83it/s]Measuring inference for batch_size=1:  59%|█████▉    | 590/1000 [00:02<00:02, 199.71it/s]Measuring inference for batch_size=1:  61%|██████    | 610/1000 [00:03<00:01, 199.57it/s]Measuring inference for batch_size=1:  63%|██████▎   | 630/1000 [00:03<00:01, 199.52it/s]Measuring inference for batch_size=1:  65%|██████▌   | 650/1000 [00:03<00:01, 199.51it/s]Measuring inference for batch_size=1:  67%|██████▋   | 670/1000 [00:03<00:01, 199.47it/s]Measuring inference for batch_size=1:  69%|██████▉   | 690/1000 [00:03<00:01, 199.43it/s]Measuring inference for batch_size=1:  71%|███████   | 710/1000 [00:03<00:01, 199.45it/s]Measuring inference for batch_size=1:  73%|███████▎  | 730/1000 [00:03<00:01, 199.47it/s]Measuring inference for batch_size=1:  75%|███████▌  | 750/1000 [00:03<00:01, 199.48it/s]Measuring inference for batch_size=1:  77%|███████▋  | 770/1000 [00:03<00:01, 199.46it/s]Measuring inference for batch_size=1:  79%|███████▉  | 790/1000 [00:03<00:01, 199.48it/s]Measuring inference for batch_size=1:  81%|████████  | 810/1000 [00:04<00:00, 199.54it/s]Measuring inference for batch_size=1:  83%|████████▎ | 830/1000 [00:04<00:00, 199.45it/s]Measuring inference for batch_size=1:  85%|████████▌ | 850/1000 [00:04<00:00, 199.43it/s]Measuring inference for batch_size=1:  87%|████████▋ | 870/1000 [00:04<00:00, 199.37it/s]Measuring inference for batch_size=1:  89%|████████▉ | 890/1000 [00:04<00:00, 199.43it/s]Measuring inference for batch_size=1:  91%|█████████ | 910/1000 [00:04<00:00, 199.36it/s]Measuring inference for batch_size=1:  93%|█████████▎| 930/1000 [00:04<00:00, 199.29it/s]Measuring inference for batch_size=1:  95%|█████████▌| 950/1000 [00:04<00:00, 199.27it/s]Measuring inference for batch_size=1:  97%|█████████▋| 970/1000 [00:04<00:00, 199.30it/s]Measuring inference for batch_size=1:  99%|█████████▉| 990/1000 [00:04<00:00, 199.31it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 201.19it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.97 GB
    total: 31.28 GB
    used: 929.43 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 93.944 us +/- 2.861 us [91.076 us, 138.521 us]
        batches_per_second: 10.65 K +/- 281.48 [7.22 K, 10.98 K]
      metrics:
        batches_per_second_max: 10979.853403141362
        batches_per_second_mean: 10653.18717288437
        batches_per_second_min: 7219.111876075732
        batches_per_second_std: 281.48056231440813
        seconds_per_batch_max: 0.0001385211944580078
        seconds_per_batch_mean: 9.394359588623047e-05
        seconds_per_batch_min: 9.107589721679688e-05
        seconds_per_batch_std: 2.861035029067923e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.109 us +/- 0.682 us [22.650 us, 31.233 us]
        batches_per_second: 41.51 K +/- 1.06 K [32.02 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 41508.186929871874
        batches_per_second_min: 32017.58778625954
        batches_per_second_std: 1057.8879186612642
        seconds_per_batch_max: 3.123283386230469e-05
        seconds_per_batch_mean: 2.410888671875e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 6.817103895632089e-07
    on_device_inference:
      human_readable:
        batch_latency: -4840362.081 us +/- 93.270 ms [-4956352.234 us, -4598495.960
          us]
        batches_per_second: -0.21 +/- 0.00 [-0.22, -0.20]
      metrics:
        batches_per_second_max: -0.20176128588339062
        batches_per_second_mean: -0.2066756884475997
        batches_per_second_min: -0.21746240697986105
        batches_per_second_std: 0.004129766745882258
        seconds_per_batch_max: -4.598495960235596
        seconds_per_batch_mean: -4.840362080574035
        seconds_per_batch_min: -4.956352233886719
        seconds_per_batch_std: 0.09327039176042536
    total:
      human_readable:
        batch_latency: 4.967 ms +/- 94.833 us [4.720 ms, 5.091 ms]
        batches_per_second: 201.42 +/- 3.99 [196.44, 211.87]
      metrics:
        batches_per_second_max: 211.86563620750618
        batches_per_second_mean: 201.42223932046872
        batches_per_second_min: 196.43611839640315
        batches_per_second_std: 3.9863458737974113
        seconds_per_batch_max: 0.0050907135009765625
        seconds_per_batch_mean: 0.0049665718078613285
        seconds_per_batch_min: 0.004719972610473633
        seconds_per_batch_std: 9.483262328486002e-05


#####
fp-fp-py-id - Run 7
2024-02-25 22:49:28
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 276.76it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 277.48it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:00<00:00, 278.62it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 278.65it/s]
STAGE:2024-02-25 22:49:21 4950:4950 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:49:21 4950:4950 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:49:21 4950:4950 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 21/1000 [00:00<00:04, 209.57it/s]Measuring inference for batch_size=1:   4%|▍         | 43/1000 [00:00<00:04, 209.93it/s]Measuring inference for batch_size=1:   6%|▋         | 65/1000 [00:00<00:04, 210.23it/s]Measuring inference for batch_size=1:   9%|▊         | 87/1000 [00:00<00:04, 210.35it/s]Measuring inference for batch_size=1:  11%|█         | 109/1000 [00:00<00:04, 210.42it/s]Measuring inference for batch_size=1:  13%|█▎        | 131/1000 [00:00<00:04, 210.34it/s]Measuring inference for batch_size=1:  15%|█▌        | 153/1000 [00:00<00:04, 210.33it/s]Measuring inference for batch_size=1:  18%|█▊        | 175/1000 [00:00<00:03, 210.33it/s]Measuring inference for batch_size=1:  20%|█▉        | 197/1000 [00:00<00:03, 210.39it/s]Measuring inference for batch_size=1:  22%|██▏       | 219/1000 [00:01<00:03, 210.34it/s]Measuring inference for batch_size=1:  24%|██▍       | 241/1000 [00:01<00:03, 210.24it/s]Measuring inference for batch_size=1:  26%|██▋       | 263/1000 [00:01<00:03, 210.30it/s]Measuring inference for batch_size=1:  28%|██▊       | 285/1000 [00:01<00:03, 210.27it/s]Measuring inference for batch_size=1:  31%|███       | 307/1000 [00:01<00:03, 210.32it/s]Measuring inference for batch_size=1:  33%|███▎      | 329/1000 [00:01<00:03, 210.28it/s]Measuring inference for batch_size=1:  35%|███▌      | 351/1000 [00:01<00:03, 210.30it/s]Measuring inference for batch_size=1:  37%|███▋      | 373/1000 [00:01<00:02, 210.30it/s]Measuring inference for batch_size=1:  40%|███▉      | 395/1000 [00:01<00:02, 210.30it/s]Measuring inference for batch_size=1:  42%|████▏     | 417/1000 [00:01<00:02, 210.31it/s]Measuring inference for batch_size=1:  44%|████▍     | 439/1000 [00:02<00:02, 210.39it/s]Measuring inference for batch_size=1:  46%|████▌     | 461/1000 [00:02<00:02, 210.37it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 210.31it/s]Measuring inference for batch_size=1:  50%|█████     | 505/1000 [00:02<00:02, 210.39it/s]Measuring inference for batch_size=1:  53%|█████▎    | 527/1000 [00:02<00:02, 210.38it/s]Measuring inference for batch_size=1:  55%|█████▍    | 549/1000 [00:02<00:02, 210.47it/s]Measuring inference for batch_size=1:  57%|█████▋    | 571/1000 [00:02<00:02, 210.42it/s]Measuring inference for batch_size=1:  59%|█████▉    | 593/1000 [00:02<00:01, 210.47it/s]Measuring inference for batch_size=1:  62%|██████▏   | 615/1000 [00:02<00:01, 210.47it/s]Measuring inference for batch_size=1:  64%|██████▎   | 637/1000 [00:03<00:01, 210.50it/s]Measuring inference for batch_size=1:  66%|██████▌   | 659/1000 [00:03<00:01, 210.53it/s]Measuring inference for batch_size=1:  68%|██████▊   | 681/1000 [00:03<00:01, 210.53it/s]Measuring inference for batch_size=1:  70%|███████   | 703/1000 [00:03<00:01, 210.58it/s]Measuring inference for batch_size=1:  72%|███████▎  | 725/1000 [00:03<00:01, 210.58it/s]Measuring inference for batch_size=1:  75%|███████▍  | 747/1000 [00:03<00:01, 210.64it/s]Measuring inference for batch_size=1:  77%|███████▋  | 769/1000 [00:03<00:01, 210.60it/s]Measuring inference for batch_size=1:  79%|███████▉  | 791/1000 [00:03<00:00, 210.61it/s]Measuring inference for batch_size=1:  81%|████████▏ | 813/1000 [00:03<00:00, 210.45it/s]Measuring inference for batch_size=1:  84%|████████▎ | 835/1000 [00:03<00:00, 210.45it/s]Measuring inference for batch_size=1:  86%|████████▌ | 857/1000 [00:04<00:00, 210.45it/s]Measuring inference for batch_size=1:  88%|████████▊ | 879/1000 [00:04<00:00, 210.36it/s]Measuring inference for batch_size=1:  90%|█████████ | 901/1000 [00:04<00:00, 210.38it/s]Measuring inference for batch_size=1:  92%|█████████▏| 923/1000 [00:04<00:00, 210.39it/s]Measuring inference for batch_size=1:  94%|█████████▍| 945/1000 [00:04<00:00, 210.34it/s]Measuring inference for batch_size=1:  97%|█████████▋| 967/1000 [00:04<00:00, 210.38it/s]Measuring inference for batch_size=1:  99%|█████████▉| 989/1000 [00:04<00:00, 210.38it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 210.39it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.99 GB
    total: 31.28 GB
    used: 914.86 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 92.931 us +/- 2.562 us [91.791 us, 140.667 us]
        batches_per_second: 10.77 K +/- 249.72 [7.11 K, 10.89 K]
      metrics:
        batches_per_second_max: 10894.296103896104
        batches_per_second_mean: 10767.447335326522
        batches_per_second_min: 7108.989830508474
        batches_per_second_std: 249.71848802125757
        seconds_per_batch_max: 0.00014066696166992188
        seconds_per_batch_mean: 9.293127059936523e-05
        seconds_per_batch_min: 9.179115295410156e-05
        seconds_per_batch_std: 2.5624893035079143e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.390 us +/- 0.624 us [22.650 us, 30.994 us]
        batches_per_second: 42.78 K +/- 957.68 [32.26 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42779.08977697228
        batches_per_second_min: 32263.876923076925
        batches_per_second_std: 957.6835031168976
        seconds_per_batch_max: 3.0994415283203125e-05
        seconds_per_batch_mean: 2.3389816284179687e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 6.237817417104329e-07
    on_device_inference:
      human_readable:
        batch_latency: -4626375.809 us +/- 14.097 ms [-4872352.123 us, -4598303.795
          us]
        batches_per_second: -0.22 +/- 0.00 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.2052396819240594
        batches_per_second_mean: -0.21615388922021014
        batches_per_second_min: -0.21747149484068903
        batches_per_second_std: 0.0006474030235571527
        seconds_per_batch_max: -4.59830379486084
        seconds_per_batch_mean: -4.62637580871582
        seconds_per_batch_min: -4.872352123260498
        seconds_per_batch_std: 0.014096904763733166
    total:
      human_readable:
        batch_latency: 4.750 ms +/- 15.916 us [4.720 ms, 5.059 ms]
        batches_per_second: 210.54 +/- 0.69 [197.68, 211.87]
      metrics:
        batches_per_second_max: 211.86563620750618
        batches_per_second_mean: 210.54375394190654
        batches_per_second_min: 197.67668960316712
        batches_per_second_std: 0.6881788471847889
        seconds_per_batch_max: 0.005058765411376953
        seconds_per_batch_mean: 0.004749658584594726
        seconds_per_batch_min: 0.004719972610473633
        seconds_per_batch_std: 1.591584266597505e-05


#####
fp-fp-py-id - Run 8
2024-02-25 22:49:40
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.24it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.23it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 287.54it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 287.95it/s]Warming up with batch_size=1:  88%|████████▊ | 88/100 [00:00<00:00, 289.31it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 289.15it/s]
STAGE:2024-02-25 22:49:33 4996:4996 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:49:33 4996:4996 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:49:33 4996:4996 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 218.72it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 219.23it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 219.44it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 219.59it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 219.67it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:03, 219.61it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:03, 219.73it/s]Measuring inference for batch_size=1:  18%|█▊        | 177/1000 [00:00<00:03, 219.84it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:00<00:03, 219.93it/s]Measuring inference for batch_size=1:  22%|██▏       | 223/1000 [00:01<00:03, 220.01it/s]Measuring inference for batch_size=1:  25%|██▍       | 246/1000 [00:01<00:03, 219.86it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:01<00:03, 219.83it/s]Measuring inference for batch_size=1:  29%|██▉       | 291/1000 [00:01<00:03, 219.90it/s]Measuring inference for batch_size=1:  31%|███▏      | 314/1000 [00:01<00:03, 219.94it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:01<00:03, 219.85it/s]Measuring inference for batch_size=1:  36%|███▌      | 358/1000 [00:01<00:02, 219.87it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:01<00:02, 219.79it/s]Measuring inference for batch_size=1:  40%|████      | 403/1000 [00:01<00:02, 219.87it/s]Measuring inference for batch_size=1:  42%|████▎     | 425/1000 [00:01<00:02, 219.84it/s]Measuring inference for batch_size=1:  45%|████▍     | 447/1000 [00:02<00:02, 219.80it/s]Measuring inference for batch_size=1:  47%|████▋     | 469/1000 [00:02<00:02, 219.76it/s]Measuring inference for batch_size=1:  49%|████▉     | 491/1000 [00:02<00:02, 219.76it/s]Measuring inference for batch_size=1:  51%|█████▏    | 513/1000 [00:02<00:02, 219.64it/s]Measuring inference for batch_size=1:  54%|█████▎    | 535/1000 [00:02<00:02, 219.62it/s]Measuring inference for batch_size=1:  56%|█████▌    | 557/1000 [00:02<00:02, 219.58it/s]Measuring inference for batch_size=1:  58%|█████▊    | 579/1000 [00:02<00:01, 219.55it/s]Measuring inference for batch_size=1:  60%|██████    | 601/1000 [00:02<00:01, 219.54it/s]Measuring inference for batch_size=1:  62%|██████▏   | 623/1000 [00:02<00:01, 219.53it/s]Measuring inference for batch_size=1:  64%|██████▍   | 645/1000 [00:02<00:01, 219.51it/s]Measuring inference for batch_size=1:  67%|██████▋   | 667/1000 [00:03<00:01, 219.58it/s]Measuring inference for batch_size=1:  69%|██████▉   | 689/1000 [00:03<00:01, 219.50it/s]Measuring inference for batch_size=1:  71%|███████   | 711/1000 [00:03<00:01, 219.50it/s]Measuring inference for batch_size=1:  73%|███████▎  | 733/1000 [00:03<00:01, 219.59it/s]Measuring inference for batch_size=1:  76%|███████▌  | 755/1000 [00:03<00:01, 219.62it/s]Measuring inference for batch_size=1:  78%|███████▊  | 777/1000 [00:03<00:01, 219.66it/s]Measuring inference for batch_size=1:  80%|███████▉  | 799/1000 [00:03<00:00, 218.57it/s]Measuring inference for batch_size=1:  82%|████████▏ | 821/1000 [00:03<00:00, 214.65it/s]Measuring inference for batch_size=1:  84%|████████▍ | 843/1000 [00:03<00:00, 212.15it/s]Measuring inference for batch_size=1:  86%|████████▋ | 865/1000 [00:03<00:00, 210.52it/s]Measuring inference for batch_size=1:  89%|████████▊ | 887/1000 [00:04<00:00, 209.28it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:04<00:00, 208.50it/s]Measuring inference for batch_size=1:  93%|█████████▎| 929/1000 [00:04<00:00, 207.97it/s]Measuring inference for batch_size=1:  95%|█████████▌| 950/1000 [00:04<00:00, 207.67it/s]Measuring inference for batch_size=1:  97%|█████████▋| 971/1000 [00:04<00:00, 207.30it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:04<00:00, 206.98it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 216.83it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 916.67 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 91.751 us +/- 2.858 us [89.645 us, 138.521 us]
        batches_per_second: 10.91 K +/- 297.71 [7.22 K, 11.16 K]
      metrics:
        batches_per_second_max: 11155.063829787234
        batches_per_second_mean: 10908.256054281197
        batches_per_second_min: 7219.111876075732
        batches_per_second_std: 297.71184843523775
        seconds_per_batch_max: 0.0001385211944580078
        seconds_per_batch_mean: 9.17508602142334e-05
        seconds_per_batch_min: 8.96453857421875e-05
        seconds_per_batch_std: 2.8580853063256237e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 22.794 us +/- 0.730 us [21.935 us, 28.372 us]
        batches_per_second: 43.91 K +/- 1.30 K [35.25 K, 45.59 K]
      metrics:
        batches_per_second_max: 45590.260869565216
        batches_per_second_mean: 43913.00749329234
        batches_per_second_min: 35246.252100840335
        batches_per_second_std: 1295.296976199013
        seconds_per_batch_max: 2.8371810913085938e-05
        seconds_per_batch_mean: 2.279376983642578e-05
        seconds_per_batch_min: 2.193450927734375e-05
        seconds_per_batch_std: 7.300898560087431e-07
    on_device_inference:
      human_readable:
        batch_latency: -4487563.382 us +/- 116.163 ms [-4811615.944 us, -4394303.799
          us]
        batches_per_second: -0.22 +/- 0.01 [-0.23, -0.21]
      metrics:
        batches_per_second_max: -0.20783038622730457
        batches_per_second_mean: -0.22298226189816786
        batches_per_second_min: -0.2275673339429569
        batches_per_second_std: 0.005570263897042031
        seconds_per_batch_max: -4.394303798675537
        seconds_per_batch_mean: -4.487563381671905
        seconds_per_batch_min: -4.811615943908691
        seconds_per_batch_std: 0.11616278107457076
    total:
      human_readable:
        batch_latency: 4.608 ms +/- 118.744 us [4.513 ms, 4.937 ms]
        batches_per_second: 217.13 +/- 5.40 [202.56, 221.60]
      metrics:
        batches_per_second_max: 221.6042690336556
        batches_per_second_mean: 217.13196568134134
        batches_per_second_min: 202.56466724620884
        batches_per_second_std: 5.400262153476358
        seconds_per_batch_max: 0.004936695098876953
        seconds_per_batch_mean: 0.004608447313308716
        seconds_per_batch_min: 0.0045125484466552734
        seconds_per_batch_std: 0.00011874385346185984


#####
fp-fp-py-id - Run 9
2024-02-25 22:49:52
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.13it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.12it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 283.01it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 284.61it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 285.51it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 285.32it/s]
STAGE:2024-02-25 22:49:45 5042:5042 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:49:45 5042:5042 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:49:45 5042:5042 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 214.74it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 215.24it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 215.53it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 215.52it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 215.56it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:04, 215.59it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:03, 215.65it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:00<00:03, 215.71it/s]Measuring inference for batch_size=1:  20%|█▉        | 198/1000 [00:00<00:03, 215.86it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:01<00:03, 215.84it/s]Measuring inference for batch_size=1:  24%|██▍       | 242/1000 [00:01<00:03, 215.83it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:01<00:03, 215.86it/s]Measuring inference for batch_size=1:  29%|██▊       | 286/1000 [00:01<00:03, 215.93it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:01<00:03, 215.92it/s]Measuring inference for batch_size=1:  33%|███▎      | 330/1000 [00:01<00:03, 215.91it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:01<00:03, 215.84it/s]Measuring inference for batch_size=1:  37%|███▋      | 374/1000 [00:01<00:02, 215.84it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:01<00:02, 215.85it/s]Measuring inference for batch_size=1:  42%|████▏     | 418/1000 [00:01<00:02, 215.79it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:02<00:02, 215.76it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 215.73it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:02<00:02, 215.68it/s]Measuring inference for batch_size=1:  51%|█████     | 506/1000 [00:02<00:02, 215.64it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:02<00:02, 215.62it/s]Measuring inference for batch_size=1:  55%|█████▌    | 550/1000 [00:02<00:02, 215.66it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:02<00:01, 215.70it/s]Measuring inference for batch_size=1:  59%|█████▉    | 594/1000 [00:02<00:01, 215.65it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:02<00:01, 215.63it/s]Measuring inference for batch_size=1:  64%|██████▍   | 638/1000 [00:02<00:01, 215.60it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:03<00:01, 215.50it/s]Measuring inference for batch_size=1:  68%|██████▊   | 682/1000 [00:03<00:01, 215.54it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:03<00:01, 215.45it/s]Measuring inference for batch_size=1:  73%|███████▎  | 726/1000 [00:03<00:01, 215.46it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:03<00:01, 215.47it/s]Measuring inference for batch_size=1:  77%|███████▋  | 770/1000 [00:03<00:01, 215.57it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:03<00:00, 215.62it/s]Measuring inference for batch_size=1:  81%|████████▏ | 814/1000 [00:03<00:00, 215.72it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:03<00:00, 215.74it/s]Measuring inference for batch_size=1:  86%|████████▌ | 858/1000 [00:03<00:00, 215.68it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:04<00:00, 215.71it/s]Measuring inference for batch_size=1:  90%|█████████ | 902/1000 [00:04<00:00, 215.70it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:04<00:00, 215.63it/s]Measuring inference for batch_size=1:  95%|█████████▍| 946/1000 [00:04<00:00, 215.64it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:04<00:00, 215.66it/s]Measuring inference for batch_size=1:  99%|█████████▉| 990/1000 [00:04<00:00, 215.63it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 215.67it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 924.16 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 91.568 us +/- 2.741 us [89.884 us, 144.243 us]
        batches_per_second: 10.93 K +/- 270.26 [6.93 K, 11.13 K]
      metrics:
        batches_per_second_max: 11125.474801061007
        batches_per_second_mean: 10928.763612207264
        batches_per_second_min: 6932.7338842975205
        batches_per_second_std: 270.2607329451869
        seconds_per_batch_max: 0.0001442432403564453
        seconds_per_batch_mean: 9.15684700012207e-05
        seconds_per_batch_min: 8.988380432128906e-05
        seconds_per_batch_std: 2.7407109489483747e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 22.731 us +/- 0.542 us [21.935 us, 28.372 us]
        batches_per_second: 44.01 K +/- 915.74 [35.25 K, 45.59 K]
      metrics:
        batches_per_second_max: 45590.260869565216
        batches_per_second_mean: 44014.89353267806
        batches_per_second_min: 35246.252100840335
        batches_per_second_std: 915.7411390162247
        seconds_per_batch_max: 2.8371810913085938e-05
        seconds_per_batch_mean: 2.273082733154297e-05
        seconds_per_batch_min: 2.193450927734375e-05
        seconds_per_batch_std: 5.423380740399526e-07
    on_device_inference:
      human_readable:
        batch_latency: -4512757.790 us +/- 15.567 ms [-4760128.021 us, -4485023.975
          us]
        batches_per_second: -0.22 +/- 0.00 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.21007838350941108
        batches_per_second_mean: -0.22159658358510087
        batches_per_second_min: -0.22296424846134455
        batches_per_second_std: 0.0007523018076521955
        seconds_per_batch_max: -4.4850239753723145
        seconds_per_batch_mean: -4.5127577896118165
        seconds_per_batch_min: -4.760128021240234
        seconds_per_batch_std: 0.01556748208020394
    total:
      human_readable:
        batch_latency: 4.633 ms +/- 17.183 us [4.604 ms, 4.946 ms]
        batches_per_second: 215.83 +/- 0.78 [202.20, 217.20]
      metrics:
        batches_per_second_max: 217.1976593651287
        batches_per_second_mean: 215.83077587325897
        batches_per_second_min: 202.2033457069855
        batches_per_second_std: 0.7819541840623827
        seconds_per_batch_max: 0.004945516586303711
        seconds_per_batch_mean: 0.004633321762084961
        seconds_per_batch_min: 0.0046041011810302734
        seconds_per_batch_std: 1.7183004808147663e-05


#####
fp-fp-py-id - Run 10
2024-02-25 22:50:05
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.54it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 274.01it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 274.75it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:00<00:00, 276.22it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 276.03it/s]
STAGE:2024-02-25 22:49:58 5088:5088 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:49:58 5088:5088 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:49:58 5088:5088 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 21/1000 [00:00<00:04, 206.83it/s]Measuring inference for batch_size=1:   4%|▍         | 42/1000 [00:00<00:04, 207.31it/s]Measuring inference for batch_size=1:   6%|▋         | 63/1000 [00:00<00:04, 207.36it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:00<00:04, 207.48it/s]Measuring inference for batch_size=1:  10%|█         | 105/1000 [00:00<00:04, 207.49it/s]Measuring inference for batch_size=1:  13%|█▎        | 126/1000 [00:00<00:04, 207.62it/s]Measuring inference for batch_size=1:  15%|█▍        | 147/1000 [00:00<00:04, 207.68it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:00<00:04, 207.77it/s]Measuring inference for batch_size=1:  19%|█▉        | 189/1000 [00:00<00:03, 207.71it/s]Measuring inference for batch_size=1:  21%|██        | 210/1000 [00:01<00:03, 207.71it/s]Measuring inference for batch_size=1:  23%|██▎       | 231/1000 [00:01<00:03, 207.73it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:01<00:03, 207.81it/s]Measuring inference for batch_size=1:  27%|██▋       | 273/1000 [00:01<00:03, 207.75it/s]Measuring inference for batch_size=1:  29%|██▉       | 294/1000 [00:01<00:03, 207.71it/s]Measuring inference for batch_size=1:  32%|███▏      | 315/1000 [00:01<00:03, 207.66it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:01<00:03, 207.62it/s]Measuring inference for batch_size=1:  36%|███▌      | 357/1000 [00:01<00:03, 207.46it/s]Measuring inference for batch_size=1:  38%|███▊      | 378/1000 [00:01<00:03, 207.32it/s]Measuring inference for batch_size=1:  40%|███▉      | 399/1000 [00:01<00:02, 207.35it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:02<00:02, 207.40it/s]Measuring inference for batch_size=1:  44%|████▍     | 441/1000 [00:02<00:02, 207.49it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 207.56it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 207.64it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:02<00:02, 207.62it/s]Measuring inference for batch_size=1:  52%|█████▎    | 525/1000 [00:02<00:02, 207.57it/s]Measuring inference for batch_size=1:  55%|█████▍    | 546/1000 [00:02<00:02, 207.54it/s]Measuring inference for batch_size=1:  57%|█████▋    | 567/1000 [00:02<00:02, 207.58it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:02<00:01, 207.67it/s]Measuring inference for batch_size=1:  61%|██████    | 609/1000 [00:02<00:01, 207.52it/s]Measuring inference for batch_size=1:  63%|██████▎   | 630/1000 [00:03<00:01, 207.50it/s]Measuring inference for batch_size=1:  65%|██████▌   | 651/1000 [00:03<00:01, 207.66it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:03<00:01, 207.66it/s]Measuring inference for batch_size=1:  69%|██████▉   | 693/1000 [00:03<00:01, 207.62it/s]Measuring inference for batch_size=1:  71%|███████▏  | 714/1000 [00:03<00:01, 207.65it/s]Measuring inference for batch_size=1:  74%|███████▎  | 735/1000 [00:03<00:01, 207.58it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:03<00:01, 207.59it/s]Measuring inference for batch_size=1:  78%|███████▊  | 777/1000 [00:03<00:01, 207.67it/s]Measuring inference for batch_size=1:  80%|███████▉  | 798/1000 [00:03<00:00, 207.57it/s]Measuring inference for batch_size=1:  82%|████████▏ | 819/1000 [00:03<00:00, 207.45it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:04<00:00, 207.34it/s]Measuring inference for batch_size=1:  86%|████████▌ | 861/1000 [00:04<00:00, 203.53it/s]Measuring inference for batch_size=1:  88%|████████▊ | 882/1000 [00:04<00:00, 200.81it/s]Measuring inference for batch_size=1:  90%|█████████ | 903/1000 [00:04<00:00, 198.98it/s]Measuring inference for batch_size=1:  92%|█████████▏| 923/1000 [00:04<00:00, 197.72it/s]Measuring inference for batch_size=1:  94%|█████████▍| 943/1000 [00:04<00:00, 196.78it/s]Measuring inference for batch_size=1:  96%|█████████▋| 963/1000 [00:04<00:00, 196.14it/s]Measuring inference for batch_size=1:  98%|█████████▊| 983/1000 [00:04<00:00, 195.46it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 205.37it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.97 GB
    total: 31.28 GB
    used: 928.34 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 93.155 us +/- 2.985 us [91.076 us, 147.581 us]
        batches_per_second: 10.74 K +/- 291.54 [6.78 K, 10.98 K]
      metrics:
        batches_per_second_max: 10979.853403141362
        batches_per_second_mean: 10744.038921619043
        batches_per_second_min: 6775.9353796445885
        batches_per_second_std: 291.5373639386189
        seconds_per_batch_max: 0.0001475811004638672
        seconds_per_batch_mean: 9.31546688079834e-05
        seconds_per_batch_min: 9.107589721679688e-05
        seconds_per_batch_std: 2.9854732111121065e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.639 us +/- 0.648 us [22.650 us, 30.041 us]
        batches_per_second: 42.33 K +/- 1.07 K [33.29 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42332.255614906695
        batches_per_second_min: 33288.12698412698
        batches_per_second_std: 1069.1241493711607
        seconds_per_batch_max: 3.0040740966796875e-05
        seconds_per_batch_mean: 2.363896369934082e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 6.483406951198453e-07
    on_device_inference:
      human_readable:
        batch_latency: -4740982.143 us +/- 116.577 ms [-5075712.204 us, -4649184.227
          us]
        batches_per_second: -0.21 +/- 0.00 [-0.22, -0.20]
      metrics:
        batches_per_second_max: -0.1970166864890357
        batches_per_second_mean: -0.2110489260273161
        batches_per_second_min: -0.21509149802985544
        batches_per_second_std: 0.004968468021708724
        seconds_per_batch_max: -4.649184226989746
        seconds_per_batch_mean: -4.7409821429252625
        seconds_per_batch_min: -5.075712203979492
        seconds_per_batch_std: 0.11657710497916565
    total:
      human_readable:
        batch_latency: 4.865 ms +/- 119.044 us [4.771 ms, 5.205 ms]
        batches_per_second: 205.65 +/- 4.82 [192.13, 209.60]
      metrics:
        batches_per_second_max: 209.5999200439758
        batches_per_second_mean: 205.64701735257577
        batches_per_second_min: 192.12605927351015
        batches_per_second_std: 4.818514694411524
        seconds_per_batch_max: 0.005204916000366211
        seconds_per_batch_mean: 0.004865490436553955
        seconds_per_batch_min: 0.004770994186401367
        seconds_per_batch_std: 0.00011904413137865995


#####
fp-fp-py-id - Run 11
2024-02-25 22:50:17
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.57it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.56it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 278.73it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 279.45it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:00<00:00, 280.61it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 280.60it/s]
STAGE:2024-02-25 22:50:10 5134:5134 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:50:10 5134:5134 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:50:10 5134:5134 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 211.00it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 211.24it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 211.51it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 211.64it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 211.83it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:04, 211.83it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:03, 211.82it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:00<00:03, 211.89it/s]Measuring inference for batch_size=1:  20%|█▉        | 198/1000 [00:00<00:03, 211.91it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:01<00:03, 211.94it/s]Measuring inference for batch_size=1:  24%|██▍       | 242/1000 [00:01<00:03, 212.00it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:01<00:03, 212.05it/s]Measuring inference for batch_size=1:  29%|██▊       | 286/1000 [00:01<00:03, 212.06it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:01<00:03, 212.01it/s]Measuring inference for batch_size=1:  33%|███▎      | 330/1000 [00:01<00:03, 211.99it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:01<00:03, 212.02it/s]Measuring inference for batch_size=1:  37%|███▋      | 374/1000 [00:01<00:02, 212.04it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:01<00:02, 212.06it/s]Measuring inference for batch_size=1:  42%|████▏     | 418/1000 [00:01<00:02, 212.15it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:02<00:02, 212.19it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 212.20it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:02<00:02, 212.27it/s]Measuring inference for batch_size=1:  51%|█████     | 506/1000 [00:02<00:02, 212.26it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:02<00:02, 212.27it/s]Measuring inference for batch_size=1:  55%|█████▌    | 550/1000 [00:02<00:02, 212.29it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:02<00:02, 212.32it/s]Measuring inference for batch_size=1:  59%|█████▉    | 594/1000 [00:02<00:01, 212.36it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:02<00:01, 212.38it/s]Measuring inference for batch_size=1:  64%|██████▍   | 638/1000 [00:03<00:01, 212.33it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:03<00:01, 212.26it/s]Measuring inference for batch_size=1:  68%|██████▊   | 682/1000 [00:03<00:01, 212.34it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:03<00:01, 212.34it/s]Measuring inference for batch_size=1:  73%|███████▎  | 726/1000 [00:03<00:01, 212.36it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:03<00:01, 212.38it/s]Measuring inference for batch_size=1:  77%|███████▋  | 770/1000 [00:03<00:01, 212.36it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:03<00:00, 212.36it/s]Measuring inference for batch_size=1:  81%|████████▏ | 814/1000 [00:03<00:00, 212.35it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:03<00:00, 212.31it/s]Measuring inference for batch_size=1:  86%|████████▌ | 858/1000 [00:04<00:00, 212.25it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:04<00:00, 212.25it/s]Measuring inference for batch_size=1:  90%|█████████ | 902/1000 [00:04<00:00, 212.25it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:04<00:00, 212.28it/s]Measuring inference for batch_size=1:  95%|█████████▍| 946/1000 [00:04<00:00, 209.28it/s]Measuring inference for batch_size=1:  97%|█████████▋| 967/1000 [00:04<00:00, 207.10it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:04<00:00, 205.55it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 211.34it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 918.35 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.090 us +/- 2.860 us [92.268 us, 140.190 us]
        batches_per_second: 10.64 K +/- 279.30 [7.13 K, 10.84 K]
      metrics:
        batches_per_second_max: 10837.994832041344
        batches_per_second_mean: 10636.593856646821
        batches_per_second_min: 7133.170068027211
        batches_per_second_std: 279.3017803185163
        seconds_per_batch_max: 0.00014019012451171875
        seconds_per_batch_mean: 9.408950805664062e-05
        seconds_per_batch_min: 9.226799011230469e-05
        seconds_per_batch_std: 2.8600929656133524e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.146 us +/- 0.705 us [22.411 us, 30.756 us]
        batches_per_second: 43.24 K +/- 1.12 K [32.51 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 43238.17956222953
        batches_per_second_min: 32513.98449612403
        batches_per_second_std: 1122.4850254598757
        seconds_per_batch_max: 3.075599670410156e-05
        seconds_per_batch_mean: 2.314591407775879e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 7.05027523420033e-07
    on_device_inference:
      human_readable:
        batch_latency: -4604128.317 us +/- 62.984 ms [-4857344.151 us, -4550079.823
          us]
        batches_per_second: -0.22 +/- 0.00 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.20587382096205117
        batches_per_second_mean: -0.21723543715465193
        batches_per_second_min: -0.21977636415215807
        batches_per_second_std: 0.002855265804606584
        seconds_per_batch_max: -4.550079822540283
        seconds_per_batch_mean: -4.60412831735611
        seconds_per_batch_min: -4.857344150543213
        seconds_per_batch_std: 0.06298446874791647
    total:
      human_readable:
        batch_latency: 4.728 ms +/- 64.270 us [4.673 ms, 4.988 ms]
        batches_per_second: 211.53 +/- 2.76 [200.46, 214.01]
      metrics:
        batches_per_second_max: 214.00602071534263
        batches_per_second_mean: 211.534925890247
        batches_per_second_min: 200.46379582277876
        batches_per_second_std: 2.76367752625957
        seconds_per_batch_max: 0.004988431930541992
        seconds_per_batch_mean: 0.004728191375732422
        seconds_per_batch_min: 0.0046727657318115234
        seconds_per_batch_std: 6.42702285221724e-05


#####
fp-fp-py-id - Run 12
2024-02-25 22:50:30
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.50it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 272.75it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 274.23it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:00<00:00, 276.21it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 275.80it/s]
STAGE:2024-02-25 22:50:23 5180:5180 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:50:23 5180:5180 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:50:23 5180:5180 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 21/1000 [00:00<00:04, 206.95it/s]Measuring inference for batch_size=1:   4%|▍         | 42/1000 [00:00<00:04, 207.30it/s]Measuring inference for batch_size=1:   6%|▋         | 63/1000 [00:00<00:04, 207.46it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:00<00:04, 207.71it/s]Measuring inference for batch_size=1:  10%|█         | 105/1000 [00:00<00:04, 207.80it/s]Measuring inference for batch_size=1:  13%|█▎        | 126/1000 [00:00<00:04, 208.05it/s]Measuring inference for batch_size=1:  15%|█▍        | 147/1000 [00:00<00:04, 208.30it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:00<00:03, 208.40it/s]Measuring inference for batch_size=1:  19%|█▉        | 189/1000 [00:00<00:03, 208.43it/s]Measuring inference for batch_size=1:  21%|██        | 210/1000 [00:01<00:03, 208.48it/s]Measuring inference for batch_size=1:  23%|██▎       | 231/1000 [00:01<00:03, 208.45it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:01<00:03, 208.54it/s]Measuring inference for batch_size=1:  27%|██▋       | 273/1000 [00:01<00:03, 208.62it/s]Measuring inference for batch_size=1:  29%|██▉       | 294/1000 [00:01<00:03, 208.70it/s]Measuring inference for batch_size=1:  32%|███▏      | 315/1000 [00:01<00:03, 208.69it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:01<00:03, 208.70it/s]Measuring inference for batch_size=1:  36%|███▌      | 357/1000 [00:01<00:03, 208.64it/s]Measuring inference for batch_size=1:  38%|███▊      | 378/1000 [00:01<00:02, 208.55it/s]Measuring inference for batch_size=1:  40%|███▉      | 399/1000 [00:01<00:02, 208.35it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:02<00:02, 208.25it/s]Measuring inference for batch_size=1:  44%|████▍     | 441/1000 [00:02<00:02, 208.37it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 208.38it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 208.43it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:02<00:02, 208.38it/s]Measuring inference for batch_size=1:  52%|█████▎    | 525/1000 [00:02<00:02, 208.41it/s]Measuring inference for batch_size=1:  55%|█████▍    | 546/1000 [00:02<00:02, 208.41it/s]Measuring inference for batch_size=1:  57%|█████▋    | 567/1000 [00:02<00:02, 208.39it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:02<00:01, 208.36it/s]Measuring inference for batch_size=1:  61%|██████    | 609/1000 [00:02<00:01, 208.25it/s]Measuring inference for batch_size=1:  63%|██████▎   | 630/1000 [00:03<00:01, 208.25it/s]Measuring inference for batch_size=1:  65%|██████▌   | 651/1000 [00:03<00:01, 208.24it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:03<00:01, 208.26it/s]Measuring inference for batch_size=1:  69%|██████▉   | 693/1000 [00:03<00:01, 208.21it/s]Measuring inference for batch_size=1:  71%|███████▏  | 714/1000 [00:03<00:01, 208.03it/s]Measuring inference for batch_size=1:  74%|███████▎  | 735/1000 [00:03<00:01, 208.05it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:03<00:01, 208.04it/s]Measuring inference for batch_size=1:  78%|███████▊  | 777/1000 [00:03<00:01, 208.15it/s]Measuring inference for batch_size=1:  80%|███████▉  | 798/1000 [00:03<00:00, 208.22it/s]Measuring inference for batch_size=1:  82%|████████▏ | 819/1000 [00:03<00:00, 208.25it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:04<00:00, 208.21it/s]Measuring inference for batch_size=1:  86%|████████▌ | 861/1000 [00:04<00:00, 208.24it/s]Measuring inference for batch_size=1:  88%|████████▊ | 882/1000 [00:04<00:00, 208.29it/s]Measuring inference for batch_size=1:  90%|█████████ | 903/1000 [00:04<00:00, 208.22it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:04<00:00, 208.23it/s]Measuring inference for batch_size=1:  94%|█████████▍| 945/1000 [00:04<00:00, 208.29it/s]Measuring inference for batch_size=1:  97%|█████████▋| 966/1000 [00:04<00:00, 208.29it/s]Measuring inference for batch_size=1:  99%|█████████▊| 987/1000 [00:04<00:00, 208.35it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 208.29it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.99 GB
    total: 31.28 GB
    used: 912.35 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.795 us +/- 2.627 us [93.222 us, 138.760 us]
        batches_per_second: 10.56 K +/- 251.43 [7.21 K, 10.73 K]
      metrics:
        batches_per_second_max: 10727.120204603581
        batches_per_second_mean: 10556.046837201733
        batches_per_second_min: 7206.707903780069
        batches_per_second_std: 251.43330221291458
        seconds_per_batch_max: 0.00013875961303710938
        seconds_per_batch_mean: 9.479451179504394e-05
        seconds_per_batch_min: 9.322166442871094e-05
        seconds_per_batch_std: 2.6273964428222086e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.405 us +/- 0.369 us [22.650 us, 28.610 us]
        batches_per_second: 42.74 K +/- 622.96 [34.95 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42735.99226230617
        batches_per_second_min: 34952.53333333333
        batches_per_second_std: 622.9553161926925
        seconds_per_batch_max: 2.86102294921875e-05
        seconds_per_batch_mean: 2.3404836654663086e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 3.6867183797475707e-07
    on_device_inference:
      human_readable:
        batch_latency: -4671765.415 us +/- 16.630 ms [-4904575.825 us, -4641536.236
          us]
        batches_per_second: -0.21 +/- 0.00 [-0.22, -0.20]
      metrics:
        batches_per_second_max: -0.20389123050279512
        batches_per_second_mean: -0.21405452330205316
        batches_per_second_min: -0.21544591040462577
        batches_per_second_std: 0.0007529022865985812
        seconds_per_batch_max: -4.641536235809326
        seconds_per_batch_mean: -4.671765414714813
        seconds_per_batch_min: -4.904575824737549
        seconds_per_batch_std: 0.01663020926697974
    total:
      human_readable:
        batch_latency: 4.797 ms +/- 18.099 us [4.766 ms, 5.085 ms]
        batches_per_second: 208.45 +/- 0.77 [196.64, 209.81]
      metrics:
        batches_per_second_max: 209.8096143264469
        batches_per_second_mean: 208.45002825214652
        batches_per_second_min: 196.6387248007501
        batches_per_second_std: 0.773218735167227
        seconds_per_batch_max: 0.005085468292236328
        seconds_per_batch_mean: 0.004797379970550537
        seconds_per_batch_min: 0.004766225814819336
        seconds_per_batch_std: 1.8098880416949064e-05


#####
fp-fp-py-id - Run 13
2024-02-25 22:50:42
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.14it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 283.43it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 285.52it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 286.26it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 286.01it/s]
STAGE:2024-02-25 22:50:35 5228:5228 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:50:35 5228:5228 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:50:35 5228:5228 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 216.35it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 216.80it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 217.05it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 216.97it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 217.04it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:04, 216.97it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:03, 216.98it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:00<00:03, 217.01it/s]Measuring inference for batch_size=1:  20%|█▉        | 198/1000 [00:00<00:03, 216.99it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:01<00:03, 217.06it/s]Measuring inference for batch_size=1:  24%|██▍       | 242/1000 [00:01<00:03, 217.04it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:01<00:03, 217.08it/s]Measuring inference for batch_size=1:  29%|██▊       | 286/1000 [00:01<00:03, 217.07it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:01<00:03, 217.03it/s]Measuring inference for batch_size=1:  33%|███▎      | 330/1000 [00:01<00:03, 217.03it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:01<00:02, 216.99it/s]Measuring inference for batch_size=1:  37%|███▋      | 374/1000 [00:01<00:02, 216.97it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:01<00:02, 217.02it/s]Measuring inference for batch_size=1:  42%|████▏     | 418/1000 [00:01<00:02, 217.08it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:02<00:02, 217.09it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 217.10it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:02<00:02, 217.09it/s]Measuring inference for batch_size=1:  51%|█████     | 506/1000 [00:02<00:02, 217.17it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:02<00:02, 215.78it/s]Measuring inference for batch_size=1:  55%|█████▌    | 550/1000 [00:02<00:02, 212.45it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:02<00:02, 209.92it/s]Measuring inference for batch_size=1:  59%|█████▉    | 594/1000 [00:02<00:01, 208.19it/s]Measuring inference for batch_size=1:  62%|██████▏   | 615/1000 [00:02<00:01, 207.08it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:02<00:01, 206.38it/s]Measuring inference for batch_size=1:  66%|██████▌   | 657/1000 [00:03<00:01, 205.88it/s]Measuring inference for batch_size=1:  68%|██████▊   | 678/1000 [00:03<00:01, 205.49it/s]Measuring inference for batch_size=1:  70%|██████▉   | 699/1000 [00:03<00:01, 205.19it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:03<00:01, 204.89it/s]Measuring inference for batch_size=1:  74%|███████▍  | 741/1000 [00:03<00:01, 204.67it/s]Measuring inference for batch_size=1:  76%|███████▌  | 762/1000 [00:03<00:01, 204.54it/s]Measuring inference for batch_size=1:  78%|███████▊  | 783/1000 [00:03<00:01, 204.36it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:03<00:00, 204.32it/s]Measuring inference for batch_size=1:  82%|████████▎ | 825/1000 [00:03<00:00, 204.20it/s]Measuring inference for batch_size=1:  85%|████████▍ | 846/1000 [00:03<00:00, 204.17it/s]Measuring inference for batch_size=1:  87%|████████▋ | 867/1000 [00:04<00:00, 204.20it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:04<00:00, 204.22it/s]Measuring inference for batch_size=1:  91%|█████████ | 909/1000 [00:04<00:00, 204.19it/s]Measuring inference for batch_size=1:  93%|█████████▎| 930/1000 [00:04<00:00, 204.18it/s]Measuring inference for batch_size=1:  95%|█████████▌| 951/1000 [00:04<00:00, 203.99it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:04<00:00, 203.96it/s]Measuring inference for batch_size=1:  99%|█████████▉| 993/1000 [00:04<00:00, 204.10it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 210.72it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 918.59 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 92.129 us +/- 2.864 us [89.645 us, 140.429 us]
        batches_per_second: 10.86 K +/- 295.08 [7.12 K, 11.16 K]
      metrics:
        batches_per_second_max: 11155.063829787234
        batches_per_second_mean: 10863.355825933713
        batches_per_second_min: 7121.059422750424
        batches_per_second_std: 295.075429051753
        seconds_per_batch_max: 0.0001404285430908203
        seconds_per_batch_mean: 9.212946891784668e-05
        seconds_per_batch_min: 8.96453857421875e-05
        seconds_per_batch_std: 2.8641349933829356e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 22.955 us +/- 0.829 us [21.696 us, 31.948 us]
        batches_per_second: 43.61 K +/- 1.39 K [31.30 K, 46.09 K]
      metrics:
        batches_per_second_max: 46091.25274725275
        batches_per_second_mean: 43612.97836258405
        batches_per_second_min: 31300.776119402984
        batches_per_second_std: 1391.1797284838904
        seconds_per_batch_max: 3.1948089599609375e-05
        seconds_per_batch_mean: 2.295517921447754e-05
        seconds_per_batch_min: 2.1696090698242188e-05
        seconds_per_batch_std: 8.294787271440756e-07
    on_device_inference:
      human_readable:
        batch_latency: -4620237.947 us +/- 142.515 ms [-4846752.167 us, -4455520.153
          us]
        batches_per_second: -0.22 +/- 0.01 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.20632373300633508
        batches_per_second_mean: -0.21664466551993883
        batches_per_second_min: -0.2244406860816085
        batches_per_second_std: 0.006665445615094487
        seconds_per_batch_max: -4.455520153045654
        seconds_per_batch_mean: -4.620237946987152
        seconds_per_batch_min: -4.846752166748047
        seconds_per_batch_std: 0.14251501169489664
    total:
      human_readable:
        batch_latency: 4.742 ms +/- 144.877 us [4.574 ms, 4.970 ms]
        batches_per_second: 211.07 +/- 6.43 [201.20, 218.61]
      metrics:
        batches_per_second_max: 218.61273845512352
        batches_per_second_mean: 211.07414605343632
        batches_per_second_min: 201.2042598100355
        batches_per_second_std: 6.432101064867069
        seconds_per_batch_max: 0.004970073699951172
        seconds_per_batch_mean: 0.004742086410522461
        seconds_per_batch_min: 0.004574298858642578
        seconds_per_batch_std: 0.00014487656527554805


#####
fp-fp-py-id - Run 14
2024-02-25 22:50:55
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.97it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  28%|██▊       | 28/100 [00:00<00:00, 274.36it/s]Warming up with batch_size=1:  56%|█████▌    | 56/100 [00:00<00:00, 276.17it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:00<00:00, 276.81it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 276.60it/s]
STAGE:2024-02-25 22:50:47 5274:5274 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:50:47 5274:5274 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:50:47 5274:5274 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 21/1000 [00:00<00:04, 206.58it/s]Measuring inference for batch_size=1:   4%|▍         | 42/1000 [00:00<00:04, 206.83it/s]Measuring inference for batch_size=1:   6%|▋         | 63/1000 [00:00<00:04, 206.80it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:00<00:04, 206.84it/s]Measuring inference for batch_size=1:  10%|█         | 105/1000 [00:00<00:04, 207.01it/s]Measuring inference for batch_size=1:  13%|█▎        | 126/1000 [00:00<00:04, 207.05it/s]Measuring inference for batch_size=1:  15%|█▍        | 147/1000 [00:00<00:04, 206.99it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:00<00:04, 206.94it/s]Measuring inference for batch_size=1:  19%|█▉        | 189/1000 [00:00<00:03, 206.88it/s]Measuring inference for batch_size=1:  21%|██        | 210/1000 [00:01<00:03, 206.88it/s]Measuring inference for batch_size=1:  23%|██▎       | 231/1000 [00:01<00:03, 206.83it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:01<00:03, 206.83it/s]Measuring inference for batch_size=1:  27%|██▋       | 273/1000 [00:01<00:03, 206.99it/s]Measuring inference for batch_size=1:  29%|██▉       | 294/1000 [00:01<00:03, 207.19it/s]Measuring inference for batch_size=1:  32%|███▏      | 315/1000 [00:01<00:03, 207.33it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:01<00:03, 207.48it/s]Measuring inference for batch_size=1:  36%|███▌      | 357/1000 [00:01<00:03, 207.58it/s]Measuring inference for batch_size=1:  38%|███▊      | 378/1000 [00:01<00:02, 207.63it/s]Measuring inference for batch_size=1:  40%|███▉      | 399/1000 [00:01<00:02, 207.74it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:02<00:02, 207.72it/s]Measuring inference for batch_size=1:  44%|████▍     | 441/1000 [00:02<00:02, 207.66it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 207.72it/s]Measuring inference for batch_size=1:  48%|████▊     | 483/1000 [00:02<00:02, 207.80it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:02<00:02, 207.86it/s]Measuring inference for batch_size=1:  52%|█████▎    | 525/1000 [00:02<00:02, 207.89it/s]Measuring inference for batch_size=1:  55%|█████▍    | 546/1000 [00:02<00:02, 207.93it/s]Measuring inference for batch_size=1:  57%|█████▋    | 567/1000 [00:02<00:02, 207.95it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:02<00:01, 207.93it/s]Measuring inference for batch_size=1:  61%|██████    | 609/1000 [00:02<00:01, 207.96it/s]Measuring inference for batch_size=1:  63%|██████▎   | 630/1000 [00:03<00:01, 207.71it/s]Measuring inference for batch_size=1:  65%|██████▌   | 651/1000 [00:03<00:01, 207.71it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:03<00:01, 207.80it/s]Measuring inference for batch_size=1:  69%|██████▉   | 693/1000 [00:03<00:01, 207.84it/s]Measuring inference for batch_size=1:  71%|███████▏  | 714/1000 [00:03<00:01, 207.86it/s]Measuring inference for batch_size=1:  74%|███████▎  | 735/1000 [00:03<00:01, 207.89it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:03<00:01, 207.93it/s]Measuring inference for batch_size=1:  78%|███████▊  | 777/1000 [00:03<00:01, 207.97it/s]Measuring inference for batch_size=1:  80%|███████▉  | 798/1000 [00:03<00:00, 207.94it/s]Measuring inference for batch_size=1:  82%|████████▏ | 819/1000 [00:03<00:00, 207.92it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:04<00:00, 207.71it/s]Measuring inference for batch_size=1:  86%|████████▌ | 861/1000 [00:04<00:00, 207.61it/s]Measuring inference for batch_size=1:  88%|████████▊ | 882/1000 [00:04<00:00, 207.62it/s]Measuring inference for batch_size=1:  90%|█████████ | 903/1000 [00:04<00:00, 207.72it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:04<00:00, 207.74it/s]Measuring inference for batch_size=1:  94%|█████████▍| 945/1000 [00:04<00:00, 207.77it/s]Measuring inference for batch_size=1:  97%|█████████▋| 966/1000 [00:04<00:00, 207.76it/s]Measuring inference for batch_size=1:  99%|█████████▊| 987/1000 [00:04<00:00, 207.64it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 207.55it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.99 GB
    total: 31.28 GB
    used: 914.03 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.363 us +/- 2.617 us [92.745 us, 138.998 us]
        batches_per_second: 10.60 K +/- 253.23 [7.19 K, 10.78 K]
      metrics:
        batches_per_second_max: 10782.272493573264
        batches_per_second_mean: 10604.312733849098
        batches_per_second_min: 7194.346483704974
        batches_per_second_std: 253.23391934338105
        seconds_per_batch_max: 0.00013899803161621094
        seconds_per_batch_mean: 9.436321258544922e-05
        seconds_per_batch_min: 9.274482727050781e-05
        seconds_per_batch_std: 2.617387090385596e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.267 us +/- 0.398 us [22.411 us, 29.087 us]
        batches_per_second: 42.99 K +/- 659.32 [34.38 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 42990.93920004
        batches_per_second_min: 34379.54098360656
        batches_per_second_std: 659.3165400794521
        seconds_per_batch_max: 2.9087066650390625e-05
        seconds_per_batch_mean: 2.326679229736328e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 3.9811305391705146e-07
    on_device_inference:
      human_readable:
        batch_latency: -4689821.250 us +/- 16.829 ms [-4902239.799 us, -4653696.060
          us]
        batches_per_second: -0.21 +/- 0.00 [-0.21, -0.20]
      metrics:
        batches_per_second_max: -0.20398838916490658
        batches_per_second_mean: -0.2132304666178845
        batches_per_second_min: -0.21488296336249738
        batches_per_second_std: 0.0007591271496289996
        seconds_per_batch_max: -4.653696060180664
        seconds_per_batch_mean: -4.6898212504386905
        seconds_per_batch_min: -4.902239799499512
        seconds_per_batch_std: 0.016828781257477426
    total:
      human_readable:
        batch_latency: 4.814 ms +/- 18.216 us [4.779 ms, 5.084 ms]
        batches_per_second: 207.71 +/- 0.78 [196.71, 209.27]
      metrics:
        batches_per_second_max: 209.26527964875518
        batches_per_second_mean: 207.70914964793647
        batches_per_second_min: 196.71250351749367
        batches_per_second_std: 0.776172900272918
        seconds_per_batch_max: 0.005083560943603516
        seconds_per_batch_mean: 0.004814492464065552
        seconds_per_batch_min: 0.004778623580932617
        seconds_per_batch_std: 1.821635741617781e-05


#####
fp-fp-py-id - Run 15
2024-02-25 22:51:05
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.17it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  5.16it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  25.56 M, 100.000% Params, 4.12 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.037% Params, 118.01 MMac, 2.863% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.001% Params, 1.61 MMac, 0.039% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.019% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.019% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.844% Params, 680.39 MMac, 16.507% MACs, 
    (0): Bottleneck(
      75.01 k, 0.293% Params, 236.43 MMac, 5.736% MACs, 
      (conv1): Conv2d(4.1 k, 0.016% Params, 12.85 MMac, 0.312% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.066% Params, 52.99 MMac, 1.285% MACs, 
        (0): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.275% Params, 221.98 MMac, 5.385% MACs, 
      (conv1): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.144% Params, 115.61 MMac, 2.805% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.001% Params, 401.41 KMac, 0.010% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.064% Params, 51.38 MMac, 1.247% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.002% Params, 1.61 MMac, 0.039% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.029% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    1.22 M, 4.772% Params, 1.04 GMac, 25.147% MACs, 
    (0): Bottleneck(
      379.39 k, 1.484% Params, 376.02 MMac, 9.122% MACs, 
      (conv1): Conv2d(32.77 k, 0.128% Params, 102.76 MMac, 2.493% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 802.82 KMac, 0.019% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.022% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.517% Params, 103.56 MMac, 2.512% MACs, 
        (0): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 1.096% Params, 220.17 MMac, 5.341% MACs, 
      (conv1): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.577% Params, 115.61 MMac, 2.805% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.001% Params, 200.7 KMac, 0.005% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.256% Params, 51.38 MMac, 1.247% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.004% Params, 802.82 KMac, 0.019% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.015% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    7.1 M, 27.775% Params, 1.47 GMac, 35.678% MACs, 
    (0): Bottleneck(
      1.51 M, 5.918% Params, 374.26 MMac, 9.080% MACs, 
      (conv1): Conv2d(131.07 k, 0.513% Params, 102.76 MMac, 2.493% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 401.41 KMac, 0.010% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.011% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 2.059% Params, 103.16 MMac, 2.503% MACs, 
        (0): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 4.371% Params, 219.27 MMac, 5.320% MACs, 
      (conv1): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 2.308% Params, 115.61 MMac, 2.805% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.002% Params, 100.35 KMac, 0.002% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 1.026% Params, 51.38 MMac, 1.247% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.008% Params, 401.41 KMac, 0.010% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.007% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 58.554% Params, 811.02 MMac, 19.676% MACs, 
    (0): Bottleneck(
      6.04 M, 23.632% Params, 373.38 MMac, 9.059% MACs, 
      (conv1): Conv2d(524.29 k, 2.051% Params, 102.76 MMac, 2.493% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 200.7 KMac, 0.005% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.005% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 8.222% Params, 102.96 MMac, 2.498% MACs, 
        (0): Conv2d(2.1 M, 8.206% Params, 102.76 MMac, 2.493% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 17.461% Params, 218.82 MMac, 5.309% MACs, 
      (conv1): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 9.231% Params, 115.61 MMac, 2.805% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.004% Params, 50.18 KMac, 0.001% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 4.103% Params, 51.38 MMac, 1.247% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.016% Params, 200.7 KMac, 0.005% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.004% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.002% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 8.017% Params, 2.05 MMac, 0.050% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:00, 284.03it/s]Warming up with batch_size=1:  58%|█████▊    | 58/100 [00:00<00:00, 284.56it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 285.92it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 285.77it/s]
STAGE:2024-02-25 22:51:00 5320:5320 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:51:00 5320:5320 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:51:00 5320:5320 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   2%|▏         | 22/1000 [00:00<00:04, 216.87it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:00<00:04, 217.45it/s]Measuring inference for batch_size=1:   7%|▋         | 66/1000 [00:00<00:04, 217.59it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:00<00:04, 217.57it/s]Measuring inference for batch_size=1:  11%|█         | 110/1000 [00:00<00:04, 217.52it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:00<00:03, 217.56it/s]Measuring inference for batch_size=1:  15%|█▌        | 154/1000 [00:00<00:03, 217.57it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:00<00:03, 217.61it/s]Measuring inference for batch_size=1:  20%|█▉        | 198/1000 [00:00<00:03, 217.58it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:01<00:03, 217.46it/s]Measuring inference for batch_size=1:  24%|██▍       | 242/1000 [00:01<00:03, 217.40it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:01<00:03, 217.45it/s]Measuring inference for batch_size=1:  29%|██▊       | 286/1000 [00:01<00:03, 217.43it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:01<00:03, 217.45it/s]Measuring inference for batch_size=1:  33%|███▎      | 330/1000 [00:01<00:03, 217.47it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:01<00:02, 217.48it/s]Measuring inference for batch_size=1:  37%|███▋      | 374/1000 [00:01<00:02, 217.53it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:01<00:02, 217.45it/s]Measuring inference for batch_size=1:  42%|████▏     | 418/1000 [00:01<00:02, 217.47it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:02<00:02, 217.55it/s]Measuring inference for batch_size=1:  46%|████▌     | 462/1000 [00:02<00:02, 217.51it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:02<00:02, 217.48it/s]Measuring inference for batch_size=1:  51%|█████     | 506/1000 [00:02<00:02, 217.37it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:02<00:02, 217.41it/s]Measuring inference for batch_size=1:  55%|█████▌    | 550/1000 [00:02<00:02, 217.38it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:02<00:01, 217.41it/s]Measuring inference for batch_size=1:  59%|█████▉    | 594/1000 [00:02<00:01, 217.46it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:02<00:01, 217.43it/s]Measuring inference for batch_size=1:  64%|██████▍   | 638/1000 [00:02<00:01, 217.36it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:03<00:01, 217.36it/s]Measuring inference for batch_size=1:  68%|██████▊   | 682/1000 [00:03<00:01, 217.26it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:03<00:01, 217.31it/s]Measuring inference for batch_size=1:  73%|███████▎  | 726/1000 [00:03<00:01, 217.31it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:03<00:01, 217.16it/s]Measuring inference for batch_size=1:  77%|███████▋  | 770/1000 [00:03<00:01, 217.16it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:03<00:00, 217.20it/s]Measuring inference for batch_size=1:  81%|████████▏ | 814/1000 [00:03<00:00, 217.12it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:03<00:00, 217.16it/s]Measuring inference for batch_size=1:  86%|████████▌ | 858/1000 [00:03<00:00, 217.20it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:04<00:00, 217.19it/s]Measuring inference for batch_size=1:  90%|█████████ | 902/1000 [00:04<00:00, 217.17it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:04<00:00, 217.16it/s]Measuring inference for batch_size=1:  95%|█████████▍| 946/1000 [00:04<00:00, 217.18it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:04<00:00, 217.09it/s]Measuring inference for batch_size=1:  99%|█████████▉| 990/1000 [00:04<00:00, 217.01it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:04<00:00, 217.34it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 4121925096
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.99 GB
    total: 31.28 GB
    used: 912.76 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 242.08 MB
    max_inference_bytes: 253842944
    post_inference: 105.85 MB
    post_inference_bytes: 110994944
    pre_inference: 105.85 MB
    pre_inference_bytes: 110994944
params: 25557032
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 91.253 us +/- 2.559 us [89.884 us, 138.760 us]
        batches_per_second: 10.97 K +/- 260.67 [7.21 K, 11.13 K]
      metrics:
        batches_per_second_max: 11125.474801061007
        batches_per_second_mean: 10965.789300977647
        batches_per_second_min: 7206.707903780069
        batches_per_second_std: 260.67113562100064
        seconds_per_batch_max: 0.00013875961303710938
        seconds_per_batch_mean: 9.125280380249024e-05
        seconds_per_batch_min: 8.988380432128906e-05
        seconds_per_batch_std: 2.558859386306375e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 22.661 us +/- 0.537 us [21.935 us, 30.279 us]
        batches_per_second: 44.15 K +/- 900.88 [33.03 K, 45.59 K]
      metrics:
        batches_per_second_max: 45590.260869565216
        batches_per_second_mean: 44149.52734456275
        batches_per_second_min: 33026.015748031496
        batches_per_second_std: 900.8752257661313
        seconds_per_batch_max: 3.0279159545898438e-05
        seconds_per_batch_mean: 2.2661209106445313e-05
        seconds_per_batch_min: 2.193450927734375e-05
        seconds_per_batch_std: 5.373521074803476e-07
    on_device_inference:
      human_readable:
        batch_latency: -4477853.608 us +/- 14.060 ms [-4708191.872 us, -4446080.208
          us]
        batches_per_second: -0.22 +/- 0.00 [-0.22, -0.21]
      metrics:
        batches_per_second_max: -0.21239576195330792
        batches_per_second_mean: -0.2233234489145828
        batches_per_second_min: -0.224917219945805
        batches_per_second_std: 0.0006908908877958334
        seconds_per_batch_max: -4.446080207824707
        seconds_per_batch_mean: -4.477853607654572
        seconds_per_batch_min: -4.708191871643066
        seconds_per_batch_std: 0.014059506417968066
    total:
      human_readable:
        batch_latency: 4.598 ms +/- 15.562 us [4.565 ms, 4.889 ms]
        batches_per_second: 217.50 +/- 0.72 [204.53, 219.07]
      metrics:
        batches_per_second_max: 219.06946620704065
        batches_per_second_mean: 217.5043002773362
        batches_per_second_min: 204.53035548836982
        batches_per_second_std: 0.7198723380675424
        seconds_per_batch_max: 0.004889249801635742
        seconds_per_batch_mean: 0.00459766173362732
        seconds_per_batch_min: 0.004564762115478516
        seconds_per_batch_std: 1.556205920275108e-05


