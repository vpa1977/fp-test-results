#####
fp-fp-py-id - Run 1
2024-02-25 22:59:25
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.91it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 99.58it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 99.67it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 99.75it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 99.78it/s]Warming up with batch_size=1:  51%|█████     | 51/100 [00:00<00:00, 99.86it/s]Warming up with batch_size=1:  61%|██████    | 61/100 [00:00<00:00, 99.86it/s]Warming up with batch_size=1:  71%|███████   | 71/100 [00:00<00:00, 99.89it/s]Warming up with batch_size=1:  81%|████████  | 81/100 [00:00<00:00, 99.90it/s]Warming up with batch_size=1:  91%|█████████ | 91/100 [00:00<00:00, 99.92it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 99.85it/s]
STAGE:2024-02-25 22:58:54 6260:6260 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:58:54 6260:6260 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:58:54 6260:6260 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 74.87it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 75.14it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:12, 75.28it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:12, 75.31it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:12, 75.32it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 75.34it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 75.34it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 75.37it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 75.38it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 75.40it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 75.42it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:11, 75.42it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:11, 75.41it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:11, 75.41it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 75.42it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 75.42it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 75.39it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 75.38it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 75.38it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 75.40it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 75.41it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:10, 75.43it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:10, 75.42it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:10, 75.43it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 75.41it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 75.40it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 75.42it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:02<00:10, 75.42it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 75.42it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 75.40it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:09, 75.38it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:09, 75.37it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:09, 75.36it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 75.37it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 75.41it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 75.39it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:03<00:09, 75.40it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 75.39it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 75.40it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 75.37it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:08, 75.37it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:08, 75.36it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 75.36it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 75.39it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 75.38it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:04<00:08, 75.40it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:04<00:08, 75.35it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 75.35it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 75.37it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:07, 75.39it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:07, 75.38it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:07, 75.38it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 75.36it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 75.36it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:05<00:07, 75.32it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:05<00:07, 75.33it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 75.30it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 75.31it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 75.37it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:06, 75.38it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:06, 75.40it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:06, 75.41it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 75.45it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:06<00:06, 75.43it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:06<00:06, 75.44it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 75.43it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 75.45it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 75.42it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:05, 75.45it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:05, 75.46it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:05, 75.48it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 75.47it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 75.49it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:07<00:05, 75.47it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:07<00:05, 75.49it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 75.50it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 75.52it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:04, 75.51it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:04, 75.53it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:04, 75.45it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 75.47it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 75.41it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:08<00:04, 75.44it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:08<00:04, 75.42it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 74.45it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 73.55it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 72.97it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 72.52it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:03, 72.21it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 71.98it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 71.81it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:09<00:03, 71.69it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:09<00:03, 71.62it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 71.52it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 71.43it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 71.43it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 71.49it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:03, 71.49it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 71.40it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 71.40it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:10<00:02, 71.40it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:10<00:02, 71.43it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 71.46it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 71.44it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 71.42it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 71.43it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:02, 71.43it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 71.42it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 71.45it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:11<00:01, 71.45it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:11<00:01, 71.47it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 71.42it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 71.40it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 71.38it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 71.30it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:01, 71.32it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 71.33it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 71.36it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:12<00:00, 71.44it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:12<00:00, 71.45it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 71.47it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 71.51it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 71.48it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 71.51it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 71.52it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 74.06it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:01, 74.58it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:01, 74.65it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 74.75it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:00, 74.81it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:00<00:00, 74.83it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:00<00:00, 74.81it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:00<00:00, 74.84it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:00<00:00, 74.83it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:00<00:00, 74.84it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:01<00:00, 74.83it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:01<00:00, 74.81it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:01<00:00, 74.77it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:01<00:00, 74.79it/s]
STAGE:2024-02-25 22:59:09 6260:6260 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:59:09 6260:6260 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:59:09 6260:6260 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:13, 73.64it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:13, 73.94it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:13, 74.04it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:13, 74.14it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:00<00:12, 74.25it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:00<00:12, 74.29it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:00<00:12, 74.27it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:00<00:12, 74.29it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:00<00:12, 74.31it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:01<00:12, 74.32it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:01<00:12, 74.33it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:01<00:12, 74.32it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:01<00:12, 74.30it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:01<00:11, 74.29it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:01<00:11, 74.29it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:01<00:11, 74.28it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:01<00:11, 74.27it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:01<00:11, 74.25it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:02<00:11, 74.25it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:02<00:11, 74.24it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:02<00:11, 74.25it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:02<00:11, 74.26it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:02<00:10, 74.25it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:02<00:10, 74.25it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:02<00:10, 74.25it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:02<00:10, 74.27it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:02<00:10, 74.28it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:03<00:10, 74.27it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:03<00:10, 74.27it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:03<00:10, 74.28it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:03<00:10, 74.28it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:03<00:10, 74.24it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:03<00:09, 74.24it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:03<00:09, 74.21it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:03<00:09, 74.20it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:03<00:09, 74.21it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:03<00:09, 74.21it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:04<00:09, 74.22it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:04<00:09, 74.21it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:04<00:09, 74.22it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:04<00:09, 74.21it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:04<00:08, 74.20it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:04<00:08, 74.20it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:04<00:08, 74.20it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:04<00:08, 74.23it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:04<00:08, 74.22it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:05<00:08, 74.24it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:05<00:08, 74.25it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:05<00:08, 74.22it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:05<00:08, 74.21it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:05<00:07, 74.22it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:05<00:07, 74.20it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:05<00:07, 74.19it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:05<00:07, 74.16it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:05<00:07, 74.20it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:06<00:07, 74.21it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:06<00:07, 74.23it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:06<00:07, 74.23it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:06<00:07, 74.23it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:06<00:07, 74.22it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:06<00:06, 74.22it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:06<00:06, 74.23it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:06<00:06, 74.24it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:06<00:06, 74.24it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:07<00:06, 74.26it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:07<00:06, 74.27it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:07<00:06, 74.28it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:07<00:06, 74.28it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:07<00:06, 74.29it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:07<00:05, 74.28it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:07<00:05, 74.25it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:07<00:05, 74.26it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:07<00:05, 74.26it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:07<00:05, 74.26it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:08<00:05, 74.24it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:08<00:05, 74.19it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:08<00:05, 74.18it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:08<00:05, 74.18it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:08<00:04, 74.18it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:08<00:04, 74.18it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:08<00:04, 74.18it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:08<00:04, 74.17it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:08<00:04, 74.15it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:09<00:04, 74.14it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:09<00:04, 74.18it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:09<00:04, 74.22it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:09<00:04, 74.24it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:09<00:03, 74.25it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:09<00:03, 74.25it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:09<00:03, 74.23it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:09<00:03, 74.24it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:09<00:03, 74.05it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:10<00:03, 74.15it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:10<00:03, 74.19it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:10<00:03, 74.21it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:10<00:03, 74.22it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:10<00:03, 74.24it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:10<00:02, 74.23it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:10<00:02, 74.22it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:10<00:02, 74.17it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:10<00:02, 74.16it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:10<00:02, 74.18it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:11<00:02, 74.18it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:11<00:02, 74.18it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:11<00:02, 74.18it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:11<00:02, 74.16it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:11<00:01, 74.17it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:11<00:01, 74.18it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:11<00:01, 74.17it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:11<00:01, 74.19it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:11<00:01, 74.20it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:12<00:01, 74.17it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:12<00:01, 74.16it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:12<00:01, 74.17it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:12<00:01, 74.15it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:12<00:00, 74.16it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:12<00:00, 74.14it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:12<00:00, 74.12it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:12<00:00, 74.10it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:12<00:00, 74.11it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:13<00:00, 74.09it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:13<00:00, 74.12it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:13<00:00, 74.15it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:13<00:00, 74.14it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:13<00:00, 74.18it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:13<00:00, 74.21it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 923.07 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_32:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 93.815 us +/- 5.211 us [90.837 us, 220.060 us]
        batches_per_second: 10.68 K +/- 406.48 [4.54 K, 11.01 K]
      metrics:
        batches_per_second_max: 11008.671916010499
        batches_per_second_mean: 10680.284808947936
        batches_per_second_min: 4544.208017334778
        batches_per_second_std: 406.4815104997276
        seconds_per_batch_max: 0.0002200603485107422
        seconds_per_batch_mean: 9.381484985351562e-05
        seconds_per_batch_min: 9.083747863769531e-05
        seconds_per_batch_std: 5.210718942135125e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.283 us +/- 0.800 us [22.173 us, 29.802 us]
        batches_per_second: 42.99 K +/- 1.31 K [33.55 K, 45.10 K]
      metrics:
        batches_per_second_max: 45100.04301075269
        batches_per_second_mean: 42993.66102895972
        batches_per_second_min: 33554.432
        batches_per_second_std: 1310.389113779121
        seconds_per_batch_max: 2.9802322387695312e-05
        seconds_per_batch_mean: 2.328348159790039e-05
        seconds_per_batch_min: 2.2172927856445312e-05
        seconds_per_batch_std: 7.995748734737646e-07
    on_device_inference:
      human_readable:
        batch_latency: -13370107.030 us +/- 344.320 ms [-13992992.401 us, -13063648.224
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07146434238896193
        batches_per_second_mean: -0.07484243400261004
        batches_per_second_min: -0.07654829515175247
        batches_per_second_std: 0.0018917294113389956
        seconds_per_batch_max: -13.063648223876953
        seconds_per_batch_mean: -13.370107029914855
        seconds_per_batch_min: -13.992992401123047
        seconds_per_batch_std: 0.34432040921747675
    total:
      human_readable:
        batch_latency: 13.495 ms +/- 346.536 us [13.185 ms, 14.119 ms]
        batches_per_second: 74.15 +/- 1.87 [70.83, 75.84]
      metrics:
        batches_per_second_max: 75.8449937614148
        batches_per_second_mean: 74.15098536011202
        batches_per_second_min: 70.82699809182864
        batches_per_second_std: 1.869000789240359
        seconds_per_batch_max: 0.01411890983581543
        seconds_per_batch_mean: 0.013494731903076172
        seconds_per_batch_min: 0.013184785842895508
        seconds_per_batch_std: 0.00034653584747923834
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 164.540 us +/- 4.867 us [161.886 us, 285.864 us]
        batches_per_second: 6.08 K +/- 134.59 [3.50 K, 6.18 K]
      metrics:
        batches_per_second_max: 6177.178203240059
        batches_per_second_mean: 6081.416247338378
        batches_per_second_min: 3498.1684737281066
        batches_per_second_std: 134.5940164535754
        seconds_per_batch_max: 0.00028586387634277344
        seconds_per_batch_mean: 0.00016453957557678223
        seconds_per_batch_min: 0.00016188621520996094
        seconds_per_batch_std: 4.866860588261482e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.148 us +/- 0.544 us [22.411 us, 30.518 us]
        batches_per_second: 43.22 K +/- 905.14 [32.77 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 43220.87361310422
        batches_per_second_min: 32768.0
        batches_per_second_std: 905.1378421736263
        seconds_per_batch_max: 3.0517578125e-05
        seconds_per_batch_mean: 2.3148298263549803e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 5.439246475108531e-07
    on_device_inference:
      human_readable:
        batch_latency: -13274213.354 us +/- 43.740 ms [-13988032.341 us, -13207743.645
          us]
        batches_per_second: -0.08 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07148968315355396
        batches_per_second_mean: -0.07533482586291998
        batches_per_second_min: -0.07571315940858625
        batches_per_second_std: 0.0002413003172729288
        seconds_per_batch_max: -13.207743644714355
        seconds_per_batch_mean: -13.274213354110717
        seconds_per_batch_min: -13.988032341003418
        seconds_per_batch_std: 0.04374036181530535
    total:
      human_readable:
        batch_latency: 13.467 ms +/- 46.076 us [13.399 ms, 14.287 ms]
        batches_per_second: 74.25 +/- 0.25 [69.99, 74.63]
      metrics:
        batches_per_second_max: 74.63439980070466
        batches_per_second_mean: 74.25467899268173
        batches_per_second_min: 69.99372538548829
        batches_per_second_std: 0.2458986060703233
        seconds_per_batch_max: 0.014286994934082031
        seconds_per_batch_mean: 0.013467317342758179
        seconds_per_batch_min: 0.01339864730834961
        seconds_per_batch_std: 4.607607934072045e-05


#####
fp-fp-py-id - Run 2
2024-02-25 23:00:03
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.20it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 96.06it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 96.34it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 96.56it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 96.68it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 96.74it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 96.73it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:00<00:00, 96.75it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:00<00:00, 96.74it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:00<00:00, 96.78it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 96.78it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 96.69it/s]
STAGE:2024-02-25 22:59:31 6306:6306 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:59:31 6306:6306 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:59:31 6306:6306 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 72.51it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 72.88it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:13, 73.01it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:13, 73.11it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:13, 73.12it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:13, 73.16it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 73.16it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 73.17it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 73.17it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 73.20it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 73.19it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:12, 73.17it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:12, 73.17it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:12, 73.12it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:12, 73.08it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 73.07it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 73.09it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 73.10it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 73.10it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 73.13it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 73.14it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:11, 73.14it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:11, 73.16it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:11, 73.17it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 73.19it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 73.19it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 73.20it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:03<00:10, 73.20it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 73.21it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 73.18it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:10, 73.13it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:10, 73.11it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:10, 73.09it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 73.08it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 73.02it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 72.93it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:04<00:09, 72.88it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 72.81it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 72.81it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 72.79it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:09, 72.82it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:09, 72.81it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:09, 72.82it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 72.80it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 72.86it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:05<00:08, 72.89it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:05<00:08, 72.92it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 72.91it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 72.88it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:08, 72.89it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:08, 72.90it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:08, 72.90it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 72.88it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 72.87it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:06<00:07, 72.88it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:06<00:07, 72.88it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 72.86it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 72.88it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 72.90it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:07, 72.94it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:07, 72.98it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:06, 73.00it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 73.02it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:07<00:06, 73.01it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:07<00:06, 73.02it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 72.99it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 72.95it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 72.96it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:06, 72.97it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:06, 72.96it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:05, 72.97it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 72.97it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 72.97it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:08<00:05, 72.94it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 72.92it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 72.93it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 72.95it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:05, 72.93it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:05, 72.93it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:04, 72.94it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 72.97it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 72.89it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:09<00:04, 72.91it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:09<00:04, 72.92it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 72.90it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 72.91it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 72.92it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 72.92it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:03, 72.88it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 72.87it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 72.83it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:10<00:03, 72.82it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:10<00:03, 72.82it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 72.82it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 72.85it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 72.84it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 72.85it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:02, 72.86it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 72.89it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 72.91it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:11<00:02, 72.92it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:11<00:02, 72.95it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 72.98it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 72.97it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 72.96it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 72.96it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:01, 72.96it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 72.96it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 72.91it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:12<00:01, 72.90it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 72.88it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 72.87it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 72.89it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 72.90it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 72.92it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:00, 72.92it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 72.92it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 72.94it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:13<00:00, 72.90it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:13<00:00, 72.90it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 72.91it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 72.93it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 72.91it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 72.92it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 72.92it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 72.96it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:01, 72.21it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:01, 72.37it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 72.50it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:00, 72.54it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:00<00:00, 72.55it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:00<00:00, 72.56it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:00<00:00, 72.58it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:00<00:00, 72.57it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:00<00:00, 72.59it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:01<00:00, 72.60it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:01<00:00, 72.58it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:01<00:00, 72.58it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:01<00:00, 72.55it/s]
STAGE:2024-02-25 22:59:47 6306:6306 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:59:47 6306:6306 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:59:47 6306:6306 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:13, 71.36it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:13, 71.67it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:13, 71.75it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:13, 71.81it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:00<00:13, 71.88it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:00<00:13, 71.91it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:00<00:13, 71.91it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:00<00:13, 71.91it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:01<00:12, 71.91it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:01<00:12, 71.90it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:01<00:12, 71.90it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:01<00:12, 71.91it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:01<00:12, 71.88it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:01<00:12, 71.88it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:01<00:12, 71.91it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:01<00:12, 71.91it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:01<00:12, 71.91it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:02<00:11, 71.95it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:02<00:11, 71.96it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:02<00:11, 71.96it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:02<00:11, 71.95it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:02<00:11, 71.97it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:02<00:11, 71.96it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:02<00:11, 71.97it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:02<00:11, 71.98it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:02<00:11, 71.96it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:03<00:10, 71.93it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:03<00:10, 71.87it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:03<00:10, 71.85it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:03<00:10, 71.82it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:03<00:10, 71.82it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:03<00:10, 71.79it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:03<00:10, 71.81it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:03<00:10, 71.80it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:03<00:10, 71.81it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:04<00:09, 71.80it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:04<00:09, 71.80it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:04<00:09, 71.81it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:04<00:09, 71.79it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:04<00:09, 71.79it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:04<00:09, 71.83it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:04<00:09, 71.85it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:04<00:09, 71.89it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:04<00:09, 71.89it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:05<00:08, 71.87it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:05<00:08, 71.87it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:05<00:08, 71.84it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:05<00:08, 71.84it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:05<00:08, 71.83it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:05<00:08, 71.83it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:05<00:08, 71.85it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:05<00:08, 71.86it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:05<00:08, 71.86it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:06<00:07, 71.86it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:06<00:07, 71.86it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:06<00:07, 71.82it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:06<00:07, 71.82it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:06<00:07, 71.85it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:06<00:07, 71.86it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:06<00:07, 71.88it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:06<00:07, 71.90it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:06<00:07, 71.89it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:07<00:06, 71.87it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:07<00:06, 71.89it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:07<00:06, 71.91it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:07<00:06, 71.89it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:07<00:06, 71.89it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:07<00:06, 71.87it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:07<00:06, 71.88it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:07<00:06, 71.86it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:07<00:06, 71.83it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:08<00:05, 71.79it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:08<00:05, 71.83it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:08<00:05, 71.83it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:08<00:05, 71.84it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:08<00:05, 71.83it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:08<00:05, 71.84it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:08<00:05, 71.85it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:08<00:05, 71.85it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:08<00:05, 71.82it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:09<00:04, 71.82it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:09<00:04, 71.82it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:09<00:04, 71.81it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:09<00:04, 71.81it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:09<00:04, 71.79it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:09<00:04, 71.79it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:09<00:04, 71.80it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:09<00:04, 71.78it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:09<00:04, 71.80it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:10<00:03, 71.80it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:10<00:03, 71.81it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:10<00:03, 71.80it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:10<00:03, 71.79it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:10<00:03, 71.79it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:10<00:03, 71.79it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:10<00:03, 71.77it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:10<00:03, 71.78it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:10<00:03, 71.78it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:11<00:02, 71.78it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:11<00:02, 71.77it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:11<00:02, 71.80it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:11<00:02, 71.79it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:11<00:02, 71.80it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:11<00:02, 71.83it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:11<00:02, 71.83it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:11<00:02, 71.79it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:11<00:02, 71.77it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:12<00:01, 71.74it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:12<00:01, 71.75it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:12<00:01, 71.77it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:12<00:01, 71.77it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:12<00:01, 71.77it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:12<00:01, 71.80it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:12<00:01, 71.82it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:12<00:01, 71.83it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:12<00:01, 71.83it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:13<00:00, 71.84it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:13<00:00, 71.80it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:13<00:00, 71.81it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:13<00:00, 71.76it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:13<00:00, 71.77it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:13<00:00, 71.78it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:13<00:00, 71.81it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:13<00:00, 71.82it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:13<00:00, 71.80it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:13<00:00, 71.84it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 923.77 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_32:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 95.923 us +/- 5.204 us [93.460 us, 223.637 us]
        batches_per_second: 10.44 K +/- 383.86 [4.47 K, 10.70 K]
      metrics:
        batches_per_second_max: 10699.755102040815
        batches_per_second_mean: 10444.362812280708
        batches_per_second_min: 4471.539445628998
        batches_per_second_std: 383.86100370912084
        seconds_per_batch_max: 0.00022363662719726562
        seconds_per_batch_mean: 9.592342376708984e-05
        seconds_per_batch_min: 9.34600830078125e-05
        seconds_per_batch_std: 5.204114411658406e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.730 us +/- 0.504 us [22.888 us, 32.663 us]
        batches_per_second: 42.16 K +/- 750.69 [30.62 K, 43.69 K]
      metrics:
        batches_per_second_max: 43690.666666666664
        batches_per_second_mean: 42156.92524318441
        batches_per_second_min: 30615.357664233576
        batches_per_second_std: 750.6926773497194
        seconds_per_batch_max: 3.266334533691406e-05
        seconds_per_batch_mean: 2.3729801177978516e-05
        seconds_per_batch_min: 2.288818359375e-05
        seconds_per_batch_std: 5.042482492842989e-07
    on_device_inference:
      human_readable:
        batch_latency: -13569244.063 us +/- 38.258 ms [-14232128.143 us, -13474911.690
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.0702635607219448
        batches_per_second_mean: -0.07369665054782594
        batches_per_second_min: -0.07421198914127629
        batches_per_second_std: 0.00020491965233035582
        seconds_per_batch_max: -13.4749116897583
        seconds_per_batch_mean: -13.569244063377381
        seconds_per_batch_min: -14.232128143310547
        seconds_per_batch_std: 0.03825786137732623
    total:
      human_readable:
        batch_latency: 13.697 ms +/- 40.884 us [13.602 ms, 14.507 ms]
        batches_per_second: 73.01 +/- 0.21 [68.93, 73.52]
      metrics:
        batches_per_second_max: 73.51850099034198
        batches_per_second_mean: 73.00846123264753
        batches_per_second_min: 68.93424274796614
        batches_per_second_std: 0.21323244509398956
        seconds_per_batch_max: 0.01450657844543457
        seconds_per_batch_mean: 0.013697161912918091
        seconds_per_batch_min: 0.013602018356323242
        seconds_per_batch_std: 4.0884482932305105e-05
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.078 us +/- 5.293 us [145.912 us, 283.241 us]
        batches_per_second: 6.76 K +/- 170.36 [3.53 K, 6.85 K]
      metrics:
        batches_per_second_max: 6853.437908496732
        batches_per_second_mean: 6759.031039343864
        batches_per_second_min: 3530.5589225589224
        batches_per_second_std: 170.36258291960044
        seconds_per_batch_max: 0.00028324127197265625
        seconds_per_batch_mean: 0.00014807772636413574
        seconds_per_batch_min: 0.00014591217041015625
        seconds_per_batch_std: 5.29279639504871e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.961 us +/- 0.565 us [23.127 us, 31.233 us]
        batches_per_second: 41.75 K +/- 842.56 [32.02 K, 43.24 K]
      metrics:
        batches_per_second_max: 43240.24742268041
        batches_per_second_mean: 41753.70706388989
        batches_per_second_min: 32017.58778625954
        batches_per_second_std: 842.5550961674039
        seconds_per_batch_max: 3.123283386230469e-05
        seconds_per_batch_mean: 2.3961305618286134e-05
        seconds_per_batch_min: 2.3126602172851562e-05
        seconds_per_batch_std: 5.650067110033994e-07
    on_device_inference:
      human_readable:
        batch_latency: -13734728.126 us +/- 31.321 ms [-14344032.288 us, -13667615.891
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.06971540358736046
        batches_per_second_mean: -0.07280851170631603
        batches_per_second_min: -0.07316564995763887
        batches_per_second_std: 0.0001632939068855432
        seconds_per_batch_max: -13.66761589050293
        seconds_per_batch_mean: -13.734728125572204
        seconds_per_batch_min: -14.344032287597656
        seconds_per_batch_std: 0.031321388195097076
    total:
      human_readable:
        batch_latency: 13.912 ms +/- 34.613 us [13.844 ms, 14.664 ms]
        batches_per_second: 71.88 +/- 0.17 [68.19, 72.23]
      metrics:
        batches_per_second_max: 72.23338959115489
        batches_per_second_mean: 71.87953553654665
        batches_per_second_min: 68.19230331506984
        batches_per_second_std: 0.17447143112322566
        seconds_per_batch_max: 0.014664411544799805
        seconds_per_batch_mean: 0.013912249565124511
        seconds_per_batch_min: 0.013844013214111328
        seconds_per_batch_std: 3.4613226659719404e-05


#####
fp-fp-py-id - Run 3
2024-02-25 23:00:39
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.89it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.88it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 99.15it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 99.40it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 99.57it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 99.59it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 99.71it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 99.68it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:00<00:00, 99.67it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:00<00:00, 99.64it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:00<00:00, 99.66it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 99.64it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 99.61it/s]
STAGE:2024-02-25 23:00:09 6352:6352 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:00:09 6352:6352 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:00:09 6352:6352 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 74.68it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 75.04it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:12, 75.11it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:12, 75.17it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:12, 75.24it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 75.30it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 75.32it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 75.32it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 75.33it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 75.36it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 75.34it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:12, 75.29it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:11, 75.31it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:11, 75.34it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 75.35it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 75.36it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 75.37it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 75.34it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 75.30it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 75.31it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 75.31it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:10, 75.27it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:10, 75.29it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:10, 75.31it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 75.34it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 75.33it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 75.32it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:02<00:10, 75.33it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 75.31it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 75.28it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:09, 75.25it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:09, 75.27it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:09, 75.27it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 75.27it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 75.27it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 75.28it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:03<00:09, 75.32it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 75.31it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 75.32it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 75.30it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:08, 75.30it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:08, 75.32it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 75.32it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 75.33it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 75.32it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:04<00:08, 75.31it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:04<00:08, 75.24it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 75.23it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 74.63it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:08, 73.59it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:08, 72.85it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:08, 72.36it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 72.07it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 71.84it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:05<00:07, 71.68it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:05<00:07, 71.57it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 71.49it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 71.44it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 71.42it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:07, 71.39it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:07, 71.28it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:07, 71.19it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 71.17it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:06<00:06, 71.23it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:07<00:06, 71.23it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 71.36it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 71.43it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 71.50it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:06, 71.53it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:06, 71.56it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:06, 71.57it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 71.55it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 71.58it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:08<00:05, 71.60it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 71.62it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 71.64it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 71.67it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:05, 71.68it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:05, 71.61it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:05, 71.50it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 71.45it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 71.42it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:09<00:04, 71.36it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:09<00:04, 71.36it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 71.27it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 71.20it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 71.20it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 71.22it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:04, 71.23it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 71.22it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 71.22it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:10<00:03, 71.24it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:10<00:03, 71.28it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 71.31it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 71.30it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 71.28it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 71.26it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:03, 71.23it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 71.26it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 71.25it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:11<00:02, 71.26it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:11<00:02, 71.30it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 71.28it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 71.29it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 71.28it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 71.29it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:02, 71.26it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 71.24it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 71.26it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:12<00:01, 71.09it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 71.08it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 71.13it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 71.10it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 71.09it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 71.13it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:01, 71.16it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 71.19it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 71.23it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:13<00:00, 71.26it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:13<00:00, 71.21it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 71.25it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 71.25it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 71.26it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 71.25it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 71.26it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 72.80it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=32:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=32:   8%|▊         | 8/100 [00:00<00:01, 74.34it/s]Warming up with batch_size=32:  16%|█▌        | 16/100 [00:00<00:01, 74.54it/s]Warming up with batch_size=32:  24%|██▍       | 24/100 [00:00<00:01, 74.65it/s]Warming up with batch_size=32:  32%|███▏      | 32/100 [00:00<00:00, 74.72it/s]Warming up with batch_size=32:  40%|████      | 40/100 [00:00<00:00, 74.74it/s]Warming up with batch_size=32:  48%|████▊     | 48/100 [00:00<00:00, 74.73it/s]Warming up with batch_size=32:  56%|█████▌    | 56/100 [00:00<00:00, 74.76it/s]Warming up with batch_size=32:  64%|██████▍   | 64/100 [00:00<00:00, 74.76it/s]Warming up with batch_size=32:  72%|███████▏  | 72/100 [00:00<00:00, 74.77it/s]Warming up with batch_size=32:  80%|████████  | 80/100 [00:01<00:00, 74.75it/s]Warming up with batch_size=32:  88%|████████▊ | 88/100 [00:01<00:00, 74.77it/s]Warming up with batch_size=32:  96%|█████████▌| 96/100 [00:01<00:00, 74.75it/s]Warming up with batch_size=32: 100%|██████████| 100/100 [00:01<00:00, 74.72it/s]
STAGE:2024-02-25 23:00:25 6352:6352 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:00:25 6352:6352 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:00:25 6352:6352 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=32:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=32:   1%|          | 8/1000 [00:00<00:13, 73.31it/s]Measuring inference for batch_size=32:   2%|▏         | 16/1000 [00:00<00:13, 73.62it/s]Measuring inference for batch_size=32:   2%|▏         | 24/1000 [00:00<00:13, 73.76it/s]Measuring inference for batch_size=32:   3%|▎         | 32/1000 [00:00<00:13, 73.78it/s]Measuring inference for batch_size=32:   4%|▍         | 40/1000 [00:00<00:13, 73.84it/s]Measuring inference for batch_size=32:   5%|▍         | 48/1000 [00:00<00:12, 73.85it/s]Measuring inference for batch_size=32:   6%|▌         | 56/1000 [00:00<00:12, 73.90it/s]Measuring inference for batch_size=32:   6%|▋         | 64/1000 [00:00<00:12, 73.92it/s]Measuring inference for batch_size=32:   7%|▋         | 72/1000 [00:00<00:12, 73.92it/s]Measuring inference for batch_size=32:   8%|▊         | 80/1000 [00:01<00:12, 73.93it/s]Measuring inference for batch_size=32:   9%|▉         | 88/1000 [00:01<00:12, 73.93it/s]Measuring inference for batch_size=32:  10%|▉         | 96/1000 [00:01<00:12, 73.94it/s]Measuring inference for batch_size=32:  10%|█         | 104/1000 [00:01<00:12, 73.95it/s]Measuring inference for batch_size=32:  11%|█         | 112/1000 [00:01<00:12, 73.97it/s]Measuring inference for batch_size=32:  12%|█▏        | 120/1000 [00:01<00:11, 73.98it/s]Measuring inference for batch_size=32:  13%|█▎        | 128/1000 [00:01<00:11, 73.96it/s]Measuring inference for batch_size=32:  14%|█▎        | 136/1000 [00:01<00:11, 73.54it/s]Measuring inference for batch_size=32:  14%|█▍        | 144/1000 [00:01<00:11, 73.65it/s]Measuring inference for batch_size=32:  15%|█▌        | 152/1000 [00:02<00:11, 73.74it/s]Measuring inference for batch_size=32:  16%|█▌        | 160/1000 [00:02<00:11, 73.80it/s]Measuring inference for batch_size=32:  17%|█▋        | 168/1000 [00:02<00:11, 73.85it/s]Measuring inference for batch_size=32:  18%|█▊        | 176/1000 [00:02<00:11, 73.91it/s]Measuring inference for batch_size=32:  18%|█▊        | 184/1000 [00:02<00:11, 73.91it/s]Measuring inference for batch_size=32:  19%|█▉        | 192/1000 [00:02<00:10, 73.94it/s]Measuring inference for batch_size=32:  20%|██        | 200/1000 [00:02<00:10, 73.95it/s]Measuring inference for batch_size=32:  21%|██        | 208/1000 [00:02<00:10, 73.95it/s]Measuring inference for batch_size=32:  22%|██▏       | 216/1000 [00:02<00:10, 73.96it/s]Measuring inference for batch_size=32:  22%|██▏       | 224/1000 [00:03<00:10, 73.95it/s]Measuring inference for batch_size=32:  23%|██▎       | 232/1000 [00:03<00:10, 73.96it/s]Measuring inference for batch_size=32:  24%|██▍       | 240/1000 [00:03<00:10, 73.92it/s]Measuring inference for batch_size=32:  25%|██▍       | 248/1000 [00:03<00:10, 73.91it/s]Measuring inference for batch_size=32:  26%|██▌       | 256/1000 [00:03<00:10, 73.89it/s]Measuring inference for batch_size=32:  26%|██▋       | 264/1000 [00:03<00:09, 73.92it/s]Measuring inference for batch_size=32:  27%|██▋       | 272/1000 [00:03<00:09, 73.95it/s]Measuring inference for batch_size=32:  28%|██▊       | 280/1000 [00:03<00:09, 73.97it/s]Measuring inference for batch_size=32:  29%|██▉       | 288/1000 [00:03<00:09, 73.96it/s]Measuring inference for batch_size=32:  30%|██▉       | 296/1000 [00:04<00:09, 73.94it/s]Measuring inference for batch_size=32:  30%|███       | 304/1000 [00:04<00:09, 73.94it/s]Measuring inference for batch_size=32:  31%|███       | 312/1000 [00:04<00:09, 73.90it/s]Measuring inference for batch_size=32:  32%|███▏      | 320/1000 [00:04<00:09, 73.89it/s]Measuring inference for batch_size=32:  33%|███▎      | 328/1000 [00:04<00:09, 73.91it/s]Measuring inference for batch_size=32:  34%|███▎      | 336/1000 [00:04<00:08, 73.90it/s]Measuring inference for batch_size=32:  34%|███▍      | 344/1000 [00:04<00:08, 73.92it/s]Measuring inference for batch_size=32:  35%|███▌      | 352/1000 [00:04<00:08, 73.92it/s]Measuring inference for batch_size=32:  36%|███▌      | 360/1000 [00:04<00:08, 73.93it/s]Measuring inference for batch_size=32:  37%|███▋      | 368/1000 [00:04<00:08, 73.91it/s]Measuring inference for batch_size=32:  38%|███▊      | 376/1000 [00:05<00:08, 73.90it/s]Measuring inference for batch_size=32:  38%|███▊      | 384/1000 [00:05<00:08, 73.90it/s]Measuring inference for batch_size=32:  39%|███▉      | 392/1000 [00:05<00:08, 73.92it/s]Measuring inference for batch_size=32:  40%|████      | 400/1000 [00:05<00:08, 73.93it/s]Measuring inference for batch_size=32:  41%|████      | 408/1000 [00:05<00:08, 73.93it/s]Measuring inference for batch_size=32:  42%|████▏     | 416/1000 [00:05<00:07, 73.95it/s]Measuring inference for batch_size=32:  42%|████▏     | 424/1000 [00:05<00:07, 73.98it/s]Measuring inference for batch_size=32:  43%|████▎     | 432/1000 [00:05<00:07, 73.53it/s]Measuring inference for batch_size=32:  44%|████▍     | 440/1000 [00:05<00:07, 73.53it/s]Measuring inference for batch_size=32:  45%|████▍     | 448/1000 [00:06<00:07, 73.62it/s]Measuring inference for batch_size=32:  46%|████▌     | 456/1000 [00:06<00:07, 73.70it/s]Measuring inference for batch_size=32:  46%|████▋     | 464/1000 [00:06<00:07, 73.78it/s]Measuring inference for batch_size=32:  47%|████▋     | 472/1000 [00:06<00:07, 73.84it/s]Measuring inference for batch_size=32:  48%|████▊     | 480/1000 [00:06<00:07, 73.87it/s]Measuring inference for batch_size=32:  49%|████▉     | 488/1000 [00:06<00:06, 73.89it/s]Measuring inference for batch_size=32:  50%|████▉     | 496/1000 [00:06<00:06, 73.88it/s]Measuring inference for batch_size=32:  50%|█████     | 504/1000 [00:06<00:06, 73.90it/s]Measuring inference for batch_size=32:  51%|█████     | 512/1000 [00:06<00:06, 73.89it/s]Measuring inference for batch_size=32:  52%|█████▏    | 520/1000 [00:07<00:06, 73.89it/s]Measuring inference for batch_size=32:  53%|█████▎    | 528/1000 [00:07<00:06, 73.92it/s]Measuring inference for batch_size=32:  54%|█████▎    | 536/1000 [00:07<00:06, 73.95it/s]Measuring inference for batch_size=32:  54%|█████▍    | 544/1000 [00:07<00:06, 73.97it/s]Measuring inference for batch_size=32:  55%|█████▌    | 552/1000 [00:07<00:06, 73.97it/s]Measuring inference for batch_size=32:  56%|█████▌    | 560/1000 [00:07<00:05, 74.00it/s]Measuring inference for batch_size=32:  57%|█████▋    | 568/1000 [00:07<00:05, 73.99it/s]Measuring inference for batch_size=32:  58%|█████▊    | 576/1000 [00:07<00:05, 74.00it/s]Measuring inference for batch_size=32:  58%|█████▊    | 584/1000 [00:07<00:05, 74.02it/s]Measuring inference for batch_size=32:  59%|█████▉    | 592/1000 [00:08<00:05, 74.02it/s]Measuring inference for batch_size=32:  60%|██████    | 600/1000 [00:08<00:05, 74.01it/s]Measuring inference for batch_size=32:  61%|██████    | 608/1000 [00:08<00:05, 74.02it/s]Measuring inference for batch_size=32:  62%|██████▏   | 616/1000 [00:08<00:05, 73.99it/s]Measuring inference for batch_size=32:  62%|██████▏   | 624/1000 [00:08<00:05, 73.97it/s]Measuring inference for batch_size=32:  63%|██████▎   | 632/1000 [00:08<00:04, 73.96it/s]Measuring inference for batch_size=32:  64%|██████▍   | 640/1000 [00:08<00:04, 73.93it/s]Measuring inference for batch_size=32:  65%|██████▍   | 648/1000 [00:08<00:04, 73.93it/s]Measuring inference for batch_size=32:  66%|██████▌   | 656/1000 [00:08<00:04, 73.92it/s]Measuring inference for batch_size=32:  66%|██████▋   | 664/1000 [00:08<00:04, 73.91it/s]Measuring inference for batch_size=32:  67%|██████▋   | 672/1000 [00:09<00:04, 73.90it/s]Measuring inference for batch_size=32:  68%|██████▊   | 680/1000 [00:09<00:04, 73.89it/s]Measuring inference for batch_size=32:  69%|██████▉   | 688/1000 [00:09<00:04, 73.89it/s]Measuring inference for batch_size=32:  70%|██████▉   | 696/1000 [00:09<00:04, 73.90it/s]Measuring inference for batch_size=32:  70%|███████   | 704/1000 [00:09<00:04, 73.90it/s]Measuring inference for batch_size=32:  71%|███████   | 712/1000 [00:09<00:03, 73.92it/s]Measuring inference for batch_size=32:  72%|███████▏  | 720/1000 [00:09<00:03, 73.93it/s]Measuring inference for batch_size=32:  73%|███████▎  | 728/1000 [00:09<00:03, 73.89it/s]Measuring inference for batch_size=32:  74%|███████▎  | 736/1000 [00:09<00:03, 73.90it/s]Measuring inference for batch_size=32:  74%|███████▍  | 744/1000 [00:10<00:03, 73.92it/s]Measuring inference for batch_size=32:  75%|███████▌  | 752/1000 [00:10<00:03, 73.89it/s]Measuring inference for batch_size=32:  76%|███████▌  | 760/1000 [00:10<00:03, 73.89it/s]Measuring inference for batch_size=32:  77%|███████▋  | 768/1000 [00:10<00:03, 73.90it/s]Measuring inference for batch_size=32:  78%|███████▊  | 776/1000 [00:10<00:03, 73.89it/s]Measuring inference for batch_size=32:  78%|███████▊  | 784/1000 [00:10<00:02, 73.90it/s]Measuring inference for batch_size=32:  79%|███████▉  | 792/1000 [00:10<00:02, 73.91it/s]Measuring inference for batch_size=32:  80%|████████  | 800/1000 [00:10<00:02, 73.94it/s]Measuring inference for batch_size=32:  81%|████████  | 808/1000 [00:10<00:02, 73.93it/s]Measuring inference for batch_size=32:  82%|████████▏ | 816/1000 [00:11<00:02, 73.92it/s]Measuring inference for batch_size=32:  82%|████████▏ | 824/1000 [00:11<00:02, 73.92it/s]Measuring inference for batch_size=32:  83%|████████▎ | 832/1000 [00:11<00:02, 73.89it/s]Measuring inference for batch_size=32:  84%|████████▍ | 840/1000 [00:11<00:02, 73.90it/s]Measuring inference for batch_size=32:  85%|████████▍ | 848/1000 [00:11<00:02, 73.89it/s]Measuring inference for batch_size=32:  86%|████████▌ | 856/1000 [00:11<00:01, 73.88it/s]Measuring inference for batch_size=32:  86%|████████▋ | 864/1000 [00:11<00:01, 73.87it/s]Measuring inference for batch_size=32:  87%|████████▋ | 872/1000 [00:11<00:01, 73.87it/s]Measuring inference for batch_size=32:  88%|████████▊ | 880/1000 [00:11<00:01, 73.87it/s]Measuring inference for batch_size=32:  89%|████████▉ | 888/1000 [00:12<00:01, 73.87it/s]Measuring inference for batch_size=32:  90%|████████▉ | 896/1000 [00:12<00:01, 73.86it/s]Measuring inference for batch_size=32:  90%|█████████ | 904/1000 [00:12<00:01, 73.86it/s]Measuring inference for batch_size=32:  91%|█████████ | 912/1000 [00:12<00:01, 73.87it/s]Measuring inference for batch_size=32:  92%|█████████▏| 920/1000 [00:12<00:01, 73.85it/s]Measuring inference for batch_size=32:  93%|█████████▎| 928/1000 [00:12<00:00, 73.84it/s]Measuring inference for batch_size=32:  94%|█████████▎| 936/1000 [00:12<00:00, 73.85it/s]Measuring inference for batch_size=32:  94%|█████████▍| 944/1000 [00:12<00:00, 73.85it/s]Measuring inference for batch_size=32:  95%|█████████▌| 952/1000 [00:12<00:00, 73.86it/s]Measuring inference for batch_size=32:  96%|█████████▌| 960/1000 [00:12<00:00, 73.87it/s]Measuring inference for batch_size=32:  97%|█████████▋| 968/1000 [00:13<00:00, 73.86it/s]Measuring inference for batch_size=32:  98%|█████████▊| 976/1000 [00:13<00:00, 73.84it/s]Measuring inference for batch_size=32:  98%|█████████▊| 984/1000 [00:13<00:00, 73.84it/s]Measuring inference for batch_size=32:  99%|█████████▉| 992/1000 [00:13<00:00, 73.85it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:13<00:00, 73.87it/s]Measuring inference for batch_size=32: 100%|██████████| 1000/1000 [00:13<00:00, 73.89it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.97 GB
    total: 31.28 GB
    used: 929.26 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_32:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 93.827 us +/- 5.211 us [90.599 us, 220.060 us]
        batches_per_second: 10.68 K +/- 407.81 [4.54 K, 11.04 K]
      metrics:
        batches_per_second_max: 11037.642105263158
        batches_per_second_mean: 10678.958605417552
        batches_per_second_min: 4544.208017334778
        batches_per_second_std: 407.8096708408872
        seconds_per_batch_max: 0.0002200603485107422
        seconds_per_batch_mean: 9.38270092010498e-05
        seconds_per_batch_min: 9.059906005859375e-05
        seconds_per_batch_std: 5.210722340268741e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.452 us +/- 0.816 us [22.411 us, 30.279 us]
        batches_per_second: 42.69 K +/- 1.30 K [33.03 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 42685.78545301697
        batches_per_second_min: 33026.015748031496
        batches_per_second_std: 1304.8578454010074
        seconds_per_batch_max: 3.0279159545898438e-05
        seconds_per_batch_mean: 2.3451805114746095e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 8.161268209507596e-07
    on_device_inference:
      human_readable:
        batch_latency: -13603123.706 us +/- 362.401 ms [-14103615.761 us, -13086015.701
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07090380346146416
        batches_per_second_mean: -0.07356535006852824
        batches_per_second_min: -0.07641745377862569
        batches_per_second_std: 0.0019828121656934837
        seconds_per_batch_max: -13.086015701293945
        seconds_per_batch_mean: -13.603123705863952
        seconds_per_batch_min: -14.103615760803223
        seconds_per_batch_std: 0.3624011059551489
    total:
      human_readable:
        batch_latency: 13.728 ms +/- 364.574 us [13.206 ms, 14.229 ms]
        batches_per_second: 72.90 +/- 1.96 [70.28, 75.72]
      metrics:
        batches_per_second_max: 75.72312691821628
        batches_per_second_mean: 72.89678884010267
        batches_per_second_min: 70.28107039327067
        batches_per_second_std: 1.9585586166490894
        seconds_per_batch_max: 0.014228582382202148
        seconds_per_batch_mean: 0.01372782039642334
        seconds_per_batch_min: 0.013206005096435547
        seconds_per_batch_std: 0.0003645744403560066
  batch_size_32:
    cpu_to_gpu:
      human_readable:
        batch_latency: 143.350 us +/- 5.495 us [140.667 us, 285.149 us]
        batches_per_second: 6.98 K +/- 184.12 [3.51 K, 7.11 K]
      metrics:
        batches_per_second_max: 7108.989830508474
        batches_per_second_mean: 6982.64803318254
        batches_per_second_min: 3506.943143812709
        batches_per_second_std: 184.1155068707361
        seconds_per_batch_max: 0.00028514862060546875
        seconds_per_batch_mean: 0.00014334988594055177
        seconds_per_batch_min: 0.00014066696166992188
        seconds_per_batch_std: 5.4953439130466335e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.057 us +/- 0.436 us [22.411 us, 28.849 us]
        batches_per_second: 43.38 K +/- 753.69 [34.66 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 43384.55739608757
        batches_per_second_min: 34663.669421487604
        batches_per_second_std: 753.6890662264002
        seconds_per_batch_max: 2.8848648071289062e-05
        seconds_per_batch_mean: 2.305722236633301e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 4.3639842602182176e-07
    on_device_inference:
      human_readable:
        batch_latency: -13353897.563 us +/- 65.196 ms [-14054207.802 us, -13278207.779
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07115306775744297
        batches_per_second_mean: -0.07488622165057157
        batches_per_second_min: -0.07531136857089708
        batches_per_second_std: 0.0003518092917620236
        seconds_per_batch_max: -13.278207778930664
        seconds_per_batch_mean: -13.353897562980652
        seconds_per_batch_min: -14.054207801818848
        seconds_per_batch_std: 0.06519646441873772
    total:
      human_readable:
        batch_latency: 13.526 ms +/- 67.010 us [13.448 ms, 14.326 ms]
        batches_per_second: 73.94 +/- 0.35 [69.80, 74.36]
      metrics:
        batches_per_second_max: 74.36049995567768
        batches_per_second_mean: 73.93529773563075
        batches_per_second_min: 69.80152773386143
        batches_per_second_std: 0.3519313438568492
        seconds_per_batch_max: 0.014326333999633789
        seconds_per_batch_mean: 0.01352565836906433
        seconds_per_batch_min: 0.013447999954223633
        seconds_per_batch_std: 6.700976664938476e-05


