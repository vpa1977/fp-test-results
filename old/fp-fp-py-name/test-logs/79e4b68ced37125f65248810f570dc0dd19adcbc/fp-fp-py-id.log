#####
fp-fp-py-id - Run 1
2024-02-25 23:02:25
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.85it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.84it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 98.96it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 99.15it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 99.41it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 99.61it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 99.72it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 99.78it/s]Warming up with batch_size=1:  71%|███████   | 71/100 [00:00<00:00, 99.87it/s]Warming up with batch_size=1:  82%|████████▏ | 82/100 [00:00<00:00, 99.92it/s]Warming up with batch_size=1:  92%|█████████▏| 92/100 [00:00<00:00, 99.93it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 99.75it/s]
STAGE:2024-02-25 23:01:54 6542:6542 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:01:54 6542:6542 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:01:54 6542:6542 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 74.69it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 75.03it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:12, 75.18it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:12, 75.29it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:12, 75.29it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 75.31it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 75.30it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 75.30it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 75.33it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 75.35it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 75.39it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:11, 75.36it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:11, 75.36it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:11, 75.35it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 75.35it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 75.37it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 75.36it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 75.35it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 75.37it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 75.36it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 75.38it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:10, 75.38it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:10, 75.38it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:10, 75.38it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 75.38it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 75.36it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 75.38it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:02<00:10, 75.36it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 75.35it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 75.37it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:09, 75.36it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:09, 75.36it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:09, 75.34it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 75.33it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 75.34it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 75.37it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:03<00:09, 75.38it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 75.42it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 75.42it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 75.41it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:08, 75.39it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:08, 75.38it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 75.38it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 75.38it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 75.36it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:04<00:08, 75.37it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:04<00:08, 75.32it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 75.33it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 75.33it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:07, 75.31it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:07, 75.35it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:07, 75.35it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 75.36it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 75.38it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:05<00:07, 75.39it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:05<00:07, 75.40it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 75.39it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 75.41it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 75.40it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:06, 75.40it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:06, 75.39it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:06, 75.41it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 75.42it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:06<00:06, 75.43it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:06<00:06, 75.43it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 75.43it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 75.41it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 75.41it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:05, 75.41it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:05, 75.39it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:05, 75.37it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 75.38it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 75.38it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:07<00:05, 75.38it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:07<00:05, 75.37it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 75.37it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 75.36it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:04, 75.39it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:04, 75.37it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:04, 75.35it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 75.37it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 75.38it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:08<00:04, 75.39it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:08<00:04, 75.42it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 75.41it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 75.41it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 75.41it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:03, 75.43it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:03, 75.42it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 75.41it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 75.40it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:09<00:03, 75.44it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:09<00:03, 75.44it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:09<00:03, 75.45it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 75.42it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 75.42it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:02, 75.36it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:02, 75.34it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 75.32it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 75.29it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:10<00:02, 75.28it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:10<00:02, 75.27it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:10<00:02, 75.26it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 75.29it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 75.29it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 75.30it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:01, 75.29it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 75.32it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 75.31it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:11<00:01, 75.32it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:11<00:01, 75.32it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:11<00:01, 75.33it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:11<00:01, 75.34it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 75.35it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 75.34it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:00, 75.34it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 75.33it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 75.33it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:12<00:00, 75.32it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:12<00:00, 75.33it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:12<00:00, 75.34it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:12<00:00, 75.37it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 75.33it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 75.37it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 75.34it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 75.36it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=64:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=64:   8%|▊         | 8/100 [00:00<00:01, 74.45it/s]Warming up with batch_size=64:  16%|█▌        | 16/100 [00:00<00:01, 74.62it/s]Warming up with batch_size=64:  24%|██▍       | 24/100 [00:00<00:01, 74.64it/s]Warming up with batch_size=64:  32%|███▏      | 32/100 [00:00<00:00, 74.72it/s]Warming up with batch_size=64:  40%|████      | 40/100 [00:00<00:00, 74.75it/s]Warming up with batch_size=64:  48%|████▊     | 48/100 [00:00<00:00, 74.78it/s]Warming up with batch_size=64:  56%|█████▌    | 56/100 [00:00<00:00, 74.77it/s]Warming up with batch_size=64:  64%|██████▍   | 64/100 [00:00<00:00, 74.72it/s]Warming up with batch_size=64:  72%|███████▏  | 72/100 [00:00<00:00, 74.70it/s]Warming up with batch_size=64:  80%|████████  | 80/100 [00:01<00:00, 74.68it/s]Warming up with batch_size=64:  88%|████████▊ | 88/100 [00:01<00:00, 74.67it/s]Warming up with batch_size=64:  96%|█████████▌| 96/100 [00:01<00:00, 74.66it/s]Warming up with batch_size=64: 100%|██████████| 100/100 [00:01<00:00, 74.69it/s]
STAGE:2024-02-25 23:02:09 6542:6542 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:02:09 6542:6542 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:02:09 6542:6542 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=64:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=64:   1%|          | 8/1000 [00:00<00:13, 73.58it/s]Measuring inference for batch_size=64:   2%|▏         | 16/1000 [00:00<00:13, 73.88it/s]Measuring inference for batch_size=64:   2%|▏         | 24/1000 [00:00<00:13, 73.99it/s]Measuring inference for batch_size=64:   3%|▎         | 32/1000 [00:00<00:13, 74.03it/s]Measuring inference for batch_size=64:   4%|▍         | 40/1000 [00:00<00:12, 74.08it/s]Measuring inference for batch_size=64:   5%|▍         | 48/1000 [00:00<00:12, 74.08it/s]Measuring inference for batch_size=64:   6%|▌         | 56/1000 [00:00<00:12, 74.07it/s]Measuring inference for batch_size=64:   6%|▋         | 64/1000 [00:00<00:12, 74.05it/s]Measuring inference for batch_size=64:   7%|▋         | 72/1000 [00:00<00:12, 74.08it/s]Measuring inference for batch_size=64:   8%|▊         | 80/1000 [00:01<00:12, 74.05it/s]Measuring inference for batch_size=64:   9%|▉         | 88/1000 [00:01<00:12, 74.10it/s]Measuring inference for batch_size=64:  10%|▉         | 96/1000 [00:01<00:12, 74.11it/s]Measuring inference for batch_size=64:  10%|█         | 104/1000 [00:01<00:12, 74.11it/s]Measuring inference for batch_size=64:  11%|█         | 112/1000 [00:01<00:11, 74.12it/s]Measuring inference for batch_size=64:  12%|█▏        | 120/1000 [00:01<00:11, 74.14it/s]Measuring inference for batch_size=64:  13%|█▎        | 128/1000 [00:01<00:11, 74.13it/s]Measuring inference for batch_size=64:  14%|█▎        | 136/1000 [00:01<00:11, 74.13it/s]Measuring inference for batch_size=64:  14%|█▍        | 144/1000 [00:01<00:11, 74.10it/s]Measuring inference for batch_size=64:  15%|█▌        | 152/1000 [00:02<00:11, 74.12it/s]Measuring inference for batch_size=64:  16%|█▌        | 160/1000 [00:02<00:11, 74.11it/s]Measuring inference for batch_size=64:  17%|█▋        | 168/1000 [00:02<00:11, 74.12it/s]Measuring inference for batch_size=64:  18%|█▊        | 176/1000 [00:02<00:11, 74.12it/s]Measuring inference for batch_size=64:  18%|█▊        | 184/1000 [00:02<00:11, 74.14it/s]Measuring inference for batch_size=64:  19%|█▉        | 192/1000 [00:02<00:10, 74.15it/s]Measuring inference for batch_size=64:  20%|██        | 200/1000 [00:02<00:10, 74.17it/s]Measuring inference for batch_size=64:  21%|██        | 208/1000 [00:02<00:10, 74.13it/s]Measuring inference for batch_size=64:  22%|██▏       | 216/1000 [00:02<00:10, 74.14it/s]Measuring inference for batch_size=64:  22%|██▏       | 224/1000 [00:03<00:10, 74.12it/s]Measuring inference for batch_size=64:  23%|██▎       | 232/1000 [00:03<00:10, 74.13it/s]Measuring inference for batch_size=64:  24%|██▍       | 240/1000 [00:03<00:10, 74.11it/s]Measuring inference for batch_size=64:  25%|██▍       | 248/1000 [00:03<00:10, 74.13it/s]Measuring inference for batch_size=64:  26%|██▌       | 256/1000 [00:03<00:10, 74.14it/s]Measuring inference for batch_size=64:  26%|██▋       | 264/1000 [00:03<00:09, 74.14it/s]Measuring inference for batch_size=64:  27%|██▋       | 272/1000 [00:03<00:09, 74.09it/s]Measuring inference for batch_size=64:  28%|██▊       | 280/1000 [00:03<00:09, 74.08it/s]Measuring inference for batch_size=64:  29%|██▉       | 288/1000 [00:03<00:09, 74.08it/s]Measuring inference for batch_size=64:  30%|██▉       | 296/1000 [00:03<00:09, 74.06it/s]Measuring inference for batch_size=64:  30%|███       | 304/1000 [00:04<00:09, 74.06it/s]Measuring inference for batch_size=64:  31%|███       | 312/1000 [00:04<00:09, 74.07it/s]Measuring inference for batch_size=64:  32%|███▏      | 320/1000 [00:04<00:09, 74.05it/s]Measuring inference for batch_size=64:  33%|███▎      | 328/1000 [00:04<00:09, 74.06it/s]Measuring inference for batch_size=64:  34%|███▎      | 336/1000 [00:04<00:08, 74.05it/s]Measuring inference for batch_size=64:  34%|███▍      | 344/1000 [00:04<00:08, 74.04it/s]Measuring inference for batch_size=64:  35%|███▌      | 352/1000 [00:04<00:08, 74.01it/s]Measuring inference for batch_size=64:  36%|███▌      | 360/1000 [00:04<00:08, 74.01it/s]Measuring inference for batch_size=64:  37%|███▋      | 368/1000 [00:04<00:08, 73.99it/s]Measuring inference for batch_size=64:  38%|███▊      | 376/1000 [00:05<00:08, 74.03it/s]Measuring inference for batch_size=64:  38%|███▊      | 384/1000 [00:05<00:08, 74.04it/s]Measuring inference for batch_size=64:  39%|███▉      | 392/1000 [00:05<00:08, 74.06it/s]Measuring inference for batch_size=64:  40%|████      | 400/1000 [00:05<00:08, 74.07it/s]Measuring inference for batch_size=64:  41%|████      | 408/1000 [00:05<00:07, 74.08it/s]Measuring inference for batch_size=64:  42%|████▏     | 416/1000 [00:05<00:07, 74.09it/s]Measuring inference for batch_size=64:  42%|████▏     | 424/1000 [00:05<00:07, 74.08it/s]Measuring inference for batch_size=64:  43%|████▎     | 432/1000 [00:05<00:07, 74.08it/s]Measuring inference for batch_size=64:  44%|████▍     | 440/1000 [00:05<00:07, 74.07it/s]Measuring inference for batch_size=64:  45%|████▍     | 448/1000 [00:06<00:07, 74.09it/s]Measuring inference for batch_size=64:  46%|████▌     | 456/1000 [00:06<00:07, 74.11it/s]Measuring inference for batch_size=64:  46%|████▋     | 464/1000 [00:06<00:07, 74.08it/s]Measuring inference for batch_size=64:  47%|████▋     | 472/1000 [00:06<00:07, 74.09it/s]Measuring inference for batch_size=64:  48%|████▊     | 480/1000 [00:06<00:07, 74.08it/s]Measuring inference for batch_size=64:  49%|████▉     | 488/1000 [00:06<00:06, 74.05it/s]Measuring inference for batch_size=64:  50%|████▉     | 496/1000 [00:06<00:06, 74.05it/s]Measuring inference for batch_size=64:  50%|█████     | 504/1000 [00:06<00:06, 74.04it/s]Measuring inference for batch_size=64:  51%|█████     | 512/1000 [00:06<00:06, 74.05it/s]Measuring inference for batch_size=64:  52%|█████▏    | 520/1000 [00:07<00:06, 74.04it/s]Measuring inference for batch_size=64:  53%|█████▎    | 528/1000 [00:07<00:06, 74.05it/s]Measuring inference for batch_size=64:  54%|█████▎    | 536/1000 [00:07<00:06, 74.03it/s]Measuring inference for batch_size=64:  54%|█████▍    | 544/1000 [00:07<00:06, 74.03it/s]Measuring inference for batch_size=64:  55%|█████▌    | 552/1000 [00:07<00:06, 74.06it/s]Measuring inference for batch_size=64:  56%|█████▌    | 560/1000 [00:07<00:05, 74.08it/s]Measuring inference for batch_size=64:  57%|█████▋    | 568/1000 [00:07<00:05, 74.06it/s]Measuring inference for batch_size=64:  58%|█████▊    | 576/1000 [00:07<00:05, 74.06it/s]Measuring inference for batch_size=64:  58%|█████▊    | 584/1000 [00:07<00:05, 74.03it/s]Measuring inference for batch_size=64:  59%|█████▉    | 592/1000 [00:07<00:05, 74.00it/s]Measuring inference for batch_size=64:  60%|██████    | 600/1000 [00:08<00:05, 74.00it/s]Measuring inference for batch_size=64:  61%|██████    | 608/1000 [00:08<00:05, 74.04it/s]Measuring inference for batch_size=64:  62%|██████▏   | 616/1000 [00:08<00:05, 74.05it/s]Measuring inference for batch_size=64:  62%|██████▏   | 624/1000 [00:08<00:05, 74.06it/s]Measuring inference for batch_size=64:  63%|██████▎   | 632/1000 [00:08<00:04, 74.03it/s]Measuring inference for batch_size=64:  64%|██████▍   | 640/1000 [00:08<00:04, 74.04it/s]Measuring inference for batch_size=64:  65%|██████▍   | 648/1000 [00:08<00:04, 74.01it/s]Measuring inference for batch_size=64:  66%|██████▌   | 656/1000 [00:08<00:04, 73.74it/s]Measuring inference for batch_size=64:  66%|██████▋   | 664/1000 [00:08<00:04, 73.78it/s]Measuring inference for batch_size=64:  67%|██████▋   | 672/1000 [00:09<00:04, 73.79it/s]Measuring inference for batch_size=64:  68%|██████▊   | 680/1000 [00:09<00:04, 73.80it/s]Measuring inference for batch_size=64:  69%|██████▉   | 688/1000 [00:09<00:04, 73.84it/s]Measuring inference for batch_size=64:  70%|██████▉   | 696/1000 [00:09<00:04, 73.87it/s]Measuring inference for batch_size=64:  70%|███████   | 704/1000 [00:09<00:04, 73.85it/s]Measuring inference for batch_size=64:  71%|███████   | 712/1000 [00:09<00:03, 73.87it/s]Measuring inference for batch_size=64:  72%|███████▏  | 720/1000 [00:09<00:03, 73.90it/s]Measuring inference for batch_size=64:  73%|███████▎  | 728/1000 [00:09<00:03, 73.92it/s]Measuring inference for batch_size=64:  74%|███████▎  | 736/1000 [00:09<00:03, 73.89it/s]Measuring inference for batch_size=64:  74%|███████▍  | 744/1000 [00:10<00:03, 73.90it/s]Measuring inference for batch_size=64:  75%|███████▌  | 752/1000 [00:10<00:03, 73.90it/s]Measuring inference for batch_size=64:  76%|███████▌  | 760/1000 [00:10<00:03, 73.91it/s]Measuring inference for batch_size=64:  77%|███████▋  | 768/1000 [00:10<00:03, 73.90it/s]Measuring inference for batch_size=64:  78%|███████▊  | 776/1000 [00:10<00:03, 73.89it/s]Measuring inference for batch_size=64:  78%|███████▊  | 784/1000 [00:10<00:02, 73.90it/s]Measuring inference for batch_size=64:  79%|███████▉  | 792/1000 [00:10<00:02, 73.90it/s]Measuring inference for batch_size=64:  80%|████████  | 800/1000 [00:10<00:02, 73.89it/s]Measuring inference for batch_size=64:  81%|████████  | 808/1000 [00:10<00:02, 73.88it/s]Measuring inference for batch_size=64:  82%|████████▏ | 816/1000 [00:11<00:02, 73.86it/s]Measuring inference for batch_size=64:  82%|████████▏ | 824/1000 [00:11<00:02, 73.82it/s]Measuring inference for batch_size=64:  83%|████████▎ | 832/1000 [00:11<00:02, 73.81it/s]Measuring inference for batch_size=64:  84%|████████▍ | 840/1000 [00:11<00:02, 73.85it/s]Measuring inference for batch_size=64:  85%|████████▍ | 848/1000 [00:11<00:02, 73.84it/s]Measuring inference for batch_size=64:  86%|████████▌ | 856/1000 [00:11<00:01, 73.82it/s]Measuring inference for batch_size=64:  86%|████████▋ | 864/1000 [00:11<00:01, 73.83it/s]Measuring inference for batch_size=64:  87%|████████▋ | 872/1000 [00:11<00:01, 73.83it/s]Measuring inference for batch_size=64:  88%|████████▊ | 880/1000 [00:11<00:01, 73.84it/s]Measuring inference for batch_size=64:  89%|████████▉ | 888/1000 [00:11<00:01, 73.82it/s]Measuring inference for batch_size=64:  90%|████████▉ | 896/1000 [00:12<00:01, 73.78it/s]Measuring inference for batch_size=64:  90%|█████████ | 904/1000 [00:12<00:01, 73.78it/s]Measuring inference for batch_size=64:  91%|█████████ | 912/1000 [00:12<00:01, 73.76it/s]Measuring inference for batch_size=64:  92%|█████████▏| 920/1000 [00:12<00:01, 73.76it/s]Measuring inference for batch_size=64:  93%|█████████▎| 928/1000 [00:12<00:00, 73.76it/s]Measuring inference for batch_size=64:  94%|█████████▎| 936/1000 [00:12<00:00, 73.73it/s]Measuring inference for batch_size=64:  94%|█████████▍| 944/1000 [00:12<00:00, 73.73it/s]Measuring inference for batch_size=64:  95%|█████████▌| 952/1000 [00:12<00:00, 73.13it/s]Measuring inference for batch_size=64:  96%|█████████▌| 960/1000 [00:12<00:00, 72.52it/s]Measuring inference for batch_size=64:  97%|█████████▋| 968/1000 [00:13<00:00, 72.10it/s]Measuring inference for batch_size=64:  98%|█████████▊| 976/1000 [00:13<00:00, 71.85it/s]Measuring inference for batch_size=64:  98%|█████████▊| 984/1000 [00:13<00:00, 71.62it/s]Measuring inference for batch_size=64:  99%|█████████▉| 992/1000 [00:13<00:00, 71.44it/s]Measuring inference for batch_size=64: 100%|██████████| 1000/1000 [00:13<00:00, 71.90it/s]Measuring inference for batch_size=64: 100%|██████████| 1000/1000 [00:13<00:00, 73.85it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 921.55 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_64:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 92.708 us +/- 4.983 us [90.599 us, 218.153 us]
        batches_per_second: 10.81 K +/- 384.33 [4.58 K, 11.04 K]
      metrics:
        batches_per_second_max: 11037.642105263158
        batches_per_second_mean: 10805.72502792947
        batches_per_second_min: 4583.938797814208
        batches_per_second_std: 384.32855843282283
        seconds_per_batch_max: 0.0002181529998779297
        seconds_per_batch_mean: 9.270787239074708e-05
        seconds_per_batch_min: 9.059906005859375e-05
        seconds_per_batch_std: 4.983284673106369e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.159 us +/- 0.607 us [22.173 us, 30.041 us]
        batches_per_second: 43.21 K +/- 959.64 [33.29 K, 45.10 K]
      metrics:
        batches_per_second_max: 45100.04301075269
        batches_per_second_mean: 43205.21197892432
        batches_per_second_min: 33288.12698412698
        batches_per_second_std: 959.6362387140252
        seconds_per_batch_max: 3.0040740966796875e-05
        seconds_per_batch_mean: 2.3158788681030275e-05
        seconds_per_batch_min: 2.2172927856445312e-05
        seconds_per_batch_std: 6.074190004076767e-07
    on_device_inference:
      human_readable:
        batch_latency: -13139311.041 us +/- 31.113 ms [-13802559.853 us, -13066880.226
          us]
        batches_per_second: -0.08 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.0724503288287949
        batches_per_second_mean: -0.0761079085308244
        batches_per_second_min: -0.07652936146149758
        batches_per_second_std: 0.00017627642063751755
        seconds_per_batch_max: -13.066880226135254
        seconds_per_batch_mean: -13.139311040878296
        seconds_per_batch_min: -13.802559852600098
        seconds_per_batch_std: 0.031112834687392985
    total:
      human_readable:
        batch_latency: 13.262 ms +/- 34.900 us [13.188 ms, 14.069 ms]
        batches_per_second: 75.40 +/- 0.19 [71.08, 75.82]
      metrics:
        batches_per_second_max: 75.82442692891749
        batches_per_second_mean: 75.40392327604663
        batches_per_second_min: 71.08026030368764
        batches_per_second_std: 0.19237420086908116
        seconds_per_batch_max: 0.014068603515625
        seconds_per_batch_mean: 0.013261998414993287
        seconds_per_batch_min: 0.013188362121582031
        seconds_per_batch_std: 3.489980362664241e-05
  batch_size_64:
    cpu_to_gpu:
      human_readable:
        batch_latency: 143.363 us +/- 5.437 us [140.905 us, 283.480 us]
        batches_per_second: 6.98 K +/- 182.79 [3.53 K, 7.10 K]
      metrics:
        batches_per_second_max: 7096.961082910321
        batches_per_second_mean: 6981.907002610626
        batches_per_second_min: 3527.5895710681243
        batches_per_second_std: 182.7856200929163
        seconds_per_batch_max: 0.0002834796905517578
        seconds_per_batch_mean: 0.00014336276054382325
        seconds_per_batch_min: 0.00014090538024902344
        seconds_per_batch_std: 5.436919939259553e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.422 us +/- 0.524 us [22.411 us, 29.802 us]
        batches_per_second: 42.71 K +/- 853.40 [33.55 K, 44.62 K]
      metrics:
        batches_per_second_max: 44620.255319148935
        batches_per_second_mean: 42713.43773512989
        batches_per_second_min: 33554.432
        batches_per_second_std: 853.396358840736
        seconds_per_batch_max: 2.9802322387695312e-05
        seconds_per_batch_mean: 2.34222412109375e-05
        seconds_per_batch_min: 2.2411346435546875e-05
        seconds_per_batch_std: 5.236748895565665e-07
    on_device_inference:
      human_readable:
        batch_latency: -13361641.390 us +/- 125.146 ms [-13971199.989 us, -13260928.154
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07157581315595742
        batches_per_second_mean: -0.07484745274061472
        batches_per_second_min: -0.07540950289358049
        batches_per_second_std: 0.0006778225787668499
        seconds_per_batch_max: -13.2609281539917
        seconds_per_batch_mean: -13.361641389846802
        seconds_per_batch_min: -13.971199989318848
        seconds_per_batch_std: 0.12514595594573488
    total:
      human_readable:
        batch_latency: 13.534 ms +/- 126.614 us [13.431 ms, 14.233 ms]
        batches_per_second: 73.89 +/- 0.67 [70.26, 74.46]
      metrics:
        batches_per_second_max: 74.45686288432863
        batches_per_second_mean: 73.8946174674858
        batches_per_second_min: 70.25987905589896
        batches_per_second_std: 0.668365316443027
        seconds_per_batch_max: 0.014232873916625977
        seconds_per_batch_mean: 0.01353393054008484
        seconds_per_batch_min: 0.013430595397949219
        seconds_per_batch_std: 0.00012661424599136917


#####
fp-fp-py-id - Run 2
2024-02-25 23:03:03
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 97.30it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 97.72it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 97.90it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 97.98it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 98.05it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 98.08it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:00<00:00, 98.01it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:00<00:00, 97.96it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:00<00:00, 97.88it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 97.81it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 97.88it/s]
STAGE:2024-02-25 23:02:31 6588:6588 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:02:31 6588:6588 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:02:31 6588:6588 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 72.95it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 73.32it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:13, 73.47it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:13, 73.53it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:13, 73.55it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 73.59it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 73.57it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 73.61it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 73.60it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 73.60it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 73.63it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:12, 73.63it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:12, 73.61it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:12, 73.61it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 73.61it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 73.59it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 73.55it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 73.54it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 73.52it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 73.54it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 73.55it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:11, 73.54it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:11, 73.58it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:10, 73.59it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 73.60it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 73.61it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 73.62it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:03<00:10, 73.62it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 73.61it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 73.60it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:10, 73.59it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:10, 73.58it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:10, 73.55it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 73.53it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 73.51it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 73.49it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:04<00:09, 73.47it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 73.45it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 73.42it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 73.39it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:09, 73.34it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:09, 73.30it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 73.30it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 73.31it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 73.32it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:05<00:08, 73.35it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:05<00:08, 73.36it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 73.37it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 73.40it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:08, 73.38it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:08, 73.42it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:07, 73.44it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 73.43it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 73.44it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:05<00:07, 73.44it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:06<00:07, 73.44it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 73.46it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 73.45it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 73.46it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:07, 73.43it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:06, 73.42it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:06, 73.40it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 73.41it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:06<00:06, 73.42it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:07<00:06, 73.41it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 73.44it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 73.47it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 73.46it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:06, 73.49it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:05, 73.50it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:05, 73.50it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 73.50it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 73.50it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:08<00:05, 73.52it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 73.53it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 73.49it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 73.52it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:05, 73.49it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:05, 73.48it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:04, 73.46it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 73.45it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 73.45it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:09<00:04, 73.43it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:09<00:04, 73.38it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 73.36it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 73.38it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 73.42it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 73.44it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:03, 73.46it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 73.44it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 73.47it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:10<00:03, 73.44it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:10<00:03, 73.43it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 73.35it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 73.37it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 73.38it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 73.37it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:02, 73.36it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 73.36it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 73.35it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:10<00:02, 73.35it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:11<00:02, 73.37it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 73.38it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 73.40it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 73.37it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 73.36it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:01, 73.37it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 73.38it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 73.40it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:11<00:01, 73.38it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 73.38it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 73.41it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 73.38it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 73.38it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 73.39it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:00, 73.38it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 73.38it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 73.39it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:12<00:00, 73.37it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:13<00:00, 73.40it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 73.43it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 73.46it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 73.48it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 73.47it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 73.47it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 73.46it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=64:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=64:   8%|▊         | 8/100 [00:00<00:01, 72.76it/s]Warming up with batch_size=64:  16%|█▌        | 16/100 [00:00<00:01, 72.89it/s]Warming up with batch_size=64:  24%|██▍       | 24/100 [00:00<00:01, 72.94it/s]Warming up with batch_size=64:  32%|███▏      | 32/100 [00:00<00:00, 72.96it/s]Warming up with batch_size=64:  40%|████      | 40/100 [00:00<00:00, 72.95it/s]Warming up with batch_size=64:  48%|████▊     | 48/100 [00:00<00:00, 72.97it/s]Warming up with batch_size=64:  56%|█████▌    | 56/100 [00:00<00:00, 73.01it/s]Warming up with batch_size=64:  64%|██████▍   | 64/100 [00:00<00:00, 73.00it/s]Warming up with batch_size=64:  72%|███████▏  | 72/100 [00:00<00:00, 73.01it/s]Warming up with batch_size=64:  80%|████████  | 80/100 [00:01<00:00, 73.00it/s]Warming up with batch_size=64:  88%|████████▊ | 88/100 [00:01<00:00, 73.01it/s]Warming up with batch_size=64:  96%|█████████▌| 96/100 [00:01<00:00, 72.99it/s]Warming up with batch_size=64: 100%|██████████| 100/100 [00:01<00:00, 72.97it/s]
STAGE:2024-02-25 23:02:47 6588:6588 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:02:47 6588:6588 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:02:47 6588:6588 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=64:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=64:   1%|          | 8/1000 [00:00<00:13, 71.65it/s]Measuring inference for batch_size=64:   2%|▏         | 16/1000 [00:00<00:13, 70.86it/s]Measuring inference for batch_size=64:   2%|▏         | 24/1000 [00:00<00:13, 71.58it/s]Measuring inference for batch_size=64:   3%|▎         | 32/1000 [00:00<00:13, 71.96it/s]Measuring inference for batch_size=64:   4%|▍         | 40/1000 [00:00<00:13, 72.18it/s]Measuring inference for batch_size=64:   5%|▍         | 48/1000 [00:00<00:13, 72.28it/s]Measuring inference for batch_size=64:   6%|▌         | 56/1000 [00:00<00:13, 72.38it/s]Measuring inference for batch_size=64:   6%|▋         | 64/1000 [00:00<00:12, 72.42it/s]Measuring inference for batch_size=64:   7%|▋         | 72/1000 [00:00<00:12, 72.44it/s]Measuring inference for batch_size=64:   8%|▊         | 80/1000 [00:01<00:12, 72.46it/s]Measuring inference for batch_size=64:   9%|▉         | 88/1000 [00:01<00:12, 72.46it/s]Measuring inference for batch_size=64:  10%|▉         | 96/1000 [00:01<00:12, 72.43it/s]Measuring inference for batch_size=64:  10%|█         | 104/1000 [00:01<00:12, 72.44it/s]Measuring inference for batch_size=64:  11%|█         | 112/1000 [00:01<00:12, 72.47it/s]Measuring inference for batch_size=64:  12%|█▏        | 120/1000 [00:01<00:12, 72.48it/s]Measuring inference for batch_size=64:  13%|█▎        | 128/1000 [00:01<00:12, 72.47it/s]Measuring inference for batch_size=64:  14%|█▎        | 136/1000 [00:01<00:11, 72.45it/s]Measuring inference for batch_size=64:  14%|█▍        | 144/1000 [00:01<00:11, 72.43it/s]Measuring inference for batch_size=64:  15%|█▌        | 152/1000 [00:02<00:11, 72.43it/s]Measuring inference for batch_size=64:  16%|█▌        | 160/1000 [00:02<00:11, 72.45it/s]Measuring inference for batch_size=64:  17%|█▋        | 168/1000 [00:02<00:11, 72.45it/s]Measuring inference for batch_size=64:  18%|█▊        | 176/1000 [00:02<00:11, 72.44it/s]Measuring inference for batch_size=64:  18%|█▊        | 184/1000 [00:02<00:11, 72.44it/s]Measuring inference for batch_size=64:  19%|█▉        | 192/1000 [00:02<00:11, 72.46it/s]Measuring inference for batch_size=64:  20%|██        | 200/1000 [00:02<00:11, 72.45it/s]Measuring inference for batch_size=64:  21%|██        | 208/1000 [00:02<00:10, 72.46it/s]Measuring inference for batch_size=64:  22%|██▏       | 216/1000 [00:02<00:10, 72.46it/s]Measuring inference for batch_size=64:  22%|██▏       | 224/1000 [00:03<00:10, 72.44it/s]Measuring inference for batch_size=64:  23%|██▎       | 232/1000 [00:03<00:10, 72.45it/s]Measuring inference for batch_size=64:  24%|██▍       | 240/1000 [00:03<00:10, 72.42it/s]Measuring inference for batch_size=64:  25%|██▍       | 248/1000 [00:03<00:10, 72.41it/s]Measuring inference for batch_size=64:  26%|██▌       | 256/1000 [00:03<00:10, 72.44it/s]Measuring inference for batch_size=64:  26%|██▋       | 264/1000 [00:03<00:10, 72.43it/s]Measuring inference for batch_size=64:  27%|██▋       | 272/1000 [00:03<00:10, 72.43it/s]Measuring inference for batch_size=64:  28%|██▊       | 280/1000 [00:03<00:09, 72.43it/s]Measuring inference for batch_size=64:  29%|██▉       | 288/1000 [00:03<00:09, 72.43it/s]Measuring inference for batch_size=64:  30%|██▉       | 296/1000 [00:04<00:09, 72.45it/s]Measuring inference for batch_size=64:  30%|███       | 304/1000 [00:04<00:09, 72.47it/s]Measuring inference for batch_size=64:  31%|███       | 312/1000 [00:04<00:09, 72.47it/s]Measuring inference for batch_size=64:  32%|███▏      | 320/1000 [00:04<00:09, 72.48it/s]Measuring inference for batch_size=64:  33%|███▎      | 328/1000 [00:04<00:09, 72.46it/s]Measuring inference for batch_size=64:  34%|███▎      | 336/1000 [00:04<00:09, 72.45it/s]Measuring inference for batch_size=64:  34%|███▍      | 344/1000 [00:04<00:09, 72.46it/s]Measuring inference for batch_size=64:  35%|███▌      | 352/1000 [00:04<00:08, 72.46it/s]Measuring inference for batch_size=64:  36%|███▌      | 360/1000 [00:04<00:08, 72.44it/s]Measuring inference for batch_size=64:  37%|███▋      | 368/1000 [00:05<00:08, 72.45it/s]Measuring inference for batch_size=64:  38%|███▊      | 376/1000 [00:05<00:08, 72.46it/s]Measuring inference for batch_size=64:  38%|███▊      | 384/1000 [00:05<00:08, 72.46it/s]Measuring inference for batch_size=64:  39%|███▉      | 392/1000 [00:05<00:08, 72.45it/s]Measuring inference for batch_size=64:  40%|████      | 400/1000 [00:05<00:08, 72.44it/s]Measuring inference for batch_size=64:  41%|████      | 408/1000 [00:05<00:08, 72.43it/s]Measuring inference for batch_size=64:  42%|████▏     | 416/1000 [00:05<00:08, 72.45it/s]Measuring inference for batch_size=64:  42%|████▏     | 424/1000 [00:05<00:07, 72.46it/s]Measuring inference for batch_size=64:  43%|████▎     | 432/1000 [00:05<00:07, 72.44it/s]Measuring inference for batch_size=64:  44%|████▍     | 440/1000 [00:06<00:07, 72.44it/s]Measuring inference for batch_size=64:  45%|████▍     | 448/1000 [00:06<00:07, 72.43it/s]Measuring inference for batch_size=64:  46%|████▌     | 456/1000 [00:06<00:07, 72.42it/s]Measuring inference for batch_size=64:  46%|████▋     | 464/1000 [00:06<00:07, 72.44it/s]Measuring inference for batch_size=64:  47%|████▋     | 472/1000 [00:06<00:07, 72.43it/s]Measuring inference for batch_size=64:  48%|████▊     | 480/1000 [00:06<00:07, 72.45it/s]Measuring inference for batch_size=64:  49%|████▉     | 488/1000 [00:06<00:07, 72.45it/s]Measuring inference for batch_size=64:  50%|████▉     | 496/1000 [00:06<00:06, 72.45it/s]Measuring inference for batch_size=64:  50%|█████     | 504/1000 [00:06<00:06, 72.45it/s]Measuring inference for batch_size=64:  51%|█████     | 512/1000 [00:07<00:06, 72.44it/s]Measuring inference for batch_size=64:  52%|█████▏    | 520/1000 [00:07<00:06, 72.47it/s]Measuring inference for batch_size=64:  53%|█████▎    | 528/1000 [00:07<00:06, 72.48it/s]Measuring inference for batch_size=64:  54%|█████▎    | 536/1000 [00:07<00:06, 72.51it/s]Measuring inference for batch_size=64:  54%|█████▍    | 544/1000 [00:07<00:06, 72.53it/s]Measuring inference for batch_size=64:  55%|█████▌    | 552/1000 [00:07<00:06, 72.53it/s]Measuring inference for batch_size=64:  56%|█████▌    | 560/1000 [00:07<00:06, 72.54it/s]Measuring inference for batch_size=64:  57%|█████▋    | 568/1000 [00:07<00:05, 72.55it/s]Measuring inference for batch_size=64:  58%|█████▊    | 576/1000 [00:07<00:05, 72.56it/s]Measuring inference for batch_size=64:  58%|█████▊    | 584/1000 [00:08<00:05, 72.56it/s]Measuring inference for batch_size=64:  59%|█████▉    | 592/1000 [00:08<00:05, 72.24it/s]Measuring inference for batch_size=64:  60%|██████    | 600/1000 [00:08<00:05, 72.29it/s]Measuring inference for batch_size=64:  61%|██████    | 608/1000 [00:08<00:05, 72.35it/s]Measuring inference for batch_size=64:  62%|██████▏   | 616/1000 [00:08<00:05, 72.38it/s]Measuring inference for batch_size=64:  62%|██████▏   | 624/1000 [00:08<00:05, 72.39it/s]Measuring inference for batch_size=64:  63%|██████▎   | 632/1000 [00:08<00:05, 72.39it/s]Measuring inference for batch_size=64:  64%|██████▍   | 640/1000 [00:08<00:04, 72.40it/s]Measuring inference for batch_size=64:  65%|██████▍   | 648/1000 [00:08<00:04, 72.43it/s]Measuring inference for batch_size=64:  66%|██████▌   | 656/1000 [00:09<00:04, 72.40it/s]Measuring inference for batch_size=64:  66%|██████▋   | 664/1000 [00:09<00:04, 72.43it/s]Measuring inference for batch_size=64:  67%|██████▋   | 672/1000 [00:09<00:04, 72.45it/s]Measuring inference for batch_size=64:  68%|██████▊   | 680/1000 [00:09<00:04, 72.46it/s]Measuring inference for batch_size=64:  69%|██████▉   | 688/1000 [00:09<00:04, 72.47it/s]Measuring inference for batch_size=64:  70%|██████▉   | 696/1000 [00:09<00:04, 72.46it/s]Measuring inference for batch_size=64:  70%|███████   | 704/1000 [00:09<00:04, 72.45it/s]Measuring inference for batch_size=64:  71%|███████   | 712/1000 [00:09<00:03, 72.45it/s]Measuring inference for batch_size=64:  72%|███████▏  | 720/1000 [00:09<00:03, 72.47it/s]Measuring inference for batch_size=64:  73%|███████▎  | 728/1000 [00:10<00:03, 72.49it/s]Measuring inference for batch_size=64:  74%|███████▎  | 736/1000 [00:10<00:03, 72.51it/s]Measuring inference for batch_size=64:  74%|███████▍  | 744/1000 [00:10<00:03, 72.52it/s]Measuring inference for batch_size=64:  75%|███████▌  | 752/1000 [00:10<00:03, 72.50it/s]Measuring inference for batch_size=64:  76%|███████▌  | 760/1000 [00:10<00:03, 72.49it/s]Measuring inference for batch_size=64:  77%|███████▋  | 768/1000 [00:10<00:03, 72.50it/s]Measuring inference for batch_size=64:  78%|███████▊  | 776/1000 [00:10<00:03, 72.51it/s]Measuring inference for batch_size=64:  78%|███████▊  | 784/1000 [00:10<00:02, 72.51it/s]Measuring inference for batch_size=64:  79%|███████▉  | 792/1000 [00:10<00:02, 72.51it/s]Measuring inference for batch_size=64:  80%|████████  | 800/1000 [00:11<00:02, 72.52it/s]Measuring inference for batch_size=64:  81%|████████  | 808/1000 [00:11<00:02, 72.51it/s]Measuring inference for batch_size=64:  82%|████████▏ | 816/1000 [00:11<00:02, 72.52it/s]Measuring inference for batch_size=64:  82%|████████▏ | 824/1000 [00:11<00:02, 72.52it/s]Measuring inference for batch_size=64:  83%|████████▎ | 832/1000 [00:11<00:02, 72.53it/s]Measuring inference for batch_size=64:  84%|████████▍ | 840/1000 [00:11<00:02, 72.50it/s]Measuring inference for batch_size=64:  85%|████████▍ | 848/1000 [00:11<00:02, 72.47it/s]Measuring inference for batch_size=64:  86%|████████▌ | 856/1000 [00:11<00:01, 72.45it/s]Measuring inference for batch_size=64:  86%|████████▋ | 864/1000 [00:11<00:01, 72.46it/s]Measuring inference for batch_size=64:  87%|████████▋ | 872/1000 [00:12<00:01, 72.46it/s]Measuring inference for batch_size=64:  88%|████████▊ | 880/1000 [00:12<00:01, 72.02it/s]Measuring inference for batch_size=64:  89%|████████▉ | 888/1000 [00:12<00:01, 71.17it/s]Measuring inference for batch_size=64:  90%|████████▉ | 896/1000 [00:12<00:01, 70.66it/s]Measuring inference for batch_size=64:  90%|█████████ | 904/1000 [00:12<00:01, 70.58it/s]Measuring inference for batch_size=64:  91%|█████████ | 912/1000 [00:12<00:01, 71.09it/s]Measuring inference for batch_size=64:  92%|█████████▏| 920/1000 [00:12<00:01, 71.46it/s]Measuring inference for batch_size=64:  93%|█████████▎| 928/1000 [00:12<00:01, 71.73it/s]Measuring inference for batch_size=64:  94%|█████████▎| 936/1000 [00:12<00:00, 71.94it/s]Measuring inference for batch_size=64:  94%|█████████▍| 944/1000 [00:13<00:00, 72.11it/s]Measuring inference for batch_size=64:  95%|█████████▌| 952/1000 [00:13<00:00, 72.21it/s]Measuring inference for batch_size=64:  96%|█████████▌| 960/1000 [00:13<00:00, 72.29it/s]Measuring inference for batch_size=64:  97%|█████████▋| 968/1000 [00:13<00:00, 72.35it/s]Measuring inference for batch_size=64:  98%|█████████▊| 976/1000 [00:13<00:00, 72.41it/s]Measuring inference for batch_size=64:  98%|█████████▊| 984/1000 [00:13<00:00, 72.43it/s]Measuring inference for batch_size=64:  99%|█████████▉| 992/1000 [00:13<00:00, 72.45it/s]Measuring inference for batch_size=64: 100%|██████████| 1000/1000 [00:13<00:00, 72.46it/s]Measuring inference for batch_size=64: 100%|██████████| 1000/1000 [00:13<00:00, 72.36it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 924.59 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_64:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.040 us +/- 5.250 us [91.553 us, 226.021 us]
        batches_per_second: 10.65 K +/- 391.62 [4.42 K, 10.92 K]
      metrics:
        batches_per_second_max: 10922.666666666666
        batches_per_second_mean: 10654.006210844605
        batches_per_second_min: 4424.371308016877
        batches_per_second_std: 391.6187581411702
        seconds_per_batch_max: 0.00022602081298828125
        seconds_per_batch_mean: 9.40396785736084e-05
        seconds_per_batch_min: 9.1552734375e-05
        seconds_per_batch_std: 5.24960268276603e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.419 us +/- 0.545 us [22.650 us, 29.802 us]
        batches_per_second: 42.72 K +/- 863.87 [33.55 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42720.1255934485
        batches_per_second_min: 33554.432
        batches_per_second_std: 863.8691466307988
        seconds_per_batch_max: 2.9802322387695312e-05
        seconds_per_batch_mean: 2.341914176940918e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 5.450079236102951e-07
    on_device_inference:
      human_readable:
        batch_latency: -13479775.305 us +/- 35.517 ms [-14153951.645 us, -13401696.205
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.07065164733415652
        batches_per_second_mean: -0.0741857187654801
        batches_per_second_min: -0.07461742041403155
        batches_per_second_std: 0.000192064827862326
        seconds_per_batch_max: -13.40169620513916
        seconds_per_batch_mean: -13.47977530479431
        seconds_per_batch_min: -14.153951644897461
        seconds_per_batch_std: 0.03551708600255697
    total:
      human_readable:
        batch_latency: 13.605 ms +/- 38.661 us [13.525 ms, 14.430 ms]
        batches_per_second: 73.50 +/- 0.20 [69.30, 73.94]
      metrics:
        batches_per_second_max: 73.9358000317298
        batches_per_second_mean: 73.50069574338748
        batches_per_second_min: 69.30099301092147
        batches_per_second_std: 0.20343318879520358
        seconds_per_batch_max: 0.014429807662963867
        seconds_per_batch_mean: 0.013605420351028442
        seconds_per_batch_min: 0.013525247573852539
        seconds_per_batch_std: 3.866112242996573e-05
  batch_size_64:
    cpu_to_gpu:
      human_readable:
        batch_latency: 144.785 us +/- 5.822 us [142.097 us, 286.341 us]
        batches_per_second: 6.91 K +/- 199.43 [3.49 K, 7.04 K]
      metrics:
        batches_per_second_max: 7037.422818791946
        batches_per_second_mean: 6914.421168388592
        batches_per_second_min: 3492.3430474604497
        batches_per_second_std: 199.42550074714052
        seconds_per_batch_max: 0.00028634071350097656
        seconds_per_batch_mean: 0.00014478540420532227
        seconds_per_batch_min: 0.00014209747314453125
        seconds_per_batch_std: 5.821598435381345e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.605 us +/- 0.870 us [22.650 us, 39.101 us]
        batches_per_second: 42.41 K +/- 1.22 K [25.58 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42408.1009180981
        batches_per_second_min: 25575.024390243903
        batches_per_second_std: 1224.332426297157
        seconds_per_batch_max: 3.910064697265625e-05
        seconds_per_batch_mean: 2.36051082611084e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 8.701772217872055e-07
    on_device_inference:
      human_readable:
        batch_latency: -13638758.588 us +/- 111.643 ms [-14315999.985 us, -13560832.024
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.06985191401689408
        batches_per_second_mean: -0.07332518355317089
        batches_per_second_min: -0.07374178798603023
        batches_per_second_std: 0.0005775484277467371
        seconds_per_batch_max: -13.560832023620605
        seconds_per_batch_mean: -13.63875858783722
        seconds_per_batch_min: -14.315999984741211
        seconds_per_batch_std: 0.1116429202296854
    total:
      human_readable:
        batch_latency: 13.813 ms +/- 113.143 us [13.733 ms, 14.518 ms]
        batches_per_second: 72.40 +/- 0.57 [68.88, 72.82]
      metrics:
        batches_per_second_max: 72.8190419972569
        batches_per_second_mean: 72.40218186644117
        batches_per_second_min: 68.8787729497159
        batches_per_second_std: 0.5706441963094905
        seconds_per_batch_max: 0.014518260955810547
        seconds_per_batch_mean: 0.01381263017654419
        seconds_per_batch_min: 0.013732671737670898
        seconds_per_batch_std: 0.00011314323801022184


#####
fp-fp-py-id - Run 3
2024-02-25 23:03:39
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.86it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 99.78it/s]Warming up with batch_size=1:  21%|██        | 21/100 [00:00<00:00, 100.05it/s]Warming up with batch_size=1:  32%|███▏      | 32/100 [00:00<00:00, 100.25it/s]Warming up with batch_size=1:  43%|████▎     | 43/100 [00:00<00:00, 100.39it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:00<00:00, 100.48it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:00<00:00, 100.54it/s]Warming up with batch_size=1:  76%|███████▌  | 76/100 [00:00<00:00, 100.58it/s]Warming up with batch_size=1:  87%|████████▋ | 87/100 [00:00<00:00, 100.59it/s]Warming up with batch_size=1:  98%|█████████▊| 98/100 [00:00<00:00, 100.55it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:00<00:00, 100.46it/s]
STAGE:2024-02-25 23:03:09 6634:6634 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:03:09 6634:6634 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:03:09 6634:6634 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 75.37it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 75.68it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:12, 75.81it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:12, 75.85it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:12, 75.89it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 75.96it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 76.00it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 76.02it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 76.01it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 75.98it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:11, 76.01it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:11, 76.01it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:11, 75.99it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:11, 76.00it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 76.02it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 76.00it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 76.00it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 75.99it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 76.00it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 76.02it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:10, 76.00it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:10, 75.99it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:10, 76.03it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:10, 76.06it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 76.09it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 76.06it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 76.04it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:02<00:10, 76.03it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 76.03it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:09, 76.07it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:09, 76.08it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:09, 76.10it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:09, 76.13it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 76.13it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 76.10it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 76.08it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:03<00:09, 76.07it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:03<00:09, 76.07it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 76.11it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:08, 76.09it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:08, 76.08it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:08, 76.11it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 76.10it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 76.10it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 76.08it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:04<00:08, 76.08it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:04<00:08, 76.05it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 76.05it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:07, 76.06it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:07, 76.07it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:07, 75.87it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:07, 74.39it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 73.37it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 72.67it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:05<00:07, 72.13it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:05<00:07, 71.84it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 71.64it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 71.45it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 71.35it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:07, 71.27it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:07, 71.18it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:07, 71.13it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 71.12it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:06<00:06, 71.11it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:06<00:06, 71.09it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 71.08it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 71.08it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 71.09it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:06, 71.07it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:06, 71.06it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:06, 71.08it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 71.10it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 71.06it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:07<00:05, 70.97it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 70.90it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 70.92it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 70.97it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:05, 71.00it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:05, 71.00it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:05, 71.04it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 71.09it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 71.08it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:08<00:04, 71.07it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:09<00:04, 71.02it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 71.04it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 71.05it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 71.01it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 71.02it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:04, 71.03it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 70.97it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 71.01it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:09<00:03, 71.01it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:10<00:03, 71.03it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 71.02it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 71.00it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 71.00it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 70.99it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:03, 70.96it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 70.99it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 71.00it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:10<00:02, 71.03it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:11<00:02, 71.06it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 71.07it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 71.08it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 71.08it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 71.05it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:02, 71.07it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 71.05it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 71.06it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:12<00:01, 71.07it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 71.06it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 71.05it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 71.07it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 71.04it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 71.01it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:01, 71.03it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 71.03it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 71.04it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:13<00:00, 71.00it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:13<00:00, 70.99it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 71.00it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 70.99it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 70.99it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 71.00it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 71.03it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 72.99it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=64:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=64:   8%|▊         | 8/100 [00:00<00:01, 75.12it/s]Warming up with batch_size=64:  16%|█▌        | 16/100 [00:00<00:01, 75.32it/s]Warming up with batch_size=64:  24%|██▍       | 24/100 [00:00<00:01, 75.37it/s]Warming up with batch_size=64:  32%|███▏      | 32/100 [00:00<00:00, 75.42it/s]Warming up with batch_size=64:  40%|████      | 40/100 [00:00<00:00, 75.41it/s]Warming up with batch_size=64:  48%|████▊     | 48/100 [00:00<00:00, 75.43it/s]Warming up with batch_size=64:  56%|█████▌    | 56/100 [00:00<00:00, 75.42it/s]Warming up with batch_size=64:  64%|██████▍   | 64/100 [00:00<00:00, 75.43it/s]Warming up with batch_size=64:  72%|███████▏  | 72/100 [00:00<00:00, 75.40it/s]Warming up with batch_size=64:  80%|████████  | 80/100 [00:01<00:00, 75.42it/s]Warming up with batch_size=64:  88%|████████▊ | 88/100 [00:01<00:00, 75.45it/s]Warming up with batch_size=64:  96%|█████████▌| 96/100 [00:01<00:00, 75.41it/s]Warming up with batch_size=64: 100%|██████████| 100/100 [00:01<00:00, 75.40it/s]
STAGE:2024-02-25 23:03:25 6634:6634 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 23:03:25 6634:6634 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 23:03:25 6634:6634 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=64:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=64:   1%|          | 8/1000 [00:00<00:13, 74.20it/s]Measuring inference for batch_size=64:   2%|▏         | 16/1000 [00:00<00:13, 74.55it/s]Measuring inference for batch_size=64:   2%|▏         | 24/1000 [00:00<00:13, 74.62it/s]Measuring inference for batch_size=64:   3%|▎         | 32/1000 [00:00<00:12, 74.63it/s]Measuring inference for batch_size=64:   4%|▍         | 40/1000 [00:00<00:12, 74.62it/s]Measuring inference for batch_size=64:   5%|▍         | 48/1000 [00:00<00:12, 74.63it/s]Measuring inference for batch_size=64:   6%|▌         | 56/1000 [00:00<00:12, 74.61it/s]Measuring inference for batch_size=64:   6%|▋         | 64/1000 [00:00<00:12, 74.61it/s]Measuring inference for batch_size=64:   7%|▋         | 72/1000 [00:00<00:12, 74.62it/s]Measuring inference for batch_size=64:   8%|▊         | 80/1000 [00:01<00:12, 74.62it/s]Measuring inference for batch_size=64:   9%|▉         | 88/1000 [00:01<00:12, 74.62it/s]Measuring inference for batch_size=64:  10%|▉         | 96/1000 [00:01<00:12, 74.63it/s]Measuring inference for batch_size=64:  10%|█         | 104/1000 [00:01<00:12, 74.63it/s]Measuring inference for batch_size=64:  11%|█         | 112/1000 [00:01<00:11, 74.59it/s]Measuring inference for batch_size=64:  12%|█▏        | 120/1000 [00:01<00:11, 74.63it/s]Measuring inference for batch_size=64:  13%|█▎        | 128/1000 [00:01<00:11, 74.67it/s]Measuring inference for batch_size=64:  14%|█▎        | 136/1000 [00:01<00:11, 74.69it/s]Measuring inference for batch_size=64:  14%|█▍        | 144/1000 [00:01<00:11, 74.68it/s]Measuring inference for batch_size=64:  15%|█▌        | 152/1000 [00:02<00:11, 74.65it/s]Measuring inference for batch_size=64:  16%|█▌        | 160/1000 [00:02<00:11, 74.65it/s]Measuring inference for batch_size=64:  17%|█▋        | 168/1000 [00:02<00:11, 74.67it/s]Measuring inference for batch_size=64:  18%|█▊        | 176/1000 [00:02<00:11, 74.68it/s]Measuring inference for batch_size=64:  18%|█▊        | 184/1000 [00:02<00:10, 74.64it/s]Measuring inference for batch_size=64:  19%|█▉        | 192/1000 [00:02<00:10, 74.63it/s]Measuring inference for batch_size=64:  20%|██        | 200/1000 [00:02<00:10, 74.62it/s]Measuring inference for batch_size=64:  21%|██        | 208/1000 [00:02<00:10, 74.62it/s]Measuring inference for batch_size=64:  22%|██▏       | 216/1000 [00:02<00:10, 74.61it/s]Measuring inference for batch_size=64:  22%|██▏       | 224/1000 [00:03<00:10, 74.64it/s]Measuring inference for batch_size=64:  23%|██▎       | 232/1000 [00:03<00:10, 74.62it/s]Measuring inference for batch_size=64:  24%|██▍       | 240/1000 [00:03<00:10, 74.63it/s]Measuring inference for batch_size=64:  25%|██▍       | 248/1000 [00:03<00:10, 74.64it/s]Measuring inference for batch_size=64:  26%|██▌       | 256/1000 [00:03<00:09, 74.66it/s]Measuring inference for batch_size=64:  26%|██▋       | 264/1000 [00:03<00:09, 74.66it/s]Measuring inference for batch_size=64:  27%|██▋       | 272/1000 [00:03<00:09, 74.66it/s]Measuring inference for batch_size=64:  28%|██▊       | 280/1000 [00:03<00:09, 74.66it/s]Measuring inference for batch_size=64:  29%|██▉       | 288/1000 [00:03<00:09, 74.63it/s]Measuring inference for batch_size=64:  30%|██▉       | 296/1000 [00:03<00:09, 74.63it/s]Measuring inference for batch_size=64:  30%|███       | 304/1000 [00:04<00:09, 74.58it/s]Measuring inference for batch_size=64:  31%|███       | 312/1000 [00:04<00:09, 74.58it/s]Measuring inference for batch_size=64:  32%|███▏      | 320/1000 [00:04<00:09, 74.60it/s]Measuring inference for batch_size=64:  33%|███▎      | 328/1000 [00:04<00:09, 74.62it/s]Measuring inference for batch_size=64:  34%|███▎      | 336/1000 [00:04<00:08, 74.61it/s]Measuring inference for batch_size=64:  34%|███▍      | 344/1000 [00:04<00:08, 74.64it/s]Measuring inference for batch_size=64:  35%|███▌      | 352/1000 [00:04<00:08, 74.63it/s]Measuring inference for batch_size=64:  36%|███▌      | 360/1000 [00:04<00:08, 74.60it/s]Measuring inference for batch_size=64:  37%|███▋      | 368/1000 [00:04<00:08, 74.56it/s]Measuring inference for batch_size=64:  38%|███▊      | 376/1000 [00:05<00:08, 74.55it/s]Measuring inference for batch_size=64:  38%|███▊      | 384/1000 [00:05<00:08, 74.54it/s]Measuring inference for batch_size=64:  39%|███▉      | 392/1000 [00:05<00:08, 74.52it/s]Measuring inference for batch_size=64:  40%|████      | 400/1000 [00:05<00:08, 74.53it/s]Measuring inference for batch_size=64:  41%|████      | 408/1000 [00:05<00:07, 74.57it/s]Measuring inference for batch_size=64:  42%|████▏     | 416/1000 [00:05<00:07, 74.58it/s]Measuring inference for batch_size=64:  42%|████▏     | 424/1000 [00:05<00:07, 74.59it/s]Measuring inference for batch_size=64:  43%|████▎     | 432/1000 [00:05<00:07, 74.61it/s]Measuring inference for batch_size=64:  44%|████▍     | 440/1000 [00:05<00:07, 74.63it/s]Measuring inference for batch_size=64:  45%|████▍     | 448/1000 [00:06<00:07, 74.64it/s]Measuring inference for batch_size=64:  46%|████▌     | 456/1000 [00:06<00:07, 74.66it/s]Measuring inference for batch_size=64:  46%|████▋     | 464/1000 [00:06<00:07, 74.67it/s]Measuring inference for batch_size=64:  47%|████▋     | 472/1000 [00:06<00:07, 74.67it/s]Measuring inference for batch_size=64:  48%|████▊     | 480/1000 [00:06<00:06, 74.64it/s]Measuring inference for batch_size=64:  49%|████▉     | 488/1000 [00:06<00:06, 74.62it/s]Measuring inference for batch_size=64:  50%|████▉     | 496/1000 [00:06<00:06, 74.62it/s]Measuring inference for batch_size=64:  50%|█████     | 504/1000 [00:06<00:06, 74.64it/s]Measuring inference for batch_size=64:  51%|█████     | 512/1000 [00:06<00:06, 74.65it/s]Measuring inference for batch_size=64:  52%|█████▏    | 520/1000 [00:06<00:06, 74.60it/s]Measuring inference for batch_size=64:  53%|█████▎    | 528/1000 [00:07<00:06, 74.62it/s]Measuring inference for batch_size=64:  54%|█████▎    | 536/1000 [00:07<00:06, 74.63it/s]Measuring inference for batch_size=64:  54%|█████▍    | 544/1000 [00:07<00:06, 74.59it/s]Measuring inference for batch_size=64:  55%|█████▌    | 552/1000 [00:07<00:06, 74.57it/s]Measuring inference for batch_size=64:  56%|█████▌    | 560/1000 [00:07<00:05, 74.57it/s]Measuring inference for batch_size=64:  57%|█████▋    | 568/1000 [00:07<00:05, 74.57it/s]Measuring inference for batch_size=64:  58%|█████▊    | 576/1000 [00:07<00:05, 74.58it/s]Measuring inference for batch_size=64:  58%|█████▊    | 584/1000 [00:07<00:05, 74.58it/s]Measuring inference for batch_size=64:  59%|█████▉    | 592/1000 [00:07<00:05, 74.59it/s]Measuring inference for batch_size=64:  60%|██████    | 600/1000 [00:08<00:05, 74.56it/s]Measuring inference for batch_size=64:  61%|██████    | 608/1000 [00:08<00:05, 74.57it/s]Measuring inference for batch_size=64:  62%|██████▏   | 616/1000 [00:08<00:05, 74.57it/s]Measuring inference for batch_size=64:  62%|██████▏   | 624/1000 [00:08<00:05, 74.57it/s]Measuring inference for batch_size=64:  63%|██████▎   | 632/1000 [00:08<00:04, 74.57it/s]Measuring inference for batch_size=64:  64%|██████▍   | 640/1000 [00:08<00:04, 74.56it/s]Measuring inference for batch_size=64:  65%|██████▍   | 648/1000 [00:08<00:04, 74.55it/s]Measuring inference for batch_size=64:  66%|██████▌   | 656/1000 [00:08<00:04, 74.56it/s]Measuring inference for batch_size=64:  66%|██████▋   | 664/1000 [00:08<00:04, 74.52it/s]Measuring inference for batch_size=64:  67%|██████▋   | 672/1000 [00:09<00:04, 74.54it/s]Measuring inference for batch_size=64:  68%|██████▊   | 680/1000 [00:09<00:04, 74.60it/s]Measuring inference for batch_size=64:  69%|██████▉   | 688/1000 [00:09<00:04, 74.65it/s]Measuring inference for batch_size=64:  70%|██████▉   | 696/1000 [00:09<00:04, 74.63it/s]Measuring inference for batch_size=64:  70%|███████   | 704/1000 [00:09<00:03, 74.64it/s]Measuring inference for batch_size=64:  71%|███████   | 712/1000 [00:09<00:03, 74.64it/s]Measuring inference for batch_size=64:  72%|███████▏  | 720/1000 [00:09<00:03, 74.62it/s]Measuring inference for batch_size=64:  73%|███████▎  | 728/1000 [00:09<00:03, 74.60it/s]Measuring inference for batch_size=64:  74%|███████▎  | 736/1000 [00:09<00:03, 74.61it/s]Measuring inference for batch_size=64:  74%|███████▍  | 744/1000 [00:09<00:03, 74.60it/s]Measuring inference for batch_size=64:  75%|███████▌  | 752/1000 [00:10<00:03, 74.57it/s]Measuring inference for batch_size=64:  76%|███████▌  | 760/1000 [00:10<00:03, 74.59it/s]Measuring inference for batch_size=64:  77%|███████▋  | 768/1000 [00:10<00:03, 74.58it/s]Measuring inference for batch_size=64:  78%|███████▊  | 776/1000 [00:10<00:03, 74.58it/s]Measuring inference for batch_size=64:  78%|███████▊  | 784/1000 [00:10<00:02, 74.58it/s]Measuring inference for batch_size=64:  79%|███████▉  | 792/1000 [00:10<00:02, 74.59it/s]Measuring inference for batch_size=64:  80%|████████  | 800/1000 [00:10<00:02, 74.57it/s]Measuring inference for batch_size=64:  81%|████████  | 808/1000 [00:10<00:02, 74.55it/s]Measuring inference for batch_size=64:  82%|████████▏ | 816/1000 [00:10<00:02, 74.55it/s]Measuring inference for batch_size=64:  82%|████████▏ | 824/1000 [00:11<00:02, 74.58it/s]Measuring inference for batch_size=64:  83%|████████▎ | 832/1000 [00:11<00:02, 74.58it/s]Measuring inference for batch_size=64:  84%|████████▍ | 840/1000 [00:11<00:02, 74.58it/s]Measuring inference for batch_size=64:  85%|████████▍ | 848/1000 [00:11<00:02, 74.59it/s]Measuring inference for batch_size=64:  86%|████████▌ | 856/1000 [00:11<00:01, 74.62it/s]Measuring inference for batch_size=64:  86%|████████▋ | 864/1000 [00:11<00:01, 74.62it/s]Measuring inference for batch_size=64:  87%|████████▋ | 872/1000 [00:11<00:01, 74.61it/s]Measuring inference for batch_size=64:  88%|████████▊ | 880/1000 [00:11<00:01, 74.61it/s]Measuring inference for batch_size=64:  89%|████████▉ | 888/1000 [00:11<00:01, 74.63it/s]Measuring inference for batch_size=64:  90%|████████▉ | 896/1000 [00:12<00:01, 74.62it/s]Measuring inference for batch_size=64:  90%|█████████ | 904/1000 [00:12<00:01, 74.63it/s]Measuring inference for batch_size=64:  91%|█████████ | 912/1000 [00:12<00:01, 74.62it/s]Measuring inference for batch_size=64:  92%|█████████▏| 920/1000 [00:12<00:01, 74.59it/s]Measuring inference for batch_size=64:  93%|█████████▎| 928/1000 [00:12<00:00, 74.62it/s]Measuring inference for batch_size=64:  94%|█████████▎| 936/1000 [00:12<00:00, 74.63it/s]Measuring inference for batch_size=64:  94%|█████████▍| 944/1000 [00:12<00:00, 74.63it/s]Measuring inference for batch_size=64:  95%|█████████▌| 952/1000 [00:12<00:00, 74.66it/s]Measuring inference for batch_size=64:  96%|█████████▌| 960/1000 [00:12<00:00, 74.63it/s]Measuring inference for batch_size=64:  97%|█████████▋| 968/1000 [00:12<00:00, 74.63it/s]Measuring inference for batch_size=64:  98%|█████████▊| 976/1000 [00:13<00:00, 74.64it/s]Measuring inference for batch_size=64:  98%|█████████▊| 984/1000 [00:13<00:00, 74.63it/s]Measuring inference for batch_size=64:  99%|█████████▉| 992/1000 [00:13<00:00, 74.63it/s]Measuring inference for batch_size=64: 100%|██████████| 1000/1000 [00:13<00:00, 74.63it/s]Measuring inference for batch_size=64: 100%|██████████| 1000/1000 [00:13<00:00, 74.61it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 921.21 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_64:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.291 us +/- 5.446 us [92.030 us, 226.736 us]
        batches_per_second: 10.41 K +/- 411.57 [4.41 K, 10.87 K]
      metrics:
        batches_per_second_max: 10866.072538860104
        batches_per_second_mean: 10406.802221806123
        batches_per_second_min: 4410.414300736067
        batches_per_second_std: 411.5718916842448
        seconds_per_batch_max: 0.00022673606872558594
        seconds_per_batch_mean: 9.629082679748535e-05
        seconds_per_batch_min: 9.202957153320312e-05
        seconds_per_batch_std: 5.4464889966364e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.474 us +/- 0.798 us [21.935 us, 32.187 us]
        batches_per_second: 42.64 K +/- 1.30 K [31.07 K, 45.59 K]
      metrics:
        batches_per_second_max: 45590.260869565216
        batches_per_second_mean: 42644.89996758604
        batches_per_second_min: 31068.91851851852
        batches_per_second_std: 1296.42900217
        seconds_per_batch_max: 3.218650817871094e-05
        seconds_per_batch_mean: 2.3473501205444336e-05
        seconds_per_batch_min: 2.193450927734375e-05
        seconds_per_batch_std: 7.97686535954076e-07
    on_device_inference:
      human_readable:
        batch_latency: -13564513.090 us +/- 453.319 ms [-14093919.754 us, -12960384.369
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07095258220937296
        batches_per_second_mean: -0.0738052478454771
        batches_per_second_min: -0.07715820546186049
        batches_per_second_std: 0.0024977247167840945
        seconds_per_batch_max: -12.960384368896484
        seconds_per_batch_mean: -13.564513090133667
        seconds_per_batch_min: -14.09391975402832
        seconds_per_batch_std: 0.4533194173526626
    total:
      human_readable:
        batch_latency: 13.693 ms +/- 456.492 us [13.083 ms, 14.223 ms]
        batches_per_second: 73.11 +/- 2.47 [70.31, 76.43]
      metrics:
        batches_per_second_max: 76.43378587699317
        batches_per_second_mean: 73.1142063889355
        batches_per_second_min: 70.30816682311922
        batches_per_second_std: 2.468328340293306
        seconds_per_batch_max: 0.014223098754882812
        seconds_per_batch_mean: 0.013692643404006957
        seconds_per_batch_min: 0.013083219528198242
        seconds_per_batch_std: 0.0004564919233631077
  batch_size_64:
    cpu_to_gpu:
      human_readable:
        batch_latency: 146.674 us +/- 5.349 us [144.243 us, 284.433 us]
        batches_per_second: 6.82 K +/- 173.30 [3.52 K, 6.93 K]
      metrics:
        batches_per_second_max: 6932.7338842975205
        batches_per_second_mean: 6823.86259867402
        batches_per_second_min: 3515.761944677284
        batches_per_second_std: 173.29822698679692
        seconds_per_batch_max: 0.00028443336486816406
        seconds_per_batch_mean: 0.00014667415618896485
        seconds_per_batch_min: 0.0001442432403564453
        seconds_per_batch_std: 5.348657046157026e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.075 us +/- 0.574 us [22.173 us, 30.041 us]
        batches_per_second: 43.36 K +/- 940.54 [33.29 K, 45.10 K]
      metrics:
        batches_per_second_max: 45100.04301075269
        batches_per_second_mean: 43359.553828893775
        batches_per_second_min: 33288.12698412698
        batches_per_second_std: 940.5439886789375
        seconds_per_batch_max: 3.0040740966796875e-05
        seconds_per_batch_mean: 2.3075342178344726e-05
        seconds_per_batch_min: 2.2172927856445312e-05
        seconds_per_batch_std: 5.736320789634884e-07
    on_device_inference:
      human_readable:
        batch_latency: -13220204.616 us +/- 34.596 ms [-13824064.255 us, -13154368.401
          us]
        batches_per_second: -0.08 +/- 0.00 [-0.08, -0.07]
      metrics:
        batches_per_second_max: -0.07233762673344195
        batches_per_second_mean: -0.07564230503737285
        batches_per_second_min: -0.07602037357843687
        batches_per_second_std: 0.0001951512406202327
        seconds_per_batch_max: -13.15436840057373
        seconds_per_batch_mean: -13.220204615592957
        seconds_per_batch_min: -13.824064254760742
        seconds_per_batch_std: 0.03459632109442929
    total:
      human_readable:
        batch_latency: 13.395 ms +/- 37.651 us [13.328 ms, 14.145 ms]
        batches_per_second: 74.65 +/- 0.21 [70.70, 75.03]
      metrics:
        batches_per_second_max: 75.0309296792544
        batches_per_second_mean: 74.65358218962687
        batches_per_second_min: 70.69687162891046
        batches_per_second_std: 0.20532357845908095
        seconds_per_batch_max: 0.0141448974609375
        seconds_per_batch_mean: 0.013395308017730713
        seconds_per_batch_min: 0.013327836990356445
        seconds_per_batch_std: 3.765101940977301e-05


