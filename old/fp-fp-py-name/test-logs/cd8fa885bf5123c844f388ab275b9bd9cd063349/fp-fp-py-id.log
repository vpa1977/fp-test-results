#####
fp-fp-py-id - Run 1
2024-02-25 22:56:24
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 97.22it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 97.45it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 97.47it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 97.51it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 97.51it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 97.53it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:00<00:00, 97.51it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:00<00:00, 97.52it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:00<00:00, 97.51it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 97.50it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 97.49it/s]
STAGE:2024-02-25 22:55:53 5979:5979 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:55:53 5979:5979 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:55:53 5979:5979 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 72.83it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 73.16it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:13, 73.30it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:13, 73.40it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:13, 73.45it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 73.45it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 73.49it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 73.58it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 73.67it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 73.65it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 73.68it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:12, 73.75it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:12, 73.78it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:12, 73.79it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 73.81it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 73.74it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 73.74it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 73.77it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 73.71it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 73.68it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 73.66it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:11, 73.65it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:11, 73.65it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:10, 73.63it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 73.60it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 73.57it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 73.61it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:03<00:10, 73.68it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 73.74it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 73.74it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:10, 73.73it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:10, 73.76it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:09, 73.79it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 73.81it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 73.76it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 73.80it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:04<00:09, 73.80it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 73.80it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 73.80it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 73.78it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:09, 73.78it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:08, 73.80it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 73.81it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 73.71it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 73.60it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:04<00:08, 73.52it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:05<00:08, 73.47it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 73.47it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 73.57it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:08, 73.65it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:08, 73.72it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:07, 73.78it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 73.73it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 73.79it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:05<00:07, 73.80it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:06<00:07, 73.79it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 73.81it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 73.80it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 73.80it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:07, 73.82it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:06, 73.83it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:06, 73.82it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 73.81it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:06<00:06, 73.81it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:07<00:06, 73.83it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 73.84it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 73.82it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 73.82it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:06, 73.83it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:05, 73.83it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:05, 73.82it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 73.78it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 73.77it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:08<00:05, 73.80it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 73.79it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 73.80it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 73.82it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:05, 73.75it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:04, 73.66it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:04, 73.59it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 73.53it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 73.48it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:09<00:04, 73.47it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:09<00:04, 73.47it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 73.46it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 73.44it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 73.44it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 73.44it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:03, 73.48it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 73.49it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 73.49it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:09<00:03, 73.49it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:10<00:03, 73.49it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 73.48it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 73.51it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 73.50it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 73.51it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:02, 73.53it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 73.52it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 73.49it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:10<00:02, 73.49it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:11<00:02, 73.49it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 73.49it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 73.48it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 73.44it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 73.39it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:01, 73.41it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 73.40it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 73.41it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:11<00:01, 73.44it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 73.42it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 73.43it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 73.42it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 73.41it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 73.47it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:00, 73.52it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 73.56it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 73.58it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:12<00:00, 73.64it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:13<00:00, 73.70it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 73.75it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 73.75it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 73.75it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 73.76it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 73.75it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 73.64it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=16:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=16:   8%|▊         | 8/100 [00:00<00:01, 73.33it/s]Warming up with batch_size=16:  16%|█▌        | 16/100 [00:00<00:01, 73.44it/s]Warming up with batch_size=16:  24%|██▍       | 24/100 [00:00<00:01, 73.44it/s]Warming up with batch_size=16:  32%|███▏      | 32/100 [00:00<00:00, 73.47it/s]Warming up with batch_size=16:  40%|████      | 40/100 [00:00<00:00, 73.48it/s]Warming up with batch_size=16:  48%|████▊     | 48/100 [00:00<00:00, 73.49it/s]Warming up with batch_size=16:  56%|█████▌    | 56/100 [00:00<00:00, 73.48it/s]Warming up with batch_size=16:  64%|██████▍   | 64/100 [00:00<00:00, 73.44it/s]Warming up with batch_size=16:  72%|███████▏  | 72/100 [00:00<00:00, 73.46it/s]Warming up with batch_size=16:  80%|████████  | 80/100 [00:01<00:00, 73.49it/s]Warming up with batch_size=16:  88%|████████▊ | 88/100 [00:01<00:00, 73.49it/s]Warming up with batch_size=16:  96%|█████████▌| 96/100 [00:01<00:00, 73.49it/s]Warming up with batch_size=16: 100%|██████████| 100/100 [00:01<00:00, 73.46it/s]
STAGE:2024-02-25 22:56:08 5979:5979 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:56:08 5979:5979 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:56:08 5979:5979 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=16:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=16:   1%|          | 8/1000 [00:00<00:13, 72.15it/s]Measuring inference for batch_size=16:   2%|▏         | 16/1000 [00:00<00:13, 72.44it/s]Measuring inference for batch_size=16:   2%|▏         | 24/1000 [00:00<00:13, 72.60it/s]Measuring inference for batch_size=16:   3%|▎         | 32/1000 [00:00<00:13, 72.62it/s]Measuring inference for batch_size=16:   4%|▍         | 40/1000 [00:00<00:13, 72.59it/s]Measuring inference for batch_size=16:   5%|▍         | 48/1000 [00:00<00:13, 72.58it/s]Measuring inference for batch_size=16:   6%|▌         | 56/1000 [00:00<00:13, 72.57it/s]Measuring inference for batch_size=16:   6%|▋         | 64/1000 [00:00<00:12, 72.56it/s]Measuring inference for batch_size=16:   7%|▋         | 72/1000 [00:00<00:12, 72.56it/s]Measuring inference for batch_size=16:   8%|▊         | 80/1000 [00:01<00:12, 72.54it/s]Measuring inference for batch_size=16:   9%|▉         | 88/1000 [00:01<00:12, 72.52it/s]Measuring inference for batch_size=16:  10%|▉         | 96/1000 [00:01<00:12, 72.49it/s]Measuring inference for batch_size=16:  10%|█         | 104/1000 [00:01<00:12, 72.45it/s]Measuring inference for batch_size=16:  11%|█         | 112/1000 [00:01<00:12, 72.42it/s]Measuring inference for batch_size=16:  12%|█▏        | 120/1000 [00:01<00:12, 72.47it/s]Measuring inference for batch_size=16:  13%|█▎        | 128/1000 [00:01<00:12, 72.50it/s]Measuring inference for batch_size=16:  14%|█▎        | 136/1000 [00:01<00:11, 72.50it/s]Measuring inference for batch_size=16:  14%|█▍        | 144/1000 [00:01<00:11, 72.52it/s]Measuring inference for batch_size=16:  15%|█▌        | 152/1000 [00:02<00:11, 72.54it/s]Measuring inference for batch_size=16:  16%|█▌        | 160/1000 [00:02<00:11, 72.54it/s]Measuring inference for batch_size=16:  17%|█▋        | 168/1000 [00:02<00:11, 72.54it/s]Measuring inference for batch_size=16:  18%|█▊        | 176/1000 [00:02<00:11, 72.57it/s]Measuring inference for batch_size=16:  18%|█▊        | 184/1000 [00:02<00:11, 72.56it/s]Measuring inference for batch_size=16:  19%|█▉        | 192/1000 [00:02<00:11, 72.54it/s]Measuring inference for batch_size=16:  20%|██        | 200/1000 [00:02<00:11, 72.55it/s]Measuring inference for batch_size=16:  21%|██        | 208/1000 [00:02<00:10, 72.53it/s]Measuring inference for batch_size=16:  22%|██▏       | 216/1000 [00:02<00:10, 72.55it/s]Measuring inference for batch_size=16:  22%|██▏       | 224/1000 [00:03<00:10, 72.59it/s]Measuring inference for batch_size=16:  23%|██▎       | 232/1000 [00:03<00:10, 72.53it/s]Measuring inference for batch_size=16:  24%|██▍       | 240/1000 [00:03<00:10, 72.58it/s]Measuring inference for batch_size=16:  25%|██▍       | 248/1000 [00:03<00:10, 72.62it/s]Measuring inference for batch_size=16:  26%|██▌       | 256/1000 [00:03<00:10, 72.63it/s]Measuring inference for batch_size=16:  26%|██▋       | 264/1000 [00:03<00:10, 72.61it/s]Measuring inference for batch_size=16:  27%|██▋       | 272/1000 [00:03<00:10, 72.62it/s]Measuring inference for batch_size=16:  28%|██▊       | 280/1000 [00:03<00:09, 72.62it/s]Measuring inference for batch_size=16:  29%|██▉       | 288/1000 [00:03<00:09, 72.62it/s]Measuring inference for batch_size=16:  30%|██▉       | 296/1000 [00:04<00:09, 72.64it/s]Measuring inference for batch_size=16:  30%|███       | 304/1000 [00:04<00:09, 72.66it/s]Measuring inference for batch_size=16:  31%|███       | 312/1000 [00:04<00:09, 72.69it/s]Measuring inference for batch_size=16:  32%|███▏      | 320/1000 [00:04<00:09, 72.70it/s]Measuring inference for batch_size=16:  33%|███▎      | 328/1000 [00:04<00:09, 72.68it/s]Measuring inference for batch_size=16:  34%|███▎      | 336/1000 [00:04<00:09, 72.67it/s]Measuring inference for batch_size=16:  34%|███▍      | 344/1000 [00:04<00:09, 72.68it/s]Measuring inference for batch_size=16:  35%|███▌      | 352/1000 [00:04<00:08, 72.67it/s]Measuring inference for batch_size=16:  36%|███▌      | 360/1000 [00:04<00:08, 72.67it/s]Measuring inference for batch_size=16:  37%|███▋      | 368/1000 [00:05<00:08, 72.68it/s]Measuring inference for batch_size=16:  38%|███▊      | 376/1000 [00:05<00:08, 72.74it/s]Measuring inference for batch_size=16:  38%|███▊      | 384/1000 [00:05<00:08, 72.73it/s]Measuring inference for batch_size=16:  39%|███▉      | 392/1000 [00:05<00:08, 72.72it/s]Measuring inference for batch_size=16:  40%|████      | 400/1000 [00:05<00:08, 72.67it/s]Measuring inference for batch_size=16:  41%|████      | 408/1000 [00:05<00:08, 72.65it/s]Measuring inference for batch_size=16:  42%|████▏     | 416/1000 [00:05<00:08, 72.63it/s]Measuring inference for batch_size=16:  42%|████▏     | 424/1000 [00:05<00:07, 72.60it/s]Measuring inference for batch_size=16:  43%|████▎     | 432/1000 [00:05<00:07, 72.61it/s]Measuring inference for batch_size=16:  44%|████▍     | 440/1000 [00:06<00:07, 72.60it/s]Measuring inference for batch_size=16:  45%|████▍     | 448/1000 [00:06<00:07, 72.64it/s]Measuring inference for batch_size=16:  46%|████▌     | 456/1000 [00:06<00:07, 72.64it/s]Measuring inference for batch_size=16:  46%|████▋     | 464/1000 [00:06<00:07, 72.64it/s]Measuring inference for batch_size=16:  47%|████▋     | 472/1000 [00:06<00:07, 72.65it/s]Measuring inference for batch_size=16:  48%|████▊     | 480/1000 [00:06<00:07, 72.65it/s]Measuring inference for batch_size=16:  49%|████▉     | 488/1000 [00:06<00:07, 72.65it/s]Measuring inference for batch_size=16:  50%|████▉     | 496/1000 [00:06<00:06, 72.56it/s]Measuring inference for batch_size=16:  50%|█████     | 504/1000 [00:06<00:06, 72.52it/s]Measuring inference for batch_size=16:  51%|█████     | 512/1000 [00:07<00:06, 72.50it/s]Measuring inference for batch_size=16:  52%|█████▏    | 520/1000 [00:07<00:06, 72.49it/s]Measuring inference for batch_size=16:  53%|█████▎    | 528/1000 [00:07<00:06, 72.51it/s]Measuring inference for batch_size=16:  54%|█████▎    | 536/1000 [00:07<00:06, 72.52it/s]Measuring inference for batch_size=16:  54%|█████▍    | 544/1000 [00:07<00:06, 72.51it/s]Measuring inference for batch_size=16:  55%|█████▌    | 552/1000 [00:07<00:06, 72.52it/s]Measuring inference for batch_size=16:  56%|█████▌    | 560/1000 [00:07<00:06, 72.49it/s]Measuring inference for batch_size=16:  57%|█████▋    | 568/1000 [00:07<00:05, 72.51it/s]Measuring inference for batch_size=16:  58%|█████▊    | 576/1000 [00:07<00:05, 72.52it/s]Measuring inference for batch_size=16:  58%|█████▊    | 584/1000 [00:08<00:05, 72.51it/s]Measuring inference for batch_size=16:  59%|█████▉    | 592/1000 [00:08<00:05, 72.51it/s]Measuring inference for batch_size=16:  60%|██████    | 600/1000 [00:08<00:05, 72.50it/s]Measuring inference for batch_size=16:  61%|██████    | 608/1000 [00:08<00:05, 72.50it/s]Measuring inference for batch_size=16:  62%|██████▏   | 616/1000 [00:08<00:05, 72.52it/s]Measuring inference for batch_size=16:  62%|██████▏   | 624/1000 [00:08<00:05, 72.50it/s]Measuring inference for batch_size=16:  63%|██████▎   | 632/1000 [00:08<00:05, 72.51it/s]Measuring inference for batch_size=16:  64%|██████▍   | 640/1000 [00:08<00:04, 72.51it/s]Measuring inference for batch_size=16:  65%|██████▍   | 648/1000 [00:08<00:04, 72.52it/s]Measuring inference for batch_size=16:  66%|██████▌   | 656/1000 [00:09<00:04, 72.50it/s]Measuring inference for batch_size=16:  66%|██████▋   | 664/1000 [00:09<00:04, 72.51it/s]Measuring inference for batch_size=16:  67%|██████▋   | 672/1000 [00:09<00:04, 72.49it/s]Measuring inference for batch_size=16:  68%|██████▊   | 680/1000 [00:09<00:04, 72.47it/s]Measuring inference for batch_size=16:  69%|██████▉   | 688/1000 [00:09<00:04, 72.44it/s]Measuring inference for batch_size=16:  70%|██████▉   | 696/1000 [00:09<00:04, 72.46it/s]Measuring inference for batch_size=16:  70%|███████   | 704/1000 [00:09<00:04, 72.49it/s]Measuring inference for batch_size=16:  71%|███████   | 712/1000 [00:09<00:03, 72.54it/s]Measuring inference for batch_size=16:  72%|███████▏  | 720/1000 [00:09<00:03, 72.53it/s]Measuring inference for batch_size=16:  73%|███████▎  | 728/1000 [00:10<00:03, 72.54it/s]Measuring inference for batch_size=16:  74%|███████▎  | 736/1000 [00:10<00:03, 72.54it/s]Measuring inference for batch_size=16:  74%|███████▍  | 744/1000 [00:10<00:03, 72.55it/s]Measuring inference for batch_size=16:  75%|███████▌  | 752/1000 [00:10<00:03, 72.55it/s]Measuring inference for batch_size=16:  76%|███████▌  | 760/1000 [00:10<00:03, 72.56it/s]Measuring inference for batch_size=16:  77%|███████▋  | 768/1000 [00:10<00:03, 72.56it/s]Measuring inference for batch_size=16:  78%|███████▊  | 776/1000 [00:10<00:03, 72.58it/s]Measuring inference for batch_size=16:  78%|███████▊  | 784/1000 [00:10<00:02, 72.56it/s]Measuring inference for batch_size=16:  79%|███████▉  | 792/1000 [00:10<00:02, 72.57it/s]Measuring inference for batch_size=16:  80%|████████  | 800/1000 [00:11<00:02, 72.56it/s]Measuring inference for batch_size=16:  81%|████████  | 808/1000 [00:11<00:02, 72.58it/s]Measuring inference for batch_size=16:  82%|████████▏ | 816/1000 [00:11<00:02, 72.58it/s]Measuring inference for batch_size=16:  82%|████████▏ | 824/1000 [00:11<00:02, 72.59it/s]Measuring inference for batch_size=16:  83%|████████▎ | 832/1000 [00:11<00:02, 72.58it/s]Measuring inference for batch_size=16:  84%|████████▍ | 840/1000 [00:11<00:02, 72.60it/s]Measuring inference for batch_size=16:  85%|████████▍ | 848/1000 [00:11<00:02, 72.61it/s]Measuring inference for batch_size=16:  86%|████████▌ | 856/1000 [00:11<00:01, 72.64it/s]Measuring inference for batch_size=16:  86%|████████▋ | 864/1000 [00:11<00:01, 72.65it/s]Measuring inference for batch_size=16:  87%|████████▋ | 872/1000 [00:12<00:01, 72.64it/s]Measuring inference for batch_size=16:  88%|████████▊ | 880/1000 [00:12<00:01, 72.63it/s]Measuring inference for batch_size=16:  89%|████████▉ | 888/1000 [00:12<00:01, 72.62it/s]Measuring inference for batch_size=16:  90%|████████▉ | 896/1000 [00:12<00:01, 72.61it/s]Measuring inference for batch_size=16:  90%|█████████ | 904/1000 [00:12<00:01, 72.61it/s]Measuring inference for batch_size=16:  91%|█████████ | 912/1000 [00:12<00:01, 72.63it/s]Measuring inference for batch_size=16:  92%|█████████▏| 920/1000 [00:12<00:01, 72.63it/s]Measuring inference for batch_size=16:  93%|█████████▎| 928/1000 [00:12<00:00, 72.61it/s]Measuring inference for batch_size=16:  94%|█████████▎| 936/1000 [00:12<00:00, 72.63it/s]Measuring inference for batch_size=16:  94%|█████████▍| 944/1000 [00:13<00:00, 72.60it/s]Measuring inference for batch_size=16:  95%|█████████▌| 952/1000 [00:13<00:00, 72.61it/s]Measuring inference for batch_size=16:  96%|█████████▌| 960/1000 [00:13<00:00, 72.60it/s]Measuring inference for batch_size=16:  97%|█████████▋| 968/1000 [00:13<00:00, 72.60it/s]Measuring inference for batch_size=16:  98%|█████████▊| 976/1000 [00:13<00:00, 72.61it/s]Measuring inference for batch_size=16:  98%|█████████▊| 984/1000 [00:13<00:00, 72.60it/s]Measuring inference for batch_size=16:  99%|█████████▉| 992/1000 [00:13<00:00, 72.60it/s]Measuring inference for batch_size=16: 100%|██████████| 1000/1000 [00:13<00:00, 72.61it/s]Measuring inference for batch_size=16: 100%|██████████| 1000/1000 [00:13<00:00, 72.57it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 921.18 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_16:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 93.499 us +/- 5.240 us [91.076 us, 219.584 us]
        batches_per_second: 10.72 K +/- 410.65 [4.55 K, 10.98 K]
      metrics:
        batches_per_second_max: 10979.853403141362
        batches_per_second_mean: 10716.74751903232
        batches_per_second_min: 4554.0760043431055
        batches_per_second_std: 410.650246845754
        seconds_per_batch_max: 0.00021958351135253906
        seconds_per_batch_mean: 9.349894523620606e-05
        seconds_per_batch_min: 9.107589721679688e-05
        seconds_per_batch_std: 5.240288675618835e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.342 us +/- 0.790 us [22.650 us, 34.094 us]
        batches_per_second: 42.88 K +/- 1.18 K [29.33 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42880.21265818533
        batches_per_second_min: 29330.797202797203
        batches_per_second_std: 1180.10581709802
        seconds_per_batch_max: 3.409385681152344e-05
        seconds_per_batch_mean: 2.3342370986938477e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 7.897370262659045e-07
    on_device_inference:
      human_readable:
        batch_latency: -13447117.875 us +/- 50.704 ms [-14164287.567 us, -13341183.662
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.07060009162197559
        batches_per_second_mean: -0.07436642554083787
        batches_per_second_min: -0.07495586788279139
        batches_per_second_std: 0.0002779510112468744
        seconds_per_batch_max: -13.34118366241455
        seconds_per_batch_mean: -13.447117875099183
        seconds_per_batch_min: -14.164287567138672
        seconds_per_batch_std: 0.050704382966884884
    total:
      human_readable:
        batch_latency: 13.572 ms +/- 53.322 us [13.463 ms, 14.431 ms]
        batches_per_second: 73.68 +/- 0.29 [69.29, 74.28]
      metrics:
        batches_per_second_max: 74.27753772047886
        batches_per_second_mean: 73.68436349413196
        batches_per_second_min: 69.29412347800228
        batches_per_second_std: 0.2854316327071657
        seconds_per_batch_max: 0.014431238174438477
        seconds_per_batch_mean: 0.013571606874465942
        seconds_per_batch_min: 0.013463020324707031
        seconds_per_batch_std: 5.3321893317981734e-05
  batch_size_16:
    cpu_to_gpu:
      human_readable:
        batch_latency: 144.284 us +/- 5.603 us [141.382 us, 282.526 us]
        batches_per_second: 6.94 K +/- 193.70 [3.54 K, 7.07 K]
      metrics:
        batches_per_second_max: 7073.025295109612
        batches_per_second_mean: 6937.920896462142
        batches_per_second_min: 3539.497046413502
        batches_per_second_std: 193.6982591655022
        seconds_per_batch_max: 0.00028252601623535156
        seconds_per_batch_mean: 0.00014428448677062988
        seconds_per_batch_min: 0.00014138221740722656
        seconds_per_batch_std: 5.603105817576856e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.647 us +/- 0.768 us [22.650 us, 30.994 us]
        batches_per_second: 42.33 K +/- 1.19 K [32.26 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42328.04733277883
        batches_per_second_min: 32263.876923076925
        batches_per_second_std: 1194.785359981557
        seconds_per_batch_max: 3.0994415283203125e-05
        seconds_per_batch_mean: 2.364659309387207e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 7.682939847660778e-07
    on_device_inference:
      human_readable:
        batch_latency: -13597553.509 us +/- 43.764 ms [-14208160.400 us, -13502079.964
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.07038208830838558
        batches_per_second_mean: -0.07354339758168581
        batches_per_second_min: -0.07406266313706138
        batches_per_second_std: 0.00023501970696073165
        seconds_per_batch_max: -13.502079963684082
        seconds_per_batch_mean: -13.597553508758544
        seconds_per_batch_min: -14.208160400390625
        seconds_per_batch_std: 0.043764257937850465
    total:
      human_readable:
        batch_latency: 13.771 ms +/- 46.320 us [13.673 ms, 14.527 ms]
        batches_per_second: 72.62 +/- 0.24 [68.84, 73.14]
      metrics:
        batches_per_second_max: 73.13775545790612
        batches_per_second_mean: 72.61779027922178
        batches_per_second_min: 68.83807648120795
        batches_per_second_std: 0.24119596455759584
        seconds_per_batch_max: 0.014526844024658203
        seconds_per_batch_mean: 0.013770884037017822
        seconds_per_batch_min: 0.013672828674316406
        seconds_per_batch_std: 4.6319894373846794e-05


#####
fp-fp-py-id - Run 2
2024-02-25 22:57:02
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.75it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 96.34it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 96.69it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 96.81it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 96.88it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 96.93it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 96.95it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:00<00:00, 96.90it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:00<00:00, 96.90it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:00<00:00, 96.87it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 96.89it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 96.86it/s]
STAGE:2024-02-25 22:56:31 6025:6025 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:56:31 6025:6025 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:56:31 6025:6025 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 72.64it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 72.97it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:13, 73.04it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:13, 73.11it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:13, 73.13it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:13, 73.14it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 73.15it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 73.16it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 73.19it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 73.20it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 73.21it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:12, 73.22it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:12, 73.21it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:12, 73.22it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:12, 73.23it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 73.27it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 73.28it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 73.27it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 73.27it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 73.24it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 73.25it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:11, 73.23it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:11, 73.22it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:11, 73.21it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:10, 73.20it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:10, 73.21it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:02<00:10, 73.20it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:03<00:10, 73.19it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:03<00:10, 73.18it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:03<00:10, 73.15it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:03<00:10, 73.07it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:03<00:10, 73.03it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:10, 73.04it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:03<00:09, 73.05it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:03<00:09, 73.06it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:03<00:09, 73.06it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:04<00:09, 73.03it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:04<00:09, 73.07it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:04<00:09, 73.07it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 73.06it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:04<00:09, 73.07it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:04<00:09, 73.07it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:04<00:08, 73.10it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:04<00:08, 73.12it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:04<00:08, 73.09it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:05<00:08, 73.06it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:05<00:08, 73.02it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:05<00:08, 73.01it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:05<00:08, 72.99it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:05<00:08, 72.97it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:05<00:08, 72.97it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:05<00:08, 72.99it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:05<00:07, 72.98it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:05<00:07, 73.00it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:06<00:07, 72.99it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:06<00:07, 73.00it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:06<00:07, 73.00it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:06<00:07, 73.03it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:06<00:07, 73.07it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:06<00:07, 73.09it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:07, 73.10it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:06<00:06, 73.12it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:06<00:06, 73.14it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:07<00:06, 73.13it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:07<00:06, 73.15it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:07<00:06, 73.14it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:07<00:06, 73.13it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 73.14it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:07<00:06, 73.15it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:07<00:06, 73.14it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:07<00:05, 73.15it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:07<00:05, 73.15it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:07<00:05, 73.15it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:08<00:05, 73.13it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 73.15it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:08<00:05, 73.15it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:08<00:05, 73.16it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:08<00:05, 73.10it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:08<00:05, 73.12it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:08<00:04, 73.13it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:08<00:04, 73.13it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:08<00:04, 73.13it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:09<00:04, 73.13it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:09<00:04, 73.13it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:09<00:04, 73.14it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:09<00:04, 73.17it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:09<00:04, 73.19it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:09<00:04, 73.18it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:09<00:03, 73.20it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:09<00:03, 73.18it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:09<00:03, 73.18it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:10<00:03, 73.17it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:10<00:03, 73.18it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:10<00:03, 73.14it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:10<00:03, 73.13it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:10<00:03, 73.15it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:10<00:03, 73.18it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:10<00:02, 73.18it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:10<00:02, 73.18it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:10<00:02, 73.18it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:11<00:02, 73.19it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:11<00:02, 73.18it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:11<00:02, 73.20it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 73.20it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:11<00:02, 73.18it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:11<00:02, 73.17it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:11<00:01, 73.16it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:11<00:01, 73.15it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:11<00:01, 73.14it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:12<00:01, 73.13it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 73.16it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:12<00:01, 73.12it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:12<00:01, 73.10it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:12<00:01, 73.12it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:12<00:01, 73.15it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:12<00:00, 73.15it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:12<00:00, 73.12it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:12<00:00, 73.09it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:13<00:00, 73.09it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:13<00:00, 73.09it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:13<00:00, 73.12it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:13<00:00, 73.12it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:13<00:00, 73.09it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:13<00:00, 73.07it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 73.06it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:13<00:00, 73.13it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=16:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=16:   8%|▊         | 8/100 [00:00<00:01, 72.46it/s]Warming up with batch_size=16:  16%|█▌        | 16/100 [00:00<00:01, 72.63it/s]Warming up with batch_size=16:  24%|██▍       | 24/100 [00:00<00:01, 72.72it/s]Warming up with batch_size=16:  32%|███▏      | 32/100 [00:00<00:00, 72.75it/s]Warming up with batch_size=16:  40%|████      | 40/100 [00:00<00:00, 72.71it/s]Warming up with batch_size=16:  48%|████▊     | 48/100 [00:00<00:00, 72.72it/s]Warming up with batch_size=16:  56%|█████▌    | 56/100 [00:00<00:00, 72.71it/s]Warming up with batch_size=16:  64%|██████▍   | 64/100 [00:00<00:00, 72.72it/s]Warming up with batch_size=16:  72%|███████▏  | 72/100 [00:00<00:00, 72.69it/s]Warming up with batch_size=16:  80%|████████  | 80/100 [00:01<00:00, 72.65it/s]Warming up with batch_size=16:  88%|████████▊ | 88/100 [00:01<00:00, 72.64it/s]Warming up with batch_size=16:  96%|█████████▌| 96/100 [00:01<00:00, 72.61it/s]Warming up with batch_size=16: 100%|██████████| 100/100 [00:01<00:00, 72.65it/s]
STAGE:2024-02-25 22:56:46 6025:6025 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:56:46 6025:6025 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:56:46 6025:6025 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=16:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=16:   1%|          | 8/1000 [00:00<00:13, 71.44it/s]Measuring inference for batch_size=16:   2%|▏         | 16/1000 [00:00<00:13, 71.66it/s]Measuring inference for batch_size=16:   2%|▏         | 24/1000 [00:00<00:13, 71.77it/s]Measuring inference for batch_size=16:   3%|▎         | 32/1000 [00:00<00:13, 71.84it/s]Measuring inference for batch_size=16:   4%|▍         | 40/1000 [00:00<00:13, 71.86it/s]Measuring inference for batch_size=16:   5%|▍         | 48/1000 [00:00<00:13, 71.90it/s]Measuring inference for batch_size=16:   6%|▌         | 56/1000 [00:00<00:13, 71.90it/s]Measuring inference for batch_size=16:   6%|▋         | 64/1000 [00:00<00:13, 71.91it/s]Measuring inference for batch_size=16:   7%|▋         | 72/1000 [00:01<00:12, 71.92it/s]Measuring inference for batch_size=16:   8%|▊         | 80/1000 [00:01<00:12, 71.92it/s]Measuring inference for batch_size=16:   9%|▉         | 88/1000 [00:01<00:12, 71.93it/s]Measuring inference for batch_size=16:  10%|▉         | 96/1000 [00:01<00:12, 71.95it/s]Measuring inference for batch_size=16:  10%|█         | 104/1000 [00:01<00:12, 71.96it/s]Measuring inference for batch_size=16:  11%|█         | 112/1000 [00:01<00:12, 71.94it/s]Measuring inference for batch_size=16:  12%|█▏        | 120/1000 [00:01<00:12, 71.93it/s]Measuring inference for batch_size=16:  13%|█▎        | 128/1000 [00:01<00:12, 71.91it/s]Measuring inference for batch_size=16:  14%|█▎        | 136/1000 [00:01<00:12, 71.89it/s]Measuring inference for batch_size=16:  14%|█▍        | 144/1000 [00:02<00:11, 71.89it/s]Measuring inference for batch_size=16:  15%|█▌        | 152/1000 [00:02<00:11, 71.91it/s]Measuring inference for batch_size=16:  16%|█▌        | 160/1000 [00:02<00:11, 71.90it/s]Measuring inference for batch_size=16:  17%|█▋        | 168/1000 [00:02<00:11, 71.90it/s]Measuring inference for batch_size=16:  18%|█▊        | 176/1000 [00:02<00:11, 71.90it/s]Measuring inference for batch_size=16:  18%|█▊        | 184/1000 [00:02<00:11, 71.92it/s]Measuring inference for batch_size=16:  19%|█▉        | 192/1000 [00:02<00:11, 71.95it/s]Measuring inference for batch_size=16:  20%|██        | 200/1000 [00:02<00:11, 71.96it/s]Measuring inference for batch_size=16:  21%|██        | 208/1000 [00:02<00:11, 71.95it/s]Measuring inference for batch_size=16:  22%|██▏       | 216/1000 [00:03<00:10, 71.96it/s]Measuring inference for batch_size=16:  22%|██▏       | 224/1000 [00:03<00:10, 71.97it/s]Measuring inference for batch_size=16:  23%|██▎       | 232/1000 [00:03<00:10, 71.96it/s]Measuring inference for batch_size=16:  24%|██▍       | 240/1000 [00:03<00:10, 71.94it/s]Measuring inference for batch_size=16:  25%|██▍       | 248/1000 [00:03<00:10, 71.93it/s]Measuring inference for batch_size=16:  26%|██▌       | 256/1000 [00:03<00:10, 71.89it/s]Measuring inference for batch_size=16:  26%|██▋       | 264/1000 [00:03<00:10, 71.88it/s]Measuring inference for batch_size=16:  27%|██▋       | 272/1000 [00:03<00:10, 71.87it/s]Measuring inference for batch_size=16:  28%|██▊       | 280/1000 [00:03<00:10, 71.88it/s]Measuring inference for batch_size=16:  29%|██▉       | 288/1000 [00:04<00:09, 71.89it/s]Measuring inference for batch_size=16:  30%|██▉       | 296/1000 [00:04<00:09, 71.88it/s]Measuring inference for batch_size=16:  30%|███       | 304/1000 [00:04<00:09, 71.87it/s]Measuring inference for batch_size=16:  31%|███       | 312/1000 [00:04<00:09, 71.87it/s]Measuring inference for batch_size=16:  32%|███▏      | 320/1000 [00:04<00:09, 71.87it/s]Measuring inference for batch_size=16:  33%|███▎      | 328/1000 [00:04<00:09, 71.88it/s]Measuring inference for batch_size=16:  34%|███▎      | 336/1000 [00:04<00:09, 71.88it/s]Measuring inference for batch_size=16:  34%|███▍      | 344/1000 [00:04<00:09, 71.89it/s]Measuring inference for batch_size=16:  35%|███▌      | 352/1000 [00:04<00:09, 71.91it/s]Measuring inference for batch_size=16:  36%|███▌      | 360/1000 [00:05<00:08, 71.91it/s]Measuring inference for batch_size=16:  37%|███▋      | 368/1000 [00:05<00:08, 71.92it/s]Measuring inference for batch_size=16:  38%|███▊      | 376/1000 [00:05<00:08, 71.93it/s]Measuring inference for batch_size=16:  38%|███▊      | 384/1000 [00:05<00:08, 71.94it/s]Measuring inference for batch_size=16:  39%|███▉      | 392/1000 [00:05<00:08, 71.94it/s]Measuring inference for batch_size=16:  40%|████      | 400/1000 [00:05<00:08, 71.90it/s]Measuring inference for batch_size=16:  41%|████      | 408/1000 [00:05<00:08, 71.89it/s]Measuring inference for batch_size=16:  42%|████▏     | 416/1000 [00:05<00:08, 71.90it/s]Measuring inference for batch_size=16:  42%|████▏     | 424/1000 [00:05<00:08, 71.90it/s]Measuring inference for batch_size=16:  43%|████▎     | 432/1000 [00:06<00:07, 71.87it/s]Measuring inference for batch_size=16:  44%|████▍     | 440/1000 [00:06<00:07, 71.87it/s]Measuring inference for batch_size=16:  45%|████▍     | 448/1000 [00:06<00:07, 71.87it/s]Measuring inference for batch_size=16:  46%|████▌     | 456/1000 [00:06<00:07, 71.90it/s]Measuring inference for batch_size=16:  46%|████▋     | 464/1000 [00:06<00:07, 71.90it/s]Measuring inference for batch_size=16:  47%|████▋     | 472/1000 [00:06<00:07, 71.90it/s]Measuring inference for batch_size=16:  48%|████▊     | 480/1000 [00:06<00:07, 71.92it/s]Measuring inference for batch_size=16:  49%|████▉     | 488/1000 [00:06<00:07, 71.92it/s]Measuring inference for batch_size=16:  50%|████▉     | 496/1000 [00:06<00:07, 71.94it/s]Measuring inference for batch_size=16:  50%|█████     | 504/1000 [00:07<00:06, 71.96it/s]Measuring inference for batch_size=16:  51%|█████     | 512/1000 [00:07<00:06, 71.96it/s]Measuring inference for batch_size=16:  52%|█████▏    | 520/1000 [00:07<00:06, 71.98it/s]Measuring inference for batch_size=16:  53%|█████▎    | 528/1000 [00:07<00:06, 72.04it/s]Measuring inference for batch_size=16:  54%|█████▎    | 536/1000 [00:07<00:06, 72.07it/s]Measuring inference for batch_size=16:  54%|█████▍    | 544/1000 [00:07<00:06, 72.09it/s]Measuring inference for batch_size=16:  55%|█████▌    | 552/1000 [00:07<00:06, 72.09it/s]Measuring inference for batch_size=16:  56%|█████▌    | 560/1000 [00:07<00:06, 72.12it/s]Measuring inference for batch_size=16:  57%|█████▋    | 568/1000 [00:07<00:05, 72.12it/s]Measuring inference for batch_size=16:  58%|█████▊    | 576/1000 [00:08<00:05, 72.10it/s]Measuring inference for batch_size=16:  58%|█████▊    | 584/1000 [00:08<00:05, 72.10it/s]Measuring inference for batch_size=16:  59%|█████▉    | 592/1000 [00:08<00:05, 72.10it/s]Measuring inference for batch_size=16:  60%|██████    | 600/1000 [00:08<00:05, 72.08it/s]Measuring inference for batch_size=16:  61%|██████    | 608/1000 [00:08<00:05, 72.06it/s]Measuring inference for batch_size=16:  62%|██████▏   | 616/1000 [00:08<00:05, 72.05it/s]Measuring inference for batch_size=16:  62%|██████▏   | 624/1000 [00:08<00:05, 72.06it/s]Measuring inference for batch_size=16:  63%|██████▎   | 632/1000 [00:08<00:05, 71.99it/s]Measuring inference for batch_size=16:  64%|██████▍   | 640/1000 [00:08<00:05, 71.96it/s]Measuring inference for batch_size=16:  65%|██████▍   | 648/1000 [00:09<00:04, 71.93it/s]Measuring inference for batch_size=16:  66%|██████▌   | 656/1000 [00:09<00:04, 71.88it/s]Measuring inference for batch_size=16:  66%|██████▋   | 664/1000 [00:09<00:04, 71.88it/s]Measuring inference for batch_size=16:  67%|██████▋   | 672/1000 [00:09<00:04, 71.90it/s]Measuring inference for batch_size=16:  68%|██████▊   | 680/1000 [00:09<00:04, 71.91it/s]Measuring inference for batch_size=16:  69%|██████▉   | 688/1000 [00:09<00:04, 71.89it/s]Measuring inference for batch_size=16:  70%|██████▉   | 696/1000 [00:09<00:04, 71.89it/s]Measuring inference for batch_size=16:  70%|███████   | 704/1000 [00:09<00:04, 71.92it/s]Measuring inference for batch_size=16:  71%|███████   | 712/1000 [00:09<00:04, 71.89it/s]Measuring inference for batch_size=16:  72%|███████▏  | 720/1000 [00:10<00:03, 71.86it/s]Measuring inference for batch_size=16:  73%|███████▎  | 728/1000 [00:10<00:03, 71.84it/s]Measuring inference for batch_size=16:  74%|███████▎  | 736/1000 [00:10<00:03, 71.85it/s]Measuring inference for batch_size=16:  74%|███████▍  | 744/1000 [00:10<00:03, 71.88it/s]Measuring inference for batch_size=16:  75%|███████▌  | 752/1000 [00:10<00:03, 71.88it/s]Measuring inference for batch_size=16:  76%|███████▌  | 760/1000 [00:10<00:03, 71.88it/s]Measuring inference for batch_size=16:  77%|███████▋  | 768/1000 [00:10<00:03, 71.88it/s]Measuring inference for batch_size=16:  78%|███████▊  | 776/1000 [00:10<00:03, 71.91it/s]Measuring inference for batch_size=16:  78%|███████▊  | 784/1000 [00:10<00:03, 71.92it/s]Measuring inference for batch_size=16:  79%|███████▉  | 792/1000 [00:11<00:02, 71.93it/s]Measuring inference for batch_size=16:  80%|████████  | 800/1000 [00:11<00:02, 71.95it/s]Measuring inference for batch_size=16:  81%|████████  | 808/1000 [00:11<00:02, 71.94it/s]Measuring inference for batch_size=16:  82%|████████▏ | 816/1000 [00:11<00:02, 71.95it/s]Measuring inference for batch_size=16:  82%|████████▏ | 824/1000 [00:11<00:02, 71.94it/s]Measuring inference for batch_size=16:  83%|████████▎ | 832/1000 [00:11<00:02, 71.91it/s]Measuring inference for batch_size=16:  84%|████████▍ | 840/1000 [00:11<00:02, 71.91it/s]Measuring inference for batch_size=16:  85%|████████▍ | 848/1000 [00:11<00:02, 71.91it/s]Measuring inference for batch_size=16:  86%|████████▌ | 856/1000 [00:11<00:02, 71.92it/s]Measuring inference for batch_size=16:  86%|████████▋ | 864/1000 [00:12<00:01, 71.91it/s]Measuring inference for batch_size=16:  87%|████████▋ | 872/1000 [00:12<00:01, 71.91it/s]Measuring inference for batch_size=16:  88%|████████▊ | 880/1000 [00:12<00:01, 71.91it/s]Measuring inference for batch_size=16:  89%|████████▉ | 888/1000 [00:12<00:01, 71.93it/s]Measuring inference for batch_size=16:  90%|████████▉ | 896/1000 [00:12<00:01, 71.94it/s]Measuring inference for batch_size=16:  90%|█████████ | 904/1000 [00:12<00:01, 71.93it/s]Measuring inference for batch_size=16:  91%|█████████ | 912/1000 [00:12<00:01, 71.91it/s]Measuring inference for batch_size=16:  92%|█████████▏| 920/1000 [00:12<00:01, 71.92it/s]Measuring inference for batch_size=16:  93%|█████████▎| 928/1000 [00:12<00:01, 71.91it/s]Measuring inference for batch_size=16:  94%|█████████▎| 936/1000 [00:13<00:00, 71.91it/s]Measuring inference for batch_size=16:  94%|█████████▍| 944/1000 [00:13<00:00, 71.91it/s]Measuring inference for batch_size=16:  95%|█████████▌| 952/1000 [00:13<00:00, 71.90it/s]Measuring inference for batch_size=16:  96%|█████████▌| 960/1000 [00:13<00:00, 71.92it/s]Measuring inference for batch_size=16:  97%|█████████▋| 968/1000 [00:13<00:00, 71.92it/s]Measuring inference for batch_size=16:  98%|█████████▊| 976/1000 [00:13<00:00, 71.91it/s]Measuring inference for batch_size=16:  98%|█████████▊| 984/1000 [00:13<00:00, 71.93it/s]Measuring inference for batch_size=16:  99%|█████████▉| 992/1000 [00:13<00:00, 71.92it/s]Measuring inference for batch_size=16: 100%|██████████| 1000/1000 [00:13<00:00, 71.91it/s]Measuring inference for batch_size=16: 100%|██████████| 1000/1000 [00:13<00:00, 71.93it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 923.98 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_16:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 93.846 us +/- 5.397 us [91.314 us, 225.306 us]
        batches_per_second: 10.68 K +/- 414.58 [4.44 K, 10.95 K]
      metrics:
        batches_per_second_max: 10951.185378590078
        batches_per_second_mean: 10677.842653490703
        batches_per_second_min: 4438.4169312169315
        batches_per_second_std: 414.5788791351224
        seconds_per_batch_max: 0.00022530555725097656
        seconds_per_batch_mean: 9.384608268737794e-05
        seconds_per_batch_min: 9.131431579589844e-05
        seconds_per_batch_std: 5.396839496544367e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.426 us +/- 0.638 us [22.650 us, 30.756 us]
        batches_per_second: 42.72 K +/- 1.01 K [32.51 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42715.432572160345
        batches_per_second_min: 32513.98449612403
        batches_per_second_std: 1014.2159375624849
        seconds_per_batch_max: 3.075599670410156e-05
        seconds_per_batch_mean: 2.3425817489624022e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 6.376070189442924e-07
    on_device_inference:
      human_readable:
        batch_latency: -13541888.528 us +/- 33.182 ms [-14212096.214 us, -13469311.714
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.0703625971089477
        batches_per_second_mean: -0.0738453787274972
        batches_per_second_min: -0.07424284337764664
        batches_per_second_std: 0.00017746511307656113
        seconds_per_batch_max: -13.469311714172363
        seconds_per_batch_mean: -13.541888527870178
        seconds_per_batch_min: -14.212096214294434
        seconds_per_batch_std: 0.03318197479959638
    total:
      human_readable:
        batch_latency: 13.667 ms +/- 36.647 us [13.593 ms, 14.486 ms]
        batches_per_second: 73.17 +/- 0.19 [69.03, 73.57]
      metrics:
        batches_per_second_max: 73.56879253490493
        batches_per_second_mean: 73.1697132051512
        batches_per_second_min: 69.03295039336383
        batches_per_second_std: 0.1906934208758434
        seconds_per_batch_max: 0.014485836029052734
        seconds_per_batch_mean: 0.01366695237159729
        seconds_per_batch_min: 0.013592720031738281
        seconds_per_batch_std: 3.6646893466197966e-05
  batch_size_16:
    cpu_to_gpu:
      human_readable:
        batch_latency: 144.889 us +/- 5.782 us [141.621 us, 280.380 us]
        batches_per_second: 6.91 K +/- 204.91 [3.57 K, 7.06 K]
      metrics:
        batches_per_second_max: 7061.117845117845
        batches_per_second_mean: 6909.679616678152
        batches_per_second_min: 3566.5850340136053
        batches_per_second_std: 204.91421498510084
        seconds_per_batch_max: 0.0002803802490234375
        seconds_per_batch_mean: 0.00014488863945007324
        seconds_per_batch_min: 0.00014162063598632812
        seconds_per_batch_std: 5.782312429039696e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.545 us +/- 0.714 us [22.650 us, 32.425 us]
        batches_per_second: 42.51 K +/- 1.13 K [30.84 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42505.871735302964
        batches_per_second_min: 30840.470588235294
        batches_per_second_std: 1129.4215545241898
        seconds_per_batch_max: 3.24249267578125e-05
        seconds_per_batch_mean: 2.3545026779174804e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 7.141810529218475e-07
    on_device_inference:
      human_readable:
        batch_latency: -13721402.319 us +/- 30.078 ms [-14297663.689 us, -13638367.653
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.06994149686099833
        batches_per_second_mean: -0.07287919354411267
        batches_per_second_min: -0.07332255776136619
        batches_per_second_std: 0.00015746522877199996
        seconds_per_batch_max: -13.638367652893066
        seconds_per_batch_mean: -13.721402318954468
        seconds_per_batch_min: -14.297663688659668
        seconds_per_batch_std: 0.030078026737098865
    total:
      human_readable:
        batch_latency: 13.895 ms +/- 33.471 us [13.813 ms, 14.614 ms]
        batches_per_second: 71.97 +/- 0.17 [68.43, 72.40]
      metrics:
        batches_per_second_max: 72.39672046258738
        batches_per_second_mean: 71.9675641671421
        batches_per_second_min: 68.42592622803726
        batches_per_second_std: 0.169510781239445
        seconds_per_batch_max: 0.014614343643188477
        seconds_per_batch_mean: 0.013895227432250976
        seconds_per_batch_min: 0.013812780380249023
        seconds_per_batch_std: 3.3470814181326725e-05


#####
fp-fp-py-id - Run 3
2024-02-25 22:57:39
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  4.74it/s]
Warning: module Bottleneck is treated as a zero-op.
Warning: module ResNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
ResNet(
  60.19 M, 100.000% Params, 11.58 GMac, 100.000% MACs, 
  (conv1): Conv2d(9.41 k, 0.016% Params, 118.01 MMac, 1.019% MACs, 3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
  (bn1): BatchNorm2d(128, 0.000% Params, 1.61 MMac, 0.014% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(0, 0.000% Params, 802.82 KMac, 0.007% MACs, inplace=True)
  (maxpool): MaxPool2d(0, 0.000% Params, 802.82 KMac, 0.007% MACs, kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    215.81 k, 0.359% Params, 680.39 MMac, 5.875% MACs, 
    (0): Bottleneck(
      75.01 k, 0.125% Params, 236.43 MMac, 2.042% MACs, 
      (conv1): Conv2d(4.1 k, 0.007% Params, 12.85 MMac, 0.111% MACs, 64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
      (downsample): Sequential(
        16.9 k, 0.028% Params, 52.99 MMac, 0.458% MACs, 
        (0): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
    (2): Bottleneck(
      70.4 k, 0.117% Params, 221.98 MMac, 1.917% MACs, 
      (conv1): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(36.86 k, 0.061% Params, 115.61 MMac, 0.998% MACs, 64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(16.38 k, 0.027% Params, 51.38 MMac, 0.444% MACs, 64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, 0.001% Params, 1.61 MMac, 0.014% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 1.2 MMac, 0.010% MACs, inplace=True)
    )
  )
  (layer2): Sequential(
    2.34 M, 3.887% Params, 1.92 GMac, 16.555% MACs, 
    (0): Bottleneck(
      379.39 k, 0.630% Params, 376.02 MMac, 3.247% MACs, 
      (conv1): Conv2d(32.77 k, 0.054% Params, 102.76 MMac, 0.887% MACs, 256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 903.17 KMac, 0.008% MACs, inplace=True)
      (downsample): Sequential(
        132.1 k, 0.219% Params, 103.56 MMac, 0.894% MACs, 
        (0): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (2): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (3): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (4): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (5): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (6): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
    (7): Bottleneck(
      280.06 k, 0.465% Params, 220.17 MMac, 1.901% MACs, 
      (conv1): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(147.46 k, 0.245% Params, 115.61 MMac, 0.998% MACs, 128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, 0.000% Params, 200.7 KMac, 0.002% MACs, 128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(65.54 k, 0.109% Params, 51.38 MMac, 0.444% MACs, 128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1.02 k, 0.002% Params, 802.82 KMac, 0.007% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 602.11 KMac, 0.005% MACs, inplace=True)
    )
  )
  (layer3): Sequential(
    40.61 M, 67.473% Params, 8.05 GMac, 69.501% MACs, 
    (0): Bottleneck(
      1.51 M, 2.513% Params, 374.26 MMac, 3.232% MACs, 
      (conv1): Conv2d(131.07 k, 0.218% Params, 102.76 MMac, 0.887% MACs, 512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 401.41 KMac, 0.003% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 451.58 KMac, 0.004% MACs, inplace=True)
      (downsample): Sequential(
        526.34 k, 0.874% Params, 103.16 MMac, 0.891% MACs, 
        (0): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (2): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (3): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (4): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (5): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (6): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (7): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (8): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (9): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (10): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (11): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (12): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (13): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (14): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (15): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (16): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (17): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (18): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (19): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (20): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (21): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (22): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (23): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (24): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (25): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (26): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (27): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (28): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (29): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (30): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (31): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (32): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (33): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (34): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
    (35): Bottleneck(
      1.12 M, 1.856% Params, 219.27 MMac, 1.893% MACs, 
      (conv1): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(589.82 k, 0.980% Params, 115.61 MMac, 0.998% MACs, 256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, 0.001% Params, 100.35 KMac, 0.001% MACs, 256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(262.14 k, 0.436% Params, 51.38 MMac, 0.444% MACs, 256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2.05 k, 0.003% Params, 401.41 KMac, 0.003% MACs, 1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 301.06 KMac, 0.003% MACs, inplace=True)
    )
  )
  (layer4): Sequential(
    14.96 M, 24.861% Params, 811.02 MMac, 7.003% MACs, 
    (0): Bottleneck(
      6.04 M, 10.034% Params, 373.38 MMac, 3.224% MACs, 
      (conv1): Conv2d(524.29 k, 0.871% Params, 102.76 MMac, 0.887% MACs, 1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 200.7 KMac, 0.002% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 225.79 KMac, 0.002% MACs, inplace=True)
      (downsample): Sequential(
        2.1 M, 3.491% Params, 102.96 MMac, 0.889% MACs, 
        (0): Conv2d(2.1 M, 3.484% Params, 102.76 MMac, 0.887% MACs, 1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
    (2): Bottleneck(
      4.46 M, 7.414% Params, 218.82 MMac, 1.890% MACs, 
      (conv1): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv2): Conv2d(2.36 M, 3.920% Params, 115.61 MMac, 0.998% MACs, 512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(1.02 k, 0.002% Params, 50.18 KMac, 0.000% MACs, 512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(1.05 M, 1.742% Params, 51.38 MMac, 0.444% MACs, 512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(4.1 k, 0.007% Params, 200.7 KMac, 0.002% MACs, 2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(0, 0.000% Params, 150.53 KMac, 0.001% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 100.35 KMac, 0.001% MACs, output_size=(1, 1))
  (fc): Linear(2.05 M, 3.404% Params, 2.05 MMac, 0.018% MACs, in_features=2048, out_features=1000, bias=True)
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:00, 96.94it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:00, 97.32it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:00, 97.47it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:00, 97.55it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:00<00:00, 97.58it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:00<00:00, 97.61it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:00<00:00, 97.63it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:00<00:00, 97.62it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:00<00:00, 97.60it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 97.56it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 97.54it/s]
STAGE:2024-02-25 22:57:09 6071:6071 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:57:09 6071:6071 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:57:09 6071:6071 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:13, 72.82it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:13, 73.17it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:13, 73.31it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:13, 73.40it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:00<00:13, 73.43it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:00<00:12, 73.44it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:00<00:12, 73.46it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:00<00:12, 73.48it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:00<00:12, 73.50it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:01<00:12, 73.48it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:01<00:12, 73.48it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:01<00:12, 73.50it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:01<00:12, 73.49it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:01<00:12, 73.49it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:01<00:11, 73.49it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:01<00:11, 73.49it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:01<00:11, 73.49it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:01<00:11, 72.36it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:02<00:11, 71.58it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:02<00:11, 71.02it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:02<00:11, 70.60it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:02<00:11, 70.33it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:02<00:11, 70.14it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:02<00:11, 70.05it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:02<00:11, 69.99it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:02<00:11, 69.98it/s]Measuring inference for batch_size=1:  22%|██▏       | 215/1000 [00:02<00:11, 69.96it/s]Measuring inference for batch_size=1:  22%|██▏       | 222/1000 [00:03<00:11, 69.89it/s]Measuring inference for batch_size=1:  23%|██▎       | 229/1000 [00:03<00:11, 69.91it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:03<00:10, 69.88it/s]Measuring inference for batch_size=1:  24%|██▍       | 243/1000 [00:03<00:10, 69.87it/s]Measuring inference for batch_size=1:  25%|██▌       | 250/1000 [00:03<00:10, 69.80it/s]Measuring inference for batch_size=1:  26%|██▌       | 257/1000 [00:03<00:10, 69.76it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:03<00:10, 69.75it/s]Measuring inference for batch_size=1:  27%|██▋       | 271/1000 [00:03<00:10, 69.75it/s]Measuring inference for batch_size=1:  28%|██▊       | 278/1000 [00:03<00:10, 69.75it/s]Measuring inference for batch_size=1:  28%|██▊       | 285/1000 [00:03<00:10, 69.77it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:04<00:10, 69.78it/s]Measuring inference for batch_size=1:  30%|██▉       | 299/1000 [00:04<00:10, 69.81it/s]Measuring inference for batch_size=1:  31%|███       | 306/1000 [00:04<00:09, 69.80it/s]Measuring inference for batch_size=1:  31%|███▏      | 313/1000 [00:04<00:09, 69.81it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:04<00:09, 69.82it/s]Measuring inference for batch_size=1:  33%|███▎      | 327/1000 [00:04<00:09, 69.80it/s]Measuring inference for batch_size=1:  33%|███▎      | 334/1000 [00:04<00:09, 69.79it/s]Measuring inference for batch_size=1:  34%|███▍      | 341/1000 [00:04<00:09, 69.77it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:04<00:09, 69.79it/s]Measuring inference for batch_size=1:  36%|███▌      | 355/1000 [00:04<00:09, 69.78it/s]Measuring inference for batch_size=1:  36%|███▌      | 362/1000 [00:05<00:09, 69.76it/s]Measuring inference for batch_size=1:  37%|███▋      | 369/1000 [00:05<00:09, 69.75it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:05<00:08, 69.73it/s]Measuring inference for batch_size=1:  38%|███▊      | 383/1000 [00:05<00:08, 69.73it/s]Measuring inference for batch_size=1:  39%|███▉      | 390/1000 [00:05<00:08, 69.71it/s]Measuring inference for batch_size=1:  40%|███▉      | 397/1000 [00:05<00:08, 69.71it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:05<00:08, 69.69it/s]Measuring inference for batch_size=1:  41%|████      | 411/1000 [00:05<00:08, 69.68it/s]Measuring inference for batch_size=1:  42%|████▏     | 418/1000 [00:05<00:08, 69.67it/s]Measuring inference for batch_size=1:  42%|████▎     | 425/1000 [00:05<00:08, 69.69it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:06<00:08, 69.73it/s]Measuring inference for batch_size=1:  44%|████▍     | 439/1000 [00:06<00:08, 69.72it/s]Measuring inference for batch_size=1:  45%|████▍     | 446/1000 [00:06<00:07, 69.70it/s]Measuring inference for batch_size=1:  45%|████▌     | 453/1000 [00:06<00:07, 69.72it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:06<00:07, 69.72it/s]Measuring inference for batch_size=1:  47%|████▋     | 467/1000 [00:06<00:07, 69.72it/s]Measuring inference for batch_size=1:  47%|████▋     | 474/1000 [00:06<00:07, 69.73it/s]Measuring inference for batch_size=1:  48%|████▊     | 481/1000 [00:06<00:07, 69.73it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:06<00:07, 69.73it/s]Measuring inference for batch_size=1:  50%|████▉     | 495/1000 [00:06<00:07, 69.73it/s]Measuring inference for batch_size=1:  50%|█████     | 502/1000 [00:07<00:07, 69.71it/s]Measuring inference for batch_size=1:  51%|█████     | 509/1000 [00:07<00:07, 69.70it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:07<00:06, 69.71it/s]Measuring inference for batch_size=1:  52%|█████▏    | 523/1000 [00:07<00:06, 69.74it/s]Measuring inference for batch_size=1:  53%|█████▎    | 530/1000 [00:07<00:06, 69.78it/s]Measuring inference for batch_size=1:  54%|█████▎    | 537/1000 [00:07<00:06, 69.81it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:07<00:06, 69.81it/s]Measuring inference for batch_size=1:  55%|█████▌    | 551/1000 [00:07<00:06, 69.79it/s]Measuring inference for batch_size=1:  56%|█████▌    | 558/1000 [00:07<00:06, 69.81it/s]Measuring inference for batch_size=1:  56%|█████▋    | 565/1000 [00:08<00:06, 69.81it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:08<00:06, 69.78it/s]Measuring inference for batch_size=1:  58%|█████▊    | 579/1000 [00:08<00:06, 69.80it/s]Measuring inference for batch_size=1:  59%|█████▊    | 586/1000 [00:08<00:05, 69.78it/s]Measuring inference for batch_size=1:  59%|█████▉    | 593/1000 [00:08<00:05, 69.78it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:08<00:05, 69.78it/s]Measuring inference for batch_size=1:  61%|██████    | 607/1000 [00:08<00:05, 69.79it/s]Measuring inference for batch_size=1:  61%|██████▏   | 614/1000 [00:08<00:05, 69.79it/s]Measuring inference for batch_size=1:  62%|██████▏   | 621/1000 [00:08<00:05, 69.80it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:08<00:05, 69.86it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:09<00:05, 69.91it/s]Measuring inference for batch_size=1:  64%|██████▍   | 643/1000 [00:09<00:05, 69.93it/s]Measuring inference for batch_size=1:  65%|██████▌   | 650/1000 [00:09<00:05, 69.94it/s]Measuring inference for batch_size=1:  66%|██████▌   | 657/1000 [00:09<00:04, 69.94it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:09<00:04, 69.91it/s]Measuring inference for batch_size=1:  67%|██████▋   | 671/1000 [00:09<00:04, 69.92it/s]Measuring inference for batch_size=1:  68%|██████▊   | 678/1000 [00:09<00:04, 69.87it/s]Measuring inference for batch_size=1:  68%|██████▊   | 685/1000 [00:09<00:04, 69.86it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:09<00:04, 69.81it/s]Measuring inference for batch_size=1:  70%|██████▉   | 699/1000 [00:09<00:04, 69.79it/s]Measuring inference for batch_size=1:  71%|███████   | 706/1000 [00:10<00:04, 69.76it/s]Measuring inference for batch_size=1:  71%|███████▏  | 713/1000 [00:10<00:04, 69.77it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:10<00:04, 69.78it/s]Measuring inference for batch_size=1:  73%|███████▎  | 727/1000 [00:10<00:03, 69.77it/s]Measuring inference for batch_size=1:  73%|███████▎  | 734/1000 [00:10<00:03, 69.79it/s]Measuring inference for batch_size=1:  74%|███████▍  | 741/1000 [00:10<00:03, 69.80it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:10<00:03, 69.77it/s]Measuring inference for batch_size=1:  76%|███████▌  | 755/1000 [00:10<00:03, 69.73it/s]Measuring inference for batch_size=1:  76%|███████▌  | 762/1000 [00:10<00:03, 69.72it/s]Measuring inference for batch_size=1:  77%|███████▋  | 769/1000 [00:10<00:03, 69.69it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:11<00:03, 69.66it/s]Measuring inference for batch_size=1:  78%|███████▊  | 783/1000 [00:11<00:03, 69.68it/s]Measuring inference for batch_size=1:  79%|███████▉  | 790/1000 [00:11<00:03, 69.62it/s]Measuring inference for batch_size=1:  80%|███████▉  | 797/1000 [00:11<00:02, 69.59it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:11<00:02, 69.61it/s]Measuring inference for batch_size=1:  81%|████████  | 811/1000 [00:11<00:02, 69.67it/s]Measuring inference for batch_size=1:  82%|████████▏ | 818/1000 [00:11<00:02, 69.66it/s]Measuring inference for batch_size=1:  82%|████████▎ | 825/1000 [00:11<00:02, 69.65it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:11<00:02, 69.67it/s]Measuring inference for batch_size=1:  84%|████████▍ | 839/1000 [00:11<00:02, 69.68it/s]Measuring inference for batch_size=1:  85%|████████▍ | 846/1000 [00:12<00:02, 69.70it/s]Measuring inference for batch_size=1:  85%|████████▌ | 853/1000 [00:12<00:02, 69.68it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:12<00:02, 69.66it/s]Measuring inference for batch_size=1:  87%|████████▋ | 867/1000 [00:12<00:01, 69.65it/s]Measuring inference for batch_size=1:  87%|████████▋ | 874/1000 [00:12<00:01, 69.65it/s]Measuring inference for batch_size=1:  88%|████████▊ | 881/1000 [00:12<00:01, 69.66it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:12<00:01, 69.67it/s]Measuring inference for batch_size=1:  90%|████████▉ | 895/1000 [00:12<00:01, 69.59it/s]Measuring inference for batch_size=1:  90%|█████████ | 902/1000 [00:12<00:01, 69.58it/s]Measuring inference for batch_size=1:  91%|█████████ | 909/1000 [00:12<00:01, 69.63it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:13<00:01, 69.63it/s]Measuring inference for batch_size=1:  92%|█████████▏| 923/1000 [00:13<00:01, 69.63it/s]Measuring inference for batch_size=1:  93%|█████████▎| 930/1000 [00:13<00:01, 69.64it/s]Measuring inference for batch_size=1:  94%|█████████▎| 937/1000 [00:13<00:00, 69.66it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:13<00:00, 69.68it/s]Measuring inference for batch_size=1:  95%|█████████▌| 951/1000 [00:13<00:00, 69.69it/s]Measuring inference for batch_size=1:  96%|█████████▌| 958/1000 [00:13<00:00, 69.70it/s]Measuring inference for batch_size=1:  96%|█████████▋| 965/1000 [00:13<00:00, 69.72it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:13<00:00, 69.67it/s]Measuring inference for batch_size=1:  98%|█████████▊| 979/1000 [00:13<00:00, 69.68it/s]Measuring inference for batch_size=1:  99%|█████████▊| 986/1000 [00:14<00:00, 69.72it/s]Measuring inference for batch_size=1:  99%|█████████▉| 993/1000 [00:14<00:00, 69.74it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:14<00:00, 69.73it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:14<00:00, 70.23it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=16:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=16:   8%|▊         | 8/100 [00:00<00:01, 72.72it/s]Warming up with batch_size=16:  16%|█▌        | 16/100 [00:00<00:01, 72.88it/s]Warming up with batch_size=16:  24%|██▍       | 24/100 [00:00<00:01, 72.94it/s]Warming up with batch_size=16:  32%|███▏      | 32/100 [00:00<00:00, 72.93it/s]Warming up with batch_size=16:  40%|████      | 40/100 [00:00<00:00, 72.95it/s]Warming up with batch_size=16:  48%|████▊     | 48/100 [00:00<00:00, 72.97it/s]Warming up with batch_size=16:  56%|█████▌    | 56/100 [00:00<00:00, 73.00it/s]Warming up with batch_size=16:  64%|██████▍   | 64/100 [00:00<00:00, 73.03it/s]Warming up with batch_size=16:  72%|███████▏  | 72/100 [00:00<00:00, 73.06it/s]Warming up with batch_size=16:  80%|████████  | 80/100 [00:01<00:00, 73.08it/s]Warming up with batch_size=16:  88%|████████▊ | 88/100 [00:01<00:00, 73.09it/s]Warming up with batch_size=16:  96%|█████████▌| 96/100 [00:01<00:00, 73.04it/s]Warming up with batch_size=16: 100%|██████████| 100/100 [00:01<00:00, 73.00it/s]
STAGE:2024-02-25 22:57:25 6071:6071 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-25 22:57:25 6071:6071 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-25 22:57:25 6071:6071 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=16:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=16:   1%|          | 8/1000 [00:00<00:13, 71.88it/s]Measuring inference for batch_size=16:   2%|▏         | 16/1000 [00:00<00:13, 72.14it/s]Measuring inference for batch_size=16:   2%|▏         | 24/1000 [00:00<00:13, 72.25it/s]Measuring inference for batch_size=16:   3%|▎         | 32/1000 [00:00<00:13, 72.28it/s]Measuring inference for batch_size=16:   4%|▍         | 40/1000 [00:00<00:13, 72.37it/s]Measuring inference for batch_size=16:   5%|▍         | 48/1000 [00:00<00:13, 72.44it/s]Measuring inference for batch_size=16:   6%|▌         | 56/1000 [00:00<00:13, 72.44it/s]Measuring inference for batch_size=16:   6%|▋         | 64/1000 [00:00<00:12, 72.46it/s]Measuring inference for batch_size=16:   7%|▋         | 72/1000 [00:00<00:12, 72.52it/s]Measuring inference for batch_size=16:   8%|▊         | 80/1000 [00:01<00:12, 72.53it/s]Measuring inference for batch_size=16:   9%|▉         | 88/1000 [00:01<00:12, 72.53it/s]Measuring inference for batch_size=16:  10%|▉         | 96/1000 [00:01<00:12, 72.50it/s]Measuring inference for batch_size=16:  10%|█         | 104/1000 [00:01<00:12, 72.47it/s]Measuring inference for batch_size=16:  11%|█         | 112/1000 [00:01<00:12, 72.49it/s]Measuring inference for batch_size=16:  12%|█▏        | 120/1000 [00:01<00:12, 72.49it/s]Measuring inference for batch_size=16:  13%|█▎        | 128/1000 [00:01<00:12, 72.52it/s]Measuring inference for batch_size=16:  14%|█▎        | 136/1000 [00:01<00:11, 72.52it/s]Measuring inference for batch_size=16:  14%|█▍        | 144/1000 [00:01<00:11, 72.50it/s]Measuring inference for batch_size=16:  15%|█▌        | 152/1000 [00:02<00:11, 72.51it/s]Measuring inference for batch_size=16:  16%|█▌        | 160/1000 [00:02<00:11, 72.52it/s]Measuring inference for batch_size=16:  17%|█▋        | 168/1000 [00:02<00:11, 72.52it/s]Measuring inference for batch_size=16:  18%|█▊        | 176/1000 [00:02<00:11, 72.51it/s]Measuring inference for batch_size=16:  18%|█▊        | 184/1000 [00:02<00:11, 72.50it/s]Measuring inference for batch_size=16:  19%|█▉        | 192/1000 [00:02<00:11, 72.46it/s]Measuring inference for batch_size=16:  20%|██        | 200/1000 [00:02<00:11, 72.42it/s]Measuring inference for batch_size=16:  21%|██        | 208/1000 [00:02<00:10, 72.39it/s]Measuring inference for batch_size=16:  22%|██▏       | 216/1000 [00:02<00:10, 72.38it/s]Measuring inference for batch_size=16:  22%|██▏       | 224/1000 [00:03<00:10, 71.39it/s]Measuring inference for batch_size=16:  23%|██▎       | 232/1000 [00:03<00:10, 71.70it/s]Measuring inference for batch_size=16:  24%|██▍       | 240/1000 [00:03<00:10, 71.92it/s]Measuring inference for batch_size=16:  25%|██▍       | 248/1000 [00:03<00:10, 72.07it/s]Measuring inference for batch_size=16:  26%|██▌       | 256/1000 [00:03<00:10, 72.15it/s]Measuring inference for batch_size=16:  26%|██▋       | 264/1000 [00:03<00:10, 72.22it/s]Measuring inference for batch_size=16:  27%|██▋       | 272/1000 [00:03<00:10, 72.26it/s]Measuring inference for batch_size=16:  28%|██▊       | 280/1000 [00:03<00:09, 72.30it/s]Measuring inference for batch_size=16:  29%|██▉       | 288/1000 [00:03<00:09, 72.32it/s]Measuring inference for batch_size=16:  30%|██▉       | 296/1000 [00:04<00:09, 72.36it/s]Measuring inference for batch_size=16:  30%|███       | 304/1000 [00:04<00:09, 72.33it/s]Measuring inference for batch_size=16:  31%|███       | 312/1000 [00:04<00:09, 72.32it/s]Measuring inference for batch_size=16:  32%|███▏      | 320/1000 [00:04<00:09, 72.30it/s]Measuring inference for batch_size=16:  33%|███▎      | 328/1000 [00:04<00:09, 72.30it/s]Measuring inference for batch_size=16:  34%|███▎      | 336/1000 [00:04<00:09, 72.30it/s]Measuring inference for batch_size=16:  34%|███▍      | 344/1000 [00:04<00:09, 72.36it/s]Measuring inference for batch_size=16:  35%|███▌      | 352/1000 [00:04<00:08, 72.36it/s]Measuring inference for batch_size=16:  36%|███▌      | 360/1000 [00:04<00:08, 72.35it/s]Measuring inference for batch_size=16:  37%|███▋      | 368/1000 [00:05<00:08, 72.33it/s]Measuring inference for batch_size=16:  38%|███▊      | 376/1000 [00:05<00:08, 72.34it/s]Measuring inference for batch_size=16:  38%|███▊      | 384/1000 [00:05<00:08, 72.34it/s]Measuring inference for batch_size=16:  39%|███▉      | 392/1000 [00:05<00:08, 72.34it/s]Measuring inference for batch_size=16:  40%|████      | 400/1000 [00:05<00:08, 72.33it/s]Measuring inference for batch_size=16:  41%|████      | 408/1000 [00:05<00:08, 72.35it/s]Measuring inference for batch_size=16:  42%|████▏     | 416/1000 [00:05<00:08, 72.35it/s]Measuring inference for batch_size=16:  42%|████▏     | 424/1000 [00:05<00:07, 72.36it/s]Measuring inference for batch_size=16:  43%|████▎     | 432/1000 [00:05<00:07, 72.35it/s]Measuring inference for batch_size=16:  44%|████▍     | 440/1000 [00:06<00:07, 72.36it/s]Measuring inference for batch_size=16:  45%|████▍     | 448/1000 [00:06<00:07, 72.36it/s]Measuring inference for batch_size=16:  46%|████▌     | 456/1000 [00:06<00:07, 72.36it/s]Measuring inference for batch_size=16:  46%|████▋     | 464/1000 [00:06<00:07, 72.36it/s]Measuring inference for batch_size=16:  47%|████▋     | 472/1000 [00:06<00:07, 72.36it/s]Measuring inference for batch_size=16:  48%|████▊     | 480/1000 [00:06<00:07, 72.36it/s]Measuring inference for batch_size=16:  49%|████▉     | 488/1000 [00:06<00:07, 72.35it/s]Measuring inference for batch_size=16:  50%|████▉     | 496/1000 [00:06<00:06, 72.34it/s]Measuring inference for batch_size=16:  50%|█████     | 504/1000 [00:06<00:06, 72.34it/s]Measuring inference for batch_size=16:  51%|█████     | 512/1000 [00:07<00:06, 72.31it/s]Measuring inference for batch_size=16:  52%|█████▏    | 520/1000 [00:07<00:06, 72.33it/s]Measuring inference for batch_size=16:  53%|█████▎    | 528/1000 [00:07<00:06, 72.34it/s]Measuring inference for batch_size=16:  54%|█████▎    | 536/1000 [00:07<00:06, 72.40it/s]Measuring inference for batch_size=16:  54%|█████▍    | 544/1000 [00:07<00:06, 72.44it/s]Measuring inference for batch_size=16:  55%|█████▌    | 552/1000 [00:07<00:06, 72.47it/s]Measuring inference for batch_size=16:  56%|█████▌    | 560/1000 [00:07<00:06, 72.47it/s]Measuring inference for batch_size=16:  57%|█████▋    | 568/1000 [00:07<00:05, 72.46it/s]Measuring inference for batch_size=16:  58%|█████▊    | 576/1000 [00:07<00:05, 72.42it/s]Measuring inference for batch_size=16:  58%|█████▊    | 584/1000 [00:08<00:05, 72.42it/s]Measuring inference for batch_size=16:  59%|█████▉    | 592/1000 [00:08<00:05, 72.41it/s]Measuring inference for batch_size=16:  60%|██████    | 600/1000 [00:08<00:05, 71.27it/s]Measuring inference for batch_size=16:  61%|██████    | 608/1000 [00:08<00:05, 70.51it/s]Measuring inference for batch_size=16:  62%|██████▏   | 616/1000 [00:08<00:05, 70.00it/s]Measuring inference for batch_size=16:  62%|██████▏   | 624/1000 [00:08<00:05, 69.65it/s]Measuring inference for batch_size=16:  63%|██████▎   | 631/1000 [00:08<00:05, 69.46it/s]Measuring inference for batch_size=16:  64%|██████▍   | 639/1000 [00:08<00:05, 70.21it/s]Measuring inference for batch_size=16:  65%|██████▍   | 647/1000 [00:08<00:04, 70.88it/s]Measuring inference for batch_size=16:  66%|██████▌   | 655/1000 [00:09<00:04, 71.35it/s]Measuring inference for batch_size=16:  66%|██████▋   | 663/1000 [00:09<00:04, 71.68it/s]Measuring inference for batch_size=16:  67%|██████▋   | 671/1000 [00:09<00:04, 71.89it/s]Measuring inference for batch_size=16:  68%|██████▊   | 679/1000 [00:09<00:04, 72.01it/s]Measuring inference for batch_size=16:  69%|██████▊   | 687/1000 [00:09<00:04, 72.10it/s]Measuring inference for batch_size=16:  70%|██████▉   | 695/1000 [00:09<00:04, 72.16it/s]Measuring inference for batch_size=16:  70%|███████   | 703/1000 [00:09<00:04, 72.20it/s]Measuring inference for batch_size=16:  71%|███████   | 711/1000 [00:09<00:04, 72.23it/s]Measuring inference for batch_size=16:  72%|███████▏  | 719/1000 [00:09<00:03, 72.23it/s]Measuring inference for batch_size=16:  73%|███████▎  | 727/1000 [00:10<00:03, 72.26it/s]Measuring inference for batch_size=16:  74%|███████▎  | 735/1000 [00:10<00:03, 72.29it/s]Measuring inference for batch_size=16:  74%|███████▍  | 743/1000 [00:10<00:03, 72.31it/s]Measuring inference for batch_size=16:  75%|███████▌  | 751/1000 [00:10<00:03, 72.31it/s]Measuring inference for batch_size=16:  76%|███████▌  | 759/1000 [00:10<00:03, 72.33it/s]Measuring inference for batch_size=16:  77%|███████▋  | 767/1000 [00:10<00:03, 72.34it/s]Measuring inference for batch_size=16:  78%|███████▊  | 775/1000 [00:10<00:03, 72.34it/s]Measuring inference for batch_size=16:  78%|███████▊  | 783/1000 [00:10<00:03, 72.33it/s]Measuring inference for batch_size=16:  79%|███████▉  | 791/1000 [00:10<00:02, 72.33it/s]Measuring inference for batch_size=16:  80%|███████▉  | 799/1000 [00:11<00:02, 72.31it/s]Measuring inference for batch_size=16:  81%|████████  | 807/1000 [00:11<00:02, 72.30it/s]Measuring inference for batch_size=16:  82%|████████▏ | 815/1000 [00:11<00:02, 72.30it/s]Measuring inference for batch_size=16:  82%|████████▏ | 823/1000 [00:11<00:02, 72.29it/s]Measuring inference for batch_size=16:  83%|████████▎ | 831/1000 [00:11<00:02, 72.27it/s]Measuring inference for batch_size=16:  84%|████████▍ | 839/1000 [00:11<00:02, 72.28it/s]Measuring inference for batch_size=16:  85%|████████▍ | 847/1000 [00:11<00:02, 72.29it/s]Measuring inference for batch_size=16:  86%|████████▌ | 855/1000 [00:11<00:02, 72.31it/s]Measuring inference for batch_size=16:  86%|████████▋ | 863/1000 [00:11<00:01, 72.30it/s]Measuring inference for batch_size=16:  87%|████████▋ | 871/1000 [00:12<00:01, 72.30it/s]Measuring inference for batch_size=16:  88%|████████▊ | 879/1000 [00:12<00:01, 72.30it/s]Measuring inference for batch_size=16:  89%|████████▊ | 887/1000 [00:12<00:01, 72.28it/s]Measuring inference for batch_size=16:  90%|████████▉ | 895/1000 [00:12<00:01, 72.29it/s]Measuring inference for batch_size=16:  90%|█████████ | 903/1000 [00:12<00:01, 72.31it/s]Measuring inference for batch_size=16:  91%|█████████ | 911/1000 [00:12<00:01, 72.32it/s]Measuring inference for batch_size=16:  92%|█████████▏| 919/1000 [00:12<00:01, 72.36it/s]Measuring inference for batch_size=16:  93%|█████████▎| 927/1000 [00:12<00:01, 72.33it/s]Measuring inference for batch_size=16:  94%|█████████▎| 935/1000 [00:12<00:00, 72.32it/s]Measuring inference for batch_size=16:  94%|█████████▍| 943/1000 [00:13<00:00, 72.30it/s]Measuring inference for batch_size=16:  95%|█████████▌| 951/1000 [00:13<00:00, 72.29it/s]Measuring inference for batch_size=16:  96%|█████████▌| 959/1000 [00:13<00:00, 72.27it/s]Measuring inference for batch_size=16:  97%|█████████▋| 967/1000 [00:13<00:00, 72.29it/s]Measuring inference for batch_size=16:  98%|█████████▊| 975/1000 [00:13<00:00, 71.18it/s]Measuring inference for batch_size=16:  98%|█████████▊| 983/1000 [00:13<00:00, 70.45it/s]Measuring inference for batch_size=16:  99%|█████████▉| 991/1000 [00:13<00:00, 69.94it/s]Measuring inference for batch_size=16: 100%|█████████▉| 998/1000 [00:13<00:00, 69.61it/s]Measuring inference for batch_size=16: 100%|██████████| 1000/1000 [00:13<00:00, 72.07it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 11580687848
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.98 GB
    total: 31.28 GB
    used: 917.77 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 374.76 MB
    max_inference_bytes: 392962560
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
  batch_size_16:
    max_inference: 378.48 MB
    max_inference_bytes: 396866048
    post_inference: 238.40 MB
    post_inference_bytes: 249983488
    pre_inference: 238.40 MB
    pre_inference_bytes: 249983488
params: 60192808
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 108.174 us +/- 5.432 us [104.189 us, 222.683 us]
        batches_per_second: 9.26 K +/- 345.49 [4.49 K, 9.60 K]
      metrics:
        batches_per_second_max: 9597.949656750572
        batches_per_second_mean: 9260.978931338117
        batches_per_second_min: 4490.689507494647
        batches_per_second_std: 345.4945410114286
        seconds_per_batch_max: 0.00022268295288085938
        seconds_per_batch_mean: 0.00010817408561706542
        seconds_per_batch_min: 0.00010418891906738281
        seconds_per_batch_std: 5.43221847467536e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.943 us +/- 0.832 us [22.650 us, 35.048 us]
        batches_per_second: 41.81 K +/- 1.21 K [28.53 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 41807.869410351814
        batches_per_second_min: 28532.680272108842
        batches_per_second_std: 1206.3903384710034
        seconds_per_batch_max: 3.504753112792969e-05
        seconds_per_batch_mean: 2.394270896911621e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 8.316698603298373e-07
    on_device_inference:
      human_readable:
        batch_latency: -14089647.074 us +/- 248.920 ms [-14328319.550 us, -13420096.397
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.0697918549723209
        batches_per_second_mean: -0.07099710371228253
        batches_per_second_min: -0.07451511303553278
        batches_per_second_std: 0.0013021887711216467
        seconds_per_batch_max: -13.420096397399902
        seconds_per_batch_mean: -14.089647073745727
        seconds_per_batch_min: -14.328319549560547
        seconds_per_batch_std: 0.24892015169088824
    total:
      human_readable:
        batch_latency: 14.230 ms +/- 250.478 us [13.556 ms, 14.510 ms]
        batches_per_second: 70.29 +/- 1.28 [68.92, 73.77]
      metrics:
        batches_per_second_max: 73.7706486562544
        batches_per_second_mean: 70.29450604057742
        batches_per_second_min: 68.91612033979067
        batches_per_second_std: 1.2842753785796288
        seconds_per_batch_max: 0.014510393142700195
        seconds_per_batch_mean: 0.014230438947677611
        seconds_per_batch_min: 0.013555526733398438
        seconds_per_batch_std: 0.0002504784999316203
  batch_size_16:
    cpu_to_gpu:
      human_readable:
        batch_latency: 144.256 us +/- 5.578 us [141.621 us, 286.579 us]
        batches_per_second: 6.94 K +/- 186.71 [3.49 K, 7.06 K]
      metrics:
        batches_per_second_max: 7061.117845117845
        batches_per_second_mean: 6938.977999849209
        batches_per_second_min: 3489.4376039933445
        batches_per_second_std: 186.7069233623837
        seconds_per_batch_max: 0.0002865791320800781
        seconds_per_batch_mean: 0.0001442561149597168
        seconds_per_batch_min: 0.00014162063598632812
        seconds_per_batch_std: 5.578001679776849e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 23.643 us +/- 0.528 us [22.650 us, 29.802 us]
        batches_per_second: 42.32 K +/- 869.39 [33.55 K, 44.15 K]
      metrics:
        batches_per_second_max: 44150.56842105263
        batches_per_second_mean: 42315.12317352415
        batches_per_second_min: 33554.432
        batches_per_second_std: 869.3906208790636
        seconds_per_batch_max: 2.9802322387695312e-05
        seconds_per_batch_mean: 2.3643016815185546e-05
        seconds_per_batch_min: 2.2649765014648438e-05
        seconds_per_batch_std: 5.280012922061619e-07
    on_device_inference:
      human_readable:
        batch_latency: -13694219.767 us +/- 195.940 ms [-14440735.817 us, -13563391.685
          us]
        batches_per_second: -0.07 +/- 0.00 [-0.07, -0.07]
      metrics:
        batches_per_second_max: -0.06924854887420984
        batches_per_second_mean: -0.07303784731710948
        batches_per_second_min: -0.07372787155222378
        batches_per_second_std: 0.0010020240083205845
        seconds_per_batch_max: -13.56339168548584
        seconds_per_batch_mean: -13.694219766616822
        seconds_per_batch_min: -14.440735816955566
        seconds_per_batch_std: 0.19593993930193232
    total:
      human_readable:
        batch_latency: 13.867 ms +/- 197.464 us [13.734 ms, 14.629 ms]
        batches_per_second: 72.13 +/- 0.98 [68.36, 72.81]
      metrics:
        batches_per_second_max: 72.81145733877267
        batches_per_second_mean: 72.12524555917138
        batches_per_second_min: 68.35789954040223
        batches_per_second_std: 0.9849689103435519
        seconds_per_batch_max: 0.014628887176513672
        seconds_per_batch_mean: 0.013867467403411866
        seconds_per_batch_min: 0.013734102249145508
        seconds_per_batch_std: 0.00019746391296548751


