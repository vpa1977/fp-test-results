#####
fp-fp-py-id - Run 1
2024-02-26 00:05:35
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.00it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.05it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.07it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.07it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.07it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.08it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.08it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.09it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.08it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.08it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.06it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.06it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.06it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.05it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.05it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.06it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.06it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.07it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.09it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.09it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.07it/s]
STAGE:2024-02-26 00:04:33 9459:9459 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:04:33 9459:9459 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:04:33 9459:9459 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.12it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.35it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.43it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.48it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.51it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 37.51it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.52it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.54it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.54it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.32it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 36.94it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 36.66it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 36.48it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 36.34it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:25, 36.25it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:25, 36.18it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:25, 36.14it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:25, 36.07it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:25, 36.04it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:25, 36.03it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:25, 36.04it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:25, 36.05it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:25, 36.05it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 36.05it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:24, 36.05it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:24, 36.07it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:03<00:24, 36.08it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:24, 36.09it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:24, 36.11it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:24, 36.11it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:24, 36.10it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:24, 36.10it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 36.09it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 36.08it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:23, 36.06it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:04<00:23, 36.08it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:23, 36.08it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:23, 36.09it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:23, 36.11it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:23, 36.12it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:23, 36.10it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 36.06it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 36.07it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:22, 36.08it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:05<00:22, 36.08it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:22, 36.07it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:22, 36.07it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:22, 36.09it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:22, 36.05it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:22, 36.04it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 36.04it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 36.03it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:21, 36.01it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:06<00:21, 36.02it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:06<00:21, 36.03it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:21, 36.03it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:21, 36.03it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:21, 36.02it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:21, 36.02it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 36.02it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 36.01it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 36.00it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:07<00:20, 36.02it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:07<00:20, 36.04it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:20, 36.04it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:20, 36.06it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:20, 36.08it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:20, 36.08it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 36.08it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 36.11it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 36.12it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:08<00:19, 36.13it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:08<00:19, 36.15it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:19, 36.14it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:19, 36.13it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:19, 36.12it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:19, 36.11it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 36.10it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 36.06it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 36.02it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:09<00:18, 36.00it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:09<00:18, 36.02it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:09<00:18, 36.06it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:18, 36.08it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:18, 36.09it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:18, 36.09it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 36.10it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 36.10it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 36.11it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:10<00:17, 36.10it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:10<00:17, 36.10it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:10<00:17, 36.10it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:17, 36.11it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:17, 36.09it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:17, 36.05it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 36.01it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 36.00it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 36.01it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:11<00:16, 36.03it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:11<00:16, 36.05it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:11<00:16, 36.07it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:16, 36.08it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:16, 36.10it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:16, 36.09it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 36.09it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 36.10it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 36.06it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:12<00:15, 36.01it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:12<00:15, 36.02it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:12<00:15, 36.05it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:12<00:15, 36.07it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:15, 36.09it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:15, 36.12it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 36.12it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 36.11it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 36.11it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:13<00:14, 36.10it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:13<00:14, 36.08it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:13<00:14, 36.10it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:13<00:14, 36.09it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:14, 36.09it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:14, 36.08it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 36.07it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 36.07it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 36.08it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:14<00:13, 36.09it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:14<00:13, 36.09it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:14<00:13, 36.09it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:14<00:13, 36.04it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:13, 36.02it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:13, 35.99it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:13, 35.97it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 35.98it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 36.02it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:15<00:12, 36.07it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:15<00:12, 36.09it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:15<00:12, 36.10it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:15<00:12, 36.11it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:15<00:12, 36.09it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:12, 36.09it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 36.09it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 36.09it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 36.09it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:16<00:11, 36.07it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:16<00:11, 36.08it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:16<00:11, 36.08it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:16<00:11, 36.08it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:16<00:11, 36.08it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:11, 36.08it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 36.07it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 36.08it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 36.10it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:17<00:10, 36.09it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:17<00:10, 36.07it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:17<00:10, 36.08it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:17<00:10, 36.10it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:17<00:10, 36.10it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:10, 36.09it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 36.08it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 36.10it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 36.09it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:18<00:09, 36.09it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:18<00:09, 36.11it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:18<00:09, 36.12it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:18<00:09, 36.13it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:18<00:09, 36.12it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:18<00:09, 36.12it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 36.12it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 36.13it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 36.12it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:19<00:08, 36.11it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:19<00:08, 36.10it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:19<00:08, 36.09it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:19<00:08, 36.08it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:19<00:08, 36.08it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:19<00:08, 36.09it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 36.08it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 36.07it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 36.07it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:20<00:07, 36.08it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:20<00:07, 36.09it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:20<00:07, 36.08it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:20<00:07, 36.10it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:20<00:07, 36.09it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:20<00:07, 36.07it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 36.08it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 36.08it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 36.06it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:21<00:06, 36.03it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:21<00:06, 36.01it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:21<00:06, 35.99it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:21<00:06, 36.01it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:21<00:06, 36.02it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:21<00:06, 36.04it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:21<00:05, 36.06it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 36.07it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 36.08it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:22<00:05, 36.05it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:22<00:05, 36.06it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:22<00:05, 36.08it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:22<00:05, 36.10it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:22<00:05, 36.11it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:22<00:05, 36.12it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:22<00:04, 36.12it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 36.10it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 36.10it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:23<00:04, 36.10it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:23<00:04, 36.10it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:23<00:04, 36.10it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:23<00:04, 36.11it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:23<00:04, 36.06it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:23<00:04, 36.03it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:23<00:03, 36.05it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 36.06it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 36.06it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:24<00:03, 36.08it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:24<00:03, 36.08it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:24<00:03, 36.07it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:24<00:03, 36.08it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:24<00:03, 36.08it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:24<00:03, 36.08it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:24<00:02, 36.08it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:24<00:02, 36.08it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 36.02it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:25<00:02, 36.00it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:25<00:02, 35.99it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:25<00:02, 35.99it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:25<00:02, 36.02it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:25<00:02, 36.06it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:25<00:02, 36.07it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:25<00:01, 36.08it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:25<00:01, 36.07it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 36.08it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:26<00:01, 36.09it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:26<00:01, 36.10it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:26<00:01, 36.09it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:26<00:01, 36.09it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:26<00:01, 36.08it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:26<00:01, 36.09it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:26<00:00, 36.11it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:26<00:00, 36.11it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 36.12it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:27<00:00, 36.11it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:27<00:00, 36.10it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:27<00:00, 36.10it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:27<00:00, 36.10it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:27<00:00, 36.07it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:27<00:00, 36.03it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.01it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:27<00:00, 36.13it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.14it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.32it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.40it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.43it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.45it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.46it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.47it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.48it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.47it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.47it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.48it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.50it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.49it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.51it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.52it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.52it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.53it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.53it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.53it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.51it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.52it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.51it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.51it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.50it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.49it/s]
STAGE:2024-02-26 00:05:04 9459:9459 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:05:04 9459:9459 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:05:04 9459:9459 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:27, 36.83it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.08it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.16it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.20it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.22it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 37.22it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:26, 37.22it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:26, 37.20it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.21it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.22it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.22it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.23it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.24it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.25it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 37.27it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:25, 37.27it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 37.29it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.29it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.29it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.30it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.30it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.27it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.28it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.29it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:24, 37.29it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:24, 37.29it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.30it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:03<00:23, 37.31it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.31it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.31it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.30it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.31it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.32it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 37.32it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:23, 37.32it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.32it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.34it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.32it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.32it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.32it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.32it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.31it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 37.31it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:22, 36.93it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:22, 36.52it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:22, 36.24it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:22, 36.04it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:22, 35.91it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:22, 35.83it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:22, 35.78it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:22, 35.73it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:22, 35.72it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:22, 35.70it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:21, 35.67it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:21, 35.65it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:06<00:21, 35.63it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:21, 35.61it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:21, 35.59it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:21, 35.58it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:21, 35.57it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:21, 35.57it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:21, 35.56it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:21, 35.55it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:20, 35.56it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:07<00:20, 35.56it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:20, 35.55it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:20, 35.55it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:20, 35.54it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:20, 35.54it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:20, 35.53it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:20, 35.54it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:19, 35.54it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:08<00:19, 35.53it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:08<00:19, 35.53it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:19, 35.52it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:19, 35.55it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:19, 35.54it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:19, 35.54it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:19, 35.54it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:19, 35.53it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:18, 35.52it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:09<00:18, 35.51it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:09<00:18, 35.52it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:18, 35.52it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:18, 35.52it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:18, 35.52it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:18, 35.52it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:18, 35.53it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:18, 35.53it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:10<00:17, 35.52it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:10<00:17, 35.52it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:10<00:17, 35.52it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:17, 35.49it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:17, 35.51it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:17, 35.51it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:17, 35.51it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:17, 35.51it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:17, 35.50it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:11<00:16, 35.51it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:11<00:16, 35.52it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:11<00:16, 35.54it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:16, 35.52it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:16, 35.53it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:16, 35.48it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:16, 35.49it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:16, 35.52it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 35.51it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:12<00:15, 35.52it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:12<00:15, 35.53it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:12<00:15, 35.53it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:12<00:15, 35.52it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:15, 35.51it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:15, 35.53it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:15, 35.52it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:15, 35.51it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 35.51it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:13<00:14, 35.49it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:13<00:14, 35.50it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:13<00:14, 35.51it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:13<00:14, 35.50it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:14, 35.49it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:14, 35.50it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:14, 35.51it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:14, 35.51it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 35.48it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:14<00:13, 35.48it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:14<00:13, 35.48it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:14<00:13, 35.49it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:14<00:13, 35.49it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:13, 35.48it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:13, 35.49it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:13, 35.49it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:13, 35.48it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 35.47it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:15<00:12, 35.44it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:15<00:12, 35.43it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:15<00:12, 35.45it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:15<00:12, 35.47it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:15<00:12, 35.47it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:12, 35.48it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:12, 35.48it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:12, 35.49it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 35.50it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:16<00:11, 35.48it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:16<00:11, 35.47it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:16<00:11, 35.45it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:16<00:11, 35.46it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:16<00:11, 35.48it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:11, 35.51it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:11, 35.52it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:11, 35.50it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 35.47it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:17<00:10, 35.44it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:17<00:10, 35.47it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:17<00:10, 35.51it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:17<00:10, 35.53it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:17<00:10, 35.52it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:10, 35.52it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:10, 35.54it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:10, 35.55it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:18<00:09, 35.54it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:18<00:09, 35.55it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:18<00:09, 35.54it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:18<00:09, 35.53it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:18<00:09, 35.55it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:18<00:09, 35.56it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:18<00:09, 35.56it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:09, 35.56it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:09, 35.55it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:19<00:08, 35.53it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:19<00:08, 35.53it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:19<00:08, 35.50it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:19<00:08, 35.48it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:19<00:08, 35.48it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:19<00:08, 35.48it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:19<00:08, 35.48it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:08, 35.48it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:08, 35.48it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:20<00:07, 35.49it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:20<00:07, 35.48it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:20<00:07, 35.49it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:20<00:07, 35.48it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:20<00:07, 35.51it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:20<00:07, 35.52it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:20<00:07, 35.51it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:07, 35.52it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:06, 35.53it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:21<00:06, 35.54it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:21<00:06, 35.54it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:21<00:06, 35.50it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:21<00:06, 35.51it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:21<00:06, 35.53it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:21<00:06, 35.53it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:21<00:06, 35.53it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:21<00:06, 35.55it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:05, 35.56it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:22<00:05, 35.55it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:22<00:05, 35.56it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:22<00:05, 35.53it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:22<00:05, 35.51it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:22<00:05, 35.53it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:22<00:05, 35.50it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:22<00:05, 35.51it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:22<00:05, 35.51it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 35.53it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:23<00:04, 35.52it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:23<00:04, 35.52it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:23<00:04, 35.50it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:23<00:04, 35.49it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:23<00:04, 35.50it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:23<00:04, 35.49it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:23<00:04, 35.50it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:23<00:04, 35.49it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 35.48it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:24<00:03, 35.48it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:24<00:03, 35.48it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:24<00:03, 35.46it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:24<00:02, 35.47it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:25<00:02, 35.48it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:25<00:02, 35.48it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:25<00:02, 35.47it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:25<00:02, 35.47it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:25<00:02, 35.48it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:25<00:02, 35.47it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:25<00:02, 35.46it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:25<00:02, 35.47it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:26<00:01, 35.46it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:26<00:01, 35.48it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:26<00:01, 35.48it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:26<00:01, 35.45it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:26<00:01, 35.46it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:26<00:01, 35.49it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:26<00:01, 35.50it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:26<00:01, 35.51it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:26<00:01, 35.50it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:27<00:00, 35.50it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:27<00:00, 35.50it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:27<00:00, 35.52it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:27<00:00, 35.52it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:27<00:00, 35.52it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:27<00:00, 35.53it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:27<00:00, 35.50it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:27<00:00, 35.48it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:27<00:00, 35.50it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:27<00:00, 35.81it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1005.73 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 100.201 us +/- 5.931 us [95.367 us, 225.306 us]
        batches_per_second: 10.01 K +/- 455.34 [4.44 K, 10.49 K]
      metrics:
        batches_per_second_max: 10485.76
        batches_per_second_mean: 10005.42910856242
        batches_per_second_min: 4438.4169312169315
        batches_per_second_std: 455.34234135747266
        seconds_per_batch_max: 0.00022530555725097656
        seconds_per_batch_mean: 0.00010020065307617187
        seconds_per_batch_min: 9.5367431640625e-05
        seconds_per_batch_std: 5.930970730253904e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 26.133 us +/- 0.609 us [24.319 us, 32.187 us]
        batches_per_second: 38.29 K +/- 858.71 [31.07 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 38285.65559023924
        batches_per_second_min: 31068.91851851852
        batches_per_second_std: 858.7123490604578
        seconds_per_batch_max: 3.218650817871094e-05
        seconds_per_batch_mean: 2.6133060455322265e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 6.0915363741955e-07
    on_device_inference:
      human_readable:
        batch_latency: -27522377.768 us +/- 223.487 ms [-27834272.385 us, -26418880.463
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03592693159644834
        batches_per_second_mean: -0.03633654870722914
        batches_per_second_min: -0.03785171750233303
        batches_per_second_std: 0.000305270702811423
        seconds_per_batch_max: -26.418880462646484
        seconds_per_batch_mean: -27.522377767562865
        seconds_per_batch_min: -27.834272384643555
        seconds_per_batch_std: 0.22348744357967185
    total:
      human_readable:
        batch_latency: 27.660 ms +/- 224.400 us [26.551 ms, 27.980 ms]
        batches_per_second: 36.16 +/- 0.30 [35.74, 37.66]
      metrics:
        batches_per_second_max: 37.663691384853
        batches_per_second_mean: 36.15537903145169
        batches_per_second_min: 35.74030931788164
        batches_per_second_std: 0.3034021323972558
        seconds_per_batch_max: 0.027979612350463867
        seconds_per_batch_mean: 0.027660284757614135
        seconds_per_batch_min: 0.026550769805908203
        seconds_per_batch_std: 0.00022440037846152422
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 153.486 us +/- 6.627 us [147.343 us, 288.486 us]
        batches_per_second: 6.52 K +/- 227.81 [3.47 K, 6.79 K]
      metrics:
        batches_per_second_max: 6786.899676375405
        batches_per_second_mean: 6524.745576176263
        batches_per_second_min: 3466.3669421487602
        batches_per_second_std: 227.807237849988
        seconds_per_batch_max: 0.0002884864807128906
        seconds_per_batch_mean: 0.0001534860134124756
        seconds_per_batch_min: 0.00014734268188476562
        seconds_per_batch_std: 6.627010323481553e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.962 us +/- 0.879 us [24.319 us, 35.048 us]
        batches_per_second: 38.56 K +/- 1.16 K [28.53 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 38557.06485049674
        batches_per_second_min: 28532.680272108842
        batches_per_second_std: 1162.1314821179856
        seconds_per_batch_max: 3.504753112792969e-05
        seconds_per_batch_mean: 2.5961875915527343e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 8.792551369743177e-07
    on_device_inference:
      human_readable:
        batch_latency: -27717692.638 us +/- 506.503 ms [-28186943.054 us, -26503007.889
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03547741938801777
        batches_per_second_mean: -0.03609047494839075
        batches_per_second_min: -0.03773156632620639
        batches_per_second_std: 0.0006805441548562622
        seconds_per_batch_max: -26.503007888793945
        seconds_per_batch_mean: -27.717692638397217
        seconds_per_batch_min: -28.18694305419922
        seconds_per_batch_std: 0.5065030009700003
    total:
      human_readable:
        batch_latency: 27.909 ms +/- 508.171 us [26.688 ms, 28.377 ms]
        batches_per_second: 35.84 +/- 0.67 [35.24, 37.47]
      metrics:
        batches_per_second_max: 37.46988511497436
        batches_per_second_mean: 35.842947389339635
        batches_per_second_min: 35.24003327143949
        batches_per_second_std: 0.6733738373220375
        seconds_per_batch_max: 0.02837681770324707
        seconds_per_batch_mean: 0.027909038066864015
        seconds_per_batch_min: 0.026688098907470703
        seconds_per_batch_std: 0.0005081708864680799


#####
fp-fp-py-id - Run 2
2024-02-26 00:06:40
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.52it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   6%|▌         | 6/100 [00:00<00:01, 51.03it/s]Warming up with batch_size=1:  12%|█▏        | 12/100 [00:00<00:01, 51.05it/s]Warming up with batch_size=1:  18%|█▊        | 18/100 [00:00<00:01, 51.06it/s]Warming up with batch_size=1:  24%|██▍       | 24/100 [00:00<00:01, 51.08it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 51.11it/s]Warming up with batch_size=1:  36%|███▌      | 36/100 [00:00<00:01, 51.12it/s]Warming up with batch_size=1:  42%|████▏     | 42/100 [00:00<00:01, 51.12it/s]Warming up with batch_size=1:  48%|████▊     | 48/100 [00:00<00:01, 51.09it/s]Warming up with batch_size=1:  54%|█████▍    | 54/100 [00:01<00:00, 51.06it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 51.05it/s]Warming up with batch_size=1:  66%|██████▌   | 66/100 [00:01<00:00, 51.03it/s]Warming up with batch_size=1:  72%|███████▏  | 72/100 [00:01<00:00, 51.04it/s]Warming up with batch_size=1:  78%|███████▊  | 78/100 [00:01<00:00, 51.05it/s]Warming up with batch_size=1:  84%|████████▍ | 84/100 [00:01<00:00, 51.04it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 51.04it/s]Warming up with batch_size=1:  96%|█████████▌| 96/100 [00:01<00:00, 51.04it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 51.05it/s]
STAGE:2024-02-26 00:05:43 9506:9506 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:05:43 9506:9506 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:05:43 9506:9506 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:25, 38.69it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:25, 38.99it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 39.11it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 39.16it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 39.16it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:24, 39.17it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:24, 39.17it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:24, 39.17it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:24, 39.19it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:24, 39.18it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 39.19it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 39.20it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 39.21it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 39.22it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:23, 39.24it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:23, 39.23it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:23, 39.23it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:23, 39.22it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:23, 39.22it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:23, 39.22it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 39.22it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 39.22it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 39.22it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 39.24it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:22, 39.25it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:22, 39.25it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:22, 39.25it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:22, 39.26it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:02<00:22, 39.27it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 39.28it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 39.28it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 39.29it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 39.27it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:21, 39.30it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:21, 39.24it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:21, 39.01it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:21, 39.12it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:21, 39.20it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:03<00:21, 39.25it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 39.30it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 39.32it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 39.35it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 39.37it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:20, 39.38it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:20, 39.35it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:20, 39.33it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:20, 39.32it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:04<00:20, 39.31it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:04<00:20, 39.30it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 39.30it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 39.31it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 39.32it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 39.33it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:19, 39.33it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:19, 39.30it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:19, 39.31it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:19, 39.33it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:05<00:19, 39.33it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:19, 39.34it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 39.33it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 39.33it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 39.34it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 39.36it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:18, 39.36it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:18, 39.33it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:18, 39.36it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:18, 39.38it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:06<00:18, 39.38it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 39.38it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 39.37it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 39.35it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 39.31it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 39.33it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:17, 39.32it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:17, 39.33it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:17, 39.36it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:07<00:17, 39.36it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:07<00:17, 39.38it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 39.40it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 39.42it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 39.40it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 39.40it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:16, 39.40it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:16, 39.39it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:16, 39.41it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:16, 39.41it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:08<00:16, 39.43it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:08<00:16, 39.43it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 39.43it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 39.43it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 39.44it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 39.45it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:15, 39.45it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:15, 39.40it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:15, 39.37it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:09<00:15, 39.34it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:09<00:15, 39.34it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:09<00:15, 39.31it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 39.29it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 39.29it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 39.28it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 39.28it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:14, 39.27it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:14, 39.26it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:14, 39.28it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:10<00:14, 39.28it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:10<00:14, 39.30it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:10<00:14, 39.28it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 39.29it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 39.28it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 39.29it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 39.29it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:13, 39.30it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:13, 39.28it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:11<00:13, 39.31it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:11<00:13, 39.34it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:11<00:13, 39.38it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 39.38it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 39.37it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 39.38it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 39.40it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:12, 39.41it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:12, 39.39it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:12, 39.38it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:12<00:12, 39.40it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:12<00:12, 39.40it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:12<00:12, 39.41it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 39.42it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 39.42it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 39.43it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 39.43it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:11, 39.42it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:11, 39.39it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:11, 39.40it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:13<00:11, 39.40it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:13<00:11, 39.39it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:13<00:11, 39.39it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 39.39it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 39.40it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 39.39it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 39.40it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:10, 39.40it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:10, 39.38it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:14<00:10, 39.39it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:14<00:10, 39.39it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:14<00:10, 39.40it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:14<00:10, 39.41it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 39.41it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 39.42it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 39.41it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 39.42it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:09, 39.42it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:09, 39.37it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:15<00:09, 39.38it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:15<00:09, 39.38it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:15<00:09, 39.39it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:15<00:09, 39.39it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 39.40it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:08, 39.40it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:16<00:08, 39.36it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:16<00:08, 39.37it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:16<00:08, 39.38it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:16<00:08, 39.40it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:16<00:08, 39.40it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 39.41it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 39.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 39.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 39.40it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:07, 39.41it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:17<00:07, 39.40it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:17<00:07, 39.42it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:17<00:07, 39.43it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:17<00:07, 39.43it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:17<00:07, 39.42it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 39.42it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 39.43it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 39.43it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:06, 39.44it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:06, 39.44it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:18<00:06, 39.41it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:18<00:06, 39.42it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:18<00:06, 39.43it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:18<00:06, 39.44it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 39.44it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 39.46it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 39.46it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 39.46it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:05, 39.45it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:19<00:05, 39.43it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:19<00:05, 39.42it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:19<00:05, 39.44it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:19<00:05, 39.43it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:19<00:05, 39.43it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 39.42it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 39.42it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 39.44it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 39.48it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:04, 39.48it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:20<00:04, 39.42it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:20<00:04, 39.44it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:20<00:04, 39.45it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:20<00:04, 39.46it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:20<00:04, 39.46it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 39.46it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 39.44it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 39.46it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 39.47it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:21<00:03, 39.47it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:21<00:03, 39.43it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:21<00:03, 39.45it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:21<00:03, 39.45it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:21<00:03, 39.44it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:21<00:03, 39.44it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 39.44it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 39.45it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 39.44it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 39.44it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:22<00:02, 39.44it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:22<00:02, 39.42it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:22<00:02, 39.43it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:22<00:02, 39.45it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:22<00:02, 39.45it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:22<00:02, 39.44it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 39.45it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 39.46it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 39.46it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:23<00:02, 39.46it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:23<00:01, 39.46it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:23<00:01, 39.35it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:23<00:01, 39.00it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:23<00:01, 38.75it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:23<00:01, 38.78it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:23<00:01, 38.99it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 39.12it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 39.20it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 39.28it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:24<00:01, 39.33it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:24<00:00, 39.35it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:24<00:00, 39.35it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:24<00:00, 39.33it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:24<00:00, 39.35it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:24<00:00, 39.38it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 39.39it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 39.39it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 39.41it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 39.41it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 39.40it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:25<00:00, 39.35it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 38.76it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 38.92it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 38.94it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 38.97it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 38.99it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:01, 38.99it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 38.98it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 38.99it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 39.02it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 39.03it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 39.03it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 39.03it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 39.02it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 39.02it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 39.02it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 39.02it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 39.02it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 39.04it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:01<00:00, 39.03it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 39.03it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 39.02it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 39.04it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 39.03it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 39.04it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 39.04it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 39.01it/s]
STAGE:2024-02-26 00:06:11 9506:9506 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:06:11 9506:9506 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:06:11 9506:9506 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 38.27it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:25, 38.52it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:25, 38.60it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:25, 38.64it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:25, 38.71it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:25, 38.76it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:25, 38.79it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:24, 38.82it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:24, 38.83it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:24, 38.81it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:24, 38.79it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:24, 38.81it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:24, 38.82it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:24, 38.81it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:24, 38.79it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:24, 38.80it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 38.81it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:23, 38.83it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:01<00:23, 38.84it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:23, 38.84it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:23, 38.83it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:22, 38.84it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:02<00:22, 38.85it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:02<00:22, 38.85it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:22, 38.82it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:22, 38.82it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:22, 38.83it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:22, 38.83it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:22, 38.85it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:22, 38.85it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 38.85it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:21, 38.85it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:03<00:21, 38.84it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:21, 38.83it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:21, 38.80it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:21, 38.82it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:21, 38.84it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:21, 38.84it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:21, 38.86it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 38.87it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:20, 38.88it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:04<00:20, 38.90it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:04<00:20, 38.91it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:20, 38.90it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:20, 38.86it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:20, 38.89it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:20, 38.89it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:20, 38.88it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:20, 38.90it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 38.89it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:05<00:19, 38.89it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:05<00:19, 38.86it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:05<00:19, 38.86it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:19, 38.83it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:19, 38.83it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:19, 38.84it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:19, 38.86it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:19, 38.85it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 38.85it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 38.84it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:06<00:18, 38.82it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:06<00:18, 38.83it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:18, 38.83it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:18, 38.80it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:18, 38.81it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:18, 38.82it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:18, 38.83it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 38.85it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 38.85it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:07<00:18, 38.84it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:07<00:17, 38.85it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:07<00:17, 38.86it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:17, 38.86it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:17, 38.84it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:17, 38.85it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:17, 38.86it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 38.86it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 38.85it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:08<00:17, 38.86it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:08<00:16, 38.84it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:08<00:16, 38.83it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:08<00:16, 38.81it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:16, 38.78it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:16, 38.78it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:16, 38.79it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:16, 38.78it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 38.79it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 38.78it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:09<00:16, 38.76it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:09<00:15, 38.77it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:09<00:15, 38.79it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:09<00:15, 38.77it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:15, 38.74it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:15, 38.75it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:15, 38.74it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:15, 38.75it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:15, 38.77it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:10<00:15, 38.79it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:10<00:15, 38.79it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:10<00:14, 38.81it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:10<00:14, 38.81it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:14, 38.79it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:14, 38.73it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:14, 38.75it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:14, 38.77it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 38.77it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:11<00:14, 38.77it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:11<00:14, 38.74it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:11<00:14, 38.76it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:11<00:13, 38.78it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:11<00:13, 38.78it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:13, 38.76it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:13, 38.74it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:13, 38.76it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:13, 38.76it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:12<00:13, 38.77it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:12<00:13, 38.77it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:12<00:13, 38.77it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:12<00:13, 38.75it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:12<00:12, 38.76it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:12<00:12, 38.77it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:12, 38.77it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:12, 38.76it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:12, 38.77it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:13<00:12, 38.78it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:13<00:12, 38.79it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:13<00:12, 38.77it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:13<00:12, 38.75it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:13<00:11, 38.75it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:13<00:11, 38.74it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:11, 38.76it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:11, 38.77it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:11, 38.76it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:14<00:11, 38.76it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:14<00:11, 38.76it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:14<00:11, 38.75it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:14<00:11, 38.76it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:14<00:11, 38.77it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:14<00:10, 38.76it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:14<00:10, 38.74it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:10, 38.72it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:10, 38.73it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:10, 38.75it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:15<00:10, 38.73it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:15<00:10, 38.74it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:15<00:10, 38.74it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:15<00:10, 38.75it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:15<00:10, 38.76it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:15<00:09, 38.77it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:15<00:09, 38.77it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:09, 38.76it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:09, 38.74it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:16<00:09, 38.76it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:16<00:09, 38.77it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:16<00:09, 38.78it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:16<00:09, 38.79it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:16<00:09, 38.79it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:16<00:08, 38.78it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:16<00:08, 38.78it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:08, 38.77it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:08, 38.77it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:17<00:08, 38.76it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:17<00:08, 38.77it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:17<00:08, 38.76it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:17<00:08, 38.76it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:17<00:08, 38.76it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:17<00:08, 38.76it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:17<00:07, 38.75it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:17<00:07, 38.76it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:07, 38.75it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 38.76it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:18<00:07, 38.78it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:18<00:07, 38.79it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:18<00:07, 38.79it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:18<00:07, 38.79it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:18<00:07, 38.78it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:18<00:07, 38.77it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:18<00:06, 38.77it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:18<00:06, 38.77it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:06, 38.76it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:19<00:06, 38.77it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:19<00:06, 38.76it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:19<00:06, 38.77it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:19<00:06, 38.78it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:19<00:06, 38.78it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:19<00:06, 38.80it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:19<00:05, 38.80it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:19<00:05, 38.79it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:05, 38.77it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:20<00:05, 38.77it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:20<00:05, 38.78it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:20<00:05, 38.79it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:20<00:05, 38.80it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:20<00:04, 38.81it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:20<00:04, 38.81it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:21<00:04, 38.81it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:21<00:04, 38.77it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:21<00:04, 38.75it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:21<00:04, 38.74it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:21<00:04, 38.73it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:21<00:04, 38.72it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:21<00:04, 38.72it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:21<00:04, 38.71it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:21<00:03, 38.72it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:21<00:03, 38.70it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:22<00:03, 38.72it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:22<00:03, 38.71it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:22<00:03, 38.71it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:22<00:03, 38.71it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:22<00:03, 38.70it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:22<00:03, 38.70it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:22<00:03, 38.68it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:22<00:02, 38.67it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:22<00:02, 38.68it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:22<00:02, 38.69it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:23<00:02, 38.68it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:23<00:02, 38.66it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:23<00:02, 38.67it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:23<00:02, 38.67it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:23<00:02, 38.67it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:23<00:02, 38.67it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:23<00:02, 38.67it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:23<00:01, 38.67it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:23<00:01, 38.67it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:24<00:01, 38.65it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:24<00:01, 38.66it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:24<00:01, 38.65it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:24<00:01, 38.70it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:24<00:01, 38.71it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:24<00:01, 38.72it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:24<00:01, 38.74it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:24<00:01, 38.76it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:24<00:00, 38.76it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:24<00:00, 38.78it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:25<00:00, 38.77it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:25<00:00, 38.76it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:25<00:00, 38.78it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:25<00:00, 38.79it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:25<00:00, 38.76it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:25<00:00, 38.77it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:25<00:00, 38.77it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:25<00:00, 38.78it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:25<00:00, 38.78it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1004.77 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 94.771 us +/- 5.717 us [91.076 us, 221.968 us]
        batches_per_second: 10.58 K +/- 473.48 [4.51 K, 10.98 K]
      metrics:
        batches_per_second_max: 10979.853403141362
        batches_per_second_mean: 10578.398712743494
        batches_per_second_min: 4505.160042964554
        batches_per_second_std: 473.47664954252207
        seconds_per_batch_max: 0.0002219676971435547
        seconds_per_batch_mean: 9.47713851928711e-05
        seconds_per_batch_min: 9.107589721679688e-05
        seconds_per_batch_std: 5.716659076574385e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.280 us +/- 0.679 us [23.365 us, 33.140 us]
        batches_per_second: 41.21 K +/- 997.94 [30.17 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 41213.724597236724
        batches_per_second_min: 30174.84892086331
        batches_per_second_std: 997.9418524142785
        seconds_per_batch_max: 3.314018249511719e-05
        seconds_per_batch_mean: 2.428007125854492e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 6.787922240947576e-07
    on_device_inference:
      human_readable:
        batch_latency: -25265615.797 us +/- 117.254 ms [-26575775.146 us, -25119199.753
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.0376282533430558
        batches_per_second_mean: -0.039580315292727514
        batches_per_second_min: -0.03981018542950311
        batches_per_second_std: 0.00017945777515230798
        seconds_per_batch_max: -25.119199752807617
        seconds_per_batch_mean: -25.265615797042848
        seconds_per_batch_min: -26.575775146484375
        seconds_per_batch_std: 0.11725436550624627
    total:
      human_readable:
        batch_latency: 25.395 ms +/- 119.875 us [25.250 ms, 26.849 ms]
        batches_per_second: 39.38 +/- 0.18 [37.25, 39.60]
      metrics:
        batches_per_second_max: 39.60365226094592
        batches_per_second_mean: 39.37792737798135
        batches_per_second_min: 37.24562213618442
        batches_per_second_std: 0.18138031321721512
        seconds_per_batch_max: 0.026848793029785156
        seconds_per_batch_mean: 0.02539548945426941
        seconds_per_batch_min: 0.02525019645690918
        seconds_per_batch_std: 0.00011987544484897432
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 146.245 us +/- 6.107 us [142.336 us, 285.864 us]
        batches_per_second: 6.85 K +/- 218.70 [3.50 K, 7.03 K]
      metrics:
        batches_per_second_max: 7025.634840871022
        batches_per_second_mean: 6846.567298219509
        batches_per_second_min: 3498.1684737281066
        batches_per_second_std: 218.70302657597838
        seconds_per_batch_max: 0.00028586387634277344
        seconds_per_batch_mean: 0.00014624476432800293
        seconds_per_batch_min: 0.0001423358917236328
        seconds_per_batch_std: 6.107160548119042e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.774 us +/- 0.591 us [23.365 us, 33.617 us]
        batches_per_second: 40.39 K +/- 876.76 [29.75 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40385.55192869268
        batches_per_second_min: 29746.836879432623
        batches_per_second_std: 876.7553423526774
        seconds_per_batch_max: 3.361701965332031e-05
        seconds_per_batch_mean: 2.477407455444336e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 5.910617294129607e-07
    on_device_inference:
      human_readable:
        batch_latency: -25587093.819 us +/- 70.538 ms [-26673311.234 us, -25411327.362
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03749065840551863
        batches_per_second_mean: -0.03908249723523045
        batches_per_second_min: -0.03935252912026207
        batches_per_second_std: 0.00010667455003472911
        seconds_per_batch_max: -25.411327362060547
        seconds_per_batch_mean: -25.587093818664552
        seconds_per_batch_min: -26.673311233520508
        seconds_per_batch_std: 0.07053774119303169
    total:
      human_readable:
        batch_latency: 25.769 ms +/- 73.793 us [25.590 ms, 27.009 ms]
        batches_per_second: 38.81 +/- 0.11 [37.03, 39.08]
      metrics:
        batches_per_second_max: 39.077851898781354
        batches_per_second_mean: 38.80645671980376
        batches_per_second_min: 37.0250081653911
        batches_per_second_std: 0.10966947137915738
        seconds_per_batch_max: 0.027008771896362305
        seconds_per_batch_mean: 0.025769116163253784
        seconds_per_batch_min: 0.025589942932128906
        seconds_per_batch_std: 7.37932039682662e-05


#####
fp-fp-py-id - Run 3
2024-02-26 00:07:48
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.37it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 48.60it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 48.65it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.67it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.69it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 48.70it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 48.70it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 48.69it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 48.72it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 48.61it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 47.78it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 47.18it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 46.81it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 46.54it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 46.38it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 46.25it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 46.16it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 46.08it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 46.05it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:02<00:00, 46.05it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 46.04it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 47.14it/s]
STAGE:2024-02-26 00:06:48 9552:9552 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:06:48 9552:9552 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:06:48 9552:9552 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 36.99it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.27it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.33it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.37it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.39it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.40it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.42it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.42it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.45it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.45it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.44it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.41it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.40it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 37.37it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:25, 37.34it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.33it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.33it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.34it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.32it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.34it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.34it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.35it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 37.38it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 37.36it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.36it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.36it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.38it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.39it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.38it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.38it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.37it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.37it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 37.37it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:23, 37.37it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.37it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.38it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.39it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.38it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 37.35it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 37.34it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 37.33it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.32it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.32it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:21, 37.34it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.36it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.37it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.36it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.38it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 37.38it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 37.38it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.38it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.40it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.39it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.38it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 37.40it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.39it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.40it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 37.39it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 37.39it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:20, 37.39it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.37it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.36it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:19, 37.36it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.35it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.35it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.35it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.36it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 37.37it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 37.37it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.36it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.36it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:18, 37.35it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.36it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.36it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.38it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.39it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.38it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 37.38it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.36it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.37it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.36it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.35it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 37.36it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.38it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.40it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:16, 37.40it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.39it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.39it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.38it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.37it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.38it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 37.38it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.39it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.38it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:15, 37.37it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.36it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.39it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.39it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.40it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 37.40it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.39it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.39it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.38it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.37it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.35it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.35it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.33it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:14, 37.33it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.34it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.34it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:13, 37.33it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.32it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.34it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.35it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.35it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:13, 37.36it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.37it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.35it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:12, 37.35it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 37.34it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.34it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.35it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.36it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.37it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 37.36it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.37it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.36it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.33it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:11, 37.33it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.32it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.35it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.35it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.36it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:11, 37.36it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.35it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.35it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:10, 37.36it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 37.35it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.36it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.35it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.35it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.36it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 37.37it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.38it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.38it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:09, 37.36it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 37.35it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.34it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.35it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.35it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.35it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.39it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.39it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 37.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.40it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.38it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.38it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.39it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:08, 37.38it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.38it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.38it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 37.37it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 37.37it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.40it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.38it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.38it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:20<00:06, 37.38it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 37.39it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.39it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.38it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.40it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.42it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.42it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.43it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.42it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.40it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 37.39it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 37.41it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.42it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.42it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.43it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.44it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:05, 37.43it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.41it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.42it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.43it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.40it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.42it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.42it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:23<00:03, 37.41it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 37.40it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 37.38it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.39it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.39it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.38it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.37it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.37it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.39it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.41it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 37.40it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.41it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.41it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.41it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.41it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.39it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 37.42it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 37.39it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 37.39it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.41it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.44it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.44it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.44it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.44it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 37.45it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.43it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.43it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.43it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.42it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.38it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 36.80it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 36.96it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.03it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.05it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.08it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.11it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.12it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.13it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.13it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.14it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.15it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.15it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.13it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.14it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.15it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.15it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.14it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.13it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.11it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.10it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.09it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.08it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.09it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.10it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.10it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.11it/s]
STAGE:2024-02-26 00:07:18 9552:9552 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:07:18 9552:9552 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:07:18 9552:9552 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:27, 36.51it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:27, 36.73it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 36.80it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 36.86it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 36.88it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 36.88it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:26, 36.88it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:26, 36.89it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:26, 36.89it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:26, 36.89it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 36.89it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 36.89it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 36.90it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 36.90it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 36.90it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:25, 36.91it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:25, 36.92it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:25, 36.93it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:25, 36.93it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 36.92it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 36.92it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 36.91it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 36.92it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 36.91it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:24, 36.90it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:24, 36.90it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:24, 36.90it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:03<00:24, 36.90it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 36.89it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 36.89it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 36.91it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 36.91it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 36.90it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 36.91it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:23, 36.91it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:23, 36.93it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:04<00:23, 36.93it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 36.93it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 36.91it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 36.91it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 36.90it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 36.92it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 36.91it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:22, 36.92it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:22, 36.93it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:22, 36.94it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:21, 36.95it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 36.95it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:21, 36.95it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:21, 36.96it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:06<00:20, 36.96it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 36.96it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 36.96it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 36.95it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 36.95it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 36.95it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:20, 36.96it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:20, 36.95it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:20, 36.95it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:07<00:20, 36.94it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 36.95it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:19, 36.94it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:19, 36.93it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:19, 36.93it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:08<00:19, 36.92it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:08<00:18, 36.93it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 36.93it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:18, 36.93it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:18, 36.94it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:09<00:17, 36.95it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 36.94it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 36.95it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 36.94it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 36.95it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 36.95it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:17, 36.96it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:17, 36.95it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:17, 36.95it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:10<00:17, 36.94it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:16, 36.95it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 36.95it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 36.95it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 36.95it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 36.95it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 36.95it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:16, 36.94it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:16, 36.93it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:11<00:16, 36.93it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:15, 36.93it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 36.94it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 36.95it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 36.96it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:15, 36.96it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:15, 36.97it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:12<00:15, 36.96it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:12<00:14, 36.96it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:14, 36.96it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 36.95it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 36.94it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 36.95it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 36.94it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 36.95it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:14, 36.94it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:14, 36.94it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:13<00:13, 36.93it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:13, 36.91it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 36.92it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 36.91it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 36.92it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 36.93it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 36.93it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:13, 36.94it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:13, 36.94it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:14<00:12, 36.95it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:12, 36.95it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:12, 36.96it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 36.96it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 36.98it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 36.97it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 36.96it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:12, 36.94it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:12, 36.95it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:15<00:12, 36.94it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:15<00:11, 36.94it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:11, 36.94it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 36.94it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 36.94it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 36.95it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 36.96it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 36.95it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:11, 36.94it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:16<00:11, 36.94it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:16<00:10, 36.95it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:10, 36.94it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 36.94it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 36.94it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 36.95it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 36.96it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 36.95it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:10, 36.97it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:17<00:10, 36.97it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:17<00:09, 36.96it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:09, 36.95it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:09, 36.96it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 36.97it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 36.96it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 36.96it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 36.96it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 36.96it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:09, 36.98it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:18<00:08, 36.98it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:18<00:08, 36.97it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:08, 36.95it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 36.97it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 36.97it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 36.96it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 36.96it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 36.96it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:08, 36.96it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:19<00:08, 36.90it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:19<00:07, 36.91it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:07, 36.93it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:07, 36.95it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 36.96it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 36.97it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 36.97it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 36.96it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:07, 36.96it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:20<00:07, 36.95it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:20<00:06, 36.96it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:06, 36.96it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:06, 36.96it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 36.96it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 36.96it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 36.97it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 36.97it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 36.98it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:21<00:06, 36.97it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:21<00:05, 36.97it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:21<00:05, 36.96it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:05, 36.97it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 36.97it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 36.96it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 36.96it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 36.96it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 36.96it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:05, 36.95it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:22<00:04, 36.93it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:22<00:04, 36.93it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 36.93it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:22<00:04, 36.93it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 36.95it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 36.94it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 36.95it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 36.94it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 36.95it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:23<00:04, 36.93it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:23<00:03, 36.94it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 36.93it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:23<00:03, 36.95it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 36.96it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 36.95it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 36.95it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 36.94it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 36.95it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:24<00:03, 36.95it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:24<00:02, 36.95it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:24<00:02, 36.95it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:24<00:02, 36.94it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 36.92it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 36.93it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 36.94it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 36.93it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 36.92it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:25<00:02, 36.92it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:25<00:01, 36.77it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:25<00:01, 36.25it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:25<00:01, 35.90it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 35.65it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 35.49it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 35.37it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 35.29it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 35.21it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:26<00:01, 35.17it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:26<00:01, 35.17it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:26<00:00, 35.14it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:26<00:00, 35.12it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 35.12it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 35.11it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 35.11it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 35.11it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 35.10it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:27<00:00, 35.09it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:27<00:00, 35.09it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:27<00:00, 36.80it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1008.55 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 99.029 us +/- 6.248 us [95.129 us, 233.412 us]
        batches_per_second: 10.13 K +/- 477.16 [4.28 K, 10.51 K]
      metrics:
        batches_per_second_max: 10512.040100250626
        batches_per_second_mean: 10126.26333804166
        batches_per_second_min: 4284.273748723187
        batches_per_second_std: 477.15771382085126
        seconds_per_batch_max: 0.0002334117889404297
        seconds_per_batch_mean: 9.90293025970459e-05
        seconds_per_batch_min: 9.512901306152344e-05
        seconds_per_batch_std: 6.248478010131863e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.303 us +/- 0.756 us [24.319 us, 34.094 us]
        batches_per_second: 39.55 K +/- 1.07 K [29.33 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 39553.34485600254
        batches_per_second_min: 29330.797202797203
        batches_per_second_std: 1071.1372415488725
        seconds_per_batch_max: 3.409385681152344e-05
        seconds_per_batch_mean: 2.5302648544311522e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 7.555601384523021e-07
    on_device_inference:
      human_readable:
        batch_latency: -26590951.599 us +/- 58.334 ms [-27746751.785 us, -26463424.683
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.036040254648134096
        batches_per_second_mean: -0.03760695548119966
        batches_per_second_min: -0.03778800408462862
        batches_per_second_std: 8.115274291298547e-05
        seconds_per_batch_max: -26.463424682617188
        seconds_per_batch_mean: -26.590951599121095
        seconds_per_batch_min: -27.74675178527832
        seconds_per_batch_std: 0.05833432114325541
    total:
      human_readable:
        batch_latency: 26.735 ms +/- 62.418 us [26.605 ms, 28.034 ms]
        batches_per_second: 37.40 +/- 0.09 [35.67, 37.59]
      metrics:
        batches_per_second_max: 37.586400336944735
        batches_per_second_mean: 37.40449419654188
        batches_per_second_min: 35.67131023455971
        batches_per_second_std: 0.0855829513732062
        seconds_per_batch_max: 0.028033733367919922
        seconds_per_batch_mean: 0.026734898090362547
        seconds_per_batch_min: 0.02660536766052246
        seconds_per_batch_std: 6.241794571427292e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 152.538 us +/- 6.467 us [147.820 us, 290.394 us]
        batches_per_second: 6.56 K +/- 219.39 [3.44 K, 6.77 K]
      metrics:
        batches_per_second_max: 6765.006451612903
        batches_per_second_mean: 6564.71108306049
        batches_per_second_min: 3443.59934318555
        batches_per_second_std: 219.3923820593741
        seconds_per_batch_max: 0.0002903938293457031
        seconds_per_batch_mean: 0.00015253758430480957
        seconds_per_batch_min: 0.00014781951904296875
        seconds_per_batch_std: 6.467362605253615e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.743 us +/- 0.818 us [24.557 us, 35.763 us]
        batches_per_second: 38.88 K +/- 1.12 K [27.96 K, 40.72 K]
      metrics:
        batches_per_second_max: 40721.398058252424
        batches_per_second_mean: 38881.56969959429
        batches_per_second_min: 27962.02666666667
        batches_per_second_std: 1120.1583466146967
        seconds_per_batch_max: 3.5762786865234375e-05
        seconds_per_batch_mean: 2.5742530822753905e-05
        seconds_per_batch_min: 2.4557113647460938e-05
        seconds_per_batch_std: 8.179952087812283e-07
    on_device_inference:
      human_readable:
        batch_latency: -26958423.388 us +/- 374.276 ms [-28381088.257 us, -26724191.666
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03523473064001122
        batches_per_second_mean: -0.037101006410145375
        batches_per_second_min: -0.037419279599216995
        batches_per_second_std: 0.0004933324535093599
        seconds_per_batch_max: -26.724191665649414
        seconds_per_batch_mean: -26.958423387527464
        seconds_per_batch_min: -28.381088256835938
        seconds_per_batch_std: 0.37427636064777
    total:
      human_readable:
        batch_latency: 27.157 ms +/- 375.608 us [26.918 ms, 28.579 ms]
        batches_per_second: 36.83 +/- 0.49 [34.99, 37.15]
      metrics:
        batches_per_second_max: 37.14962401353374
        batches_per_second_mean: 36.829738445338826
        batches_per_second_min: 34.99073154860723
        batches_per_second_std: 0.487982313321039
        seconds_per_batch_max: 0.028578996658325195
        seconds_per_batch_mean: 0.02715694785118103
        seconds_per_batch_min: 0.02691817283630371
        seconds_per_batch_std: 0.0003756080845554148


#####
fp-fp-py-id - Run 4
2024-02-26 00:08:56
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 48.84it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 48.89it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.93it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.94it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 48.94it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 48.95it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 48.96it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 48.95it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 48.95it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 48.95it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 48.95it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 48.96it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 48.95it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 48.93it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 48.92it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 48.91it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 48.91it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 48.91it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 48.92it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.93it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.93it/s]
STAGE:2024-02-26 00:07:56 9598:9598 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:07:56 9598:9598 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:07:56 9598:9598 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.08it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.29it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.36it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 37.43it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.42it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.43it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.42it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.40it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.42it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.44it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 37.43it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:25, 37.43it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.43it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.44it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.44it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.42it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.41it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.41it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.43it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 37.44it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 37.45it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.49it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.47it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.49it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.48it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.48it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.50it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.50it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.49it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 37.53it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 37.52it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.52it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.52it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.52it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.51it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.52it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.52it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 37.53it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 37.52it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 37.50it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.49it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.50it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:21, 37.50it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.51it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.53it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.55it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.54it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 37.54it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 37.55it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.54it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.55it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.54it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.56it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 37.57it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.54it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.53it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 37.54it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 37.55it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 37.54it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.54it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.53it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:19, 37.51it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.49it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.51it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.51it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.54it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 37.54it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 37.55it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.55it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.53it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:18, 37.53it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.53it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.56it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.57it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.56it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.57it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 37.55it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.54it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.52it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.54it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.54it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.54it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.51it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.52it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.50it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.52it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 37.51it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.55it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.55it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:16, 37.56it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.55it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.56it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.54it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.53it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.54it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 37.54it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.54it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.53it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 37.53it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 37.53it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.51it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.50it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.54it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.52it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 37.52it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.51it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.52it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.51it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:14, 37.51it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.51it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.55it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.55it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.57it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.56it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.53it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.55it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.54it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:13, 37.54it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 37.52it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.52it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.54it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.54it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.57it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 37.56it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.56it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.55it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 37.54it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 37.55it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.54it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.55it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.54it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.53it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 37.53it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.55it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.56it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.57it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:11, 37.58it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 37.58it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.58it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.57it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.56it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.57it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 37.56it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.58it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.58it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 37.59it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 37.59it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.57it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.57it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.56it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.56it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 37.56it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.56it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.60it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 37.59it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 37.58it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.57it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.56it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.54it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.54it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.53it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.53it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.54it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.55it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 37.56it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.56it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.56it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.53it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.53it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.52it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 37.54it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.55it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.55it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 37.55it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 37.55it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.54it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.52it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.53it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.53it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:07, 37.55it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.57it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.57it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.56it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 37.57it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.56it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.59it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.60it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.59it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.58it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.60it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.60it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.56it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 37.54it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 37.53it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.52it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.54it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.54it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.54it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:05, 37.53it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.52it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.52it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 37.53it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 37.51it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.49it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.48it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.49it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.48it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.49it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.49it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.49it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.50it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 37.52it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 37.50it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.52it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.51it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.51it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.50it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.51it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.52it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.51it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 37.49it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 37.49it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.50it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.50it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.50it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.50it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.50it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.50it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.50it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 37.50it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 37.52it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 37.54it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.53it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.51it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.51it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.50it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.53it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.55it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.54it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 37.53it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 37.53it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.54it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.52it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.52it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.53it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.54it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.52it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.19it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.27it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.29it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.30it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.30it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.33it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.33it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.33it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.33it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.31it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.32it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.34it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.35it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.38it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.37it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.35it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.33it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.34it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.34it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.34it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.34it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.34it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.38it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.33it/s]
STAGE:2024-02-26 00:08:26 9598:9598 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:08:26 9598:9598 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:08:26 9598:9598 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:27, 36.58it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 36.85it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 36.93it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.03it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.06it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 37.06it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:26, 37.07it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:26, 37.10it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.09it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.06it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.05it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.07it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.07it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.05it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 37.03it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:25, 37.04it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:25, 37.03it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:25, 37.03it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.05it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.06it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.04it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.04it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.03it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.06it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:24, 37.04it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:24, 37.05it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:24, 37.06it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:03<00:23, 37.05it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.04it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.02it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.02it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.06it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.06it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 37.07it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.06it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.07it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.04it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:22, 37.08it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:22, 37.04it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:21, 37.02it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.02it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 36.99it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.01it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.03it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:21, 37.06it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:21, 37.07it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:21, 37.06it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:21, 37.06it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:06<00:20, 37.05it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.09it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.05it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.04it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.03it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.02it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:20, 37.03it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:20, 37.02it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:20, 37.01it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:07<00:20, 37.00it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.03it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.01it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.01it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.00it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.01it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:19, 37.00it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:19, 37.01it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:19, 37.00it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:19, 37.01it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:08<00:18, 37.00it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.01it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.00it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.02it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.04it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.06it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:18, 37.06it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:18, 37.10it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:18, 37.10it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:09<00:17, 37.11it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.10it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.09it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.06it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.06it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.06it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:17, 37.08it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:17, 37.05it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:17, 37.06it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:10<00:16, 37.06it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:16, 37.07it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.09it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.07it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.05it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.08it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 37.09it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:16, 37.11it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:16, 37.08it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:11<00:15, 37.10it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:15, 37.07it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 37.06it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.05it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.05it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.05it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 37.03it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:15, 37.07it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:15, 37.10it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 37.13it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:12<00:14, 37.12it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:14, 37.12it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.11it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.09it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.08it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.07it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 37.06it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:14, 37.06it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:13<00:13, 37.07it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:13, 37.08it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.03it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.02it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.02it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:13, 37.07it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:13, 37.08it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:14<00:12, 37.08it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:12, 37.07it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:12, 37.09it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.07it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.07it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.06it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.04it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:12, 37.03it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:12, 37.03it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:15<00:11, 37.07it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:15<00:11, 37.10it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:11, 37.11it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 37.11it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.08it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.11it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.08it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 37.06it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:11, 37.04it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:11, 37.04it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:16<00:10, 37.03it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:10, 37.03it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 37.07it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.09it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.07it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.05it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.03it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:10, 37.04it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:10, 37.04it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:17<00:09, 37.06it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:09, 37.05it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:09, 37.08it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 37.08it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.06it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.06it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.09it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 37.05it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:09, 37.04it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:18<00:08, 37.04it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:18<00:08, 37.06it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:08, 37.07it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 37.09it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.12it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.15it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.15it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.15it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:08, 37.12it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 37.14it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:19<00:07, 37.12it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:07, 37.10it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:07, 37.06it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 37.06it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.08it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.09it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.10it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:07, 37.09it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:07, 37.08it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:20<00:06, 37.08it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:06, 37.10it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:06, 37.08it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 37.09it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.07it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.08it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.12it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.11it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:06, 37.11it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:21<00:05, 37.10it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:21<00:05, 37.14it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:05, 37.10it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 37.10it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 37.13it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.15it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.13it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.12it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:05, 37.14it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:22<00:04, 37.12it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:22<00:04, 37.09it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 37.07it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:22<00:04, 37.09it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 37.07it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 37.05it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 37.09it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 37.09it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 37.10it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:22<00:03, 37.08it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:23<00:03, 37.07it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 37.08it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:23<00:03, 37.11it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 37.13it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 37.14it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 37.11it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 37.11it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 37.09it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:03, 37.12it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:24<00:02, 37.13it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:24<00:02, 37.09it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:24<00:02, 37.09it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 37.07it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 37.05it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 37.06it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 37.07it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 37.08it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 37.11it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:25<00:01, 37.14it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:25<00:01, 37.15it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:25<00:01, 37.15it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 37.11it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 37.09it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 37.08it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 37.08it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 37.06it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 37.05it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:26<00:00, 37.05it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:26<00:00, 37.05it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:26<00:00, 37.05it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 37.07it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 37.05it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 37.07it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 37.06it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 37.04it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 37.03it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.03it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.07it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 999.95 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.878 us +/- 5.746 us [93.222 us, 224.113 us]
        batches_per_second: 10.35 K +/- 457.99 [4.46 K, 10.73 K]
      metrics:
        batches_per_second_max: 10727.120204603581
        batches_per_second_mean: 10347.74779633293
        batches_per_second_min: 4462.025531914894
        batches_per_second_std: 457.98713483994936
        seconds_per_batch_max: 0.00022411346435546875
        seconds_per_batch_mean: 9.68775749206543e-05
        seconds_per_batch_min: 9.322166442871094e-05
        seconds_per_batch_std: 5.746077914276883e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.674 us +/- 0.794 us [23.842 us, 36.955 us]
        batches_per_second: 40.56 K +/- 1.05 K [27.06 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 40561.36395471229
        batches_per_second_min: 27060.025806451613
        batches_per_second_std: 1053.3217791506238
        seconds_per_batch_max: 3.695487976074219e-05
        seconds_per_batch_mean: 2.4674415588378907e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 7.938277543095295e-07
    on_device_inference:
      human_readable:
        batch_latency: -26492845.104 us +/- 64.882 ms [-27647712.708 us, -26336191.177
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03616935732003695
        batches_per_second_mean: -0.037746263794671345
        batches_per_second_min: -0.0379705627615334
        batches_per_second_std: 9.126019669075754e-05
        seconds_per_batch_max: -26.336191177368164
        seconds_per_batch_mean: -26.49284510421753
        seconds_per_batch_min: -27.64771270751953
        seconds_per_batch_std: 0.06488213075972975
    total:
      human_readable:
        batch_latency: 26.633 ms +/- 68.790 us [26.474 ms, 27.935 ms]
        batches_per_second: 37.55 +/- 0.10 [35.80, 37.77]
      metrics:
        batches_per_second_max: 37.773591022893065
        batches_per_second_mean: 37.547778845279005
        batches_per_second_min: 35.79796186607036
        batches_per_second_std: 0.09540921558792591
        seconds_per_batch_max: 0.027934551239013672
        seconds_per_batch_mean: 0.026632908582687378
        seconds_per_batch_min: 0.026473522186279297
        seconds_per_batch_std: 6.878997015025662e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.051 us +/- 5.963 us [144.005 us, 285.149 us]
        batches_per_second: 6.76 K +/- 208.72 [3.51 K, 6.94 K]
      metrics:
        batches_per_second_max: 6944.211920529801
        batches_per_second_mean: 6762.462221269187
        batches_per_second_min: 3506.943143812709
        batches_per_second_std: 208.72427179177572
        seconds_per_batch_max: 0.00028514862060546875
        seconds_per_batch_mean: 0.00014805102348327637
        seconds_per_batch_min: 0.00014400482177734375
        seconds_per_batch_std: 5.962848944551506e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.127 us +/- 0.641 us [24.080 us, 33.855 us]
        batches_per_second: 39.82 K +/- 879.09 [29.54 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 39820.54476472345
        batches_per_second_min: 29537.352112676057
        batches_per_second_std: 879.0906382869432
        seconds_per_batch_max: 3.3855438232421875e-05
        seconds_per_batch_mean: 2.512669563293457e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 6.406178560090092e-07
    on_device_inference:
      human_readable:
        batch_latency: -26769259.344 us +/- 74.371 ms [-27930303.574 us, -26565856.934
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035803406051945284
        batches_per_second_mean: -0.037356567524045106
        batches_per_second_min: -0.03764230163926893
        batches_per_second_std: 0.00010280261975972396
        seconds_per_batch_max: -26.56585693359375
        seconds_per_batch_mean: -26.769259344100952
        seconds_per_batch_min: -27.9303035736084
        seconds_per_batch_std: 0.07437121692960774
    total:
      human_readable:
        batch_latency: 26.961 ms +/- 77.759 us [26.754 ms, 28.274 ms]
        batches_per_second: 37.09 +/- 0.11 [35.37, 37.38]
      metrics:
        batches_per_second_max: 37.37739161431181
        batches_per_second_mean: 37.091238111664076
        batches_per_second_min: 35.3681086094949
        batches_per_second_std: 0.10563152390042044
        seconds_per_batch_max: 0.028274059295654297
        seconds_per_batch_mean: 0.026960766553878784
        seconds_per_batch_min: 0.026754140853881836
        seconds_per_batch_std: 7.775938647476132e-05


#####
fp-fp-py-id - Run 5
2024-02-26 00:10:04
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.40it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 48.68it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 48.74it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 48.74it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 48.76it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 48.77it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 48.76it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 48.75it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 48.78it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 48.78it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 48.76it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 48.74it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 48.74it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 48.73it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 48.73it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 48.73it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 48.73it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 48.74it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 48.75it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 48.75it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.74it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 48.74it/s]
STAGE:2024-02-26 00:09:04 9644:9644 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:09:04 9644:9644 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:09:04 9644:9644 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.00it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.23it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.33it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:26, 37.39it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:26, 37.40it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:26, 37.38it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:26, 37.35it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.33it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.34it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.35it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.37it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.37it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:25, 37.36it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:25, 37.38it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:25, 37.39it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:25, 37.41it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.41it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.42it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.41it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:24, 37.41it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:24, 37.40it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.40it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 37.41it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:23, 37.40it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 37.41it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 37.41it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 37.41it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.40it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:22, 37.41it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.41it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.42it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:05<00:21, 37.41it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.42it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.44it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 37.45it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:21, 37.45it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:21, 37.45it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:21, 37.44it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 37.43it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 37.44it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 37.44it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 37.43it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 37.44it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 37.44it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:20, 37.42it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:20, 37.42it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:20, 37.43it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 37.44it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 37.44it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 37.45it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:07<00:19, 37.42it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 37.41it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 37.40it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 37.38it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:19, 37.37it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:19, 37.40it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:19, 37.39it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 37.39it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 37.40it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:08<00:18, 37.40it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 37.40it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 37.41it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 37.41it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:18, 37.40it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:18, 37.40it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:18, 37.39it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 37.39it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 37.39it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 37.40it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:09<00:17, 37.39it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 37.39it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 37.39it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 37.39it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:17, 37.39it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:17, 37.40it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:17, 37.40it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 37.40it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 37.40it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:10<00:16, 37.41it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:16, 37.42it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:16, 37.43it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 37.42it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 37.42it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:11<00:15, 37.41it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:11<00:15, 37.42it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 37.42it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 37.42it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 37.43it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:15, 37.41it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:15, 37.42it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 37.41it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 37.41it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 37.43it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:12<00:14, 37.44it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:12<00:14, 37.44it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 37.44it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 37.44it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:14, 37.43it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:14, 37.43it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 37.43it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 37.42it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 37.42it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:13<00:13, 37.43it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:13<00:13, 37.41it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 37.40it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 37.42it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 37.41it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:13, 37.41it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:13, 37.41it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 37.41it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 37.41it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:14<00:12, 37.40it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:14<00:12, 37.39it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:14<00:12, 37.39it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 37.41it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 37.41it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:12, 37.42it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:12, 37.41it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 37.41it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 37.41it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 37.42it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 37.42it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 37.42it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:11, 37.41it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 37.40it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 37.40it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:16<00:10, 37.39it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:16<00:10, 37.41it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:16<00:10, 37.41it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 37.41it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:10, 37.40it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:10, 37.38it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 37.38it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 37.37it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:17<00:09, 37.38it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:17<00:09, 37.39it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 37.39it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 37.40it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 37.39it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:09, 37.39it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 37.41it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 37.40it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 37.43it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 37.42it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:08, 37.40it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:08, 37.41it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 37.42it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 37.42it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:19<00:07, 37.41it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:19<00:07, 37.41it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 37.38it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 37.38it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:07, 37.39it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 37.39it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 37.40it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 37.41it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:20<00:06, 37.41it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:20<00:06, 37.41it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:20<00:06, 37.40it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 37.40it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 37.39it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:06, 37.39it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 37.39it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 37.39it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 37.39it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:21<00:05, 37.38it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:21<00:05, 37.38it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:21<00:05, 37.39it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 37.40it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 37.40it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 37.40it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:05, 37.40it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 37.39it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 37.40it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:22<00:04, 37.42it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:22<00:04, 37.41it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:22<00:04, 37.40it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 37.38it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 37.38it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:04, 37.38it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 37.37it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 37.39it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 37.40it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:23<00:03, 37.40it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:23<00:03, 37.40it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:23<00:03, 37.41it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.41it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.40it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.40it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 37.38it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.40it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 37.41it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:24<00:02, 37.41it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:24<00:02, 37.41it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 37.43it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 37.43it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:02, 37.42it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 37.42it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 37.43it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:25<00:01, 37.42it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 37.44it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 37.44it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 37.44it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 37.45it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 37.45it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:26<00:00, 37.45it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:26<00:00, 37.46it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:26<00:00, 37.45it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.43it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 37.43it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 37.41it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 36.96it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.14it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.20it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.25it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.28it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.29it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.29it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.31it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.33it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.34it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.35it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.35it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.35it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.36it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.36it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.35it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.35it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.34it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.33it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.32it/s]
STAGE:2024-02-26 00:09:34 9644:9644 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:09:34 9644:9644 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:09:34 9644:9644 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:27, 36.55it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 36.82it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 36.92it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 36.97it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.01it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 37.03it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:26, 37.04it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:26, 37.05it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:26, 37.06it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.05it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.05it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.06it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.06it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.06it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 37.07it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:25, 37.07it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:25, 37.09it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:25, 37.07it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.08it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.07it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.07it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.06it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.06it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.06it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:24, 37.07it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:24, 37.08it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:24, 37.09it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:03<00:23, 37.09it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.10it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.09it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.09it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.08it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 37.09it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:23, 37.09it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:23, 37.09it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.08it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.07it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.08it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.07it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.07it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 37.07it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:22, 37.07it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:22, 37.06it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:21, 37.05it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.06it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.05it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.06it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.05it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:21, 37.04it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:21, 37.04it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:21, 37.04it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:21, 37.04it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:06<00:20, 37.05it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.05it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.06it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.06it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.07it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.07it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:20, 37.08it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:20, 37.08it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:20, 37.09it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:07<00:19, 37.07it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.08it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.06it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.06it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.05it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.04it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:19, 37.03it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:19, 37.01it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:19, 37.02it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:19, 37.02it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:08<00:18, 37.02it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.02it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.03it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.04it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.04it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.03it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:18, 37.03it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:18, 37.04it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:18, 37.03it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:09<00:17, 37.04it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.04it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.04it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.04it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.03it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.02it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:17, 37.01it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:17, 37.00it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:17, 37.01it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:10<00:16, 37.02it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:16, 37.03it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.04it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.03it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.03it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.02it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 37.02it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:16, 37.02it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:16, 37.02it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:11<00:15, 37.02it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:15, 37.01it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 37.01it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.01it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.02it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.01it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 37.02it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:15, 37.02it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:15, 37.02it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:15, 37.02it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:12<00:14, 37.03it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:14, 37.04it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:14, 37.05it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:14, 37.04it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.03it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.03it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 37.02it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:13, 37.02it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:13, 37.04it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:14<00:12, 37.04it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:12, 37.04it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:12, 37.04it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.05it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.07it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.07it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.06it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:12, 37.06it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:12, 37.06it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:15<00:11, 37.05it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:15<00:11, 37.04it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:11, 37.04it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 37.03it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.06it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.06it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.07it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 37.06it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:11, 37.06it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:11, 37.05it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:16<00:10, 37.06it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:10, 37.06it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 37.06it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.07it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.07it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.07it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.06it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:10, 37.05it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:10, 37.06it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:17<00:09, 37.06it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:09, 37.06it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:09, 37.05it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 37.05it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.04it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.03it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.01it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 37.01it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:09, 37.01it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:18<00:08, 37.02it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:18<00:08, 37.02it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:08, 37.02it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 37.03it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.03it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.02it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.04it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.04it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:08, 37.04it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:19<00:07, 37.03it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:19<00:07, 37.03it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:07, 37.03it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:07, 37.02it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 37.02it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.01it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.01it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.01it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:07, 37.04it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:07, 37.03it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:20<00:06, 37.05it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:06, 37.05it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:06, 37.05it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 37.05it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.04it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.04it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.04it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.04it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:06, 37.03it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:21<00:05, 37.02it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:21<00:05, 37.03it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:05, 37.04it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 37.04it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 37.04it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.02it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.02it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.02it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:05, 37.02it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:22<00:04, 37.02it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:22<00:04, 37.03it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 37.04it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:22<00:04, 37.04it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 37.04it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 37.05it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 37.06it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 37.05it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 37.05it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:23<00:03, 37.05it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:23<00:03, 37.04it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 37.04it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:23<00:03, 37.03it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 37.03it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 37.03it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 37.03it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 37.02it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 37.02it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:03, 37.02it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:24<00:02, 37.02it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:24<00:02, 37.02it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:24<00:02, 37.03it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 37.04it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 37.04it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 37.04it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 37.02it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 37.03it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 37.02it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:25<00:01, 37.01it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:25<00:01, 37.01it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:25<00:01, 37.02it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 37.02it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 37.02it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 37.01it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 37.01it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 37.01it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 37.01it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:26<00:00, 37.02it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:26<00:00, 37.02it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:26<00:00, 37.01it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 37.02it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 37.02it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 37.04it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 37.03it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 37.04it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 37.04it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.03it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.04it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1006.46 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.939 us +/- 5.710 us [92.983 us, 223.875 us]
        batches_per_second: 10.34 K +/- 454.77 [4.47 K, 10.75 K]
      metrics:
        batches_per_second_max: 10754.625641025641
        batches_per_second_mean: 10340.831903439892
        batches_per_second_min: 4466.777422790203
        batches_per_second_std: 454.7690885305569
        seconds_per_batch_max: 0.0002238750457763672
        seconds_per_batch_mean: 9.69390869140625e-05
        seconds_per_batch_min: 9.298324584960938e-05
        seconds_per_batch_std: 5.7100305768455705e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.232 us +/- 0.771 us [24.319 us, 33.855 us]
        batches_per_second: 39.66 K +/- 1.02 K [29.54 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 39663.30878934835
        batches_per_second_min: 29537.352112676057
        batches_per_second_std: 1015.7075932886432
        seconds_per_batch_max: 3.3855438232421875e-05
        seconds_per_batch_mean: 2.523183822631836e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 7.712057934705368e-07
    on_device_inference:
      human_readable:
        batch_latency: -26576252.556 us +/- 49.984 ms [-27706975.937 us, -26459039.688
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03609199366534184
        batches_per_second_mean: -0.03762770769766723
        batches_per_second_min: -0.03779426660179812
        batches_per_second_std: 6.929438231223596e-05
        seconds_per_batch_max: -26.45903968811035
        seconds_per_batch_mean: -26.57625255584717
        seconds_per_batch_min: -27.70697593688965
        seconds_per_batch_std: 0.04998399479552861
    total:
      human_readable:
        batch_latency: 26.715 ms +/- 54.238 us [26.600 ms, 27.990 ms]
        batches_per_second: 37.43 +/- 0.07 [35.73, 37.59]
      metrics:
        batches_per_second_max: 37.59347494846285
        batches_per_second_mean: 37.43179060838975
        batches_per_second_min: 35.727522849817284
        batches_per_second_std: 0.07409253637372192
        seconds_per_batch_max: 0.027989625930786133
        seconds_per_batch_mean: 0.026715366840362548
        seconds_per_batch_min: 0.026600360870361328
        seconds_per_batch_std: 5.423838386968128e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.693 us +/- 6.365 us [144.720 us, 299.454 us]
        batches_per_second: 6.73 K +/- 213.45 [3.34 K, 6.91 K]
      metrics:
        batches_per_second_max: 6909.891268533773
        batches_per_second_mean: 6733.94561950145
        batches_per_second_min: 3339.4140127388537
        batches_per_second_std: 213.44790437689963
        seconds_per_batch_max: 0.0002994537353515625
        seconds_per_batch_mean: 0.00014869284629821778
        seconds_per_batch_min: 0.00014472007751464844
        seconds_per_batch_std: 6.365416330002872e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.652 us +/- 0.888 us [24.557 us, 42.200 us]
        batches_per_second: 39.02 K +/- 1.09 K [23.70 K, 40.72 K]
      metrics:
        batches_per_second_max: 40721.398058252424
        batches_per_second_mean: 39019.940693935234
        batches_per_second_min: 23696.632768361582
        batches_per_second_std: 1086.1452908151193
        seconds_per_batch_max: 4.220008850097656e-05
        seconds_per_batch_mean: 2.5652170181274415e-05
        seconds_per_batch_min: 2.4557113647460938e-05
        seconds_per_batch_std: 8.87524200906227e-07
    on_device_inference:
      human_readable:
        batch_latency: -26789427.864 us +/- 53.197 ms [-28052288.055 us, -26683967.590
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035647716080214435
        batches_per_second_mean: -0.037328301621093206
        batches_per_second_min: -0.03747568635041791
        batches_per_second_std: 7.227121257428219e-05
        seconds_per_batch_max: -26.68396759033203
        seconds_per_batch_mean: -26.789427864074707
        seconds_per_batch_min: -28.052288055419922
        seconds_per_batch_std: 0.05319662170868639
    total:
      human_readable:
        batch_latency: 26.980 ms +/- 57.629 us [26.872 ms, 28.407 ms]
        batches_per_second: 37.06 +/- 0.08 [35.20, 37.21]
      metrics:
        batches_per_second_max: 37.21356768314864
        batches_per_second_mean: 37.06403609497563
        batches_per_second_min: 35.20276633066716
        batches_per_second_std: 0.07676615659782766
        seconds_per_batch_max: 0.028406858444213867
        seconds_per_batch_mean: 0.026980451345443725
        seconds_per_batch_min: 0.026871919631958008
        seconds_per_batch_std: 5.762888401979486e-05


#####
fp-fp-py-id - Run 6
2024-02-26 00:11:10
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.42it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.40it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.37it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.44it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.49it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.51it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.51it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.53it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.53it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.53it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.55it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.55it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.53it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.51it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.51it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.52it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.53it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.52it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.52it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.53it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.54it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.52it/s]
STAGE:2024-02-26 00:10:12 9725:9725 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:10:12 9725:9725 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:10:12 9725:9725 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.61it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.86it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.96it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.02it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.03it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.04it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.07it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.06it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.08it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 38.12it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 38.12it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.12it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.13it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.12it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.13it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.12it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.13it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.13it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:24, 38.15it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 38.13it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 38.10it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.09it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.11it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.11it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.12it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.11it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.11it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.11it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.12it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 38.12it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.12it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.14it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.15it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.15it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.13it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.13it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.13it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.13it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.14it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 38.14it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.14it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.14it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.15it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.15it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.15it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.16it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.17it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 38.17it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 38.18it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.18it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.17it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.17it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.17it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.16it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.17it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.19it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.19it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.20it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 38.20it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.20it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.20it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.20it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.19it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.20it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.21it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.22it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 38.23it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 38.22it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 38.22it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.22it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.20it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.20it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.20it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.20it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.20it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.18it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 38.18it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 38.18it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.18it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.19it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.18it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.18it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.18it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.18it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.18it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 38.17it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 38.17it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:16, 38.18it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.17it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.16it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.17it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.16it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.12it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.13it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.13it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 38.13it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 38.13it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.16it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.17it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.19it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.20it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.21it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.20it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.20it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 38.20it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 38.19it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:14, 38.17it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.19it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.19it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.18it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.19it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.18it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.19it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.18it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 38.18it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 38.18it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.19it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.19it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.18it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.18it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.18it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.18it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.18it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 38.20it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 38.21it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 38.20it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.20it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.21it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.20it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.20it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.21it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.22it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.22it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 38.23it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 38.23it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.23it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.23it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.24it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.24it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.23it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.22it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.21it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 38.21it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 38.21it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 38.21it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.22it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.22it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.21it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.21it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.22it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.23it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.22it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 38.21it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 38.23it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.25it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.24it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.24it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.25it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.24it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.23it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.23it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 38.23it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 38.24it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 38.23it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.22it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.20it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.20it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.20it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.20it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.21it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.21it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 38.20it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 38.20it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.20it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.20it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.19it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.19it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.19it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.20it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.20it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 38.20it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 38.21it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 38.22it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.22it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.20it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.19it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.19it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.18it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.19it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.18it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 38.18it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 38.18it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.17it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.20it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.22it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.21it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.22it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.20it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.20it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 38.21it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 38.22it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 38.21it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.22it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.20it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.20it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.20it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.20it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.21it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.21it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 38.20it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 38.21it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.22it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.22it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.22it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.22it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.22it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.23it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.21it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 38.21it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 38.21it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 38.22it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.23it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.22it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.22it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.22it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.20it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.20it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.22it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 38.21it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 38.20it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.20it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.20it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.22it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.21it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.21it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.21it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.21it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 38.22it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 38.21it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 38.22it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.21it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.20it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.20it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.20it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.19it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.18it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.18it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 38.17it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 38.18it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.18it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.18it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.74it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.92it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.98it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.99it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 38.00it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:01, 38.03it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 38.05it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 38.05it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 38.05it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 38.06it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 38.06it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 38.08it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 38.07it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 38.08it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 38.10it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 38.10it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 38.10it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 38.10it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:01<00:00, 38.10it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 38.09it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 38.10it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 38.09it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 38.10it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 38.10it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 38.10it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 38.07it/s]
STAGE:2024-02-26 00:10:41 9725:9725 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:10:41 9725:9725 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:10:41 9725:9725 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 37.31it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.52it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.61it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.62it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.65it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:25, 37.66it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:25, 37.67it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:25, 37.67it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.68it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.68it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.69it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.68it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.69it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.70it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:24, 37.68it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:24, 37.68it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 37.69it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.69it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.70it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.71it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.71it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.71it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.69it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:23, 37.69it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:23, 37.70it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:23, 37.70it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.70it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:02<00:23, 37.70it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.71it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.73it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.74it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.75it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:22, 37.75it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:22, 37.74it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:22, 37.74it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.72it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.72it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.72it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.72it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.73it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.70it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.70it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:21, 37.71it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:21, 37.72it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 37.73it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:21, 37.74it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:04<00:21, 37.73it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.73it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.73it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.74it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.74it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:20, 37.74it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:20, 37.73it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:20, 37.73it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 37.71it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:05<00:20, 37.71it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.71it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.72it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.72it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.71it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.70it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:19, 37.71it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:19, 37.71it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 37.70it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 37.69it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.70it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.69it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.68it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.70it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.70it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:18, 37.71it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:18, 37.72it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 37.72it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 37.70it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:07<00:18, 37.70it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.70it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.71it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.72it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.71it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.70it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:17, 37.71it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 37.71it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:08<00:17, 37.72it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.71it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.71it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.71it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.71it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.71it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:16, 37.69it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:16, 37.69it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 37.69it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 37.68it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:09<00:16, 37.69it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.69it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.70it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.71it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.71it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 37.71it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:15, 37.70it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:15, 37.71it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:15, 37.70it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:10<00:15, 37.70it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:15, 37.69it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.69it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.68it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.70it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:15, 37.70it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:14, 37.72it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:14, 37.72it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 37.74it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:11<00:14, 37.74it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:11<00:14, 37.74it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.73it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.73it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.73it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.71it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 37.71it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:13, 37.72it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:12<00:13, 37.73it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:12<00:13, 37.73it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:13, 37.72it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.72it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.73it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.72it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 37.71it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:12, 37.69it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:12, 37.70it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:13<00:12, 37.70it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:13<00:12, 37.71it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:12, 37.70it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.68it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.69it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.69it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.69it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:11, 37.69it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:11, 37.70it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:14<00:11, 37.71it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:14<00:11, 37.70it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:14<00:11, 37.70it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:11, 37.72it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.72it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.72it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.72it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 37.72it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:10, 37.72it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:10, 37.71it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:15<00:10, 37.70it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:15<00:10, 37.70it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:10, 37.70it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.70it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.72it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.71it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.71it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:09, 37.72it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:09, 37.72it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:16<00:09, 37.73it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:16<00:09, 37.73it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:16<00:09, 37.73it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:09, 37.73it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.72it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.73it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.73it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:09, 37.72it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:08, 37.71it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:17<00:08, 37.72it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:17<00:08, 37.72it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:17<00:08, 37.72it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:08, 37.72it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.73it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.74it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.74it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.73it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 37.75it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:18<00:07, 37.74it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 37.72it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.72it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.70it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.71it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:06, 37.72it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:06, 37.72it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:19<00:06, 37.72it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:19<00:06, 37.73it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:19<00:06, 37.74it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 37.73it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.72it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.73it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.75it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.76it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:05, 37.75it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:20<00:05, 37.75it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:20<00:05, 37.74it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:20<00:05, 37.75it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 37.76it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.75it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.74it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:04, 37.74it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:21<00:04, 37.75it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:21<00:04, 37.75it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:21<00:04, 37.75it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:21<00:04, 37.74it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 37.74it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 37.74it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 37.74it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 37.75it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 37.76it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:22<00:03, 37.75it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:22<00:03, 37.75it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:22<00:03, 37.74it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:22<00:03, 37.75it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 37.75it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:23<00:03, 37.76it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 37.76it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 37.76it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 37.77it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:02, 37.77it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:23<00:02, 37.77it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:23<00:02, 37.77it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:23<00:02, 37.75it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:23<00:02, 37.75it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:24<00:02, 37.75it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 37.74it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 37.74it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 37.74it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 37.73it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:24<00:01, 37.73it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:24<00:01, 37.73it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:24<00:01, 37.72it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:24<00:01, 37.73it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 37.74it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:25<00:01, 37.74it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 37.74it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 37.74it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 37.75it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:25<00:00, 37.74it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:26<00:00, 37.74it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 37.73it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 37.73it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 37.72it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.72it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.72it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1002.30 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.217 us +/- 6.288 us [92.030 us, 225.067 us]
        batches_per_second: 10.42 K +/- 507.16 [4.44 K, 10.87 K]
      metrics:
        batches_per_second_max: 10866.072538860104
        batches_per_second_mean: 10424.47123437233
        batches_per_second_min: 4443.118644067797
        batches_per_second_std: 507.1572133956817
        seconds_per_batch_max: 0.000225067138671875
        seconds_per_batch_mean: 9.621715545654297e-05
        seconds_per_batch_min: 9.202957153320312e-05
        seconds_per_batch_std: 6.2884946717502966e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.531 us +/- 0.676 us [23.365 us, 37.432 us]
        batches_per_second: 40.79 K +/- 896.46 [26.72 K, 42.80 K]
      metrics:
        batches_per_second_max: 42799.02040816326
        batches_per_second_mean: 40789.30256704503
        batches_per_second_min: 26715.31210191083
        batches_per_second_std: 896.4571610518987
        seconds_per_batch_max: 3.743171691894531e-05
        seconds_per_batch_mean: 2.4530887603759766e-05
        seconds_per_batch_min: 2.3365020751953125e-05
        seconds_per_batch_std: 6.761132228678359e-07
    on_device_inference:
      human_readable:
        batch_latency: -26036261.396 us +/- 59.654 ms [-27344863.892 us, -25933631.897
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03656993883619696
        batches_per_second_mean: -0.0384081689175917
        batches_per_second_min: -0.038559967380301034
        batches_per_second_std: 8.594783998273758e-05
        seconds_per_batch_max: -25.933631896972656
        seconds_per_batch_mean: -26.03626139640808
        seconds_per_batch_min: -27.344863891601562
        seconds_per_batch_std: 0.05965437439319219
    total:
      human_readable:
        batch_latency: 26.173 ms +/- 64.491 us [26.067 ms, 27.627 ms]
        batches_per_second: 38.21 +/- 0.09 [36.20, 38.36]
      metrics:
        batches_per_second_max: 38.36300442688326
        batches_per_second_mean: 38.208224381371
        batches_per_second_min: 36.195861164328
        batches_per_second_std: 0.09160297348902062
        seconds_per_batch_max: 0.02762746810913086
        seconds_per_batch_mean: 0.02617253017425537
        seconds_per_batch_min: 0.02606678009033203
        seconds_per_batch_std: 6.449130973236041e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 147.206 us +/- 6.347 us [143.051 us, 289.679 us]
        batches_per_second: 6.80 K +/- 221.89 [3.45 K, 6.99 K]
      metrics:
        batches_per_second_max: 6990.506666666667
        batches_per_second_mean: 6802.337802388853
        batches_per_second_min: 3452.1020576131687
        batches_per_second_std: 221.8941730595423
        seconds_per_batch_max: 0.00028967857360839844
        seconds_per_batch_mean: 0.00014720630645751953
        seconds_per_batch_min: 0.0001430511474609375
        seconds_per_batch_std: 6.346973123953075e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.687 us +/- 0.516 us [23.603 us, 32.902 us]
        batches_per_second: 40.52 K +/- 772.80 [30.39 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40522.718681794555
        batches_per_second_min: 30393.507246376812
        batches_per_second_std: 772.8010573512687
        seconds_per_batch_max: 3.2901763916015625e-05
        seconds_per_batch_mean: 2.4687290191650392e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 5.163226129278106e-07
    on_device_inference:
      human_readable:
        batch_latency: -26307341.290 us +/- 52.992 ms [-27454944.611 us, -26203008.652
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.0364233115084876
        batches_per_second_mean: -0.03801235427849249
        batches_per_second_min: -0.038163556456096016
        batches_per_second_std: 7.507057117784325e-05
        seconds_per_batch_max: -26.2030086517334
        seconds_per_batch_mean: -26.307341289520263
        seconds_per_batch_min: -27.454944610595703
        seconds_per_batch_std: 0.05299157582710565
    total:
      human_readable:
        batch_latency: 26.495 ms +/- 57.515 us [26.387 ms, 27.799 ms]
        batches_per_second: 37.74 +/- 0.08 [35.97, 37.90]
      metrics:
        batches_per_second_max: 37.897826047671536
        batches_per_second_mean: 37.74336381484596
        batches_per_second_min: 35.97265795860957
        batches_per_second_std: 0.07996360867960739
        seconds_per_batch_max: 0.027798891067504883
        seconds_per_batch_mean: 0.026494845628738405
        seconds_per_batch_min: 0.026386737823486328
        seconds_per_batch_std: 5.7514749183973314e-05


#####
fp-fp-py-id - Run 7
2024-02-26 00:12:18
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.19it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.49it/s]Warming up with batch_size=1:  10%|█         | 10/100 [00:00<00:01, 49.51it/s]Warming up with batch_size=1:  15%|█▌        | 15/100 [00:00<00:01, 49.53it/s]Warming up with batch_size=1:  20%|██        | 20/100 [00:00<00:01, 49.56it/s]Warming up with batch_size=1:  25%|██▌       | 25/100 [00:00<00:01, 49.55it/s]Warming up with batch_size=1:  30%|███       | 30/100 [00:00<00:01, 49.56it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 49.58it/s]Warming up with batch_size=1:  40%|████      | 40/100 [00:00<00:01, 49.59it/s]Warming up with batch_size=1:  45%|████▌     | 45/100 [00:00<00:01, 49.61it/s]Warming up with batch_size=1:  50%|█████     | 50/100 [00:01<00:01, 49.63it/s]Warming up with batch_size=1:  55%|█████▌    | 55/100 [00:01<00:00, 49.63it/s]Warming up with batch_size=1:  60%|██████    | 60/100 [00:01<00:00, 49.62it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 49.58it/s]Warming up with batch_size=1:  70%|███████   | 70/100 [00:01<00:00, 49.60it/s]Warming up with batch_size=1:  75%|███████▌  | 75/100 [00:01<00:00, 49.59it/s]Warming up with batch_size=1:  80%|████████  | 80/100 [00:01<00:00, 49.58it/s]Warming up with batch_size=1:  85%|████████▌ | 85/100 [00:01<00:00, 49.58it/s]Warming up with batch_size=1:  90%|█████████ | 90/100 [00:01<00:00, 49.59it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 49.58it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.59it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:02<00:00, 49.58it/s]
STAGE:2024-02-26 00:11:18 9772:9772 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:11:18 9772:9772 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:11:18 9772:9772 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.52it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 37.78it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:26, 37.86it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 37.92it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 37.95it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 37.96it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 37.96it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 37.97it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 37.96it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 37.97it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:25, 37.96it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:25, 37.97it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 37.96it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 37.98it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 37.97it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 37.98it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 37.99it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 37.99it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:02<00:24, 37.99it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 37.99it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:24, 37.98it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:24, 37.97it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 37.98it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 37.98it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 37.99it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.00it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.00it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 37.99it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.01it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:23, 38.02it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:23, 38.03it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.02it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.01it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.00it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.01it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.00it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.01it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:04<00:22, 38.01it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.01it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:22, 37.99it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:22, 37.99it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 37.98it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 37.98it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 37.98it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 37.99it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 37.98it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 37.97it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 37.98it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:21, 37.99it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:21, 38.01it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.00it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.01it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.02it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.03it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.04it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.04it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:06<00:20, 38.04it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.05it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:20, 38.04it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.05it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.04it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.03it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:07<00:19, 38.03it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:19, 38.02it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:19, 38.03it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.03it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.04it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.05it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.04it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.03it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.05it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:08<00:18, 38.04it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 38.05it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:18, 38.03it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.03it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.02it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.02it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.02it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.02it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:09<00:17, 38.01it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 38.03it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:17, 38.05it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.07it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.06it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.06it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.05it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.04it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.03it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 38.03it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:16, 38.03it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.02it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.03it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.03it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.03it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.03it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.02it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.02it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:11<00:15, 38.04it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 38.04it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:15, 38.05it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.04it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.04it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.05it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.06it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 38.06it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:14, 38.05it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.07it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.06it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.05it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.06it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.05it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.04it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.04it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:13<00:13, 38.05it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 38.05it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:13, 38.06it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.06it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.06it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.05it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.04it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:14<00:12, 38.05it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:12, 38.07it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.07it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.08it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.08it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.08it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.07it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.08it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.06it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:15<00:11, 38.07it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 38.07it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:11, 38.09it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.11it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.12it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.12it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.11it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.12it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.11it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.10it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:16<00:10, 38.08it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 38.06it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.08it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.09it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.10it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.10it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.10it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.10it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.10it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:17<00:09, 38.10it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 38.10it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:09, 38.09it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.07it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.07it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.06it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.05it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.05it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:18<00:08, 38.05it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 38.06it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.07it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.06it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.07it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.07it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.07it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.07it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.06it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:19<00:07, 38.06it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:19<00:07, 38.06it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:07, 38.08it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.07it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.05it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.04it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.06it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:20<00:06, 38.07it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 38.07it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.07it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.06it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.05it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.04it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:21<00:05, 38.03it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:21<00:05, 38.04it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:05, 38.04it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.02it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.04it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.04it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.03it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:22<00:04, 38.04it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 38.03it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.04it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.02it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.01it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.01it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.01it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:23<00:03, 37.98it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:23<00:03, 37.97it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 37.97it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.00it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 37.99it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.00it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.00it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 37.99it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 37.99it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.01it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:24<00:02, 38.01it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 38.02it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.03it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.04it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:25<00:01, 38.05it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:25<00:01, 38.05it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 38.04it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.05it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.04it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.02it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.00it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 37.99it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.00it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.00it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:26<00:00, 37.99it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:26<00:00, 38.01it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.02it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.03it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.48it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 37.61it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 37.67it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 37.70it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 37.71it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:02, 37.72it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 37.72it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 37.73it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 37.74it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 37.74it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 37.73it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 37.73it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 37.74it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 37.75it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 37.75it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 37.77it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 37.75it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 37.77it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:02<00:00, 37.76it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 37.77it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 37.78it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 37.78it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 37.77it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 37.77it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.77it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 37.74it/s]
STAGE:2024-02-26 00:11:48 9772:9772 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:11:48 9772:9772 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:11:48 9772:9772 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 37.11it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.39it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.46it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:26, 37.47it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:26, 37.50it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:26, 37.50it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:25, 37.53it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:25, 37.55it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.57it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.57it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.56it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.56it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:25, 37.54it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:25, 37.55it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:24, 37.55it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 37.55it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.55it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.54it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.53it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.53it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.52it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:24, 37.51it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:24, 37.51it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:23, 37.51it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:23, 37.50it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.49it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:02<00:23, 37.51it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.52it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.51it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.53it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:23, 37.55it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:23, 37.52it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:23, 37.51it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:22, 37.50it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.50it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.49it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.48it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.50it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.50it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.50it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:22, 37.51it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:22, 37.51it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:21, 37.51it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 37.51it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:21, 37.50it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:05<00:21, 37.48it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.48it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.49it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.49it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:21, 37.50it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:21, 37.50it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:21, 37.50it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:20, 37.50it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 37.49it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:05<00:20, 37.48it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.48it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.48it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.48it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.48it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:20, 37.48it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:20, 37.47it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:19, 37.46it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 37.48it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 37.50it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:07<00:19, 37.50it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.49it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.49it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.51it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:19, 37.50it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:19, 37.50it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:18, 37.50it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 37.50it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 37.49it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:07<00:18, 37.48it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.48it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.49it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.48it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:18, 37.50it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:18, 37.50it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 37.50it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 37.49it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:08<00:17, 37.48it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:09<00:17, 37.47it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.47it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.47it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.47it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:17, 37.47it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:17, 37.49it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:16, 37.50it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 37.50it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 37.48it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:10<00:16, 37.48it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.48it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.49it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.49it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.31it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:16, 36.71it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:16, 36.29it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:16, 36.01it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:16, 35.81it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:11<00:16, 35.68it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:11<00:16, 35.59it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:16, 35.51it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:16, 35.47it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:16, 35.43it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:16, 35.39it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:15, 35.36it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:15, 35.37it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:15, 35.34it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:12<00:15, 35.27it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:12<00:15, 35.28it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:15, 35.28it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:15, 35.29it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:15, 35.30it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:15, 35.29it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:14, 35.30it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:14, 35.31it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:14, 35.31it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:13<00:14, 35.33it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:13<00:14, 35.34it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:13<00:14, 35.34it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:14, 35.36it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:14, 35.35it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:14, 35.36it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:13, 35.35it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:13, 35.35it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:13, 35.34it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:14<00:13, 35.33it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:14<00:13, 35.34it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:14<00:13, 35.34it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:13, 35.35it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:13, 35.35it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:13, 35.35it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 35.34it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:12, 35.33it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:12, 35.31it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:15<00:12, 35.31it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:15<00:12, 35.30it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:15<00:12, 35.30it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:15<00:12, 35.29it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:12, 35.30it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:12, 35.27it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 35.27it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:11, 35.27it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:16<00:11, 35.26it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:16<00:11, 35.24it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:16<00:11, 35.21it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:16<00:11, 35.23it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:16<00:11, 35.24it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:11, 35.23it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:11, 35.20it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 35.20it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 35.22it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:17<00:10, 35.21it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:17<00:10, 35.23it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:17<00:10, 35.24it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:17<00:10, 35.25it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:17<00:10, 35.21it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:17<00:10, 35.19it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 35.20it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 35.23it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 35.26it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:18<00:09, 35.26it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:18<00:09, 35.29it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:18<00:09, 35.30it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:18<00:09, 35.30it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:18<00:09, 35.30it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:18<00:09, 35.30it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 35.30it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 35.28it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 35.29it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:19<00:08, 35.30it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:19<00:08, 35.28it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:19<00:08, 35.27it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:19<00:08, 35.29it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:19<00:08, 35.30it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:19<00:08, 35.31it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:19<00:07, 35.29it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 35.29it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 35.28it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:20<00:07, 35.28it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:20<00:07, 35.26it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:20<00:07, 35.27it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:20<00:07, 35.26it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:20<00:07, 35.27it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:20<00:07, 35.26it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:20<00:06, 35.26it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 35.27it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 35.27it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:21<00:06, 35.27it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:21<00:06, 35.27it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:21<00:06, 35.28it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:21<00:06, 35.24it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:21<00:06, 35.21it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:21<00:06, 35.18it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:21<00:05, 35.20it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:21<00:05, 35.21it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:22<00:05, 35.21it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:22<00:05, 35.22it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:22<00:05, 35.24it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:22<00:05, 35.26it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:22<00:05, 35.28it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:22<00:05, 35.30it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:22<00:04, 35.31it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:22<00:04, 35.31it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:22<00:04, 35.31it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:23<00:04, 35.25it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:23<00:04, 35.23it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:23<00:04, 35.21it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:23<00:04, 35.19it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:23<00:04, 35.22it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:23<00:04, 35.25it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:23<00:03, 35.26it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:23<00:03, 35.26it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:23<00:03, 35.28it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:24<00:03, 35.47it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:24<00:03, 36.04it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:24<00:03, 36.44it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:24<00:03, 36.74it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:24<00:03, 36.93it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:24<00:02, 37.09it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:24<00:02, 37.21it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:24<00:02, 37.29it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:24<00:02, 37.35it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:25<00:02, 37.39it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:25<00:02, 37.40it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:25<00:02, 37.43it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:25<00:02, 37.43it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:25<00:02, 37.43it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:25<00:01, 37.44it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:25<00:01, 37.43it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:25<00:01, 37.42it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:25<00:01, 37.42it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:26<00:01, 37.43it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:26<00:01, 37.44it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:26<00:01, 37.46it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:26<00:01, 37.46it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:26<00:00, 37.46it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:26<00:00, 37.46it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:26<00:00, 37.44it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:27<00:00, 37.44it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:27<00:00, 37.46it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:27<00:00, 37.45it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:27<00:00, 37.44it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:27<00:00, 37.43it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:27<00:00, 36.40it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.90 GB
    total: 31.28 GB
    used: 1003.94 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 96.212 us +/- 5.912 us [92.506 us, 234.604 us]
        batches_per_second: 10.42 K +/- 455.97 [4.26 K, 10.81 K]
      metrics:
        batches_per_second_max: 10810.061855670103
        batches_per_second_mean: 10419.555368323683
        batches_per_second_min: 4262.504065040651
        batches_per_second_std: 455.97154817408324
        seconds_per_batch_max: 0.0002346038818359375
        seconds_per_batch_mean: 9.621238708496093e-05
        seconds_per_batch_min: 9.250640869140625e-05
        seconds_per_batch_std: 5.912175378264223e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.219 us +/- 0.603 us [24.080 us, 33.379 us]
        batches_per_second: 39.67 K +/- 853.16 [29.96 K, 41.53 K]
      metrics:
        batches_per_second_max: 41527.762376237624
        batches_per_second_mean: 39672.62257393801
        batches_per_second_min: 29959.314285714285
        batches_per_second_std: 853.1604256217998
        seconds_per_batch_max: 3.337860107421875e-05
        seconds_per_batch_mean: 2.5219202041625977e-05
        seconds_per_batch_min: 2.4080276489257812e-05
        seconds_per_batch_std: 6.033107122638094e-07
    on_device_inference:
      human_readable:
        batch_latency: -26140257.093 us +/- 58.257 ms [-27396640.778 us, -26022335.052
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.036500825342720866
        batches_per_second_mean: -0.03825535671529501
        batches_per_second_min: -0.038428526801414155
        batches_per_second_std: 8.344200240547688e-05
        seconds_per_batch_max: -26.022335052490234
        seconds_per_batch_mean: -26.140257093429565
        seconds_per_batch_min: -27.39664077758789
        seconds_per_batch_std: 0.05825654187134901
    total:
      human_readable:
        batch_latency: 26.277 ms +/- 63.201 us [26.157 ms, 27.688 ms]
        batches_per_second: 38.06 +/- 0.09 [36.12, 38.23]
      metrics:
        batches_per_second_max: 38.23117519984687
        batches_per_second_mean: 38.05700158656973
        batches_per_second_min: 36.11638380133123
        batches_per_second_std: 0.08921319070697917
        seconds_per_batch_max: 0.027688264846801758
        seconds_per_batch_mean: 0.026276521921157838
        seconds_per_batch_min: 0.02615666389465332
        seconds_per_batch_std: 6.320064846718337e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 149.655 us +/- 6.368 us [144.243 us, 285.149 us]
        batches_per_second: 6.69 K +/- 227.67 [3.51 K, 6.93 K]
      metrics:
        batches_per_second_max: 6932.7338842975205
        batches_per_second_mean: 6691.337275485612
        batches_per_second_min: 3506.943143812709
        batches_per_second_std: 227.6683149165702
        seconds_per_batch_max: 0.00028514862060546875
        seconds_per_batch_mean: 0.00014965510368347167
        seconds_per_batch_min: 0.0001442432403564453
        seconds_per_batch_std: 6.368018761630157e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.901 us +/- 1.103 us [24.319 us, 45.300 us]
        batches_per_second: 38.67 K +/- 1.35 K [22.08 K, 41.12 K]
      metrics:
        batches_per_second_max: 41120.62745098039
        batches_per_second_mean: 38665.30738537284
        batches_per_second_min: 22075.284210526315
        batches_per_second_std: 1351.8520234027144
        seconds_per_batch_max: 4.5299530029296875e-05
        seconds_per_batch_mean: 2.5900602340698243e-05
        seconds_per_batch_min: 2.4318695068359375e-05
        seconds_per_batch_std: 1.1025609125975747e-06
    on_device_inference:
      human_readable:
        batch_latency: -27266799.021 us +/- 832.280 ms [-28339839.935 us, -26317440.033
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.035286014398207916
        batches_per_second_mean: -0.03670875356309571
        batches_per_second_min: -0.03799761674188816
        batches_per_second_std: 0.001117671067596141
        seconds_per_batch_max: -26.317440032958984
        seconds_per_batch_mean: -27.266799020767213
        seconds_per_batch_min: -28.339839935302734
        seconds_per_batch_std: 0.8322798736519668
    total:
      human_readable:
        batch_latency: 27.458 ms +/- 834.695 us [26.503 ms, 28.532 ms]
        batches_per_second: 36.45 +/- 1.11 [35.05, 37.73]
      metrics:
        batches_per_second_max: 37.731115569029264
        batches_per_second_mean: 36.453134512231934
        batches_per_second_min: 35.04833210776121
        batches_per_second_std: 1.105392117153902
        seconds_per_batch_max: 0.028532028198242188
        seconds_per_batch_mean: 0.027457793951034547
        seconds_per_batch_min: 0.026503324508666992
        seconds_per_batch_std: 0.0008346952804870175


#####
fp-fp-py-id - Run 8
2024-02-26 00:13:22
#####
Benchmarking on 12 threads
Warming up with batch_size=1:   0%|          | 0/1 [00:00<?, ?it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.44it/s]Warming up with batch_size=1: 100%|██████████| 1/1 [00:00<00:00,  3.43it/s]
Warning: module SiLU is treated as a zero-op.
Warning: module Conv2dNormActivation is treated as a zero-op.
Warning: module StochasticDepth is treated as a zero-op.
Warning: module FusedMBConv is treated as a zero-op.
Warning: module Sigmoid is treated as a zero-op.
Warning: module SqueezeExcitation is treated as a zero-op.
Warning: module MBConv is treated as a zero-op.
Warning: module Dropout is treated as a zero-op.
Warning: module EfficientNet is treated as a zero-op.
Warning! No positional inputs found for a module, assuming batch size is 1.
EfficientNet(
  118.52 M, 100.000% Params, 12.31 GMac, 100.000% MACs, 
  (features): Sequential(
    117.23 M, 98.919% Params, 12.31 GMac, 99.989% MACs, 
    (0): Conv2dNormActivation(
      928, 0.001% Params, 11.64 MMac, 0.095% MACs, 
      (0): Conv2d(864, 0.001% Params, 10.84 MMac, 0.088% MACs, 3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
    (1): Sequential(
      37.12 k, 0.031% Params, 465.63 MMac, 3.782% MACs, 
      (0): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0, mode=row)
      )
      (1): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.002531645569620253, mode=row)
      )
      (2): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.005063291139240506, mode=row)
      )
      (3): FusedMBConv(
        9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
        (block): Sequential(
          9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
          (0): Conv2dNormActivation(
            9.28 k, 0.008% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(9.22 k, 0.008% Params, 115.61 MMac, 0.939% MACs, 32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(64, 0.000% Params, 802.82 KMac, 0.007% MACs, 32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.007594936708860761, mode=row)
      )
    )
    (2): Sequential(
      1.03 M, 0.871% Params, 3.24 GMac, 26.297% MACs, 
      (0): FusedMBConv(
        45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
        (block): Sequential(
          45.44 k, 0.038% Params, 142.5 MMac, 1.158% MACs, 
          (0): Conv2dNormActivation(
            37.12 k, 0.031% Params, 116.41 MMac, 0.946% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 115.61 MMac, 0.939% MACs, 32, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(256, 0.000% Params, 802.82 KMac, 0.007% MACs, 128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.32 k, 0.007% Params, 26.09 MMac, 0.212% MACs, 
            (0): Conv2d(8.19 k, 0.007% Params, 25.69 MMac, 0.209% MACs, 128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.010126582278481013, mode=row)
      )
      (1): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.012658227848101266, mode=row)
      )
      (2): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.015189873417721522, mode=row)
      )
      (3): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.017721518987341773, mode=row)
      )
      (4): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.020253164556962026, mode=row)
      )
      (5): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02278481012658228, mode=row)
      )
      (6): FusedMBConv(
        164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
        (block): Sequential(
          164.48 k, 0.139% Params, 515.81 MMac, 4.190% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 464.03 MMac, 3.769% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 462.42 MMac, 3.756% MACs, 64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 1.61 MMac, 0.013% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            16.51 k, 0.014% Params, 51.78 MMac, 0.421% MACs, 
            (0): Conv2d(16.38 k, 0.014% Params, 51.38 MMac, 0.417% MACs, 256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(128, 0.000% Params, 401.41 KMac, 0.003% MACs, 64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.02531645569620253, mode=row)
      )
    )
    (3): Sequential(
      2.39 M, 2.017% Params, 1.87 GMac, 15.223% MACs, 
      (0): FusedMBConv(
        172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
        (block): Sequential(
          172.74 k, 0.146% Params, 135.43 MMac, 1.100% MACs, 
          (0): Conv2dNormActivation(
            147.97 k, 0.125% Params, 116.01 MMac, 0.942% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 115.61 MMac, 0.939% MACs, 64, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
            (1): BatchNorm2d(512, 0.000% Params, 401.41 KMac, 0.003% MACs, 256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            24.77 k, 0.021% Params, 19.42 MMac, 0.158% MACs, 
            (0): Conv2d(24.58 k, 0.021% Params, 19.27 MMac, 0.157% MACs, 256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.027848101265822787, mode=row)
      )
      (1): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.030379746835443044, mode=row)
      )
      (2): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.03291139240506329, mode=row)
      )
      (3): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.035443037974683546, mode=row)
      )
      (4): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0379746835443038, mode=row)
      )
      (5): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04050632911392405, mode=row)
      )
      (6): FusedMBConv(
        369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
        (block): Sequential(
          369.6 k, 0.312% Params, 289.77 MMac, 2.354% MACs, 
          (0): Conv2dNormActivation(
            332.54 k, 0.281% Params, 260.71 MMac, 2.118% MACs, 
            (0): Conv2d(331.78 k, 0.280% Params, 260.11 MMac, 2.113% MACs, 96, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            37.06 k, 0.031% Params, 29.05 MMac, 0.236% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(192, 0.000% Params, 150.53 KMac, 0.001% MACs, 96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04303797468354431, mode=row)
      )
    )
    (4): Sequential(
      3.55 M, 2.998% Params, 585.49 MMac, 4.756% MACs, 
      (0): MBConv(
        134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
        (block): Sequential(
          134.81 k, 0.114% Params, 44.95 MMac, 0.365% MACs, 
          (0): Conv2dNormActivation(
            37.63 k, 0.032% Params, 29.5 MMac, 0.240% MACs, 
            (0): Conv2d(36.86 k, 0.031% Params, 28.9 MMac, 0.235% MACs, 96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 602.11 KMac, 0.005% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            4.22 k, 0.004% Params, 827.9 KMac, 0.007% MACs, 
            (0): Conv2d(3.46 k, 0.003% Params, 677.38 KMac, 0.006% MACs, 384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 150.53 KMac, 0.001% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            18.84 k, 0.016% Params, 94.1 KMac, 0.001% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 75.26 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(9.24 k, 0.008% Params, 9.24 KMac, 0.000% MACs, 384, 24, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(9.6 k, 0.008% Params, 9.6 KMac, 0.000% MACs, 24, 384, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            74.11 k, 0.063% Params, 14.53 MMac, 0.118% MACs, 
            (0): Conv2d(73.73 k, 0.062% Params, 14.45 MMac, 0.117% MACs, 384, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04556962025316456, mode=row)
      )
      (1): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.04810126582278482, mode=row)
      )
      (2): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05063291139240506, mode=row)
      )
      (3): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.053164556962025315, mode=row)
      )
      (4): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.055696202531645575, mode=row)
      )
      (5): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.05822784810126583, mode=row)
      )
      (6): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06075949367088609, mode=row)
      )
      (7): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06329113924050633, mode=row)
      )
      (8): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06582278481012659, mode=row)
      )
      (9): MBConv(
        379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
        (block): Sequential(
          379.82 k, 0.320% Params, 60.06 MMac, 0.488% MACs, 
          (0): Conv2dNormActivation(
            148.99 k, 0.126% Params, 29.2 MMac, 0.237% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            8.45 k, 0.007% Params, 1.66 MMac, 0.013% MACs, 
            (0): Conv2d(6.91 k, 0.006% Params, 1.35 MMac, 0.011% MACs, 768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=768, bias=False)
            (1): BatchNorm2d(1.54 k, 0.001% Params, 301.06 KMac, 0.002% MACs, 768, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            74.54 k, 0.063% Params, 225.07 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 150.53 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(36.91 k, 0.031% Params, 36.91 KMac, 0.000% MACs, 768, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(37.63 k, 0.032% Params, 37.63 KMac, 0.000% MACs, 48, 768, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            147.84 k, 0.125% Params, 28.98 MMac, 0.235% MACs, 
            (0): Conv2d(147.46 k, 0.124% Params, 28.9 MMac, 0.235% MACs, 768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(384, 0.000% Params, 75.26 KMac, 0.001% MACs, 192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.06835443037974684, mode=row)
      )
    )
    (5): Sequential(
      14.5 M, 12.236% Params, 2.29 GMac, 18.620% MACs, 
      (0): MBConv(
        606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
        (block): Sequential(
          606.45 k, 0.512% Params, 97.29 MMac, 0.790% MACs, 
          (0): Conv2dNormActivation(
            223.49 k, 0.189% Params, 43.8 MMac, 0.356% MACs, 
            (0): Conv2d(221.18 k, 0.187% Params, 43.35 MMac, 0.352% MACs, 192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            12.67 k, 0.011% Params, 2.48 MMac, 0.020% MACs, 
            (0): Conv2d(10.37 k, 0.009% Params, 2.03 MMac, 0.017% MACs, 1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)
            (1): BatchNorm2d(2.3 k, 0.002% Params, 451.58 KMac, 0.004% MACs, 1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            111.79 k, 0.094% Params, 337.58 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 225.79 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(55.34 k, 0.047% Params, 55.34 KMac, 0.000% MACs, 1152, 48, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(56.45 k, 0.048% Params, 56.45 KMac, 0.000% MACs, 48, 1152, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            258.5 k, 0.218% Params, 50.67 MMac, 0.412% MACs, 
            (0): Conv2d(258.05 k, 0.218% Params, 50.58 MMac, 0.411% MACs, 1152, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07088607594936709, mode=row)
      )
      (1): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07341772151898734, mode=row)
      )
      (2): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0759493670886076, mode=row)
      )
      (3): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.07848101265822785, mode=row)
      )
      (4): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.0810126582278481, mode=row)
      )
      (5): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08354430379746836, mode=row)
      )
      (6): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08607594936708862, mode=row)
      )
      (7): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.08860759493670886, mode=row)
      )
      (8): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09113924050632911, mode=row)
      )
      (9): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09367088607594937, mode=row)
      )
      (10): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09620253164556963, mode=row)
      )
      (11): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.09873417721518989, mode=row)
      )
      (12): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10126582278481013, mode=row)
      )
      (13): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10379746835443039, mode=row)
      )
      (14): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10632911392405063, mode=row)
      )
      (15): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.10886075949367088, mode=row)
      )
      (16): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11139240506329115, mode=row)
      )
      (17): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11392405063291139, mode=row)
      )
      (18): MBConv(
        771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
        (block): Sequential(
          771.96 k, 0.651% Params, 121.94 MMac, 0.991% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 2.9 MMac, 0.024% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 2.37 MMac, 0.019% MACs, 1344, 1344, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 415.35 KMac, 0.003% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 263.42 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            301.5 k, 0.254% Params, 59.09 MMac, 0.480% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 1344, 224, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(448, 0.000% Params, 87.81 KMac, 0.001% MACs, 224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11645569620253166, mode=row)
      )
    )
    (6): Sequential(
      54.87 M, 46.295% Params, 2.22 GMac, 18.003% MACs, 
      (0): MBConv(
        987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
        (block): Sequential(
          987.32 k, 0.833% Params, 85.8 MMac, 0.697% MACs, 
          (0): Conv2dNormActivation(
            303.74 k, 0.256% Params, 59.53 MMac, 0.484% MACs, 
            (0): Conv2d(301.06 k, 0.254% Params, 59.01 MMac, 0.479% MACs, 224, 1344, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 526.85 KMac, 0.004% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            14.78 k, 0.012% Params, 724.42 KMac, 0.006% MACs, 
            (0): Conv2d(12.1 k, 0.010% Params, 592.7 KMac, 0.005% MACs, 1344, 1344, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=1344, bias=False)
            (1): BatchNorm2d(2.69 k, 0.002% Params, 131.71 KMac, 0.001% MACs, 1344, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            151.93 k, 0.128% Params, 217.78 KMac, 0.002% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 65.86 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(75.32 k, 0.064% Params, 75.32 KMac, 0.001% MACs, 1344, 56, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(76.61 k, 0.065% Params, 76.61 KMac, 0.001% MACs, 56, 1344, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            516.86 k, 0.436% Params, 25.33 MMac, 0.206% MACs, 
            (0): Conv2d(516.1 k, 0.435% Params, 25.29 MMac, 0.205% MACs, 1344, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.11898734177215191, mode=row)
      )
      (1): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12151898734177217, mode=row)
      )
      (2): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12405063291139241, mode=row)
      )
      (3): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12658227848101267, mode=row)
      )
      (4): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.12911392405063293, mode=row)
      )
      (5): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13164556962025317, mode=row)
      )
      (6): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13417721518987344, mode=row)
      )
      (7): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13670886075949368, mode=row)
      )
      (8): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.13924050632911392, mode=row)
      )
      (9): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14177215189873418, mode=row)
      )
      (10): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14430379746835442, mode=row)
      )
      (11): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1468354430379747, mode=row)
      )
      (12): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.14936708860759496, mode=row)
      )
      (13): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1518987341772152, mode=row)
      )
      (14): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15443037974683546, mode=row)
      )
      (15): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1569620253164557, mode=row)
      )
      (16): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.15949367088607597, mode=row)
      )
      (17): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1620253164556962, mode=row)
      )
      (18): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16455696202531644, mode=row)
      )
      (19): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1670886075949367, mode=row)
      )
      (20): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.16962025316455698, mode=row)
      )
      (21): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17215189873417724, mode=row)
      )
      (22): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17468354430379748, mode=row)
      )
      (23): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.17721518987341772, mode=row)
      )
      (24): MBConv(
        2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
        (block): Sequential(
          2.24 M, 1.894% Params, 88.77 MMac, 0.721% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            885.5 k, 0.747% Params, 43.39 MMac, 0.352% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 2304, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(768, 0.001% Params, 37.63 KMac, 0.000% MACs, 384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.179746835443038, mode=row)
      )
    )
    (7): Sequential(
      40.03 M, 33.777% Params, 1.59 GMac, 12.886% MACs, 
      (0): MBConv(
        2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
        (block): Sequential(
          2.84 M, 2.392% Params, 117.69 MMac, 0.956% MACs, 
          (0): Conv2dNormActivation(
            889.34 k, 0.750% Params, 43.58 MMac, 0.354% MACs, 
            (0): Conv2d(884.74 k, 0.747% Params, 43.35 MMac, 0.352% MACs, 384, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            25.34 k, 0.021% Params, 1.24 MMac, 0.010% MACs, 
            (0): Conv2d(20.74 k, 0.017% Params, 1.02 MMac, 0.008% MACs, 2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)
            (1): BatchNorm2d(4.61 k, 0.004% Params, 225.79 KMac, 0.002% MACs, 2304, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            444.77 k, 0.375% Params, 557.66 KMac, 0.005% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 112.9 KMac, 0.001% MACs, output_size=1)
            (fc1): Conv2d(221.28 k, 0.187% Params, 221.28 KMac, 0.002% MACs, 2304, 96, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(223.49 k, 0.189% Params, 223.49 KMac, 0.002% MACs, 96, 2304, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            1.48 M, 1.245% Params, 72.32 MMac, 0.587% MACs, 
            (0): Conv2d(1.47 M, 1.244% Params, 72.25 MMac, 0.587% MACs, 2304, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18227848101265823, mode=row)
      )
      (1): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1848101265822785, mode=row)
      )
      (2): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.18734177215189873, mode=row)
      )
      (3): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.189873417721519, mode=row)
      )
      (4): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19240506329113927, mode=row)
      )
      (5): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.1949367088607595, mode=row)
      )
      (6): MBConv(
        6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
        (block): Sequential(
          6.2 M, 5.231% Params, 244.77 MMac, 1.988% MACs, 
          (0): Conv2dNormActivation(
            2.47 M, 2.080% Params, 120.8 MMac, 0.981% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 640, 3840, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (1): Conv2dNormActivation(
            42.24 k, 0.036% Params, 2.07 MMac, 0.017% MACs, 
            (0): Conv2d(34.56 k, 0.029% Params, 1.69 MMac, 0.014% MACs, 3840, 3840, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3840, bias=False)
            (1): BatchNorm2d(7.68 k, 0.006% Params, 376.32 KMac, 0.003% MACs, 3840, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
            (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
          )
          (2): SqueezeExcitation(
            1.23 M, 1.040% Params, 1.42 MMac, 0.012% MACs, 
            (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 188.16 KMac, 0.002% MACs, output_size=1)
            (fc1): Conv2d(614.56 k, 0.519% Params, 614.56 KMac, 0.005% MACs, 3840, 160, kernel_size=(1, 1), stride=(1, 1))
            (fc2): Conv2d(618.24 k, 0.522% Params, 618.24 KMac, 0.005% MACs, 160, 3840, kernel_size=(1, 1), stride=(1, 1))
            (activation): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
            (scale_activation): Sigmoid(0, 0.000% Params, 0.0 Mac, 0.000% MACs, )
          )
          (3): Conv2dNormActivation(
            2.46 M, 2.075% Params, 120.49 MMac, 0.979% MACs, 
            (0): Conv2d(2.46 M, 2.074% Params, 120.42 MMac, 0.978% MACs, 3840, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (1): BatchNorm2d(1.28 k, 0.001% Params, 62.72 KMac, 0.001% MACs, 640, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (stochastic_depth): StochasticDepth(p=0.19746835443037977, mode=row)
      )
    )
    (8): Conv2dNormActivation(
      821.76 k, 0.693% Params, 40.27 MMac, 0.327% MACs, 
      (0): Conv2d(819.2 k, 0.691% Params, 40.14 MMac, 0.326% MACs, 640, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (1): BatchNorm2d(2.56 k, 0.002% Params, 125.44 KMac, 0.001% MACs, 1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      (2): SiLU(0, 0.000% Params, 0.0 Mac, 0.000% MACs, inplace=True)
    )
  )
  (avgpool): AdaptiveAvgPool2d(0, 0.000% Params, 62.72 KMac, 0.001% MACs, output_size=1)
  (classifier): Sequential(
    1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, 
    (0): Dropout(0, 0.000% Params, 0.0 Mac, 0.000% MACs, p=0.4, inplace=True)
    (1): Linear(1.28 M, 1.081% Params, 1.28 MMac, 0.010% MACs, in_features=1280, out_features=1000, bias=True)
  )
)
Warming up with batch_size=1:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=1:   5%|▌         | 5/100 [00:00<00:01, 49.98it/s]Warming up with batch_size=1:  11%|█         | 11/100 [00:00<00:01, 50.06it/s]Warming up with batch_size=1:  17%|█▋        | 17/100 [00:00<00:01, 50.09it/s]Warming up with batch_size=1:  23%|██▎       | 23/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  29%|██▉       | 29/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  35%|███▌      | 35/100 [00:00<00:01, 50.11it/s]Warming up with batch_size=1:  41%|████      | 41/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  47%|████▋     | 47/100 [00:00<00:01, 50.10it/s]Warming up with batch_size=1:  53%|█████▎    | 53/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1:  59%|█████▉    | 59/100 [00:01<00:00, 50.09it/s]Warming up with batch_size=1:  65%|██████▌   | 65/100 [00:01<00:00, 50.09it/s]Warming up with batch_size=1:  71%|███████   | 71/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1:  77%|███████▋  | 77/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1:  83%|████████▎ | 83/100 [00:01<00:00, 50.07it/s]Warming up with batch_size=1:  89%|████████▉ | 89/100 [00:01<00:00, 50.08it/s]Warming up with batch_size=1:  95%|█████████▌| 95/100 [00:01<00:00, 50.10it/s]Warming up with batch_size=1: 100%|██████████| 100/100 [00:01<00:00, 50.09it/s]
STAGE:2024-02-26 00:12:26 9818:9818 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:12:26 9818:9818 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:12:26 9818:9818 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=1:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=1:   0%|          | 4/1000 [00:00<00:26, 37.81it/s]Measuring inference for batch_size=1:   1%|          | 8/1000 [00:00<00:26, 38.11it/s]Measuring inference for batch_size=1:   1%|          | 12/1000 [00:00<00:25, 38.22it/s]Measuring inference for batch_size=1:   2%|▏         | 16/1000 [00:00<00:25, 38.26it/s]Measuring inference for batch_size=1:   2%|▏         | 20/1000 [00:00<00:25, 38.29it/s]Measuring inference for batch_size=1:   2%|▏         | 24/1000 [00:00<00:25, 38.29it/s]Measuring inference for batch_size=1:   3%|▎         | 28/1000 [00:00<00:25, 38.29it/s]Measuring inference for batch_size=1:   3%|▎         | 32/1000 [00:00<00:25, 38.29it/s]Measuring inference for batch_size=1:   4%|▎         | 36/1000 [00:00<00:25, 38.29it/s]Measuring inference for batch_size=1:   4%|▍         | 40/1000 [00:01<00:25, 38.29it/s]Measuring inference for batch_size=1:   4%|▍         | 44/1000 [00:01<00:24, 38.29it/s]Measuring inference for batch_size=1:   5%|▍         | 48/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   5%|▌         | 52/1000 [00:01<00:24, 38.30it/s]Measuring inference for batch_size=1:   6%|▌         | 56/1000 [00:01<00:24, 38.29it/s]Measuring inference for batch_size=1:   6%|▌         | 60/1000 [00:01<00:24, 38.29it/s]Measuring inference for batch_size=1:   6%|▋         | 64/1000 [00:01<00:24, 38.27it/s]Measuring inference for batch_size=1:   7%|▋         | 68/1000 [00:01<00:24, 38.26it/s]Measuring inference for batch_size=1:   7%|▋         | 72/1000 [00:01<00:24, 38.22it/s]Measuring inference for batch_size=1:   8%|▊         | 76/1000 [00:01<00:24, 38.23it/s]Measuring inference for batch_size=1:   8%|▊         | 80/1000 [00:02<00:24, 38.25it/s]Measuring inference for batch_size=1:   8%|▊         | 84/1000 [00:02<00:23, 38.27it/s]Measuring inference for batch_size=1:   9%|▉         | 88/1000 [00:02<00:23, 38.29it/s]Measuring inference for batch_size=1:   9%|▉         | 92/1000 [00:02<00:23, 38.28it/s]Measuring inference for batch_size=1:  10%|▉         | 96/1000 [00:02<00:23, 38.29it/s]Measuring inference for batch_size=1:  10%|█         | 100/1000 [00:02<00:23, 38.29it/s]Measuring inference for batch_size=1:  10%|█         | 104/1000 [00:02<00:23, 38.32it/s]Measuring inference for batch_size=1:  11%|█         | 108/1000 [00:02<00:23, 38.33it/s]Measuring inference for batch_size=1:  11%|█         | 112/1000 [00:02<00:23, 38.33it/s]Measuring inference for batch_size=1:  12%|█▏        | 116/1000 [00:03<00:23, 38.32it/s]Measuring inference for batch_size=1:  12%|█▏        | 120/1000 [00:03<00:22, 38.33it/s]Measuring inference for batch_size=1:  12%|█▏        | 124/1000 [00:03<00:22, 38.34it/s]Measuring inference for batch_size=1:  13%|█▎        | 128/1000 [00:03<00:22, 38.34it/s]Measuring inference for batch_size=1:  13%|█▎        | 132/1000 [00:03<00:22, 38.33it/s]Measuring inference for batch_size=1:  14%|█▎        | 136/1000 [00:03<00:22, 38.33it/s]Measuring inference for batch_size=1:  14%|█▍        | 140/1000 [00:03<00:22, 38.33it/s]Measuring inference for batch_size=1:  14%|█▍        | 144/1000 [00:03<00:22, 38.32it/s]Measuring inference for batch_size=1:  15%|█▍        | 148/1000 [00:03<00:22, 38.31it/s]Measuring inference for batch_size=1:  15%|█▌        | 152/1000 [00:03<00:22, 38.31it/s]Measuring inference for batch_size=1:  16%|█▌        | 156/1000 [00:04<00:22, 38.32it/s]Measuring inference for batch_size=1:  16%|█▌        | 160/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  16%|█▋        | 164/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  17%|█▋        | 168/1000 [00:04<00:21, 38.32it/s]Measuring inference for batch_size=1:  17%|█▋        | 172/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  18%|█▊        | 176/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  18%|█▊        | 180/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  18%|█▊        | 184/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  19%|█▉        | 188/1000 [00:04<00:21, 38.30it/s]Measuring inference for batch_size=1:  19%|█▉        | 192/1000 [00:05<00:21, 38.30it/s]Measuring inference for batch_size=1:  20%|█▉        | 196/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  20%|██        | 200/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  20%|██        | 204/1000 [00:05<00:20, 38.29it/s]Measuring inference for batch_size=1:  21%|██        | 208/1000 [00:05<00:20, 38.30it/s]Measuring inference for batch_size=1:  21%|██        | 212/1000 [00:05<00:20, 38.31it/s]Measuring inference for batch_size=1:  22%|██▏       | 216/1000 [00:05<00:20, 38.31it/s]Measuring inference for batch_size=1:  22%|██▏       | 220/1000 [00:05<00:20, 38.31it/s]Measuring inference for batch_size=1:  22%|██▏       | 224/1000 [00:05<00:20, 38.31it/s]Measuring inference for batch_size=1:  23%|██▎       | 228/1000 [00:05<00:20, 38.33it/s]Measuring inference for batch_size=1:  23%|██▎       | 232/1000 [00:06<00:20, 38.34it/s]Measuring inference for batch_size=1:  24%|██▎       | 236/1000 [00:06<00:19, 38.34it/s]Measuring inference for batch_size=1:  24%|██▍       | 240/1000 [00:06<00:19, 38.34it/s]Measuring inference for batch_size=1:  24%|██▍       | 244/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  25%|██▍       | 248/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  25%|██▌       | 252/1000 [00:06<00:19, 38.32it/s]Measuring inference for batch_size=1:  26%|██▌       | 256/1000 [00:06<00:19, 38.33it/s]Measuring inference for batch_size=1:  26%|██▌       | 260/1000 [00:06<00:19, 38.32it/s]Measuring inference for batch_size=1:  26%|██▋       | 264/1000 [00:06<00:19, 38.32it/s]Measuring inference for batch_size=1:  27%|██▋       | 268/1000 [00:06<00:19, 38.31it/s]Measuring inference for batch_size=1:  27%|██▋       | 272/1000 [00:07<00:18, 38.32it/s]Measuring inference for batch_size=1:  28%|██▊       | 276/1000 [00:07<00:18, 38.32it/s]Measuring inference for batch_size=1:  28%|██▊       | 280/1000 [00:07<00:18, 38.31it/s]Measuring inference for batch_size=1:  28%|██▊       | 284/1000 [00:07<00:18, 38.31it/s]Measuring inference for batch_size=1:  29%|██▉       | 288/1000 [00:07<00:18, 38.31it/s]Measuring inference for batch_size=1:  29%|██▉       | 292/1000 [00:07<00:18, 38.31it/s]Measuring inference for batch_size=1:  30%|██▉       | 296/1000 [00:07<00:18, 38.31it/s]Measuring inference for batch_size=1:  30%|███       | 300/1000 [00:07<00:18, 38.31it/s]Measuring inference for batch_size=1:  30%|███       | 304/1000 [00:07<00:18, 38.29it/s]Measuring inference for batch_size=1:  31%|███       | 308/1000 [00:08<00:18, 38.30it/s]Measuring inference for batch_size=1:  31%|███       | 312/1000 [00:08<00:17, 38.32it/s]Measuring inference for batch_size=1:  32%|███▏      | 316/1000 [00:08<00:17, 38.32it/s]Measuring inference for batch_size=1:  32%|███▏      | 320/1000 [00:08<00:17, 38.33it/s]Measuring inference for batch_size=1:  32%|███▏      | 324/1000 [00:08<00:17, 38.32it/s]Measuring inference for batch_size=1:  33%|███▎      | 328/1000 [00:08<00:17, 38.32it/s]Measuring inference for batch_size=1:  33%|███▎      | 332/1000 [00:08<00:17, 38.33it/s]Measuring inference for batch_size=1:  34%|███▎      | 336/1000 [00:08<00:17, 38.32it/s]Measuring inference for batch_size=1:  34%|███▍      | 340/1000 [00:08<00:17, 38.33it/s]Measuring inference for batch_size=1:  34%|███▍      | 344/1000 [00:08<00:17, 38.34it/s]Measuring inference for batch_size=1:  35%|███▍      | 348/1000 [00:09<00:17, 38.34it/s]Measuring inference for batch_size=1:  35%|███▌      | 352/1000 [00:09<00:16, 38.34it/s]Measuring inference for batch_size=1:  36%|███▌      | 356/1000 [00:09<00:16, 38.34it/s]Measuring inference for batch_size=1:  36%|███▌      | 360/1000 [00:09<00:16, 38.33it/s]Measuring inference for batch_size=1:  36%|███▋      | 364/1000 [00:09<00:16, 38.33it/s]Measuring inference for batch_size=1:  37%|███▋      | 368/1000 [00:09<00:16, 38.33it/s]Measuring inference for batch_size=1:  37%|███▋      | 372/1000 [00:09<00:16, 38.33it/s]Measuring inference for batch_size=1:  38%|███▊      | 376/1000 [00:09<00:16, 38.32it/s]Measuring inference for batch_size=1:  38%|███▊      | 380/1000 [00:09<00:16, 38.32it/s]Measuring inference for batch_size=1:  38%|███▊      | 384/1000 [00:10<00:16, 38.34it/s]Measuring inference for batch_size=1:  39%|███▉      | 388/1000 [00:10<00:15, 38.34it/s]Measuring inference for batch_size=1:  39%|███▉      | 392/1000 [00:10<00:15, 38.35it/s]Measuring inference for batch_size=1:  40%|███▉      | 396/1000 [00:10<00:15, 38.35it/s]Measuring inference for batch_size=1:  40%|████      | 400/1000 [00:10<00:15, 38.33it/s]Measuring inference for batch_size=1:  40%|████      | 404/1000 [00:10<00:15, 38.33it/s]Measuring inference for batch_size=1:  41%|████      | 408/1000 [00:10<00:15, 38.32it/s]Measuring inference for batch_size=1:  41%|████      | 412/1000 [00:10<00:15, 38.32it/s]Measuring inference for batch_size=1:  42%|████▏     | 416/1000 [00:10<00:15, 38.33it/s]Measuring inference for batch_size=1:  42%|████▏     | 420/1000 [00:10<00:15, 38.33it/s]Measuring inference for batch_size=1:  42%|████▏     | 424/1000 [00:11<00:15, 38.34it/s]Measuring inference for batch_size=1:  43%|████▎     | 428/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  43%|████▎     | 432/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  44%|████▎     | 436/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  44%|████▍     | 440/1000 [00:11<00:14, 38.34it/s]Measuring inference for batch_size=1:  44%|████▍     | 444/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  45%|████▍     | 448/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  45%|████▌     | 452/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  46%|████▌     | 456/1000 [00:11<00:14, 38.35it/s]Measuring inference for batch_size=1:  46%|████▌     | 460/1000 [00:12<00:14, 38.35it/s]Measuring inference for batch_size=1:  46%|████▋     | 464/1000 [00:12<00:13, 38.33it/s]Measuring inference for batch_size=1:  47%|████▋     | 468/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  47%|████▋     | 472/1000 [00:12<00:13, 38.35it/s]Measuring inference for batch_size=1:  48%|████▊     | 476/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  48%|████▊     | 480/1000 [00:12<00:13, 38.35it/s]Measuring inference for batch_size=1:  48%|████▊     | 484/1000 [00:12<00:13, 38.33it/s]Measuring inference for batch_size=1:  49%|████▉     | 488/1000 [00:12<00:13, 38.33it/s]Measuring inference for batch_size=1:  49%|████▉     | 492/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  50%|████▉     | 496/1000 [00:12<00:13, 38.34it/s]Measuring inference for batch_size=1:  50%|█████     | 500/1000 [00:13<00:13, 38.34it/s]Measuring inference for batch_size=1:  50%|█████     | 504/1000 [00:13<00:12, 38.34it/s]Measuring inference for batch_size=1:  51%|█████     | 508/1000 [00:13<00:12, 38.34it/s]Measuring inference for batch_size=1:  51%|█████     | 512/1000 [00:13<00:12, 38.34it/s]Measuring inference for batch_size=1:  52%|█████▏    | 516/1000 [00:13<00:12, 38.33it/s]Measuring inference for batch_size=1:  52%|█████▏    | 520/1000 [00:13<00:12, 38.35it/s]Measuring inference for batch_size=1:  52%|█████▏    | 524/1000 [00:13<00:12, 38.35it/s]Measuring inference for batch_size=1:  53%|█████▎    | 528/1000 [00:13<00:12, 38.33it/s]Measuring inference for batch_size=1:  53%|█████▎    | 532/1000 [00:13<00:12, 38.35it/s]Measuring inference for batch_size=1:  54%|█████▎    | 536/1000 [00:13<00:12, 38.36it/s]Measuring inference for batch_size=1:  54%|█████▍    | 540/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  54%|█████▍    | 544/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  55%|█████▍    | 548/1000 [00:14<00:11, 38.37it/s]Measuring inference for batch_size=1:  55%|█████▌    | 552/1000 [00:14<00:11, 38.35it/s]Measuring inference for batch_size=1:  56%|█████▌    | 556/1000 [00:14<00:11, 38.36it/s]Measuring inference for batch_size=1:  56%|█████▌    | 560/1000 [00:14<00:11, 38.36it/s]Measuring inference for batch_size=1:  56%|█████▋    | 564/1000 [00:14<00:11, 38.36it/s]Measuring inference for batch_size=1:  57%|█████▋    | 568/1000 [00:14<00:11, 38.36it/s]Measuring inference for batch_size=1:  57%|█████▋    | 572/1000 [00:14<00:11, 38.36it/s]Measuring inference for batch_size=1:  58%|█████▊    | 576/1000 [00:15<00:11, 38.36it/s]Measuring inference for batch_size=1:  58%|█████▊    | 580/1000 [00:15<00:10, 38.35it/s]Measuring inference for batch_size=1:  58%|█████▊    | 584/1000 [00:15<00:10, 38.34it/s]Measuring inference for batch_size=1:  59%|█████▉    | 588/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  59%|█████▉    | 592/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  60%|█████▉    | 596/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  60%|██████    | 600/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  60%|██████    | 604/1000 [00:15<00:10, 38.33it/s]Measuring inference for batch_size=1:  61%|██████    | 608/1000 [00:15<00:10, 38.34it/s]Measuring inference for batch_size=1:  61%|██████    | 612/1000 [00:15<00:10, 38.35it/s]Measuring inference for batch_size=1:  62%|██████▏   | 616/1000 [00:16<00:10, 38.34it/s]Measuring inference for batch_size=1:  62%|██████▏   | 620/1000 [00:16<00:09, 38.34it/s]Measuring inference for batch_size=1:  62%|██████▏   | 624/1000 [00:16<00:09, 38.35it/s]Measuring inference for batch_size=1:  63%|██████▎   | 628/1000 [00:16<00:09, 38.34it/s]Measuring inference for batch_size=1:  63%|██████▎   | 632/1000 [00:16<00:09, 38.32it/s]Measuring inference for batch_size=1:  64%|██████▎   | 636/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  64%|██████▍   | 640/1000 [00:16<00:09, 38.34it/s]Measuring inference for batch_size=1:  64%|██████▍   | 644/1000 [00:16<00:09, 38.34it/s]Measuring inference for batch_size=1:  65%|██████▍   | 648/1000 [00:16<00:09, 38.33it/s]Measuring inference for batch_size=1:  65%|██████▌   | 652/1000 [00:17<00:09, 38.33it/s]Measuring inference for batch_size=1:  66%|██████▌   | 656/1000 [00:17<00:08, 38.33it/s]Measuring inference for batch_size=1:  66%|██████▌   | 660/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  66%|██████▋   | 664/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  67%|██████▋   | 668/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  67%|██████▋   | 672/1000 [00:17<00:08, 38.32it/s]Measuring inference for batch_size=1:  68%|██████▊   | 676/1000 [00:17<00:08, 38.33it/s]Measuring inference for batch_size=1:  68%|██████▊   | 680/1000 [00:17<00:08, 38.31it/s]Measuring inference for batch_size=1:  68%|██████▊   | 684/1000 [00:17<00:08, 38.29it/s]Measuring inference for batch_size=1:  69%|██████▉   | 688/1000 [00:17<00:08, 38.30it/s]Measuring inference for batch_size=1:  69%|██████▉   | 692/1000 [00:18<00:08, 38.31it/s]Measuring inference for batch_size=1:  70%|██████▉   | 696/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  70%|███████   | 700/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  70%|███████   | 704/1000 [00:18<00:07, 38.34it/s]Measuring inference for batch_size=1:  71%|███████   | 708/1000 [00:18<00:07, 38.34it/s]Measuring inference for batch_size=1:  71%|███████   | 712/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  72%|███████▏  | 716/1000 [00:18<00:07, 38.31it/s]Measuring inference for batch_size=1:  72%|███████▏  | 720/1000 [00:18<00:07, 38.32it/s]Measuring inference for batch_size=1:  72%|███████▏  | 724/1000 [00:18<00:07, 38.33it/s]Measuring inference for batch_size=1:  73%|███████▎  | 728/1000 [00:18<00:07, 38.34it/s]Measuring inference for batch_size=1:  73%|███████▎  | 732/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  74%|███████▎  | 736/1000 [00:19<00:06, 38.34it/s]Measuring inference for batch_size=1:  74%|███████▍  | 740/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  74%|███████▍  | 744/1000 [00:19<00:06, 38.36it/s]Measuring inference for batch_size=1:  75%|███████▍  | 748/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  75%|███████▌  | 752/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  76%|███████▌  | 756/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  76%|███████▌  | 760/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  76%|███████▋  | 764/1000 [00:19<00:06, 38.35it/s]Measuring inference for batch_size=1:  77%|███████▋  | 768/1000 [00:20<00:06, 38.36it/s]Measuring inference for batch_size=1:  77%|███████▋  | 772/1000 [00:20<00:05, 38.37it/s]Measuring inference for batch_size=1:  78%|███████▊  | 776/1000 [00:20<00:05, 38.37it/s]Measuring inference for batch_size=1:  78%|███████▊  | 780/1000 [00:20<00:05, 38.38it/s]Measuring inference for batch_size=1:  78%|███████▊  | 784/1000 [00:20<00:05, 38.36it/s]Measuring inference for batch_size=1:  79%|███████▉  | 788/1000 [00:20<00:05, 38.38it/s]Measuring inference for batch_size=1:  79%|███████▉  | 792/1000 [00:20<00:05, 38.39it/s]Measuring inference for batch_size=1:  80%|███████▉  | 796/1000 [00:20<00:05, 38.40it/s]Measuring inference for batch_size=1:  80%|████████  | 800/1000 [00:20<00:05, 38.41it/s]Measuring inference for batch_size=1:  80%|████████  | 804/1000 [00:20<00:05, 38.41it/s]Measuring inference for batch_size=1:  81%|████████  | 808/1000 [00:21<00:04, 38.41it/s]Measuring inference for batch_size=1:  81%|████████  | 812/1000 [00:21<00:04, 38.42it/s]Measuring inference for batch_size=1:  82%|████████▏ | 816/1000 [00:21<00:04, 38.41it/s]Measuring inference for batch_size=1:  82%|████████▏ | 820/1000 [00:21<00:04, 38.40it/s]Measuring inference for batch_size=1:  82%|████████▏ | 824/1000 [00:21<00:04, 38.39it/s]Measuring inference for batch_size=1:  83%|████████▎ | 828/1000 [00:21<00:04, 38.39it/s]Measuring inference for batch_size=1:  83%|████████▎ | 832/1000 [00:21<00:04, 38.39it/s]Measuring inference for batch_size=1:  84%|████████▎ | 836/1000 [00:21<00:04, 38.38it/s]Measuring inference for batch_size=1:  84%|████████▍ | 840/1000 [00:21<00:04, 38.39it/s]Measuring inference for batch_size=1:  84%|████████▍ | 844/1000 [00:22<00:04, 38.38it/s]Measuring inference for batch_size=1:  85%|████████▍ | 848/1000 [00:22<00:03, 38.38it/s]Measuring inference for batch_size=1:  85%|████████▌ | 852/1000 [00:22<00:03, 38.38it/s]Measuring inference for batch_size=1:  86%|████████▌ | 856/1000 [00:22<00:03, 38.36it/s]Measuring inference for batch_size=1:  86%|████████▌ | 860/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  86%|████████▋ | 864/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  87%|████████▋ | 868/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  87%|████████▋ | 872/1000 [00:22<00:03, 38.36it/s]Measuring inference for batch_size=1:  88%|████████▊ | 876/1000 [00:22<00:03, 38.35it/s]Measuring inference for batch_size=1:  88%|████████▊ | 880/1000 [00:22<00:03, 38.34it/s]Measuring inference for batch_size=1:  88%|████████▊ | 884/1000 [00:23<00:03, 38.34it/s]Measuring inference for batch_size=1:  89%|████████▉ | 888/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  89%|████████▉ | 892/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  90%|████████▉ | 896/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  90%|█████████ | 900/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  90%|█████████ | 904/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  91%|█████████ | 908/1000 [00:23<00:02, 38.33it/s]Measuring inference for batch_size=1:  91%|█████████ | 912/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  92%|█████████▏| 916/1000 [00:23<00:02, 38.34it/s]Measuring inference for batch_size=1:  92%|█████████▏| 920/1000 [00:24<00:02, 38.34it/s]Measuring inference for batch_size=1:  92%|█████████▏| 924/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  93%|█████████▎| 928/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  93%|█████████▎| 932/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  94%|█████████▎| 936/1000 [00:24<00:01, 38.33it/s]Measuring inference for batch_size=1:  94%|█████████▍| 940/1000 [00:24<00:01, 38.33it/s]Measuring inference for batch_size=1:  94%|█████████▍| 944/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  95%|█████████▍| 948/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  95%|█████████▌| 952/1000 [00:24<00:01, 38.35it/s]Measuring inference for batch_size=1:  96%|█████████▌| 956/1000 [00:24<00:01, 38.34it/s]Measuring inference for batch_size=1:  96%|█████████▌| 960/1000 [00:25<00:01, 38.34it/s]Measuring inference for batch_size=1:  96%|█████████▋| 964/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1:  97%|█████████▋| 968/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1:  97%|█████████▋| 972/1000 [00:25<00:00, 38.31it/s]Measuring inference for batch_size=1:  98%|█████████▊| 976/1000 [00:25<00:00, 38.31it/s]Measuring inference for batch_size=1:  98%|█████████▊| 980/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1:  98%|█████████▊| 984/1000 [00:25<00:00, 38.31it/s]Measuring inference for batch_size=1:  99%|█████████▉| 988/1000 [00:25<00:00, 38.31it/s]Measuring inference for batch_size=1:  99%|█████████▉| 992/1000 [00:25<00:00, 38.33it/s]Measuring inference for batch_size=1: 100%|█████████▉| 996/1000 [00:25<00:00, 38.32it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.32it/s]Measuring inference for batch_size=1: 100%|██████████| 1000/1000 [00:26<00:00, 38.33it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
Warming up with batch_size=512:   0%|          | 0/100 [00:00<?, ?it/s]Warming up with batch_size=512:   4%|▍         | 4/100 [00:00<00:02, 37.86it/s]Warming up with batch_size=512:   8%|▊         | 8/100 [00:00<00:02, 38.01it/s]Warming up with batch_size=512:  12%|█▏        | 12/100 [00:00<00:02, 38.08it/s]Warming up with batch_size=512:  16%|█▌        | 16/100 [00:00<00:02, 38.10it/s]Warming up with batch_size=512:  20%|██        | 20/100 [00:00<00:02, 38.13it/s]Warming up with batch_size=512:  24%|██▍       | 24/100 [00:00<00:01, 38.16it/s]Warming up with batch_size=512:  28%|██▊       | 28/100 [00:00<00:01, 38.17it/s]Warming up with batch_size=512:  32%|███▏      | 32/100 [00:00<00:01, 38.16it/s]Warming up with batch_size=512:  36%|███▌      | 36/100 [00:00<00:01, 38.17it/s]Warming up with batch_size=512:  40%|████      | 40/100 [00:01<00:01, 38.16it/s]Warming up with batch_size=512:  44%|████▍     | 44/100 [00:01<00:01, 38.18it/s]Warming up with batch_size=512:  48%|████▊     | 48/100 [00:01<00:01, 38.17it/s]Warming up with batch_size=512:  52%|█████▏    | 52/100 [00:01<00:01, 38.17it/s]Warming up with batch_size=512:  56%|█████▌    | 56/100 [00:01<00:01, 38.17it/s]Warming up with batch_size=512:  60%|██████    | 60/100 [00:01<00:01, 38.17it/s]Warming up with batch_size=512:  64%|██████▍   | 64/100 [00:01<00:00, 38.18it/s]Warming up with batch_size=512:  68%|██████▊   | 68/100 [00:01<00:00, 38.18it/s]Warming up with batch_size=512:  72%|███████▏  | 72/100 [00:01<00:00, 38.18it/s]Warming up with batch_size=512:  76%|███████▌  | 76/100 [00:01<00:00, 38.18it/s]Warming up with batch_size=512:  80%|████████  | 80/100 [00:02<00:00, 38.19it/s]Warming up with batch_size=512:  84%|████████▍ | 84/100 [00:02<00:00, 38.19it/s]Warming up with batch_size=512:  88%|████████▊ | 88/100 [00:02<00:00, 38.18it/s]Warming up with batch_size=512:  92%|█████████▏| 92/100 [00:02<00:00, 38.18it/s]Warming up with batch_size=512:  96%|█████████▌| 96/100 [00:02<00:00, 38.19it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 38.19it/s]Warming up with batch_size=512: 100%|██████████| 100/100 [00:02<00:00, 38.16it/s]
STAGE:2024-02-26 00:12:55 9818:9818 ActivityProfilerController.cpp:312] Completed Stage: Warm Up
STAGE:2024-02-26 00:12:55 9818:9818 ActivityProfilerController.cpp:318] Completed Stage: Collection
STAGE:2024-02-26 00:12:55 9818:9818 ActivityProfilerController.cpp:322] Completed Stage: Post Processing
Measuring inference for batch_size=512:   0%|          | 0/1000 [00:00<?, ?it/s]Measuring inference for batch_size=512:   0%|          | 4/1000 [00:00<00:26, 37.50it/s]Measuring inference for batch_size=512:   1%|          | 8/1000 [00:00<00:26, 37.75it/s]Measuring inference for batch_size=512:   1%|          | 12/1000 [00:00<00:26, 37.85it/s]Measuring inference for batch_size=512:   2%|▏         | 16/1000 [00:00<00:25, 37.90it/s]Measuring inference for batch_size=512:   2%|▏         | 20/1000 [00:00<00:25, 37.93it/s]Measuring inference for batch_size=512:   2%|▏         | 24/1000 [00:00<00:25, 37.92it/s]Measuring inference for batch_size=512:   3%|▎         | 28/1000 [00:00<00:25, 37.93it/s]Measuring inference for batch_size=512:   3%|▎         | 32/1000 [00:00<00:25, 37.95it/s]Measuring inference for batch_size=512:   4%|▎         | 36/1000 [00:00<00:25, 37.97it/s]Measuring inference for batch_size=512:   4%|▍         | 40/1000 [00:01<00:25, 37.98it/s]Measuring inference for batch_size=512:   4%|▍         | 44/1000 [00:01<00:25, 37.98it/s]Measuring inference for batch_size=512:   5%|▍         | 48/1000 [00:01<00:25, 37.96it/s]Measuring inference for batch_size=512:   5%|▌         | 52/1000 [00:01<00:24, 37.96it/s]Measuring inference for batch_size=512:   6%|▌         | 56/1000 [00:01<00:24, 37.96it/s]Measuring inference for batch_size=512:   6%|▌         | 60/1000 [00:01<00:24, 37.95it/s]Measuring inference for batch_size=512:   6%|▋         | 64/1000 [00:01<00:24, 37.95it/s]Measuring inference for batch_size=512:   7%|▋         | 68/1000 [00:01<00:24, 37.94it/s]Measuring inference for batch_size=512:   7%|▋         | 72/1000 [00:01<00:24, 37.93it/s]Measuring inference for batch_size=512:   8%|▊         | 76/1000 [00:02<00:24, 37.93it/s]Measuring inference for batch_size=512:   8%|▊         | 80/1000 [00:02<00:24, 37.93it/s]Measuring inference for batch_size=512:   8%|▊         | 84/1000 [00:02<00:24, 37.95it/s]Measuring inference for batch_size=512:   9%|▉         | 88/1000 [00:02<00:24, 37.96it/s]Measuring inference for batch_size=512:   9%|▉         | 92/1000 [00:02<00:23, 37.97it/s]Measuring inference for batch_size=512:  10%|▉         | 96/1000 [00:02<00:23, 37.96it/s]Measuring inference for batch_size=512:  10%|█         | 100/1000 [00:02<00:23, 37.97it/s]Measuring inference for batch_size=512:  10%|█         | 104/1000 [00:02<00:23, 37.97it/s]Measuring inference for batch_size=512:  11%|█         | 108/1000 [00:02<00:23, 37.96it/s]Measuring inference for batch_size=512:  11%|█         | 112/1000 [00:02<00:23, 37.96it/s]Measuring inference for batch_size=512:  12%|█▏        | 116/1000 [00:03<00:23, 37.96it/s]Measuring inference for batch_size=512:  12%|█▏        | 120/1000 [00:03<00:23, 37.95it/s]Measuring inference for batch_size=512:  12%|█▏        | 124/1000 [00:03<00:23, 37.95it/s]Measuring inference for batch_size=512:  13%|█▎        | 128/1000 [00:03<00:22, 37.95it/s]Measuring inference for batch_size=512:  13%|█▎        | 132/1000 [00:03<00:22, 37.95it/s]Measuring inference for batch_size=512:  14%|█▎        | 136/1000 [00:03<00:22, 37.96it/s]Measuring inference for batch_size=512:  14%|█▍        | 140/1000 [00:03<00:22, 37.97it/s]Measuring inference for batch_size=512:  14%|█▍        | 144/1000 [00:03<00:22, 37.98it/s]Measuring inference for batch_size=512:  15%|█▍        | 148/1000 [00:03<00:22, 37.98it/s]Measuring inference for batch_size=512:  15%|█▌        | 152/1000 [00:04<00:22, 37.97it/s]Measuring inference for batch_size=512:  16%|█▌        | 156/1000 [00:04<00:22, 37.95it/s]Measuring inference for batch_size=512:  16%|█▌        | 160/1000 [00:04<00:22, 37.95it/s]Measuring inference for batch_size=512:  16%|█▋        | 164/1000 [00:04<00:22, 37.96it/s]Measuring inference for batch_size=512:  17%|█▋        | 168/1000 [00:04<00:21, 37.97it/s]Measuring inference for batch_size=512:  17%|█▋        | 172/1000 [00:04<00:21, 37.96it/s]Measuring inference for batch_size=512:  18%|█▊        | 176/1000 [00:04<00:21, 37.95it/s]Measuring inference for batch_size=512:  18%|█▊        | 180/1000 [00:04<00:21, 37.95it/s]Measuring inference for batch_size=512:  18%|█▊        | 184/1000 [00:04<00:21, 37.96it/s]Measuring inference for batch_size=512:  19%|█▉        | 188/1000 [00:04<00:21, 37.96it/s]Measuring inference for batch_size=512:  19%|█▉        | 192/1000 [00:05<00:21, 37.96it/s]Measuring inference for batch_size=512:  20%|█▉        | 196/1000 [00:05<00:21, 37.96it/s]Measuring inference for batch_size=512:  20%|██        | 200/1000 [00:05<00:21, 37.95it/s]Measuring inference for batch_size=512:  20%|██        | 204/1000 [00:05<00:20, 37.95it/s]Measuring inference for batch_size=512:  21%|██        | 208/1000 [00:05<00:20, 37.96it/s]Measuring inference for batch_size=512:  21%|██        | 212/1000 [00:05<00:20, 37.95it/s]Measuring inference for batch_size=512:  22%|██▏       | 216/1000 [00:05<00:20, 37.95it/s]Measuring inference for batch_size=512:  22%|██▏       | 220/1000 [00:05<00:20, 37.95it/s]Measuring inference for batch_size=512:  22%|██▏       | 224/1000 [00:05<00:20, 37.95it/s]Measuring inference for batch_size=512:  23%|██▎       | 228/1000 [00:06<00:20, 37.94it/s]Measuring inference for batch_size=512:  23%|██▎       | 232/1000 [00:06<00:20, 37.95it/s]Measuring inference for batch_size=512:  24%|██▎       | 236/1000 [00:06<00:20, 37.95it/s]Measuring inference for batch_size=512:  24%|██▍       | 240/1000 [00:06<00:20, 37.95it/s]Measuring inference for batch_size=512:  24%|██▍       | 244/1000 [00:06<00:19, 37.95it/s]Measuring inference for batch_size=512:  25%|██▍       | 248/1000 [00:06<00:19, 37.96it/s]Measuring inference for batch_size=512:  25%|██▌       | 252/1000 [00:06<00:19, 37.96it/s]Measuring inference for batch_size=512:  26%|██▌       | 256/1000 [00:06<00:19, 37.96it/s]Measuring inference for batch_size=512:  26%|██▌       | 260/1000 [00:06<00:19, 37.97it/s]Measuring inference for batch_size=512:  26%|██▋       | 264/1000 [00:06<00:19, 37.97it/s]Measuring inference for batch_size=512:  27%|██▋       | 268/1000 [00:07<00:19, 37.97it/s]Measuring inference for batch_size=512:  27%|██▋       | 272/1000 [00:07<00:19, 37.98it/s]Measuring inference for batch_size=512:  28%|██▊       | 276/1000 [00:07<00:19, 37.97it/s]Measuring inference for batch_size=512:  28%|██▊       | 280/1000 [00:07<00:18, 37.95it/s]Measuring inference for batch_size=512:  28%|██▊       | 284/1000 [00:07<00:18, 37.95it/s]Measuring inference for batch_size=512:  29%|██▉       | 288/1000 [00:07<00:18, 37.94it/s]Measuring inference for batch_size=512:  29%|██▉       | 292/1000 [00:07<00:18, 37.95it/s]Measuring inference for batch_size=512:  30%|██▉       | 296/1000 [00:07<00:18, 37.95it/s]Measuring inference for batch_size=512:  30%|███       | 300/1000 [00:07<00:18, 37.95it/s]Measuring inference for batch_size=512:  30%|███       | 304/1000 [00:08<00:18, 37.94it/s]Measuring inference for batch_size=512:  31%|███       | 308/1000 [00:08<00:18, 37.94it/s]Measuring inference for batch_size=512:  31%|███       | 312/1000 [00:08<00:18, 37.94it/s]Measuring inference for batch_size=512:  32%|███▏      | 316/1000 [00:08<00:18, 37.94it/s]Measuring inference for batch_size=512:  32%|███▏      | 320/1000 [00:08<00:17, 37.94it/s]Measuring inference for batch_size=512:  32%|███▏      | 324/1000 [00:08<00:17, 37.94it/s]Measuring inference for batch_size=512:  33%|███▎      | 328/1000 [00:08<00:17, 37.93it/s]Measuring inference for batch_size=512:  33%|███▎      | 332/1000 [00:08<00:17, 37.93it/s]Measuring inference for batch_size=512:  34%|███▎      | 336/1000 [00:08<00:17, 37.93it/s]Measuring inference for batch_size=512:  34%|███▍      | 340/1000 [00:08<00:17, 37.94it/s]Measuring inference for batch_size=512:  34%|███▍      | 344/1000 [00:09<00:17, 37.93it/s]Measuring inference for batch_size=512:  35%|███▍      | 348/1000 [00:09<00:17, 37.94it/s]Measuring inference for batch_size=512:  35%|███▌      | 352/1000 [00:09<00:17, 37.93it/s]Measuring inference for batch_size=512:  36%|███▌      | 356/1000 [00:09<00:16, 37.93it/s]Measuring inference for batch_size=512:  36%|███▌      | 360/1000 [00:09<00:16, 37.93it/s]Measuring inference for batch_size=512:  36%|███▋      | 364/1000 [00:09<00:16, 37.91it/s]Measuring inference for batch_size=512:  37%|███▋      | 368/1000 [00:09<00:16, 37.91it/s]Measuring inference for batch_size=512:  37%|███▋      | 372/1000 [00:09<00:16, 37.92it/s]Measuring inference for batch_size=512:  38%|███▊      | 376/1000 [00:09<00:16, 37.93it/s]Measuring inference for batch_size=512:  38%|███▊      | 380/1000 [00:10<00:16, 37.93it/s]Measuring inference for batch_size=512:  38%|███▊      | 384/1000 [00:10<00:16, 37.94it/s]Measuring inference for batch_size=512:  39%|███▉      | 388/1000 [00:10<00:16, 37.93it/s]Measuring inference for batch_size=512:  39%|███▉      | 392/1000 [00:10<00:16, 37.93it/s]Measuring inference for batch_size=512:  40%|███▉      | 396/1000 [00:10<00:15, 37.93it/s]Measuring inference for batch_size=512:  40%|████      | 400/1000 [00:10<00:15, 37.94it/s]Measuring inference for batch_size=512:  40%|████      | 404/1000 [00:10<00:15, 37.94it/s]Measuring inference for batch_size=512:  41%|████      | 408/1000 [00:10<00:15, 37.94it/s]Measuring inference for batch_size=512:  41%|████      | 412/1000 [00:10<00:15, 37.95it/s]Measuring inference for batch_size=512:  42%|████▏     | 416/1000 [00:10<00:15, 37.95it/s]Measuring inference for batch_size=512:  42%|████▏     | 420/1000 [00:11<00:15, 37.94it/s]Measuring inference for batch_size=512:  42%|████▏     | 424/1000 [00:11<00:15, 37.94it/s]Measuring inference for batch_size=512:  43%|████▎     | 428/1000 [00:11<00:15, 37.93it/s]Measuring inference for batch_size=512:  43%|████▎     | 432/1000 [00:11<00:14, 37.94it/s]Measuring inference for batch_size=512:  44%|████▎     | 436/1000 [00:11<00:14, 37.94it/s]Measuring inference for batch_size=512:  44%|████▍     | 440/1000 [00:11<00:14, 37.94it/s]Measuring inference for batch_size=512:  44%|████▍     | 444/1000 [00:11<00:14, 37.94it/s]Measuring inference for batch_size=512:  45%|████▍     | 448/1000 [00:11<00:14, 37.92it/s]Measuring inference for batch_size=512:  45%|████▌     | 452/1000 [00:11<00:14, 37.92it/s]Measuring inference for batch_size=512:  46%|████▌     | 456/1000 [00:12<00:14, 37.92it/s]Measuring inference for batch_size=512:  46%|████▌     | 460/1000 [00:12<00:14, 37.91it/s]Measuring inference for batch_size=512:  46%|████▋     | 464/1000 [00:12<00:14, 37.91it/s]Measuring inference for batch_size=512:  47%|████▋     | 468/1000 [00:12<00:14, 37.92it/s]Measuring inference for batch_size=512:  47%|████▋     | 472/1000 [00:12<00:13, 37.92it/s]Measuring inference for batch_size=512:  48%|████▊     | 476/1000 [00:12<00:13, 37.93it/s]Measuring inference for batch_size=512:  48%|████▊     | 480/1000 [00:12<00:13, 37.91it/s]Measuring inference for batch_size=512:  48%|████▊     | 484/1000 [00:12<00:13, 37.91it/s]Measuring inference for batch_size=512:  49%|████▉     | 488/1000 [00:12<00:13, 37.92it/s]Measuring inference for batch_size=512:  49%|████▉     | 492/1000 [00:12<00:13, 37.92it/s]Measuring inference for batch_size=512:  50%|████▉     | 496/1000 [00:13<00:13, 37.93it/s]Measuring inference for batch_size=512:  50%|█████     | 500/1000 [00:13<00:13, 37.92it/s]Measuring inference for batch_size=512:  50%|█████     | 504/1000 [00:13<00:13, 37.91it/s]Measuring inference for batch_size=512:  51%|█████     | 508/1000 [00:13<00:12, 37.90it/s]Measuring inference for batch_size=512:  51%|█████     | 512/1000 [00:13<00:12, 37.90it/s]Measuring inference for batch_size=512:  52%|█████▏    | 516/1000 [00:13<00:12, 37.92it/s]Measuring inference for batch_size=512:  52%|█████▏    | 520/1000 [00:13<00:12, 37.92it/s]Measuring inference for batch_size=512:  52%|█████▏    | 524/1000 [00:13<00:12, 37.92it/s]Measuring inference for batch_size=512:  53%|█████▎    | 528/1000 [00:13<00:12, 37.94it/s]Measuring inference for batch_size=512:  53%|█████▎    | 532/1000 [00:14<00:12, 37.94it/s]Measuring inference for batch_size=512:  54%|█████▎    | 536/1000 [00:14<00:12, 37.95it/s]Measuring inference for batch_size=512:  54%|█████▍    | 540/1000 [00:14<00:12, 37.95it/s]Measuring inference for batch_size=512:  54%|█████▍    | 544/1000 [00:14<00:12, 37.96it/s]Measuring inference for batch_size=512:  55%|█████▍    | 548/1000 [00:14<00:11, 37.95it/s]Measuring inference for batch_size=512:  55%|█████▌    | 552/1000 [00:14<00:11, 37.95it/s]Measuring inference for batch_size=512:  56%|█████▌    | 556/1000 [00:14<00:11, 37.95it/s]Measuring inference for batch_size=512:  56%|█████▌    | 560/1000 [00:14<00:11, 37.95it/s]Measuring inference for batch_size=512:  56%|█████▋    | 564/1000 [00:14<00:11, 37.96it/s]Measuring inference for batch_size=512:  57%|█████▋    | 568/1000 [00:14<00:11, 37.95it/s]Measuring inference for batch_size=512:  57%|█████▋    | 572/1000 [00:15<00:11, 37.94it/s]Measuring inference for batch_size=512:  58%|█████▊    | 576/1000 [00:15<00:11, 37.93it/s]Measuring inference for batch_size=512:  58%|█████▊    | 580/1000 [00:15<00:11, 37.93it/s]Measuring inference for batch_size=512:  58%|█████▊    | 584/1000 [00:15<00:10, 37.94it/s]Measuring inference for batch_size=512:  59%|█████▉    | 588/1000 [00:15<00:10, 37.95it/s]Measuring inference for batch_size=512:  59%|█████▉    | 592/1000 [00:15<00:10, 37.94it/s]Measuring inference for batch_size=512:  60%|█████▉    | 596/1000 [00:15<00:10, 37.94it/s]Measuring inference for batch_size=512:  60%|██████    | 600/1000 [00:15<00:10, 37.95it/s]Measuring inference for batch_size=512:  60%|██████    | 604/1000 [00:15<00:10, 37.95it/s]Measuring inference for batch_size=512:  61%|██████    | 608/1000 [00:16<00:10, 37.93it/s]Measuring inference for batch_size=512:  61%|██████    | 612/1000 [00:16<00:10, 37.93it/s]Measuring inference for batch_size=512:  62%|██████▏   | 616/1000 [00:16<00:10, 37.93it/s]Measuring inference for batch_size=512:  62%|██████▏   | 620/1000 [00:16<00:10, 37.93it/s]Measuring inference for batch_size=512:  62%|██████▏   | 624/1000 [00:16<00:09, 37.95it/s]Measuring inference for batch_size=512:  63%|██████▎   | 628/1000 [00:16<00:09, 37.94it/s]Measuring inference for batch_size=512:  63%|██████▎   | 632/1000 [00:16<00:09, 37.94it/s]Measuring inference for batch_size=512:  64%|██████▎   | 636/1000 [00:16<00:09, 37.93it/s]Measuring inference for batch_size=512:  64%|██████▍   | 640/1000 [00:16<00:09, 37.94it/s]Measuring inference for batch_size=512:  64%|██████▍   | 644/1000 [00:16<00:09, 37.93it/s]Measuring inference for batch_size=512:  65%|██████▍   | 648/1000 [00:17<00:09, 37.93it/s]Measuring inference for batch_size=512:  65%|██████▌   | 652/1000 [00:17<00:09, 37.94it/s]Measuring inference for batch_size=512:  66%|██████▌   | 656/1000 [00:17<00:09, 37.95it/s]Measuring inference for batch_size=512:  66%|██████▌   | 660/1000 [00:17<00:08, 37.96it/s]Measuring inference for batch_size=512:  66%|██████▋   | 664/1000 [00:17<00:08, 37.96it/s]Measuring inference for batch_size=512:  67%|██████▋   | 668/1000 [00:17<00:08, 37.95it/s]Measuring inference for batch_size=512:  67%|██████▋   | 672/1000 [00:17<00:08, 37.94it/s]Measuring inference for batch_size=512:  68%|██████▊   | 676/1000 [00:17<00:08, 37.94it/s]Measuring inference for batch_size=512:  68%|██████▊   | 680/1000 [00:17<00:08, 37.94it/s]Measuring inference for batch_size=512:  68%|██████▊   | 684/1000 [00:18<00:08, 37.93it/s]Measuring inference for batch_size=512:  69%|██████▉   | 688/1000 [00:18<00:08, 37.93it/s]Measuring inference for batch_size=512:  69%|██████▉   | 692/1000 [00:18<00:08, 37.91it/s]Measuring inference for batch_size=512:  70%|██████▉   | 696/1000 [00:18<00:08, 37.90it/s]Measuring inference for batch_size=512:  70%|███████   | 700/1000 [00:18<00:07, 37.91it/s]Measuring inference for batch_size=512:  70%|███████   | 704/1000 [00:18<00:07, 37.91it/s]Measuring inference for batch_size=512:  71%|███████   | 708/1000 [00:18<00:07, 37.90it/s]Measuring inference for batch_size=512:  71%|███████   | 712/1000 [00:18<00:07, 37.91it/s]Measuring inference for batch_size=512:  72%|███████▏  | 716/1000 [00:18<00:07, 37.92it/s]Measuring inference for batch_size=512:  72%|███████▏  | 720/1000 [00:18<00:07, 37.93it/s]Measuring inference for batch_size=512:  72%|███████▏  | 724/1000 [00:19<00:07, 37.94it/s]Measuring inference for batch_size=512:  73%|███████▎  | 728/1000 [00:19<00:07, 37.94it/s]Measuring inference for batch_size=512:  73%|███████▎  | 732/1000 [00:19<00:07, 37.94it/s]Measuring inference for batch_size=512:  74%|███████▎  | 736/1000 [00:19<00:06, 37.94it/s]Measuring inference for batch_size=512:  74%|███████▍  | 740/1000 [00:19<00:06, 37.95it/s]Measuring inference for batch_size=512:  74%|███████▍  | 744/1000 [00:19<00:06, 37.96it/s]Measuring inference for batch_size=512:  75%|███████▍  | 748/1000 [00:19<00:06, 37.96it/s]Measuring inference for batch_size=512:  75%|███████▌  | 752/1000 [00:19<00:06, 37.96it/s]Measuring inference for batch_size=512:  76%|███████▌  | 756/1000 [00:19<00:06, 37.94it/s]Measuring inference for batch_size=512:  76%|███████▌  | 760/1000 [00:20<00:06, 37.93it/s]Measuring inference for batch_size=512:  76%|███████▋  | 764/1000 [00:20<00:06, 37.96it/s]Measuring inference for batch_size=512:  77%|███████▋  | 768/1000 [00:20<00:06, 37.97it/s]Measuring inference for batch_size=512:  77%|███████▋  | 772/1000 [00:20<00:06, 37.97it/s]Measuring inference for batch_size=512:  78%|███████▊  | 776/1000 [00:20<00:05, 37.96it/s]Measuring inference for batch_size=512:  78%|███████▊  | 780/1000 [00:20<00:05, 37.95it/s]Measuring inference for batch_size=512:  78%|███████▊  | 784/1000 [00:20<00:05, 37.94it/s]Measuring inference for batch_size=512:  79%|███████▉  | 788/1000 [00:20<00:05, 37.95it/s]Measuring inference for batch_size=512:  79%|███████▉  | 792/1000 [00:20<00:05, 37.94it/s]Measuring inference for batch_size=512:  80%|███████▉  | 796/1000 [00:20<00:05, 37.94it/s]Measuring inference for batch_size=512:  80%|████████  | 800/1000 [00:21<00:05, 37.94it/s]Measuring inference for batch_size=512:  80%|████████  | 804/1000 [00:21<00:05, 37.94it/s]Measuring inference for batch_size=512:  81%|████████  | 808/1000 [00:21<00:05, 37.94it/s]Measuring inference for batch_size=512:  81%|████████  | 812/1000 [00:21<00:04, 37.94it/s]Measuring inference for batch_size=512:  82%|████████▏ | 816/1000 [00:21<00:04, 37.96it/s]Measuring inference for batch_size=512:  82%|████████▏ | 820/1000 [00:21<00:04, 37.96it/s]Measuring inference for batch_size=512:  82%|████████▏ | 824/1000 [00:21<00:04, 37.95it/s]Measuring inference for batch_size=512:  83%|████████▎ | 828/1000 [00:21<00:04, 37.97it/s]Measuring inference for batch_size=512:  83%|████████▎ | 832/1000 [00:21<00:04, 37.96it/s]Measuring inference for batch_size=512:  84%|████████▎ | 836/1000 [00:22<00:04, 37.95it/s]Measuring inference for batch_size=512:  84%|████████▍ | 840/1000 [00:22<00:04, 37.95it/s]Measuring inference for batch_size=512:  84%|████████▍ | 844/1000 [00:22<00:04, 37.95it/s]Measuring inference for batch_size=512:  85%|████████▍ | 848/1000 [00:22<00:04, 37.95it/s]Measuring inference for batch_size=512:  85%|████████▌ | 852/1000 [00:22<00:03, 37.95it/s]Measuring inference for batch_size=512:  86%|████████▌ | 856/1000 [00:22<00:03, 37.96it/s]Measuring inference for batch_size=512:  86%|████████▌ | 860/1000 [00:22<00:03, 37.96it/s]Measuring inference for batch_size=512:  86%|████████▋ | 864/1000 [00:22<00:03, 37.96it/s]Measuring inference for batch_size=512:  87%|████████▋ | 868/1000 [00:22<00:03, 37.94it/s]Measuring inference for batch_size=512:  87%|████████▋ | 872/1000 [00:22<00:03, 37.94it/s]Measuring inference for batch_size=512:  88%|████████▊ | 876/1000 [00:23<00:03, 37.94it/s]Measuring inference for batch_size=512:  88%|████████▊ | 880/1000 [00:23<00:03, 37.92it/s]Measuring inference for batch_size=512:  88%|████████▊ | 884/1000 [00:23<00:03, 37.92it/s]Measuring inference for batch_size=512:  89%|████████▉ | 888/1000 [00:23<00:02, 37.94it/s]Measuring inference for batch_size=512:  89%|████████▉ | 892/1000 [00:23<00:02, 37.95it/s]Measuring inference for batch_size=512:  90%|████████▉ | 896/1000 [00:23<00:02, 37.96it/s]Measuring inference for batch_size=512:  90%|█████████ | 900/1000 [00:23<00:02, 37.97it/s]Measuring inference for batch_size=512:  90%|█████████ | 904/1000 [00:23<00:02, 37.96it/s]Measuring inference for batch_size=512:  91%|█████████ | 908/1000 [00:23<00:02, 37.97it/s]Measuring inference for batch_size=512:  91%|█████████ | 912/1000 [00:24<00:02, 37.95it/s]Measuring inference for batch_size=512:  92%|█████████▏| 916/1000 [00:24<00:02, 37.95it/s]Measuring inference for batch_size=512:  92%|█████████▏| 920/1000 [00:24<00:02, 37.94it/s]Measuring inference for batch_size=512:  92%|█████████▏| 924/1000 [00:24<00:02, 37.94it/s]Measuring inference for batch_size=512:  93%|█████████▎| 928/1000 [00:24<00:01, 37.94it/s]Measuring inference for batch_size=512:  93%|█████████▎| 932/1000 [00:24<00:01, 37.95it/s]Measuring inference for batch_size=512:  94%|█████████▎| 936/1000 [00:24<00:01, 37.94it/s]Measuring inference for batch_size=512:  94%|█████████▍| 940/1000 [00:24<00:01, 37.93it/s]Measuring inference for batch_size=512:  94%|█████████▍| 944/1000 [00:24<00:01, 37.94it/s]Measuring inference for batch_size=512:  95%|█████████▍| 948/1000 [00:24<00:01, 37.94it/s]Measuring inference for batch_size=512:  95%|█████████▌| 952/1000 [00:25<00:01, 37.94it/s]Measuring inference for batch_size=512:  96%|█████████▌| 956/1000 [00:25<00:01, 37.95it/s]Measuring inference for batch_size=512:  96%|█████████▌| 960/1000 [00:25<00:01, 37.96it/s]Measuring inference for batch_size=512:  96%|█████████▋| 964/1000 [00:25<00:00, 37.96it/s]Measuring inference for batch_size=512:  97%|█████████▋| 968/1000 [00:25<00:00, 37.97it/s]Measuring inference for batch_size=512:  97%|█████████▋| 972/1000 [00:25<00:00, 37.95it/s]Measuring inference for batch_size=512:  98%|█████████▊| 976/1000 [00:25<00:00, 37.95it/s]Measuring inference for batch_size=512:  98%|█████████▊| 980/1000 [00:25<00:00, 37.94it/s]Measuring inference for batch_size=512:  98%|█████████▊| 984/1000 [00:25<00:00, 37.95it/s]Measuring inference for batch_size=512:  99%|█████████▉| 988/1000 [00:26<00:00, 37.93it/s]Measuring inference for batch_size=512:  99%|█████████▉| 992/1000 [00:26<00:00, 37.93it/s]Measuring inference for batch_size=512: 100%|█████████▉| 996/1000 [00:26<00:00, 37.93it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.93it/s]Measuring inference for batch_size=512: 100%|██████████| 1000/1000 [00:26<00:00, 37.94it/s]
Unable to measure energy consumption. Device must be a NVIDIA Jetson.
device: cuda
flops: 12310546408
machine_info:
  cpu:
    architecture: x86_64
    cores:
      physical: 12
      total: 24
    frequency: 3.80 GHz
    model: AMD Ryzen 9 3900X 12-Core Processor
  gpus:
  - memory: 12288.0 MB
    name: NVIDIA GeForce RTX 3060
  memory:
    available: 29.89 GB
    total: 31.28 GB
    used: 1010.49 MB
  system:
    node: fp
    release: 6.5.0-9-generic
    system: Linux
memory:
  batch_size_1:
    max_inference: 606.61 MB
    max_inference_bytes: 636080640
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
  batch_size_512:
    max_inference: 606.52 MB
    max_inference_bytes: 635978240
    post_inference: 471.91 MB
    post_inference_bytes: 494838272
    pre_inference: 471.91 MB
    pre_inference_bytes: 494838272
params: 118515272
timing:
  batch_size_1:
    cpu_to_gpu:
      human_readable:
        batch_latency: 108.834 us +/- 6.007 us [105.143 us, 226.259 us]
        batches_per_second: 9.21 K +/- 394.41 [4.42 K, 9.51 K]
      metrics:
        batches_per_second_max: 9510.893424036281
        batches_per_second_mean: 9209.167067053091
        batches_per_second_min: 4419.709167544784
        batches_per_second_std: 394.405548347664
        seconds_per_batch_max: 0.0002262592315673828
        seconds_per_batch_mean: 0.00010883426666259765
        seconds_per_batch_min: 0.00010514259338378906
        seconds_per_batch_std: 6.0074941339671315e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 24.501 us +/- 0.692 us [23.603 us, 32.187 us]
        batches_per_second: 40.84 K +/- 996.61 [31.07 K, 42.37 K]
      metrics:
        batches_per_second_max: 42366.707070707074
        batches_per_second_mean: 40842.91733897519
        batches_per_second_min: 31068.91851851852
        batches_per_second_std: 996.6128941126383
        seconds_per_batch_max: 3.218650817871094e-05
        seconds_per_batch_mean: 2.4500846862792968e-05
        seconds_per_batch_min: 2.3603439331054688e-05
        seconds_per_batch_std: 6.915907797926259e-07
    on_device_inference:
      human_readable:
        batch_latency: -25924525.831 us +/- 55.611 ms [-27151008.606 us, -25812000.275
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.036831044272167344
        batches_per_second_mean: -0.03857368514056093
        batches_per_second_min: -0.03874167012859455
        batches_per_second_std: 8.088278629727413e-05
        seconds_per_batch_max: -25.812000274658203
        seconds_per_batch_mean: -25.924525831222535
        seconds_per_batch_min: -27.15100860595703
        seconds_per_batch_std: 0.055610842568869015
    total:
      human_readable:
        batch_latency: 26.072 ms +/- 59.745 us [25.956 ms, 27.433 ms]
        batches_per_second: 38.36 +/- 0.09 [36.45, 38.53]
      metrics:
        batches_per_second_max: 38.52686305308312
        batches_per_second_mean: 38.3552310901737
        batches_per_second_min: 36.45287282398032
        batches_per_second_std: 0.08558990812653663
        seconds_per_batch_max: 0.027432680130004883
        seconds_per_batch_mean: 0.026072196245193482
        seconds_per_batch_min: 0.025955915451049805
        seconds_per_batch_std: 5.97450019562261e-05
  batch_size_512:
    cpu_to_gpu:
      human_readable:
        batch_latency: 148.809 us +/- 6.661 us [144.482 us, 292.063 us]
        batches_per_second: 6.73 K +/- 231.58 [3.42 K, 6.92 K]
      metrics:
        batches_per_second_max: 6921.293729372937
        batches_per_second_mean: 6729.9500052841195
        batches_per_second_min: 3423.9216326530614
        batches_per_second_std: 231.58059130963468
        seconds_per_batch_max: 0.00029206275939941406
        seconds_per_batch_mean: 0.00014880943298339845
        seconds_per_batch_min: 0.00014448165893554688
        seconds_per_batch_std: 6.661360896769957e-06
    gpu_to_cpu:
      human_readable:
        batch_latency: 25.042 us +/- 0.683 us [23.842 us, 33.140 us]
        batches_per_second: 39.96 K +/- 964.15 [30.17 K, 41.94 K]
      metrics:
        batches_per_second_max: 41943.04
        batches_per_second_mean: 39958.99257824265
        batches_per_second_min: 30174.84892086331
        batches_per_second_std: 964.1497920097561
        seconds_per_batch_max: 3.314018249511719e-05
        seconds_per_batch_mean: 2.5042057037353517e-05
        seconds_per_batch_min: 2.384185791015625e-05
        seconds_per_batch_std: 6.834277615124493e-07
    on_device_inference:
      human_readable:
        batch_latency: -26150276.751 us +/- 51.009 ms [-27270847.321 us, -26051103.592
          us]
        batches_per_second: -0.04 +/- 0.00 [-0.04, -0.04]
      metrics:
        batches_per_second_max: -0.03666919433215427
        batches_per_second_mean: -0.038240655684184645
        batches_per_second_min: -0.038386089728275466
        batches_per_second_std: 7.31255427600486e-05
        seconds_per_batch_max: -26.051103591918945
        seconds_per_batch_mean: -26.150276750564576
        seconds_per_batch_min: -27.27084732055664
        seconds_per_batch_std: 0.05100922962526788
    total:
      human_readable:
        batch_latency: 26.338 ms +/- 55.369 us [26.236 ms, 27.615 ms]
        batches_per_second: 37.97 +/- 0.08 [36.21, 38.12]
      metrics:
        batches_per_second_max: 38.1158295544388
        batches_per_second_mean: 37.967494124853786
        batches_per_second_min: 36.2117986307165
        batches_per_second_std: 0.07786846147624917
        seconds_per_batch_max: 0.02761530876159668
        seconds_per_batch_mean: 0.026338433265686034
        seconds_per_batch_min: 0.02623581886291504
        seconds_per_batch_std: 5.536860998149143e-05


